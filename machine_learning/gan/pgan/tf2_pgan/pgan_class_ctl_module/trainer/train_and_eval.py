import tensorflow as tf


class TrainAndEval(object):
    """Class that contains methods used for both training and evaluation.
    """
    def __init__(self):
        """Instantiate instance of `TrainAndEval`.
        """
        pass

    def generator_loss_phase(self, mode, training):
        """Gets fake logits and loss for generator.

        Args:
            mode: str, what mode currently in: TRAIN or EVAL.
            training: bool, if model should be training.

        Returns:
            Fake images tensor of shape
                [batch_size, iamge_height, image_width, image_depth], fake
                logits tensor of shape [batch_size, 1], and generator loss
                tensor of shape [].
        """
        block_idx = (self.growth_idx + 1) // 2
        batch_size = (
            self.params["train_batch_size_schedule"][block_idx]
            if mode == "TRAIN"
            else self.params["eval_batch_size"]
        )

        # Create random noise latent vector for each batch example.
        Z = tf.random.normal(
            shape=[batch_size, self.params["generator_latent_size"]],
            mean=0.0,
            stddev=1.0,
            dtype=tf.float32
        )

        # Get generated image from generator network from gaussian noise.
        fake_images = (
            self.network_objects["generator"].models[self.growth_idx](
                inputs=Z, training=training
            )
        )

        if self.params["write_summaries"] and mode == "TRAIN":
            # Add summaries for TensorBoard.
            with self.summary_file_writer.as_default():
                with tf.summary.record_if(
                    condition=tf.equal(
                        x=tf.math.floormod(
                            x=self.global_step,
                            y=self.params["save_summary_steps"]
                        ),
                        y=0
                    )
                ):
                    tf.summary.image(
                        name="fake_images",
                        data=fake_images,
                        step=self.global_step,
                        max_outputs=5
                    )
                    self.summary_file_writer.flush()

        # Get fake logits from discriminator using generator's output image.
        fake_logits = (
            self.network_objects["discriminator"].models[self.growth_idx](
                inputs=fake_images, training=training
            )
        )

        # Get generator total loss.
        generator_total_loss = (
            self.network_objects["generator"].get_generator_loss(
                global_batch_size=(
                    self.global_batch_size_schedule[self.block_idx]
                ),
                fake_logits=fake_logits,
                global_step=self.global_step,
                summary_file_writer=self.summary_file_writer,
                growth_idx=self.growth_idx
            )
        )

        return fake_images, fake_logits, generator_total_loss

    def discriminator_loss_phase(
        self, fake_images, real_images, fake_logits, training
    ):
        """Gets real logits and loss for discriminator.

        Args:
            fake_images: tensor, images generated by the generator from random
                noise of shape [batch_size, image_size, image_size, 3].
            real_images: tensor, real images from input of shape
                [batch_size, image_height, image_width, 3].
            fake_logits: tensor, output of discriminator using fake images
                with shape [batch_size, 1].
            training: bool, if in training mode.

        Returns:
            Real logits of shape [batch_size, 1] and discriminator loss of
                shape [].
        """
        # Get real logits from discriminator using real image.
        real_logits = (
            self.network_objects["discriminator"].models[self.growth_idx](
                inputs=real_images, training=training
            )
        )

        # Get discriminator total loss.
        discriminator_total_loss = (
            self.network_objects["discriminator"].get_discriminator_loss(
                global_batch_size=(
                    self.global_batch_size_schedule[self.block_idx]
                ),
                fake_images=fake_images,
                real_images=real_images,
                fake_logits=fake_logits,
                real_logits=real_logits,
                global_step=self.global_step,
                summary_file_writer=self.summary_file_writer,
                growth_idx=self.growth_idx
            )
        )

        return real_logits, discriminator_total_loss
