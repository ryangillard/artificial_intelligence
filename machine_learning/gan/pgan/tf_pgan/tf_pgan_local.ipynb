{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2-dlenv_tfe\n",
      "1.18.1\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and modules\n",
    "import math\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_generator_discriminator_conv_layer_properties(\n",
    "        conv_num_filters, conv_kernel_sizes, conv_strides, depth):\n",
    "    \"\"\"Calculates generator and discriminator conv layer properties.\n",
    "\n",
    "    Args:\n",
    "        num_filters: list, nested list of ints of the number of filters\n",
    "            for each conv layer.\n",
    "        kernel_sizes: list, nested list of ints of the kernel sizes for\n",
    "            each conv layer.\n",
    "        strides: list, nested list of ints of the strides for each conv\n",
    "            layer.\n",
    "        depth: int, depth dimension of images.\n",
    "\n",
    "    Returns:\n",
    "        Nested lists of conv layer properties for both generator and\n",
    "            discriminator.\n",
    "    \"\"\"\n",
    "    def make_generator(num_filters, kernel_sizes, strides, depth):\n",
    "        \"\"\"Calculates generator conv layer properties.\n",
    "\n",
    "        Args:\n",
    "            num_filters: list, nested list of ints of the number of filters\n",
    "                for each conv layer.\n",
    "            kernel_sizes: list, nested list of ints of the kernel sizes for\n",
    "                each conv layer.\n",
    "            strides: list, nested list of ints of the strides for each conv\n",
    "                layer.\n",
    "            depth: int, depth dimension of images.\n",
    "\n",
    "        Returns:\n",
    "            Nested list of conv layer properties for generator.\n",
    "        \"\"\"\n",
    "        # Get the number of growths.\n",
    "        num_growths = len(num_filters) - 1\n",
    "\n",
    "        # Make base block.\n",
    "        in_out = num_filters[0]\n",
    "        base = [\n",
    "            [kernel_sizes[0][i]] * 2 + in_out + [strides[0][i]] * 2\n",
    "            for i in range(len(num_filters[0]))\n",
    "        ]\n",
    "        blocks = [base]\n",
    "\n",
    "        # Add growth blocks.\n",
    "        for i in range(1, num_growths + 1):\n",
    "            in_out = [[blocks[i - 1][-1][-3], num_filters[i][0]]]\n",
    "            block = [[kernel_sizes[i][0]] * 2 + in_out[0] + [strides[i][0]] * 2]\n",
    "            for j in range(1, len(num_filters[i])):\n",
    "                in_out.append([block[-1][-3], num_filters[i][j]])\n",
    "                block.append(\n",
    "                    [kernel_sizes[i][j]] * 2 + in_out[j] + [strides[i][j]] * 2\n",
    "                )\n",
    "            blocks.append(block)\n",
    "\n",
    "        # Add toRGB conv.\n",
    "        blocks[-1].append([1, 1, blocks[-1][-1][-3], depth] + [1] * 2)\n",
    "\n",
    "        return blocks\n",
    "\n",
    "    def make_discriminator(generator):\n",
    "        \"\"\"Calculates discriminator conv layer properties.\n",
    "\n",
    "        Args:\n",
    "            generator: list, nested list of conv layer properties for\n",
    "                generator.\n",
    "\n",
    "        Returns:\n",
    "            Nested list of conv layer properties for discriminator.\n",
    "        \"\"\"\n",
    "        # Reverse generator.\n",
    "        discriminator = generator[::-1]\n",
    "\n",
    "        # Reverse input and output shapes.\n",
    "        discriminator = [\n",
    "            [\n",
    "                conv[0:2] + conv[2:4][::-1] + conv[-2:]\n",
    "                for conv in block[::-1]\n",
    "            ]\n",
    "            for block in discriminator\n",
    "        ]\n",
    "\n",
    "        return discriminator\n",
    "\n",
    "    # Calculate conv layer properties for generator using args.\n",
    "    generator = make_generator(\n",
    "        conv_num_filters, conv_kernel_sizes, conv_strides, depth\n",
    "    )\n",
    "\n",
    "    # Calculate conv layer properties for discriminator using generator\n",
    "    # properties.\n",
    "    discriminator = make_discriminator(generator)\n",
    "\n",
    "    return generator, discriminator\n",
    "\n",
    "\n",
    "def split_up_generator_conv_layer_properties(\n",
    "        generator, num_filters, strides, depth):\n",
    "    \"\"\"Splits up generator conv layer properties into lists.\n",
    "\n",
    "    Args:\n",
    "        generator: list, nested list of conv layer properties for\n",
    "            generator.\n",
    "        num_filters: list, nested list of ints of the number of filters\n",
    "            for each conv layer.\n",
    "        strides: list, nested list of ints of the strides for each conv\n",
    "            layer.\n",
    "        depth: int, depth dimension of images.\n",
    "\n",
    "    Returns:\n",
    "        Nested lists of conv layer properties for generator.\n",
    "    \"\"\"\n",
    "    generator_base_conv_blocks = [generator[0][0:len(num_filters[0])]]\n",
    "\n",
    "    generator_growth_conv_blocks = []\n",
    "    if len(num_filters) > 1:\n",
    "        generator_growth_conv_blocks = generator[1:-1] + [generator[-1][:-1]]\n",
    "\n",
    "    generator_to_rgb_layers = [\n",
    "        [[1] * 2 + [num_filters[i][0]] + [depth] + [strides[i][0]] * 2]\n",
    "        for i in range(len(num_filters))\n",
    "    ]\n",
    "\n",
    "    return (generator_base_conv_blocks,\n",
    "            generator_growth_conv_blocks,\n",
    "            generator_to_rgb_layers)\n",
    "\n",
    "\n",
    "def split_up_discriminator_conv_layer_properties(\n",
    "        discriminator, num_filters, strides, depth):\n",
    "    \"\"\"Splits up discriminator conv layer properties into lists.\n",
    "\n",
    "    Args:\n",
    "        discriminator: list, nested list of conv layer properties for\n",
    "            discriminator.\n",
    "        num_filters: list, nested list of ints of the number of filters\n",
    "            for each conv layer.\n",
    "        strides: list, nested list of ints of the strides for each conv\n",
    "            layer.\n",
    "        depth: int, depth dimension of images.\n",
    "\n",
    "    Returns:\n",
    "        Nested lists of conv layer properties for discriminator.\n",
    "    \"\"\"\n",
    "    discriminator_from_rgb_layers = [\n",
    "        [[1] * 2 + [depth] + [num_filters[i][0]] + [strides[i][0]] * 2]\n",
    "        for i in range(len(num_filters))\n",
    "    ]\n",
    "\n",
    "    if len(num_filters) > 1:\n",
    "        discriminator_base_conv_blocks = [discriminator[-1]]\n",
    "    else:\n",
    "        discriminator_base_conv_blocks = [discriminator[-1][1:]]\n",
    "\n",
    "    discriminator_growth_conv_blocks = []\n",
    "    if len(num_filters) > 1:\n",
    "        discriminator_growth_conv_blocks = [discriminator[0][1:]] + discriminator[1:-1]\n",
    "        discriminator_growth_conv_blocks = discriminator_growth_conv_blocks[::-1]\n",
    "\n",
    "    return (discriminator_from_rgb_layers,\n",
    "            discriminator_base_conv_blocks,\n",
    "            discriminator_growth_conv_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_num_filters = [[512, 512], [512, 512], [512, 512], [512, 512], [256, 256]]\n",
      "conv_kernel_sizes = [[4, 3], [3, 3], [3, 3], [3, 3], [3, 3]]\n",
      "conv_strides = [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1]]\n"
     ]
    }
   ],
   "source": [
    "arguments = {}\n",
    "# File arguments.\n",
    "arguments[\"train_file_pattern\"] = \"data/train.tfrecord\"\n",
    "arguments[\"eval_file_pattern\"] = \"data/eval.tfrecord\"\n",
    "arguments[\"output_dir\"] = \"local_trained_model\"\n",
    "\n",
    "# Training parameters.\n",
    "arguments[\"train_batch_size\"] = 32\n",
    "arguments[\"train_steps\"] = 400\n",
    "\n",
    "# Eval parameters.\n",
    "arguments[\"eval_batch_size\"] = 32\n",
    "arguments[\"eval_steps\"] = 10\n",
    "arguments[\"start_delay_secs\"] = 600\n",
    "arguments[\"throttle_secs\"] = 600\n",
    "\n",
    "# Serving parameters.\n",
    "arguments[\"exports_to_keep\"] = 20\n",
    "arguments[\"predict_all_resolutions\"] = True\n",
    "\n",
    "# Image parameters.\n",
    "arguments[\"height\"] = 32\n",
    "arguments[\"width\"] = 32\n",
    "arguments[\"depth\"] = 3\n",
    "\n",
    "# Shared parameters.\n",
    "arguments[\"num_steps_until_growth\"] = 100\n",
    "\n",
    "# Full lists for full 1024x1024 network growth.\n",
    "full_conv_num_filters = [[512, 512], [512, 512], [512, 512], [512, 512], [256, 256], [128, 128], [64, 64], [32, 32], [16, 16]]\n",
    "full_conv_kernel_sizes = [[4, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]]\n",
    "full_conv_strides = [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]]\n",
    "\n",
    "# Set final image size as a multiple of 2, starting at 4.\n",
    "image_size = 64\n",
    "prop_list_len = max(\n",
    "    min(int(math.log(image_size, 2) - 1), len(full_conv_num_filters)), 1\n",
    ")\n",
    "\n",
    "# Get slices of lists.\n",
    "conv_num_filters = full_conv_num_filters[0:prop_list_len]\n",
    "print(\"conv_num_filters = {}\".format(conv_num_filters))\n",
    "conv_kernel_sizes = full_conv_kernel_sizes[0:prop_list_len]\n",
    "print(\"conv_kernel_sizes = {}\".format(conv_kernel_sizes))\n",
    "conv_strides = full_conv_strides[0:prop_list_len]\n",
    "print(\"conv_strides = {}\".format(conv_strides))\n",
    "\n",
    "arguments[\"conv_num_filters\"] = conv_num_filters\n",
    "arguments[\"conv_kernel_sizes\"] = conv_kernel_sizes\n",
    "arguments[\"conv_strides\"] = conv_strides\n",
    "\n",
    "# Truncate lists if over the 1024x1024 current limit.\n",
    "if len(arguments[\"conv_num_filters\"]) > 9:\n",
    "    arguments[\"conv_num_filters\"] = arguments[\"conv_num_filters\"][0:10]\n",
    "    arguments[\"conv_kernel_sizes\"] = arguments[\"conv_kernel_sizes\"][0:10]\n",
    "    arguments[\"conv_strides\"] = arguments[\"conv_strides\"][0:10]\n",
    "\n",
    "# Get conv layer properties for generator and discriminator.\n",
    "(generator,\n",
    " discriminator) = calc_generator_discriminator_conv_layer_properties(\n",
    "    arguments[\"conv_num_filters\"],\n",
    "    arguments[\"conv_kernel_sizes\"],\n",
    "    arguments[\"conv_strides\"],\n",
    "    arguments[\"depth\"]\n",
    ")\n",
    "\n",
    "# Split up generator properties into separate lists.\n",
    "(generator_base_conv_blocks,\n",
    " generator_growth_conv_blocks,\n",
    " generator_to_rgb_layers) = split_up_generator_conv_layer_properties(\n",
    "    generator,\n",
    "    arguments[\"conv_num_filters\"],\n",
    "    arguments[\"conv_strides\"],\n",
    "    arguments[\"depth\"]\n",
    ")\n",
    "arguments[\"generator_base_conv_blocks\"] = generator_base_conv_blocks\n",
    "arguments[\"generator_growth_conv_blocks\"] = generator_growth_conv_blocks\n",
    "arguments[\"generator_to_rgb_layers\"] = generator_to_rgb_layers\n",
    "\n",
    "# Split up discriminator properties into separate lists.\n",
    "(discriminator_from_rgb_layers,\n",
    " discriminator_base_conv_blocks,\n",
    " discriminator_growth_conv_blocks) = split_up_discriminator_conv_layer_properties(\n",
    "    discriminator,\n",
    "    arguments[\"conv_num_filters\"],\n",
    "    arguments[\"conv_strides\"],\n",
    "    arguments[\"depth\"]\n",
    ")\n",
    "arguments[\"discriminator_from_rgb_layers\"] = discriminator_from_rgb_layers\n",
    "arguments[\"discriminator_base_conv_blocks\"] = discriminator_base_conv_blocks\n",
    "arguments[\"discriminator_growth_conv_blocks\"] = discriminator_growth_conv_blocks\n",
    "\n",
    "# Generator parameters.\n",
    "arguments[\"latent_size\"] = 512\n",
    "arguments[\"generator_projection_dims\"] = [4, 4, 512]\n",
    "arguments[\"generator_l1_regularization_scale\"] = 0.01\n",
    "arguments[\"generator_l2_regularization_scale\"] = 0.01\n",
    "arguments[\"generator_optimizer\"] = \"GradientDescent\"\n",
    "arguments[\"generator_learning_rate\"] = 0.0001\n",
    "arguments[\"generator_clip_gradients\"] = 2.0\n",
    "arguments[\"generator_train_steps\"] = 1\n",
    "\n",
    "# Discriminator hyperparameters.\n",
    "arguments[\"discriminator_l1_regularization_scale\"] = 0.01\n",
    "arguments[\"discriminator_l2_regularization_scale\"] = 0.01\n",
    "arguments[\"discriminator_optimizer\"] = \"GradientDescent\"\n",
    "arguments[\"discriminator_learning_rate\"] = 0.0001\n",
    "arguments[\"discriminator_clip_gradients\"] = 2.0\n",
    "arguments[\"discriminator_gradient_penalty_coefficient\"] = 10.0\n",
    "arguments[\"discriminator_train_steps\"] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print_object.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_obj(function_name, object_name, object_value):\n",
    "    \"\"\"Prints enclosing function, object name, and object value.\n",
    "\n",
    "    Args:\n",
    "        function_name: str, name of function.\n",
    "        object_name: str, name of object.\n",
    "        object_value: object, value of passed object.\n",
    "    \"\"\"\n",
    "#     pass\n",
    "    print(\"{}: {} = {}\".format(function_name, object_name, object_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_example(protos, params):\n",
    "    \"\"\"Decodes TFRecord file into tensors.\n",
    "\n",
    "    Given protobufs, decode into image and label tensors.\n",
    "\n",
    "    Args:\n",
    "        protos: protobufs from TFRecord file.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Image and label tensors.\n",
    "    \"\"\"\n",
    "    # Create feature schema map for protos.\n",
    "    features = {\n",
    "        \"image_raw\": tf.FixedLenFeature(shape=[], dtype=tf.string),\n",
    "        \"label\": tf.FixedLenFeature(shape=[], dtype=tf.int64)\n",
    "    }\n",
    "\n",
    "    # Parse features from tf.Example.\n",
    "    parsed_features = tf.parse_single_example(\n",
    "        serialized=protos, features=features\n",
    "    )\n",
    "    print_obj(\"\\ndecode_example\", \"features\", features)\n",
    "\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length height * width * depth) to a uint8 tensor with shape\n",
    "    # [height * width * depth].\n",
    "    image = tf.decode_raw(\n",
    "        input_bytes=parsed_features[\"image_raw\"], out_type=tf.uint8\n",
    "    )\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Reshape flattened image back into normal dimensions.\n",
    "    image = tf.reshape(\n",
    "        tensor=image,\n",
    "        shape=[params[\"height\"], params[\"width\"], params[\"depth\"]]\n",
    "    )\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Convert from [0, 255] -> [-1.0, 1.0] floats.\n",
    "    image = tf.cast(x=image, dtype=tf.float32) * (2. / 255) - 1.0\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "    label = tf.cast(x=parsed_features[\"label\"], dtype=tf.int32)\n",
    "    print_obj(\"decode_example\", \"label\", label)\n",
    "\n",
    "    return {\"image\": image}, label\n",
    "\n",
    "\n",
    "def read_dataset(filename, mode, batch_size, params):\n",
    "    \"\"\"Reads CSV time series data using tf.data, doing necessary preprocessing.\n",
    "\n",
    "    Given filename, mode, batch size, and other parameters, read CSV dataset\n",
    "    using Dataset API, apply necessary preprocessing, and return an input\n",
    "    function to the Estimator API.\n",
    "\n",
    "    Args:\n",
    "        filename: str, file pattern that to read into our tf.data dataset.\n",
    "        mode: The estimator ModeKeys. Can be TRAIN or EVAL.\n",
    "        batch_size: int, number of examples per batch.\n",
    "        params: dict, dictionary of user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        An input function.\n",
    "    \"\"\"\n",
    "    def _input_fn():\n",
    "        \"\"\"Wrapper input function used by Estimator API to get data tensors.\n",
    "\n",
    "        Returns:\n",
    "            Batched dataset object of dictionary of feature tensors and label\n",
    "                tensor.\n",
    "        \"\"\"\n",
    "        # Create list of files that match pattern.\n",
    "        file_list = tf.gfile.Glob(filename=filename)\n",
    "\n",
    "        # Create dataset from file list.\n",
    "        dataset = tf.data.TFRecordDataset(\n",
    "            filenames=file_list, num_parallel_reads=40\n",
    "        )\n",
    "\n",
    "        # Shuffle and repeat if training with fused op.\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            dataset = dataset.apply(\n",
    "                tf.contrib.data.shuffle_and_repeat(\n",
    "                    buffer_size=50 * batch_size,\n",
    "                    count=None  # indefinitely\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Decode CSV file into a features dictionary of tensors, then batch.\n",
    "        dataset = dataset.apply(\n",
    "            tf.contrib.data.map_and_batch(\n",
    "                map_func=lambda x: decode_example(\n",
    "                    protos=x,\n",
    "                    params=params\n",
    "                ),\n",
    "                batch_size=batch_size,\n",
    "                num_parallel_calls=4\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Prefetch data to improve latency.\n",
    "        dataset = dataset.prefetch(buffer_size=2)\n",
    "\n",
    "        # Create a iterator, then get batch of features from example queue.\n",
    "        batched_dataset = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        return batched_dataset\n",
    "    return _input_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(object):\n",
    "    \"\"\"\n",
    "    Fields:\n",
    "        name: str, name of `Generator`.\n",
    "        kernel_regularizer: `l1_l2_regularizer` object, regularizar for kernel\n",
    "            variables.\n",
    "        bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "            variables.\n",
    "        projection_layer: `Dense` layer for projection of noise to image.\n",
    "        conv_layer_blocks: list, lists of block layers for each block.\n",
    "        to_rgb_conv_layers: list, toRGB 1x1 conv layers.\n",
    "        build_generator_tensors: list, tensors used to build layer internals.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_regularizer, bias_regularizer, params, name):\n",
    "        \"\"\"Creates generator network and returns generated output.\n",
    "\n",
    "        Args:\n",
    "            kernel_regularizer: `l1_l2_regularizer` object, regularizar for\n",
    "                kernel variables.\n",
    "            bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "                variables.\n",
    "            params: dict, user passed parameters.\n",
    "            name: str, name of generator.\n",
    "        \"\"\"\n",
    "        # Set name of generator.\n",
    "        self.name = name\n",
    "\n",
    "        # Regularizer for kernel weights.\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "\n",
    "        # Regularizer for bias weights.\n",
    "        self.bias_regularizer = bias_regularizer\n",
    "\n",
    "        # Instantiate generator layers.\n",
    "        (self.projection_layer,\n",
    "         self.conv_layer_blocks,\n",
    "         self.to_rgb_conv_layers) = self.instantiate_generator_layers(params)\n",
    "\n",
    "        # Build generator layer internals.\n",
    "        self.build_generator_tensors = self.build_generator_layers(\n",
    "            params\n",
    "        )\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def instantiate_generator_projection_layer(self, params):\n",
    "        \"\"\"Instantiates generator projection layer.\n",
    "\n",
    "        Projection layer projects latent noise vector into an image.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Latent vector projection `Dense` layer.\n",
    "        \"\"\"\n",
    "        # Project latent vectors.\n",
    "        projection_height = params[\"generator_projection_dims\"][0]\n",
    "        projection_width = params[\"generator_projection_dims\"][1]\n",
    "        projection_depth = params[\"generator_projection_dims\"][2]\n",
    "\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     projection_height * projection_width * projection_depth\n",
    "            # )\n",
    "            projection_layer = tf.layers.Dense(\n",
    "                units=projection_height * projection_width * projection_depth,\n",
    "                activation=tf.nn.leaky_relu,\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                kernel_regularizer=self.kernel_regularizer,\n",
    "                bias_regularizer=self.bias_regularizer,\n",
    "                name=\"{}_projection_layer\".format(self.name)\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_generator_projection_layer\",\n",
    "                \"projection_layer\",\n",
    "                projection_layer\n",
    "            )\n",
    "\n",
    "        return projection_layer\n",
    "\n",
    "    def instantiate_generator_base_conv_layer_block(self, params):\n",
    "        \"\"\"Instantiates generator base conv layer block.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of base block conv layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"generator_base_conv_blocks\"][0]\n",
    "\n",
    "            # Create list of base conv layers.\n",
    "            base_conv_layers = [\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=conv_block[i][3],\n",
    "                    kernel_size=conv_block[i][0:2],\n",
    "                    strides=conv_block[i][4:6],\n",
    "                    padding=\"same\",\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_base_layers_conv2d_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        i,\n",
    "                        conv_block[i][0],\n",
    "                        conv_block[i][1],\n",
    "                        conv_block[i][2],\n",
    "                        conv_block[i][3]\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_generator_base_conv_layer_block\",\n",
    "                \"base_conv_layers\",\n",
    "                base_conv_layers\n",
    "            )\n",
    "\n",
    "        return base_conv_layers\n",
    "\n",
    "    def instantiate_generator_growth_layer_block(self, params, block_idx):\n",
    "        \"\"\"Instantiates generator growth layer block.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "            block_idx: int, the current growth block's index.\n",
    "\n",
    "        Returns:\n",
    "            List of growth block conv layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"generator_growth_conv_blocks\"][block_idx]\n",
    "\n",
    "            # Create new inner convolutional layers.\n",
    "            conv_layers = [\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=conv_block[i][3],\n",
    "                    kernel_size=conv_block[i][0:2],\n",
    "                    strides=conv_block[i][4:6],\n",
    "                    padding=\"same\",\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_growth_layers_conv2d_{}_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        block_idx,\n",
    "                        i,\n",
    "                        conv_block[i][0],\n",
    "                        conv_block[i][1],\n",
    "                        conv_block[i][2],\n",
    "                        conv_block[i][3]\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_generator_growth_layer_block\",\n",
    "                \"conv_layers\",\n",
    "                conv_layers\n",
    "            )\n",
    "\n",
    "        return conv_layers\n",
    "\n",
    "    def instantiate_generator_to_rgb_layers(self, params):\n",
    "        \"\"\"Instantiates generator toRGB layers of 1x1 convs.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of toRGB 1x1 conv layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get toRGB layer properties.\n",
    "            to_rgb = [\n",
    "                params[\"generator_to_rgb_layers\"][i][0][:]\n",
    "                for i in range(len(params[\"generator_to_rgb_layers\"]))\n",
    "            ]\n",
    "\n",
    "            # Create list to hold toRGB 1x1 convs.\n",
    "            to_rgb_conv_layers = [\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=to_rgb[i][3],\n",
    "                    kernel_size=to_rgb[i][0:2],\n",
    "                    strides=to_rgb[i][4:6],\n",
    "                    padding=\"same\",\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_to_rgb_layers_conv2d_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        i,\n",
    "                        to_rgb[i][0],\n",
    "                        to_rgb[i][1],\n",
    "                        to_rgb[i][2],\n",
    "                        to_rgb[i][3]\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(to_rgb))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_generator_to_rgb_layers\",\n",
    "                \"to_rgb_conv_layers\",\n",
    "                to_rgb_conv_layers\n",
    "            )\n",
    "\n",
    "        return to_rgb_conv_layers\n",
    "\n",
    "    def instantiate_generator_layers(self, params):\n",
    "        \"\"\"Instantiates layers of generator network.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            projection_layer: `Dense` layer for projection of noise to image.\n",
    "            conv_layer_blocks: list, lists of block layers for each block.\n",
    "            to_rgb_conv_layers: list, toRGB 1x1 conv layers.\n",
    "        \"\"\"\n",
    "        # Instantiate noise-image projection `Dense` layer.\n",
    "        projection_layer = self.instantiate_generator_projection_layer(\n",
    "            params=params\n",
    "        )\n",
    "        print_obj(\n",
    "            \"\\ninstantiate_generator_layers\",\n",
    "            \"projection_layer\",\n",
    "            projection_layer\n",
    "        )\n",
    "\n",
    "        # Instantiate base convolutional `Conv2D` layers, for post-growth.\n",
    "        conv_layer_blocks = [\n",
    "            self.instantiate_generator_base_conv_layer_block(\n",
    "                params=params\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Instantiate growth block `Conv2D` layers.\n",
    "        conv_layer_blocks.extend(\n",
    "            [\n",
    "                self.instantiate_generator_growth_layer_block(\n",
    "                    params=params, block_idx=block_idx\n",
    "                )\n",
    "                for block_idx in range(\n",
    "                    len(params[\"generator_growth_conv_blocks\"])\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        print_obj(\n",
    "            \"instantiate_generator_layers\",\n",
    "            \"conv_layer_blocks\",\n",
    "            conv_layer_blocks\n",
    "        )\n",
    "\n",
    "        # Instantiate toRGB 1x1 `Conv2D` layers.\n",
    "        to_rgb_conv_layers = self.instantiate_generator_to_rgb_layers(\n",
    "            params=params\n",
    "        )\n",
    "        print_obj(\n",
    "            \"instantiate_generator_layers\",\n",
    "            \"to_rgb_conv_layers\",\n",
    "            to_rgb_conv_layers\n",
    "        )\n",
    "\n",
    "        return projection_layer, conv_layer_blocks, to_rgb_conv_layers\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def build_generator_projection_layer(self, params):\n",
    "        \"\"\"Builds generator projection layer internals using call.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Latent vector projection tensor.\n",
    "        \"\"\"\n",
    "        # Project latent vectors.\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     projection_height * projection_width * projection_depth\n",
    "            # )\n",
    "            projection_tensor = self.projection_layer(\n",
    "                inputs=tf.zeros(\n",
    "                    shape=[1, params[\"latent_size\"]], dtype=tf.float32\n",
    "                )\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\nbuild_generator_projection_layer\",\n",
    "                \"projection_tensor\",\n",
    "                projection_tensor\n",
    "            )\n",
    "\n",
    "        return projection_tensor\n",
    "\n",
    "    def build_generator_base_conv_layer_block(self, params):\n",
    "        \"\"\"Builds generator base conv layer block internals using call.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of base conv tensors.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"generator_base_conv_blocks\"][0]\n",
    "\n",
    "            # Create list of base conv layers.\n",
    "            base_conv_tensors = [\n",
    "                # The base conv block is always the 0th one.\n",
    "                self.conv_layer_blocks[0][i](\n",
    "                    inputs=tf.zeros(\n",
    "                        shape=[1] + conv_block[i][0:3], dtype=tf.float32\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\nbuild_generator_base_conv_layer_block\",\n",
    "                \"base_conv_tensors\",\n",
    "                base_conv_tensors\n",
    "            )\n",
    "\n",
    "        return base_conv_tensors\n",
    "\n",
    "    def build_generator_growth_layer_block(\n",
    "            self, params, growth_block_idx):\n",
    "        \"\"\"Builds generator growth block internals through call.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "            growth_block_idx: int, the current growth block's index.\n",
    "\n",
    "        Returns:\n",
    "            List of growth block tensors.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"generator_growth_conv_blocks\"][growth_block_idx]\n",
    "\n",
    "            # Create new inner convolutional layers.\n",
    "            conv_tensors = [\n",
    "                self.conv_layer_blocks[1 + growth_block_idx][i](\n",
    "                    inputs=tf.zeros(\n",
    "                        shape=[1] + conv_block[i][0:3], dtype=tf.float32\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\nbuild_generator_growth_layer_block\",\n",
    "                \"conv_tensors\",\n",
    "                conv_tensors\n",
    "            )\n",
    "\n",
    "        return conv_tensors\n",
    "\n",
    "    def build_generator_to_rgb_layers(self, params):\n",
    "        \"\"\"Builds generator toRGB layers of 1x1 convs internals through call.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of toRGB 1x1 conv tensors.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get toRGB layer properties.\n",
    "            to_rgb = [\n",
    "                params[\"generator_to_rgb_layers\"][i][0][:]\n",
    "                for i in range(len(params[\"generator_to_rgb_layers\"]))\n",
    "            ]\n",
    "\n",
    "            # Create list to hold toRGB 1x1 convs.\n",
    "            to_rgb_conv_tensors = [\n",
    "                self.to_rgb_conv_layers[i](\n",
    "                    inputs=tf.zeros(\n",
    "                        shape=[1] + to_rgb[i][0:3], dtype=tf.float32)\n",
    "                    )\n",
    "                for i in range(len(to_rgb))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\nbuild_generator_to_rgb_layers\",\n",
    "                \"to_rgb_conv_tensors\",\n",
    "                to_rgb_conv_tensors\n",
    "            )\n",
    "\n",
    "        return to_rgb_conv_tensors\n",
    "\n",
    "    def build_generator_layers(self, params):\n",
    "        \"\"\"Builds generator layer internals.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of toRGB tensors.\n",
    "        \"\"\"\n",
    "        # Build projection layer internals using call.\n",
    "        projection_tensor = self.build_generator_projection_layer(\n",
    "            params=params\n",
    "        )\n",
    "        print_obj(\n",
    "            \"\\nbuild_generator_layers\",\n",
    "            \"projection_tensor\",\n",
    "            projection_tensor\n",
    "        )\n",
    "\n",
    "        with tf.control_dependencies(control_inputs=[projection_tensor]):\n",
    "            # Build base convolutional layer block's internals using call.\n",
    "            conv_block_tensors = [\n",
    "                self.build_generator_base_conv_layer_block(\n",
    "                    params=params\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            # Build growth block layer internals through call.\n",
    "            conv_block_tensors.extend(\n",
    "                [\n",
    "                    self.build_generator_growth_layer_block(\n",
    "                        params=params,\n",
    "                        growth_block_idx=growth_block_idx\n",
    "                    )\n",
    "                    for growth_block_idx in range(\n",
    "                        len(params[\"generator_growth_conv_blocks\"])\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            print_obj(\n",
    "                \"build_generator_layers\",\n",
    "                \"conv_block_tensors\",\n",
    "                conv_block_tensors\n",
    "            )\n",
    "\n",
    "            # Flatten block tensor lists of lists into list.\n",
    "            conv_block_tensors = [\n",
    "                item for sublist in conv_block_tensors for item in sublist\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"build_generator_layers\",\n",
    "                \"conv_block_tensors\",\n",
    "                conv_block_tensors\n",
    "            )\n",
    "\n",
    "            with tf.control_dependencies(\n",
    "                    control_inputs=conv_block_tensors):\n",
    "                # Build toRGB 1x1 conv layer internals through call.\n",
    "                to_rgb_conv_tensors = self.build_generator_to_rgb_layers(\n",
    "                    params=params\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"build_generator_layers\",\n",
    "                    \"to_rgb_conv_tensors\",\n",
    "                    to_rgb_conv_tensors\n",
    "                )\n",
    "\n",
    "        return to_rgb_conv_tensors\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def use_generator_projection_layer(self, Z, params):\n",
    "        \"\"\"Uses projection layer to convert random noise vector into an image.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Latent vector projection tensor.\n",
    "        \"\"\"\n",
    "        # Project latent vectors.\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     projection_height * projection_width * projection_depth\n",
    "            # )\n",
    "            projection_tensor = self.projection_layer(inputs=Z)\n",
    "            print_obj(\n",
    "                \"\\nuse_generator_projection_layer\",\n",
    "                \"projection_tensor\",\n",
    "                projection_tensor\n",
    "            )\n",
    "\n",
    "        # Reshape projection into \"image\".\n",
    "        # shape = (\n",
    "        #     cur_batch_size,\n",
    "        #     projection_height,\n",
    "        #     projection_width,\n",
    "        #     projection_depth\n",
    "        # )\n",
    "        projection_tensor_reshaped = tf.reshape(\n",
    "            tensor=projection_tensor,\n",
    "            shape=[-1] + params[\"generator_projection_dims\"],\n",
    "            name=\"{}_projection_reshaped\".format(self.name)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"use_generator_projection_layer\",\n",
    "            \"projection_tensor_reshaped\",\n",
    "            projection_tensor_reshaped\n",
    "        )\n",
    "\n",
    "        return projection_tensor_reshaped\n",
    "\n",
    "    def upsample_generator_image(self, image, original_image_size, block_idx):\n",
    "        \"\"\"Upsamples generator image.\n",
    "\n",
    "        Args:\n",
    "            image: tensor, image created by generator conv block.\n",
    "            original_image_size: list, the height and width dimensions of the\n",
    "                original image before any growth.\n",
    "            block_idx: int, index of the current generator growth block.\n",
    "\n",
    "        Returns:\n",
    "            Upsampled image tensor.\n",
    "        \"\"\"\n",
    "        # Upsample from s X s to 2s X 2s image.\n",
    "        upsampled_image = tf.image.resize(\n",
    "            images=image,\n",
    "            size=tf.convert_to_tensor(\n",
    "                value=original_image_size,\n",
    "                dtype=tf.int32,\n",
    "                name=\"{}_upsample_generator_image_original_image_size\".format(\n",
    "                    self.name\n",
    "                )\n",
    "            ) * 2 ** block_idx,\n",
    "            method=\"nearest\",\n",
    "            name=\"{}_growth_upsampled_image_{}_{}x{}_{}x{}\".format(\n",
    "                self.name,\n",
    "                block_idx,\n",
    "                original_image_size[0] * 2 ** (block_idx - 1),\n",
    "                original_image_size[1] * 2 ** (block_idx - 1),\n",
    "                original_image_size[0] * 2 ** block_idx,\n",
    "                original_image_size[1] * 2 ** block_idx\n",
    "            )\n",
    "        )\n",
    "        print_obj(\n",
    "            \"\\nupsample_generator_image\",\n",
    "            \"upsampled_image\",\n",
    "            upsampled_image\n",
    "        )\n",
    "\n",
    "        return upsampled_image\n",
    "\n",
    "    def create_base_generator_network(self, Z, params):\n",
    "        \"\"\"Creates base generator network.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            projection_layer: `Dense` layer for projection of noise into image.\n",
    "            to_rgb_conv_layers: list, toRGB 1x1 conv layers.\n",
    "            blocks: list, lists of block layers for each block.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Final network block conv tensor.\n",
    "        \"\"\"\n",
    "        print_obj(\"\\ncreate_base_generator_network\", \"Z\", Z)\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Project latent noise vectors into image.\n",
    "            projection = self.use_generator_projection_layer(\n",
    "                Z=Z, params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_base_generator_network\", \"projection\", projection\n",
    "            )\n",
    "\n",
    "            # Only need the first block and toRGB conv layer for base network.\n",
    "            block_layers = self.conv_layer_blocks[0]\n",
    "            to_rgb_conv_layer = self.to_rgb_conv_layers[0]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            block_conv = block_layers[0](inputs=projection)\n",
    "            print_obj(\n",
    "                \"create_base_generator_network\", \"block_conv_0\", block_conv\n",
    "            )\n",
    "\n",
    "            for i in range(1, len(block_layers)):\n",
    "                block_conv = block_layers[i](inputs=block_conv)\n",
    "                print_obj(\n",
    "                    \"create_base_generator_network\",\n",
    "                    \"block_conv_{}\".format(i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Convert convolution to RGB image.\n",
    "            to_rgb_conv = to_rgb_conv_layer(inputs=block_conv)\n",
    "            print_obj(\n",
    "                \"create_base_generator_network\", \"to_rgb_conv\", to_rgb_conv\n",
    "            )\n",
    "\n",
    "        return to_rgb_conv\n",
    "\n",
    "    def create_growth_transition_generator_network(\n",
    "            self, Z, original_image_size, alpha_var, params, trans_idx):\n",
    "        \"\"\"Creates growth transition generator network.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            original_image_size: list, the height and width dimensions of the\n",
    "                original image before any growth.\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "            trans_idx: int, index of current growth transition.\n",
    "\n",
    "        Returns:\n",
    "            Weighted sum tensor of growing and shrinking network paths.\n",
    "        \"\"\"\n",
    "        print_obj(\n",
    "            \"\\nEntered create_growth_transition_generator_network\",\n",
    "            \"trans_idx\",\n",
    "            trans_idx\n",
    "        )\n",
    "        print_obj(\"create_growth_transition_generator_network\", \"Z\", Z)\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Project latent noise vectors into image.\n",
    "            projection = self.use_generator_projection_layer(\n",
    "                Z=Z, params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_generator_network\",\n",
    "                \"projection\",\n",
    "                projection\n",
    "            )\n",
    "\n",
    "            # Permanent blocks.\n",
    "            permanent_blocks = self.conv_layer_blocks[0:trans_idx + 1]\n",
    "\n",
    "            # Base block doesn't need any upsampling so handle differently.\n",
    "            base_block_conv_layers = permanent_blocks[0]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            block_conv = base_block_conv_layers[0](inputs=projection)\n",
    "            print_obj(\n",
    "                \"create_growth_transition_generator_network\",\n",
    "                \"base_block_conv_{}_0\".format(trans_idx),\n",
    "                block_conv\n",
    "            )\n",
    "            for i in range(1, len(base_block_conv_layers)):\n",
    "                block_conv = base_block_conv_layers[i](inputs=block_conv)\n",
    "                print_obj(\n",
    "                    \"create_growth_transition_generator_network\",\n",
    "                    \"base_block_conv_{}_{}\".format(trans_idx, i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Growth blocks require first prev conv layer's image upsampled.\n",
    "            for i in range(1, len(permanent_blocks)):\n",
    "                # Upsample previous block's image.\n",
    "                block_conv = self.upsample_generator_image(\n",
    "                    image=block_conv,\n",
    "                    original_image_size=original_image_size,\n",
    "                    block_idx=i\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_growth_transition_generator_network\",\n",
    "                    \"upsample_generator_image_block_conv_{}_{}\".format(\n",
    "                        trans_idx, i\n",
    "                    ),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "                block_conv_layers = permanent_blocks[i]\n",
    "                for j in range(0, len(block_conv_layers)):\n",
    "                    block_conv = block_conv_layers[j](inputs=block_conv)\n",
    "                    print_obj(\n",
    "                        \"create_growth_transition_generator_network\",\n",
    "                        \"block_conv_{}_{}_{}\".format(trans_idx, i, j),\n",
    "                        block_conv\n",
    "                    )\n",
    "\n",
    "            # Upsample most recent block conv image for both side chains.\n",
    "            upsampled_block_conv = self.upsample_generator_image(\n",
    "                image=block_conv,\n",
    "                original_image_size=original_image_size,\n",
    "                block_idx=len(permanent_blocks)\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_generator_network\",\n",
    "                \"upsampled_block_conv_{}\".format(trans_idx),\n",
    "                upsampled_block_conv\n",
    "            )\n",
    "\n",
    "            # Growing side chain.\n",
    "            growing_block_layers = self.conv_layer_blocks[trans_idx + 1]\n",
    "            growing_to_rgb_conv_layer = self.to_rgb_conv_layers[trans_idx + 1]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            block_conv = growing_block_layers[0](inputs=upsampled_block_conv)\n",
    "            print_obj(\n",
    "                \"create_growth_transition_generator_network\",\n",
    "                \"growing_block_conv_{}_0\".format(trans_idx),\n",
    "                block_conv\n",
    "            )\n",
    "            for i in range(1, len(growing_block_layers)):\n",
    "                block_conv = growing_block_layers[i](inputs=block_conv)\n",
    "                print_obj(\n",
    "                    \"create_growth_transition_generator_network\",\n",
    "                    \"growing_block_conv_{}_{}\".format(trans_idx, i),\n",
    "                    block_conv\n",
    "                )\n",
    "            growing_to_rgb_conv = growing_to_rgb_conv_layer(inputs=block_conv)\n",
    "            print_obj(\n",
    "                \"create_growth_transition_generator_network\",\n",
    "                \"growing_to_rgb_conv_{}\".format(trans_idx),\n",
    "                growing_to_rgb_conv\n",
    "            )\n",
    "\n",
    "            # Shrinking side chain.\n",
    "            shrinking_to_rgb_conv_layer = self.to_rgb_conv_layers[trans_idx]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            shrinking_to_rgb_conv = shrinking_to_rgb_conv_layer(\n",
    "                inputs=upsampled_block_conv\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_generator_network\",\n",
    "                \"shrinking_to_rgb_conv_{}\".format(trans_idx),\n",
    "                shrinking_to_rgb_conv\n",
    "            )\n",
    "\n",
    "            # Weighted sum.\n",
    "            weighted_sum = tf.add(\n",
    "                x=growing_to_rgb_conv * alpha_var,\n",
    "                y=shrinking_to_rgb_conv * (1.0 - alpha_var),\n",
    "                name=\"growth_transition_weighted_sum_{}\".format(trans_idx)\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_generator_network\",\n",
    "                \"weighted_sum_{}\".format(trans_idx),\n",
    "                weighted_sum\n",
    "            )\n",
    "\n",
    "        return weighted_sum\n",
    "\n",
    "    def create_final_generator_network(self, Z, original_image_size, params):\n",
    "        \"\"\"Creates final generator network.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            original_image_size: list, the height and width dimensions of the\n",
    "                original image before any growth.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Final network block conv tensor.\n",
    "        \"\"\"\n",
    "        print_obj(\"\\ncreate_final_generator_network\", \"Z\", Z)\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Project latent noise vectors into image.\n",
    "            projection = self.use_generator_projection_layer(\n",
    "                Z=Z, params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_final_generator_network\", \"projection\", projection\n",
    "            )\n",
    "\n",
    "            # Base block doesn't need any upsampling so handle differently.\n",
    "            base_block_conv_layers = self.conv_layer_blocks[0]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            block_conv = base_block_conv_layers[0](inputs=projection)\n",
    "            print_obj(\n",
    "                \"\\ncreate_final_generator_network\",\n",
    "                \"base_block_conv\",\n",
    "                block_conv\n",
    "            )\n",
    "\n",
    "            for i in range(1, len(base_block_conv_layers)):\n",
    "                block_conv = base_block_conv_layers[i](inputs=block_conv)\n",
    "                print_obj(\n",
    "                    \"create_final_generator_network\",\n",
    "                    \"base_block_conv_{}\".format(i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Growth blocks require first prev conv layer's image upsampled.\n",
    "            for i in range(1, len(self.conv_layer_blocks)):\n",
    "                # Upsample previous block's image.\n",
    "                block_conv = self.upsample_generator_image(\n",
    "                    image=block_conv,\n",
    "                    original_image_size=original_image_size,\n",
    "                    block_idx=i\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_final_generator_network\",\n",
    "                    \"upsample_generator_image_block_conv_{}\".format(i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "                block_conv_layers = self.conv_layer_blocks[i]\n",
    "                for j in range(0, len(block_conv_layers)):\n",
    "                    block_conv = block_conv_layers[j](inputs=block_conv)\n",
    "                    print_obj(\n",
    "                        \"create_final_generator_network\",\n",
    "                        \"block_conv_{}_{}\".format(i, j),\n",
    "                        block_conv\n",
    "                    )\n",
    "\n",
    "            # Only need the last toRGB conv layer.\n",
    "            to_rgb_conv_layer = self.to_rgb_conv_layers[-1]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            to_rgb_conv = to_rgb_conv_layer(inputs=block_conv)\n",
    "            print_obj(\n",
    "                \"create_final_generator_network\", \"to_rgb_conv\", to_rgb_conv\n",
    "            )\n",
    "\n",
    "        return to_rgb_conv\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def switch_case_generator_outputs(\n",
    "            self, Z, original_image_size, alpha_var, params, growth_index):\n",
    "        \"\"\"Uses switch case to use the correct network to generate images.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            original_image_size: list, the height and width dimensions of the\n",
    "                original image before any growth.\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "            growth_index: int, current growth stage.\n",
    "\n",
    "        Returns:\n",
    "            Generated image output tensor.\n",
    "        \"\"\"\n",
    "        # Switch to case based on number of steps for gen outputs.\n",
    "        generated_outputs = tf.switch_case(\n",
    "            branch_index=growth_index,\n",
    "            branch_fns=[\n",
    "                # 4x4\n",
    "                lambda: self.create_base_generator_network(\n",
    "                    Z=Z, params=params\n",
    "                ),\n",
    "                # 8x8\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(0, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 16x16\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(1, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 32x32\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(2, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 64x64\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(3, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 128x128\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(4, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 256x256\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(5, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 512x512\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(6, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 1024x1024\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(7, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 1024x1024\n",
    "                lambda: self.create_final_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    params=params\n",
    "                )\n",
    "            ],\n",
    "            name=\"{}_switch_case_generated_outputs\".format(self.name)\n",
    "        )\n",
    "\n",
    "        return generated_outputs\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def get_train_eval_generator_outputs(self, Z, alpha_var, params):\n",
    "        \"\"\"Uses generator network and returns generated output for train/eval.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Generated image output tensor of shape\n",
    "                [cur_batch_size, image_size, image_size, depth].\n",
    "        \"\"\"\n",
    "        print_obj(\"\\nget_train_eval_generator_outputs\", \"Z\", Z)\n",
    "\n",
    "        # Get generator's output image tensor.\n",
    "        train_steps = params[\"train_steps\"]\n",
    "        num_steps_until_growth = params[\"num_steps_until_growth\"]\n",
    "        num_stages = train_steps // num_steps_until_growth\n",
    "        if (num_stages <= 0 or len(params[\"conv_num_filters\"]) == 1):\n",
    "            print(\n",
    "                \"\\nget_train_eval_generator_outputs: NOT GOING TO GROW, SKIP SWITCH CASE!\"\n",
    "            )\n",
    "            # If never going to grow, no sense using the switch case.\n",
    "            # 4x4\n",
    "            generated_outputs = self.create_base_generator_network(\n",
    "                Z=Z, params=params\n",
    "            )\n",
    "        else:\n",
    "            # Find growth index based on global step and growth frequency.\n",
    "            growth_index = tf.cast(\n",
    "                x=tf.floordiv(\n",
    "                    x=tf.train.get_or_create_global_step(),\n",
    "                    y=params[\"num_steps_until_growth\"],\n",
    "                    name=\"{}_global_step_floordiv\".format(self.name)\n",
    "                ),\n",
    "                dtype=tf.int32,\n",
    "                name=\"{}_growth_index\".format(self.name)\n",
    "            )\n",
    "\n",
    "            # Switch to case based on number of steps for gen outputs.\n",
    "            generated_outputs = self.switch_case_generator_outputs(\n",
    "                Z=Z,\n",
    "                original_image_size=params[\"generator_projection_dims\"][0:2],\n",
    "                alpha_var=alpha_var,\n",
    "                params=params,\n",
    "                growth_index=growth_index\n",
    "            )\n",
    "\n",
    "        print_obj(\n",
    "            \"\\nget_train_eval_generator_outputs\",\n",
    "            \"generated_outputs\",\n",
    "            generated_outputs\n",
    "        )\n",
    "\n",
    "        # Wrap generated outputs in a control dependency for the build\n",
    "        # generator tensors to ensure generator internals are built.\n",
    "        with tf.control_dependencies(\n",
    "                control_inputs=self.build_generator_tensors):\n",
    "            generated_outputs = tf.identity(\n",
    "                input=generated_outputs,\n",
    "                name=\"{}_generated_outputs_identity\".format(self.name)\n",
    "            )\n",
    "\n",
    "        return generated_outputs\n",
    "\n",
    "    def get_predict_generator_outputs(self, Z, params):\n",
    "        \"\"\"Uses generator network and returns generated output for predict.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Generated image output tensor of shape\n",
    "                [cur_batch_size, image_size, image_size, depth].\n",
    "        \"\"\"\n",
    "        print_obj(\"\\nget_predict_generator_outputs\", \"Z\", Z)\n",
    "\n",
    "        if params[\"predict_all_resolutions\"]:\n",
    "            generated_outputs = [\n",
    "                # 4x4\n",
    "                self.create_base_generator_network(Z=Z, params=params)\n",
    "            ]\n",
    "\n",
    "            generated_outputs.extend(\n",
    "                [\n",
    "                    # 8x8 through 1024x1024\n",
    "                    self.create_growth_transition_generator_network(\n",
    "                        Z=Z,\n",
    "                        original_image_size=params[\"generator_projection_dims\"][0:2],\n",
    "                        alpha_var=tf.ones(shape=[], dtype=tf.float32),\n",
    "                        params=params,\n",
    "                        trans_idx=i\n",
    "                    )\n",
    "                    for i in range(len(params[\"conv_num_filters\"]) - 1)\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            # 1024x1024\n",
    "            generated_outputs = self.create_final_generator_network(\n",
    "                Z=Z,\n",
    "                original_image_size=params[\"generator_projection_dims\"][0:2],\n",
    "                params=params\n",
    "            )\n",
    "        print_obj(\n",
    "            \"get_predict_generator_outputs\",\n",
    "            \"generated_outputs\",\n",
    "            generated_outputs\n",
    "        )\n",
    "\n",
    "        return generated_outputs\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def get_generator_loss(self, fake_logits, params):\n",
    "        \"\"\"Gets generator loss.\n",
    "\n",
    "        Args:\n",
    "            fake_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "                discriminator having processed generator's output image.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Generator's total loss tensor of shape [].\n",
    "        \"\"\"\n",
    "        # Calculate base generator loss.\n",
    "        generator_loss = -tf.reduce_mean(\n",
    "            input_tensor=fake_logits,\n",
    "            name=\"{}_loss\".format(self.name)\n",
    "        )\n",
    "        print_obj(\"\\nget_generator_loss\", \"generator_loss\", generator_loss)\n",
    "\n",
    "        # Get generator regularization losses.\n",
    "        generator_reg_loss = get_regularization_loss(\n",
    "            params=params, scope=self.name\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_generator_loss\",\n",
    "            \"generator_reg_loss\",\n",
    "            generator_reg_loss\n",
    "        )\n",
    "\n",
    "        # Combine losses for total losses.\n",
    "        generator_total_loss = tf.math.add(\n",
    "            x=generator_loss,\n",
    "            y=generator_reg_loss,\n",
    "            name=\"{}_total_loss\".format(self.name)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_generator_loss\", \"generator_total_loss\", generator_total_loss\n",
    "        )\n",
    "\n",
    "        return generator_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## discriminator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(object):\n",
    "    \"\"\"\n",
    "    Fields:\n",
    "        name: str, name of `Discriminator`.\n",
    "        kernel_regularizer: `l1_l2_regularizer` object, regularizar for kernel\n",
    "            variables.\n",
    "        bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "            variables.\n",
    "        from_rgb_conv_layers: list, fromRGB 1x1 `Conv2D` layers.\n",
    "        conv_layer_blocks: list, lists of `Conv2D` block layers for each\n",
    "            block.\n",
    "        transition_downsample_layers: list, `AveragePooling2D` layers for\n",
    "            downsampling shrinking transition paths.\n",
    "        flatten_layer: `Flatten` layer prior to logits layer.\n",
    "        logits_layer: `Dense` layer for logits.\n",
    "        build_discriminator_tensors: list, tensors used to build layer\n",
    "            internals.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_regularizer, bias_regularizer, params, name):\n",
    "        \"\"\"Creates generator network and returns generated output.\n",
    "\n",
    "        Args:\n",
    "            kernel_regularizer: `l1_l2_regularizer` object, regularizar for\n",
    "                kernel variables.\n",
    "            bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "                variables.\n",
    "            params: dict, user passed parameters.\n",
    "            name: str, name of discriminator.\n",
    "        \"\"\"\n",
    "        # Set name of discriminator.\n",
    "        self.name = name\n",
    "\n",
    "        # Regularizer for kernel weights.\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "\n",
    "        # Regularizer for bias weights.\n",
    "        self.bias_regularizer = bias_regularizer\n",
    "\n",
    "        # Instantiate discriminator layers.\n",
    "        (self.from_rgb_conv_layers,\n",
    "         self.conv_layer_blocks,\n",
    "         self.transition_downsample_layers,\n",
    "         self.flatten_layer,\n",
    "         self.logits_layer) = self.instantiate_discriminator_layers(\n",
    "            params\n",
    "        )\n",
    "\n",
    "        # Build discriminator layer internals.\n",
    "        self.build_discriminator_tensors = self.build_discriminator_layers(\n",
    "            params\n",
    "        )\n",
    "\n",
    "    def instantiate_discriminator_from_rgb_layers(self, params):\n",
    "        \"\"\"Instantiates discriminator fromRGB layers of 1x1 convs.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of fromRGB 1x1 Conv2D layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get fromRGB layer properties.\n",
    "            from_rgb = [\n",
    "                params[\"discriminator_from_rgb_layers\"][i][0][:]\n",
    "                for i in range(len(params[\"discriminator_from_rgb_layers\"]))\n",
    "            ]\n",
    "\n",
    "            # Create list to hold toRGB 1x1 convs.\n",
    "            from_rgb_conv_layers = [\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=from_rgb[i][3],\n",
    "                    kernel_size=from_rgb[i][0:2],\n",
    "                    strides=from_rgb[i][4:6],\n",
    "                    padding=\"same\",\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_from_rgb_layers_conv2d_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        i,\n",
    "                        from_rgb[i][0],\n",
    "                        from_rgb[i][1],\n",
    "                        from_rgb[i][2],\n",
    "                        from_rgb[i][3]\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(from_rgb))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_discriminator_from_rgb_layers\",\n",
    "                \"from_rgb_conv_layers\",\n",
    "                from_rgb_conv_layers\n",
    "            )\n",
    "\n",
    "        return from_rgb_conv_layers\n",
    "\n",
    "    def instantiate_discriminator_base_conv_layer_block(self, params):\n",
    "        \"\"\"Instantiates discriminator base conv layer block.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of base conv layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"discriminator_base_conv_blocks\"][0]\n",
    "\n",
    "            # Create list of base conv layers.\n",
    "            base_conv_layers = [\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=conv_block[i][3],\n",
    "                    kernel_size=conv_block[i][0:2],\n",
    "                    strides=conv_block[i][4:6],\n",
    "                    padding=\"same\",\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_base_layers_conv2d_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        i,\n",
    "                        conv_block[i][0],\n",
    "                        conv_block[i][1],\n",
    "                        conv_block[i][2],\n",
    "                        conv_block[i][3]\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block) - 1)\n",
    "            ]\n",
    "\n",
    "            # Have valid padding for layer just before flatten and logits.\n",
    "            base_conv_layers.append(\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=conv_block[-1][3],\n",
    "                    kernel_size=conv_block[-1][0:2],\n",
    "                    strides=conv_block[-1][4:6],\n",
    "                    padding=\"valid\",\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_base_layers_conv2d_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        len(conv_block) - 1,\n",
    "                        conv_block[-1][0],\n",
    "                        conv_block[-1][1],\n",
    "                        conv_block[-1][2],\n",
    "                        conv_block[-1][3]\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_discriminator_base_conv_layer_block\",\n",
    "                \"base_conv_layers\",\n",
    "                base_conv_layers\n",
    "            )\n",
    "\n",
    "        return base_conv_layers\n",
    "\n",
    "    def instantiate_discriminator_growth_layer_block(self, params, block_idx):\n",
    "        \"\"\"Instantiates discriminator growth block layers.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "            block_idx: int, the current growth block's index.\n",
    "\n",
    "        Returns:\n",
    "            List of growth block layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"discriminator_growth_conv_blocks\"][block_idx]\n",
    "\n",
    "            # Create new inner convolutional layers.\n",
    "            conv_layers = [\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=conv_block[i][3],\n",
    "                    kernel_size=conv_block[i][0:2],\n",
    "                    strides=conv_block[i][4:6],\n",
    "                    padding=\"same\",\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_growth_layers_conv2d_{}_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        block_idx,\n",
    "                        i,\n",
    "                        conv_block[i][0],\n",
    "                        conv_block[i][1],\n",
    "                        conv_block[i][2],\n",
    "                        conv_block[i][3]\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_discriminator_growth_layer_block\",\n",
    "                \"conv_layers\",\n",
    "                conv_layers\n",
    "            )\n",
    "\n",
    "            # Down sample from 2s X 2s to s X s image.\n",
    "            downsampled_image_layer = tf.layers.AveragePooling2D(\n",
    "                pool_size=(2, 2),\n",
    "                strides=(2, 2),\n",
    "                name=\"{}_growth_downsampled_image_{}\".format(\n",
    "                    self.name,\n",
    "                    block_idx\n",
    "                )\n",
    "            )\n",
    "            print_obj(\n",
    "                \"instantiate_discriminator_growth_layer_block\",\n",
    "                \"downsampled_image_layer\",\n",
    "                downsampled_image_layer\n",
    "            )\n",
    "\n",
    "        return conv_layers + [downsampled_image_layer]\n",
    "\n",
    "    def instantiate_discriminator_growth_transition_downsample_layers(\n",
    "            self, params):\n",
    "        \"\"\"Instantiates discriminator growth transition downsample layers.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of growth transition downsample layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Down sample from 2s X 2s to s X s image.\n",
    "            downsample_layers = [\n",
    "                tf.layers.AveragePooling2D(\n",
    "                    pool_size=(2, 2),\n",
    "                    strides=(2, 2),\n",
    "                    name=\"{}_growth_transition_downsample_layer_{}\".format(\n",
    "                        self.name,\n",
    "                        layer_idx\n",
    "                    )\n",
    "                )\n",
    "                for layer_idx in range(\n",
    "                    1 + len(params[\"discriminator_growth_conv_blocks\"])\n",
    "                )\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_discriminator_growth_transition_downsample_layers\",\n",
    "                \"downsample_layers\",\n",
    "                downsample_layers\n",
    "            )\n",
    "\n",
    "        return downsample_layers\n",
    "\n",
    "    def instantiate_discriminator_logits_layer(self):\n",
    "        \"\"\"Instantiates discriminator flatten and logits layers.\n",
    "\n",
    "        Returns:\n",
    "            Flatten and logits layers of discriminator.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Flatten layer to ready final block conv tensor for dense layer.\n",
    "            flatten_layer = tf.layers.Flatten(\n",
    "                name=\"{}_flatten_layer\".format(self.name)\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\ncreate_discriminator_logits_layer\",\n",
    "                \"flatten_layer\",\n",
    "                flatten_layer\n",
    "            )\n",
    "\n",
    "            # Final linear layer for logits.\n",
    "            logits_layer = tf.layers.Dense(\n",
    "                units=1,\n",
    "                activation=None,\n",
    "                kernel_regularizer=self.kernel_regularizer,\n",
    "                bias_regularizer=self.bias_regularizer,\n",
    "                name=\"{}_layers_dense_logits\".format(self.name)\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_discriminator_network\",\n",
    "                \"logits_layer\",\n",
    "                logits_layer\n",
    "            )\n",
    "\n",
    "        return flatten_layer, logits_layer\n",
    "\n",
    "    def instantiate_discriminator_layers(self, params):\n",
    "        \"\"\"Instantiates layers of discriminator network.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            from_rgb_conv_layers: list, fromRGB 1x1 `Conv2D` layers.\n",
    "            conv_layer_blocks: list, lists of `Conv2D` block layers for each\n",
    "                block.\n",
    "            transition_downsample_layers: list, `AveragePooling2D` layers for\n",
    "                downsampling shrinking transition paths.\n",
    "            flatten_layer: `Flatten` layer prior to logits layer.\n",
    "            logits_layer: `Dense` layer for logits.\n",
    "        \"\"\"\n",
    "        # Instantiate fromRGB 1x1 `Conv2D` layers.\n",
    "        from_rgb_conv_layers = self.instantiate_discriminator_from_rgb_layers(\n",
    "            params=params\n",
    "        )\n",
    "        print_obj(\n",
    "            \"instantiate_discriminator_layers\",\n",
    "            \"from_rgb_conv_layers\",\n",
    "            from_rgb_conv_layers\n",
    "        )\n",
    "\n",
    "        # Instantiate base conv block's `Conv2D` layers, for post-growth.\n",
    "        conv_layer_blocks = [\n",
    "            self.instantiate_discriminator_base_conv_layer_block(\n",
    "                params=params\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Instantiate growth `Conv2D` layer blocks.\n",
    "        conv_layer_blocks.extend(\n",
    "            [\n",
    "                self.instantiate_discriminator_growth_layer_block(\n",
    "                    params=params,\n",
    "                    block_idx=block_idx\n",
    "                )\n",
    "                for block_idx in range(\n",
    "                    len(params[\"discriminator_growth_conv_blocks\"])\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        print_obj(\n",
    "            \"instantiate_discriminator_layers\",\n",
    "            \"conv_layer_blocks\",\n",
    "            conv_layer_blocks\n",
    "        )\n",
    "\n",
    "        # Instantiate transition downsample `AveragePooling2D` layers.\n",
    "        transition_downsample_layers = (\n",
    "            self.instantiate_discriminator_growth_transition_downsample_layers(\n",
    "                params=params\n",
    "            )\n",
    "        )\n",
    "        print_obj(\n",
    "            \"instantiate_discriminator_layers\",\n",
    "            \"transition_downsample_layers\",\n",
    "            transition_downsample_layers\n",
    "        )\n",
    "\n",
    "        # Instantiate `Flatten` and `Dense` logits layers.\n",
    "        (flatten_layer,\n",
    "         logits_layer) = self.instantiate_discriminator_logits_layer()\n",
    "        print_obj(\n",
    "            \"instantiate_discriminator_layers\",\n",
    "            \"flatten_layer\",\n",
    "            flatten_layer\n",
    "        )\n",
    "        print_obj(\n",
    "            \"instantiate_discriminator_layers\",\n",
    "            \"logits_layer\",\n",
    "            logits_layer\n",
    "        )\n",
    "\n",
    "        return (from_rgb_conv_layers,\n",
    "                conv_layer_blocks,\n",
    "                transition_downsample_layers,\n",
    "                flatten_layer,\n",
    "                logits_layer)\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def build_discriminator_from_rgb_layers(self, params):\n",
    "        \"\"\"Creates discriminator fromRGB layers of 1x1 convs.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of tensors from fromRGB 1x1 `Conv2D` layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get fromRGB layer properties.\n",
    "            from_rgb = [\n",
    "                params[\"discriminator_from_rgb_layers\"][i][0][:]\n",
    "                for i in range(len(params[\"discriminator_from_rgb_layers\"]))\n",
    "            ]\n",
    "\n",
    "            # Create list to hold fromRGB 1x1 convs.\n",
    "            from_rgb_conv_tensors = [\n",
    "                self.from_rgb_conv_layers[i](\n",
    "                    inputs=tf.zeros(\n",
    "                        shape=[1] + from_rgb[i][0:3], dtype=tf.float32\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(from_rgb))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\nbuild_discriminator_from_rgb_layers\",\n",
    "                \"from_rgb_conv_tensors\",\n",
    "                from_rgb_conv_tensors\n",
    "            )\n",
    "\n",
    "        return from_rgb_conv_tensors\n",
    "\n",
    "    def build_discriminator_base_conv_layer_block(self, params):\n",
    "        \"\"\"Creates discriminator base conv layer block.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of tensors from base `Conv2D` layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"discriminator_base_conv_blocks\"][0]\n",
    "\n",
    "            # Create list of base conv layer tensors.\n",
    "            base_conv_tensors = [\n",
    "                # The base conv block is always the 0th one.\n",
    "                self.conv_layer_blocks[0][i](\n",
    "                    inputs=tf.zeros(\n",
    "                        shape=[1] + conv_block[i][0:3], dtype=tf.float32\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\nbuild_discriminator_base_conv_layer_block\",\n",
    "                \"base_conv_tensors\",\n",
    "                base_conv_tensors\n",
    "            )\n",
    "\n",
    "        return base_conv_tensors\n",
    "\n",
    "    def build_discriminator_growth_layer_block(self, params, block_idx):\n",
    "        \"\"\"Creates discriminator growth block.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "            block_idx: int, the current growth block's index.\n",
    "\n",
    "        Returns:\n",
    "            List of tensors from growth block `Conv2D` layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"discriminator_growth_conv_blocks\"][block_idx]\n",
    "\n",
    "            # Create new inner convolutional layers.\n",
    "            conv_tensors = [\n",
    "                self.conv_layer_blocks[1 + block_idx][i](\n",
    "                    inputs=tf.zeros(\n",
    "                        shape=[1] + conv_block[i][0:3], dtype=tf.float32\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\nbuild_discriminator_growth_layer_block\",\n",
    "                \"conv_tensors\",\n",
    "                conv_tensors\n",
    "            )\n",
    "\n",
    "        return conv_tensors\n",
    "\n",
    "    def build_discriminator_logits_layer(self, params):\n",
    "        \"\"\"Builds flatten and logits layer internals using call.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Final logits tensor of discriminator.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            block_conv_size = params[\"discriminator_base_conv_blocks\"][-1][-1][3]\n",
    "\n",
    "            # Flatten final block conv tensor.\n",
    "            block_conv_flat = self.flatten_layer(\n",
    "                inputs=tf.zeros(\n",
    "                    shape=[1, 1, 1, block_conv_size],\n",
    "                    dtype=tf.float32\n",
    "                )\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\nbuild_discriminator_logits_layer\",\n",
    "                \"block_conv_flat\",\n",
    "                block_conv_flat\n",
    "            )\n",
    "\n",
    "            # Final linear layer for logits.\n",
    "            logits = self.logits_layer(inputs=block_conv_flat)\n",
    "            print_obj(\"build_discriminator_logits_layer\", \"logits\", logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def build_discriminator_layers(self, params):\n",
    "        \"\"\"Builds discriminator layer internals.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Logits tensor.\n",
    "        \"\"\"\n",
    "        # Build fromRGB 1x1 `Conv2D` layers internals through call.\n",
    "        from_rgb_conv_tensors = self.build_discriminator_from_rgb_layers(\n",
    "            params=params\n",
    "        )\n",
    "        print_obj(\n",
    "            \"\\nbuild_discriminator_layers\",\n",
    "            \"from_rgb_conv_tensors\",\n",
    "            from_rgb_conv_tensors\n",
    "        )\n",
    "\n",
    "        with tf.control_dependencies(control_inputs=from_rgb_conv_tensors):\n",
    "            # Create base convolutional block's layer internals using call.\n",
    "            conv_block_tensors = [\n",
    "                self.build_discriminator_base_conv_layer_block(\n",
    "                    params=params\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            # Build growth `Conv2D` layer block internals through call.\n",
    "            conv_block_tensors.extend(\n",
    "                [\n",
    "                    self.build_discriminator_growth_layer_block(\n",
    "                        params=params, block_idx=block_idx\n",
    "                    )\n",
    "                    for block_idx in range(\n",
    "                       len(params[\"discriminator_growth_conv_blocks\"])\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Flatten conv block tensor lists of lists into list.\n",
    "            conv_block_tensors = [\n",
    "                item for sublist in conv_block_tensors for item in sublist\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"build_discriminator_layers\",\n",
    "                \"conv_block_tensors\",\n",
    "                conv_block_tensors\n",
    "            )\n",
    "\n",
    "            with tf.control_dependencies(control_inputs=conv_block_tensors):\n",
    "                # Build logits layer internals using call.\n",
    "                logits_tensor = self.build_discriminator_logits_layer(\n",
    "                    params=params\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"build_discriminator_layers\",\n",
    "                    \"logits_tensor\",\n",
    "                    logits_tensor\n",
    "                )\n",
    "\n",
    "        return logits_tensor\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def use_discriminator_logits_layer(self, block_conv, params):\n",
    "        \"\"\"Uses flatten and logits layers to get logits tensor.\n",
    "\n",
    "        Args:\n",
    "            block_conv: tensor, output of last conv layer of discriminator.\n",
    "            flatten_layer: `Flatten` layer.\n",
    "            logits_layer: `Dense` layer for logits.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Final logits tensor of discriminator.\n",
    "        \"\"\"\n",
    "        print_obj(\n",
    "            \"\\nuse_discriminator_logits_layer\", \"block_conv\", block_conv\n",
    "        )\n",
    "        # Set shape to remove ambiguity for dense layer.\n",
    "        block_conv.set_shape(\n",
    "            [\n",
    "                block_conv.get_shape()[0],\n",
    "                params[\"generator_projection_dims\"][0] / 4,\n",
    "                params[\"generator_projection_dims\"][1] / 4,\n",
    "                block_conv.get_shape()[-1]]\n",
    "        )\n",
    "        print_obj(\"use_discriminator_logits_layer\", \"block_conv\", block_conv)\n",
    "\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Flatten final block conv tensor.\n",
    "            block_conv_flat = self.flatten_layer(inputs=block_conv)\n",
    "            print_obj(\n",
    "                \"use_discriminator_logits_layer\",\n",
    "                \"block_conv_flat\",\n",
    "                block_conv_flat\n",
    "            )\n",
    "\n",
    "            # Final linear layer for logits.\n",
    "            logits = self.logits_layer(inputs=block_conv_flat)\n",
    "            print_obj(\"use_discriminator_logits_layer\", \"logits\", logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def create_base_discriminator_network(self, X, params):\n",
    "        \"\"\"Creates base discriminator network.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, input image to discriminator.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Final logits tensor of discriminator.\n",
    "        \"\"\"\n",
    "        print_obj(\"\\ncreate_base_discriminator_network\", \"X\", X)\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Only need the first fromRGB conv layer & block for base network.\n",
    "            from_rgb_conv_layer = self.from_rgb_conv_layers[0]\n",
    "            block_layers = self.conv_layer_blocks[0]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            from_rgb_conv = from_rgb_conv_layer(inputs=X)\n",
    "            print_obj(\n",
    "                \"create_base_discriminator_network\",\n",
    "                \"from_rgb_conv\",\n",
    "                from_rgb_conv\n",
    "            )\n",
    "\n",
    "            block_conv = from_rgb_conv\n",
    "            for i in range(len(block_layers)):\n",
    "                block_conv = block_layers[i](inputs=block_conv)\n",
    "                print_obj(\n",
    "                    \"create_base_discriminator_network\",\n",
    "                    \"block_conv\",\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Get logits now.\n",
    "            logits = self.use_discriminator_logits_layer(\n",
    "                block_conv=block_conv,\n",
    "                params=params\n",
    "            )\n",
    "            print_obj(\"create_base_discriminator_network\", \"logits\", logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def create_growth_transition_discriminator_network(\n",
    "            self, X, alpha_var, params, trans_idx):\n",
    "        \"\"\"Creates growth transition discriminator network.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, input image to discriminator.\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "            trans_idx: int, index of current growth transition.\n",
    "\n",
    "        Returns:\n",
    "            Final logits tensor of discriminator.\n",
    "        \"\"\"\n",
    "        print_obj(\n",
    "            \"\\nEntered create_growth_transition_discriminator_network\",\n",
    "            \"trans_idx\",\n",
    "            trans_idx\n",
    "        )\n",
    "        print_obj(\"create_growth_transition_discriminator_network\", \"X\", X)\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Growing side chain.\n",
    "            growing_from_rgb_conv_layer = self.from_rgb_conv_layers[trans_idx + 1]\n",
    "            growing_block_layers = self.conv_layer_blocks[trans_idx + 1]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            growing_block_conv = growing_from_rgb_conv_layer(inputs=X)\n",
    "            print_obj(\n",
    "                \"\\ncreate_growth_transition_discriminator_network\",\n",
    "                \"growing_block_conv\",\n",
    "                growing_block_conv\n",
    "            )\n",
    "            for i in range(len(growing_block_layers)):\n",
    "                growing_block_conv = growing_block_layers[i](\n",
    "                    inputs=growing_block_conv\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_growth_transition_discriminator_network\",\n",
    "                    \"growing_block_conv\",\n",
    "                    growing_block_conv\n",
    "                )\n",
    "\n",
    "            # Shrinking side chain.\n",
    "            transition_downsample_layer = self.transition_downsample_layers[trans_idx]\n",
    "            shrinking_from_rgb_conv_layer = self.from_rgb_conv_layers[trans_idx]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            transition_downsample = transition_downsample_layer(inputs=X)\n",
    "            print_obj(\n",
    "                \"create_growth_transition_discriminator_network\",\n",
    "                \"transition_downsample\",\n",
    "                transition_downsample\n",
    "            )\n",
    "            shrinking_from_rgb_conv = shrinking_from_rgb_conv_layer(\n",
    "                inputs=transition_downsample\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_discriminator_network\",\n",
    "                \"shrinking_from_rgb_conv\",\n",
    "                shrinking_from_rgb_conv\n",
    "            )\n",
    "\n",
    "            # Weighted sum.\n",
    "            weighted_sum = tf.add(\n",
    "                x=growing_block_conv * alpha_var,\n",
    "                y=shrinking_from_rgb_conv * (1.0 - alpha_var),\n",
    "                name=\"{}_growth_transition_weighted_sum_{}\".format(\n",
    "                    self.name, trans_idx\n",
    "                )\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_discriminator_network\",\n",
    "                \"weighted_sum\",\n",
    "                weighted_sum\n",
    "            )\n",
    "\n",
    "            # Permanent blocks.\n",
    "            permanent_blocks = self.conv_layer_blocks[0:trans_idx + 1]\n",
    "\n",
    "            # Reverse order of blocks and flatten.\n",
    "            permanent_block_layers = [\n",
    "                item for sublist in permanent_blocks[::-1] for item in sublist\n",
    "            ]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            block_conv = weighted_sum\n",
    "            for i in range(len(permanent_block_layers)):\n",
    "                block_conv = permanent_block_layers[i](inputs=block_conv)\n",
    "                print_obj(\n",
    "                    \"create_growth_transition_discriminator_network\",\n",
    "                    \"block_conv\",\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Get logits now.\n",
    "            logits = self.use_discriminator_logits_layer(\n",
    "                block_conv=block_conv, params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_discriminator_network\",\n",
    "                \"logits\",\n",
    "                logits\n",
    "            )\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def create_final_discriminator_network(self, X, params):\n",
    "        \"\"\"Creates final discriminator network.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, input image to discriminator.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Final logits tensor of discriminator.\n",
    "        \"\"\"\n",
    "        print_obj(\"\\ncreate_final_discriminator_network\", \"X\", X)\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Only need the last fromRGB conv layer.\n",
    "            from_rgb_conv_layer = self.from_rgb_conv_layers[-1]\n",
    "\n",
    "            # Reverse order of blocks.\n",
    "            reversed_blocks = self.conv_layer_blocks[::-1]\n",
    "\n",
    "            # Flatten list of lists block layers into list.\n",
    "            block_layers = [\n",
    "                item for sublist in reversed_blocks for item in sublist\n",
    "            ]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            block_conv = from_rgb_conv_layer(inputs=X)\n",
    "            print_obj(\n",
    "                \"\\ncreate_final_discriminator_network\",\n",
    "                \"block_conv\",\n",
    "                block_conv\n",
    "            )\n",
    "\n",
    "            for i in range(len(block_layers)):\n",
    "                block_conv = block_layers[i](inputs=block_conv)\n",
    "                print_obj(\n",
    "                    \"create_final_discriminator_network\",\n",
    "                    \"block_conv\",\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Get logits now.\n",
    "            logits = self.use_discriminator_logits_layer(\n",
    "                block_conv=block_conv,\n",
    "                params=params\n",
    "            )\n",
    "            print_obj(\"create_final_discriminator_network\", \"logits\", logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def switch_case_discriminator_logits(\n",
    "            self, X, alpha_var, params, growth_index):\n",
    "        \"\"\"Uses switch case to use the correct network to get logits.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, image tensors of shape\n",
    "                [cur_batch_size, image_size, image_size, depth].\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "            growth_index: int, current growth stage.\n",
    "\n",
    "        Returns:\n",
    "            Logits tensor of shape [cur_batch_size, 1].\n",
    "        \"\"\"\n",
    "        # Switch to case based on number of steps to get logits.\n",
    "        logits = tf.switch_case(\n",
    "            branch_index=growth_index,\n",
    "            branch_fns=[\n",
    "                # 4x4\n",
    "                lambda: self.create_base_discriminator_network(\n",
    "                    X=X, params=params\n",
    "                ),\n",
    "                # 8x8\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(0, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 16x16\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(1, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 32x32\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(2, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 64x64\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(3, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 128x128\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(4, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 256x256\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(5, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 512x512\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(6, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 1024x1024\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(7, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 1024x1024\n",
    "                lambda: self.create_final_discriminator_network(\n",
    "                    X=X, params=params\n",
    "                )\n",
    "            ],\n",
    "            name=\"{}_switch_case_logits\".format(self.name)\n",
    "        )\n",
    "\n",
    "        return logits\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def get_discriminator_logits(self, X, alpha_var, params):\n",
    "        \"\"\"Uses generator network and returns generated output for train/eval.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, image tensors of shape\n",
    "                [cur_batch_size, image_size, image_size, depth].\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Logits tensor of shape [cur_batch_size, 1].\n",
    "        \"\"\"\n",
    "        print_obj(\"\\nget_discriminator_logits\", \"X\", X)\n",
    "\n",
    "        # Get discriminator's logits tensor.\n",
    "        train_steps = params[\"train_steps\"]\n",
    "        num_steps_until_growth = params[\"num_steps_until_growth\"]\n",
    "        num_stages = train_steps // num_steps_until_growth\n",
    "        if (num_stages <= 0 or len(params[\"conv_num_filters\"]) == 1):\n",
    "            print(\n",
    "                \"\\nget_discriminator_logits: NOT GOING TO GROW, SKIP SWITCH CASE!\"\n",
    "            )\n",
    "            # If never going to grow, no sense using the switch case.\n",
    "            # 4x4\n",
    "            logits = self.create_base_discriminator_network(\n",
    "                X=X, params=params\n",
    "            )\n",
    "        else:\n",
    "            # Find growth index based on global step and growth frequency.\n",
    "            growth_index = tf.cast(\n",
    "                x=tf.floordiv(\n",
    "                    x=tf.train.get_or_create_global_step(),\n",
    "                    y=params[\"num_steps_until_growth\"],\n",
    "                    name=\"{}_global_step_floordiv\".format(self.name)\n",
    "                ),\n",
    "                dtype=tf.int32,\n",
    "                name=\"{}_growth_index\".format(self.name)\n",
    "            )\n",
    "\n",
    "            # Switch to case based on number of steps for logits.\n",
    "            logits = self.switch_case_discriminator_logits(\n",
    "                X=X,\n",
    "                alpha_var=alpha_var,\n",
    "                params=params,\n",
    "                growth_index=growth_index\n",
    "            )\n",
    "\n",
    "        print_obj(\n",
    "            \"\\nget_discriminator_logits\", \"logits\", logits\n",
    "        )\n",
    "\n",
    "        # Wrap logits in a control dependency for the build discriminator\n",
    "        # tensors to ensure discriminator internals are built.\n",
    "        with tf.control_dependencies(\n",
    "                control_inputs=[self.build_discriminator_tensors]):\n",
    "            logits = tf.identity(\n",
    "                input=logits, name=\"{}_logits_identity\".format(self.name)\n",
    "            )\n",
    "\n",
    "        return logits\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def get_gradient_penalty_loss(\n",
    "            self,\n",
    "            cur_batch_size,\n",
    "            fake_images,\n",
    "            real_images,\n",
    "            alpha_var,\n",
    "            params):\n",
    "        \"\"\"Gets discriminator gradient penalty loss.\n",
    "\n",
    "        Args:\n",
    "            cur_batch_size: tensor, in case of a partial batch instead of\n",
    "                using the user passed int.\n",
    "            fake_images: tensor, images generated by the generator from random\n",
    "                noise of shape [cur_batch_size, image_size, image_size, 3].\n",
    "            real_images: tensor, real images from input of shape\n",
    "                [cur_batch_size, image_size, image_size, 3].\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Discriminator's gradient penalty loss of shape [].\n",
    "        \"\"\"\n",
    "        with tf.name_scope(name=\"{}/gradient_penalty\".format(self.name)):\n",
    "            # Get a random uniform number rank 4 tensor.\n",
    "            random_uniform_num = tf.random.uniform(\n",
    "                shape=[cur_batch_size, 1, 1, 1],\n",
    "                minval=0., maxval=1.,\n",
    "                dtype=tf.float32,\n",
    "                name=\"random_uniform_num\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\nget_gradient_penalty_loss\",\n",
    "                \"random_uniform_num\",\n",
    "                random_uniform_num\n",
    "            )\n",
    "\n",
    "            # Find the element-wise difference between images.\n",
    "            image_difference = real_images - fake_images\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"image_difference\",\n",
    "                image_difference\n",
    "            )\n",
    "\n",
    "            # Get random samples from this mixed image distribution.\n",
    "            mixed_images = random_uniform_num * image_difference\n",
    "            mixed_images += fake_images\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"mixed_images\",\n",
    "                mixed_images\n",
    "            )\n",
    "\n",
    "            # Send to the discriminator to get logits.\n",
    "            mixed_logits = self.get_discriminator_logits(\n",
    "                X=mixed_images, alpha_var=alpha_var, params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"mixed_logits\",\n",
    "                mixed_logits\n",
    "            )\n",
    "\n",
    "            # Get the mixed loss.\n",
    "            mixed_loss = tf.reduce_sum(\n",
    "                input_tensor=mixed_images,\n",
    "                name=\"mixed_loss\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"mixed_loss\",\n",
    "                mixed_loss\n",
    "            )\n",
    "\n",
    "            # Get gradient from returned list of length 1.\n",
    "            mixed_gradients = tf.gradients(\n",
    "                ys=mixed_loss,\n",
    "                xs=[mixed_images],\n",
    "                name=\"gradients\"\n",
    "            )[0]\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"mixed_gradients\",\n",
    "                mixed_gradients\n",
    "            )\n",
    "\n",
    "            # Get gradient's L2 norm.\n",
    "            mixed_norms = tf.sqrt(\n",
    "                x=tf.reduce_sum(\n",
    "                    input_tensor=tf.square(\n",
    "                        x=mixed_gradients,\n",
    "                        name=\"squared_grads\"\n",
    "                    ),\n",
    "                    axis=[1, 2, 3]\n",
    "                )\n",
    "            )\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"mixed_norms\",\n",
    "                mixed_norms\n",
    "            )\n",
    "\n",
    "            # Get squared difference from target of 1.0.\n",
    "            squared_difference = tf.square(\n",
    "                x=mixed_norms - 1.0,\n",
    "                name=\"squared_difference\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"squared_difference\",\n",
    "                squared_difference\n",
    "            )\n",
    "\n",
    "            # Get gradient penalty scalar.\n",
    "            gradient_penalty = tf.reduce_mean(\n",
    "                input_tensor=squared_difference, name=\"gradient_penalty\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"gradient_penalty\",\n",
    "                gradient_penalty\n",
    "            )\n",
    "\n",
    "            # Multiply with lambda to get gradient penalty loss.\n",
    "            gradient_penalty_loss = tf.multiply(\n",
    "                x=params[\"discriminator_gradient_penalty_coefficient\"],\n",
    "                y=gradient_penalty,\n",
    "                name=\"gradient_penalty_loss\"\n",
    "            )\n",
    "\n",
    "            return gradient_penalty_loss\n",
    "\n",
    "    def get_discriminator_loss(\n",
    "            self,\n",
    "            cur_batch_size,\n",
    "            fake_images,\n",
    "            real_images,\n",
    "            fake_logits,\n",
    "            real_logits,\n",
    "            alpha_var,\n",
    "            params):\n",
    "        \"\"\"Gets discriminator loss.\n",
    "\n",
    "        Args:\n",
    "            cur_batch_size: tensor, in case of a partial batch instead of\n",
    "                using the user passed int.\n",
    "            fake_images: tensor, images generated by the generator from random\n",
    "                noise of shape [cur_batch_size, image_size, image_size, 3].\n",
    "            real_images: tensor, real images from input of shape\n",
    "                [cur_batch_size, image_size, image_size, 3].\n",
    "            fake_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "                discriminator having processed generator's output image.\n",
    "            fake_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "                discriminator having processed real image.\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Discriminator's total loss tensor of shape [].\n",
    "        \"\"\"\n",
    "        # Calculate base discriminator loss.\n",
    "        discriminator_real_loss = tf.reduce_mean(\n",
    "            input_tensor=real_logits,\n",
    "            name=\"{}_real_loss\".format(self.name)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"\\nget_discriminator_loss\",\n",
    "            \"discriminator_real_loss\",\n",
    "            discriminator_real_loss\n",
    "        )\n",
    "\n",
    "        discriminator_generated_loss = tf.reduce_mean(\n",
    "            input_tensor=fake_logits,\n",
    "            name=\"{}_generated_loss\".format(self.name)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_discriminator_loss\",\n",
    "            \"discriminator_generated_loss\",\n",
    "            discriminator_generated_loss\n",
    "        )\n",
    "\n",
    "        discriminator_loss = tf.add(\n",
    "            x=discriminator_real_loss, y=-discriminator_generated_loss,\n",
    "            name=\"{}_loss\".format(self.name)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_discriminator_loss\",\n",
    "            \"discriminator_loss\",\n",
    "            discriminator_loss\n",
    "        )\n",
    "\n",
    "        # Get discriminator gradient penalty loss.\n",
    "        discriminator_gradient_penalty = self.get_gradient_penalty_loss(\n",
    "            cur_batch_size=cur_batch_size,\n",
    "            fake_images=fake_images,\n",
    "            real_images=real_images,\n",
    "            alpha_var=alpha_var,\n",
    "            params=params\n",
    "        )\n",
    "\n",
    "        # Get discriminator Wasserstein GP loss.\n",
    "        discriminator_wasserstein_gp_loss = tf.add(\n",
    "            x=discriminator_loss,\n",
    "            y=discriminator_gradient_penalty,\n",
    "            name=\"{}_wasserstein_gp_loss\".format(self.name)\n",
    "        )\n",
    "\n",
    "        # Get discriminator regularization losses.\n",
    "        discriminator_reg_loss = get_regularization_loss(\n",
    "            params=params, scope=self.name\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_discriminator_loss\",\n",
    "            \"discriminator_reg_loss\",\n",
    "            discriminator_reg_loss\n",
    "        )\n",
    "\n",
    "        # Combine losses for total losses.\n",
    "        discriminator_total_loss = tf.math.add(\n",
    "            x=discriminator_wasserstein_gp_loss,\n",
    "            y=discriminator_reg_loss,\n",
    "            name=\"{}_total_loss\".format(self.name)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_discriminator_loss\",\n",
    "            \"discriminator_total_loss\",\n",
    "            discriminator_total_loss\n",
    "        )\n",
    "\n",
    "        return discriminator_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regularization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regularization_loss(params, scope=None):\n",
    "    \"\"\"Gets regularization losses from variables attached to a regularizer.\n",
    "\n",
    "    Args:\n",
    "        params: dict, user passed parameters.\n",
    "        scope: str, the name of the variable scope.\n",
    "\n",
    "    Returns:\n",
    "        Scalar regularization loss tensor.\n",
    "    \"\"\"\n",
    "    def sum_nd_tensor_list_to_scalar_tensor(t_list):\n",
    "        \"\"\"Sums different shape tensors into a scalar tensor.\n",
    "\n",
    "        Args:\n",
    "            t_list: list, tensors of varying shapes.\n",
    "\n",
    "        Returns:\n",
    "            Scalar tensor.\n",
    "        \"\"\"\n",
    "        # Sum list of tensors into a list of scalars.\n",
    "        t_reduce_sum_list = [\n",
    "            tf.reduce_sum(\n",
    "                # Remove the :0 from the end of the name.\n",
    "                input_tensor=t, name=\"{}_reduce_sum\".format(t.name[:-2])\n",
    "            )\n",
    "            for t in t_list\n",
    "        ]\n",
    "        print_obj(\n",
    "            \"\\nsum_nd_tensor_list_to_scalar_tensor\",\n",
    "            \"t_reduce_sum_list\",\n",
    "            t_reduce_sum_list\n",
    "        )\n",
    "\n",
    "        # Add all scalars together into one scalar.\n",
    "        t_scalar_sum_tensor = tf.add_n(\n",
    "            inputs=t_reduce_sum_list,\n",
    "            name=\"{}_t_scalar_sum_tensor\".format(scope)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"sum_nd_tensor_list_to_scalar_tensor\",\n",
    "            \"t_scalar_sum_tensor\",\n",
    "            t_scalar_sum_tensor\n",
    "        )\n",
    "\n",
    "        return t_scalar_sum_tensor\n",
    "\n",
    "    print_obj(\"\\nget_regularization_loss\", \"scope\", scope)\n",
    "    lambda1 = params[\"discriminator_l1_regularization_scale\"]\n",
    "    lambda2 = params[\"discriminator_l2_regularization_scale\"]\n",
    "    if lambda1 <= 0. and lambda2 <= 0.:\n",
    "        # No regularization so return zero.\n",
    "        return tf.zeros(shape=[], dtype=tf.float32)\n",
    "\n",
    "    # Get list of trainable variables with a regularizer attached in scope.\n",
    "    trainable_reg_vars_list = tf.get_collection(\n",
    "        tf.GraphKeys.REGULARIZATION_LOSSES, scope=scope)\n",
    "    print_obj(\n",
    "        \"get_regularization_loss\",\n",
    "        \"trainable_reg_vars_list\",\n",
    "        trainable_reg_vars_list\n",
    "    )\n",
    "    \n",
    "    for var in trainable_reg_vars_list:\n",
    "        print_obj(\n",
    "            \"get_regularization_loss_{}\".format(scope),\n",
    "            \"{}\".format(var.name),\n",
    "            var.graph\n",
    "        )\n",
    "\n",
    "    l1_loss = 0.\n",
    "    if lambda1 > 0.:\n",
    "        # For L1 regularization, take the absolute value element-wise of each.\n",
    "        trainable_reg_vars_abs_list = [\n",
    "            tf.abs(\n",
    "                x=var,\n",
    "                # Clean up regularizer scopes in variable names.\n",
    "                name=\"{}_abs\".format((\"/\").join(var.name.split(\"/\")[0:3]))\n",
    "            )\n",
    "            for var in trainable_reg_vars_list\n",
    "        ]\n",
    "\n",
    "        # Get L1 loss\n",
    "        l1_loss = tf.multiply(\n",
    "            x=lambda1,\n",
    "            y=sum_nd_tensor_list_to_scalar_tensor(\n",
    "                t_list=trainable_reg_vars_abs_list\n",
    "            ),\n",
    "            name=\"{}_l1_loss\".format(scope)\n",
    "        )\n",
    "\n",
    "    l2_loss = 0.\n",
    "    if lambda2 > 0.:\n",
    "        # For L2 regularization, square all variables element-wise.\n",
    "        trainable_reg_vars_squared_list = [\n",
    "            tf.square(\n",
    "                x=var,\n",
    "                # Clean up regularizer scopes in variable names.\n",
    "                name=\"{}_squared\".format((\"/\").join(var.name.split(\"/\")[0:3]))\n",
    "            )\n",
    "            for var in trainable_reg_vars_list\n",
    "        ]\n",
    "        print_obj(\n",
    "            \"get_regularization_loss\",\n",
    "            \"trainable_reg_vars_squared_list\",\n",
    "            trainable_reg_vars_squared_list\n",
    "        )\n",
    "\n",
    "        # Get L2 loss\n",
    "        l2_loss = tf.multiply(\n",
    "            x=lambda2,\n",
    "            y=sum_nd_tensor_list_to_scalar_tensor(\n",
    "                t_list=trainable_reg_vars_squared_list\n",
    "            ),\n",
    "            name=\"{}_l2_loss\".format(scope)\n",
    "        )\n",
    "\n",
    "    l1_l2_loss = tf.add(\n",
    "        x=l1_loss, y=l2_loss, name=\"{}_l1_l2_loss\".format(scope)\n",
    "    )\n",
    "\n",
    "    return l1_l2_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pgan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(loss, global_step, alpha_var, params, scope):\n",
    "    \"\"\"Trains network and returns loss and train op.\n",
    "\n",
    "    Args:\n",
    "        loss: tensor, shape of [].\n",
    "        global_step: tensor, the current training step or batch in the\n",
    "            training loop.\n",
    "        alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "        params: dict, user passed parameters.\n",
    "        scope: str, the variables that to train.\n",
    "\n",
    "    Returns:\n",
    "        Loss tensor and training op.\n",
    "    \"\"\"\n",
    "    print_obj(\"\\ntrain_network\", \"loss\", loss)\n",
    "    print_obj(\"train_network\", \"global_step\", global_step)\n",
    "    print_obj(\"train_network\", \"alpha_var\", alpha_var)\n",
    "    print_obj(\"train_network\", \"scope\", scope)\n",
    "\n",
    "    # Create optimizer map.\n",
    "    optimizers = {\n",
    "        \"Adam\": tf.train.AdamOptimizer,\n",
    "        \"Adadelta\": tf.train.AdadeltaOptimizer,\n",
    "        \"AdagradDA\": tf.train.AdagradDAOptimizer,\n",
    "        \"Adagrad\": tf.train.AdagradOptimizer,\n",
    "        \"Ftrl\": tf.train.FtrlOptimizer,\n",
    "        \"GradientDescent\": tf.train.GradientDescentOptimizer,\n",
    "        \"Momentum\": tf.train.MomentumOptimizer,\n",
    "        \"ProximalAdagrad\": tf.train.ProximalAdagradOptimizer,\n",
    "        \"ProximalGradientDescent\": tf.train.ProximalGradientDescentOptimizer,\n",
    "        \"RMSProp\": tf.train.RMSPropOptimizer\n",
    "    }\n",
    "\n",
    "    # Get optimizer and instantiate it.\n",
    "    optimizer = optimizers[params[\"{}_optimizer\".format(scope)]](\n",
    "        learning_rate=params[\"{}_learning_rate\".format(scope)]\n",
    "    )\n",
    "    print_obj(\"train_network\", \"optimizer\", optimizer)\n",
    "\n",
    "    # Get trainable variables.\n",
    "    variables = tf.trainable_variables(scope=scope)\n",
    "    print_obj(\"\\ntrain_network\", \"variables\", variables)\n",
    "\n",
    "    # Get gradients.\n",
    "    gradients = tf.gradients(\n",
    "        ys=loss,\n",
    "        xs=variables,\n",
    "        name=\"{}_gradients\".format(scope)\n",
    "    )\n",
    "    print_obj(\"\\ntrain_network\", \"gradients\", gradients)\n",
    "\n",
    "    # Clip gradients.\n",
    "    if params[\"{}_clip_gradients\".format(scope)]:\n",
    "        gradients, _ = tf.clip_by_global_norm(\n",
    "            t_list=gradients,\n",
    "            clip_norm=params[\"{}_clip_gradients\".format(scope)],\n",
    "            name=\"{}_clip_by_global_norm_gradients\".format(scope)\n",
    "        )\n",
    "        print_obj(\"\\ntrain_network\", \"gradients\", gradients)\n",
    "\n",
    "    # Zip back together gradients and variables.\n",
    "    grads_and_vars = zip(gradients, variables)\n",
    "    print_obj(\"train_network\", \"grads_and_vars\", grads_and_vars)\n",
    "\n",
    "    # Create train op by applying gradients to variables and incrementing\n",
    "    # global step.\n",
    "    train_op = optimizer.apply_gradients(\n",
    "        grads_and_vars=grads_and_vars,\n",
    "        global_step=global_step,\n",
    "        name=\"{}_apply_gradients\".format(scope)\n",
    "    )\n",
    "    print_obj(\"train_network\", \"train_op\", train_op)\n",
    "\n",
    "    # Update alpha variable to linearly scale from 0 to 1 based on steps.\n",
    "    alpha_var_update_op = tf.assign(\n",
    "        ref=alpha_var,\n",
    "        value=tf.divide(\n",
    "            x=tf.cast(\n",
    "                x=tf.mod(x=global_step, y=params[\"num_steps_until_growth\"]),\n",
    "                dtype=tf.float32\n",
    "            ),\n",
    "            y=params[\"num_steps_until_growth\"]\n",
    "        )\n",
    "    )\n",
    "    print_obj(\"train_network\", \"alpha_var_update_op\", alpha_var_update_op)\n",
    "\n",
    "    # Ensure alpha variable gets updated.\n",
    "    with tf.control_dependencies(control_inputs=[alpha_var_update_op]):\n",
    "        loss = tf.identity(\n",
    "            input=loss, name=\"{}_train_network_loss_identity\".format(scope)\n",
    "        )\n",
    "\n",
    "    return loss, train_op\n",
    "\n",
    "\n",
    "def resize_real_image(image, params, block_idx):\n",
    "    \"\"\"Resizes real images to match the GAN's current size.\n",
    "\n",
    "    Args:\n",
    "        image: tensor, original image.\n",
    "        params: dict, user passed parameters.\n",
    "        block_idx: int, index of current block.\n",
    "\n",
    "    Returns:\n",
    "        Resized image tensor.\n",
    "    \"\"\"\n",
    "    print_obj(\"\\nresize_real_image\", \"block_idx\", block_idx)\n",
    "    print_obj(\"resize_real_image\", \"image\", image)\n",
    "\n",
    "    # Resize image to match GAN size at current block index.\n",
    "    resized_image = tf.image.resize(\n",
    "        images=image,\n",
    "        size=[\n",
    "            params[\"generator_projection_dims\"][0] * (2 ** block_idx),\n",
    "            params[\"generator_projection_dims\"][1] * (2 ** block_idx)\n",
    "        ],\n",
    "        method=\"nearest\",\n",
    "        name=\"resize_real_images_resized_image_{}\".format(block_idx)\n",
    "    )\n",
    "    print_obj(\"resize_real_images\", \"resized_image\", resized_image)\n",
    "\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "def resize_real_images(image, params):\n",
    "    \"\"\"Resizes real images to match the GAN's current size.\n",
    "\n",
    "    Args:\n",
    "        image: tensor, original image.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Resized image tensor.\n",
    "    \"\"\"\n",
    "    print_obj(\"\\nresize_real_images\", \"image\", image)\n",
    "    # Resize real image for each block.\n",
    "    num_stages = params[\"train_steps\"] // params[\"num_steps_until_growth\"]\n",
    "    if (num_stages <= 0 or len(params[\"conv_num_filters\"]) == 1):\n",
    "        print(\n",
    "            \"\\nresize_real_images: NEVER GOING TO GROW, SKIP SWITCH CASE!\"\n",
    "        )\n",
    "        # If we never are going to grow, no sense using the switch case.\n",
    "        resized_image = resize_real_image(0, image, params)  # 4x4\n",
    "    else:\n",
    "        # Find growth index based on global step and growth frequency.\n",
    "        growth_index = tf.cast(\n",
    "            x=tf.floordiv(\n",
    "                x=tf.train.get_or_create_global_step(),\n",
    "                y=params[\"num_steps_until_growth\"],\n",
    "                name=\"resize_real_images_global_step_floordiv\"\n",
    "            ),\n",
    "            dtype=tf.int32,\n",
    "            name=\"resize_real_images_growth_index\"\n",
    "        )\n",
    "\n",
    "        # Switch to case based on number of steps for resized image.\n",
    "        resized_image = tf.switch_case(\n",
    "            branch_index=growth_index,\n",
    "            branch_fns=[\n",
    "                # 4x4\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(0, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 8x8\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(1, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 16x16\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(2, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 32x32\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(3, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 64x64\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(4, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 128x128\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(5, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 256x256\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(6, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 512x512\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(7, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 1024x1024\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(8, len(params[\"conv_num_filters\"]) - 1)\n",
    "                )\n",
    "            ],\n",
    "            name=\"resize_real_images_switch_case_resized_image\"\n",
    "        )\n",
    "        print_obj(\n",
    "            \"resize_real_images\", \"selected resized_image\", resized_image\n",
    "        )\n",
    "\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "def pgan_model(features, labels, mode, params):\n",
    "    \"\"\"Progressively Growing GAN custom Estimator model function.\n",
    "\n",
    "    Args:\n",
    "        features: dict, keys are feature names and values are feature tensors.\n",
    "        labels: tensor, label data.\n",
    "        mode: tf.estimator.ModeKeys with values of either TRAIN, EVAL, or\n",
    "            PREDICT.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Instance of `tf.estimator.EstimatorSpec` class.\n",
    "    \"\"\"\n",
    "    print_obj(\"\\npgan_model\", \"features\", features)\n",
    "    print_obj(\"pgan_model\", \"labels\", labels)\n",
    "    print_obj(\"pgan_model\", \"mode\", mode)\n",
    "    print_obj(\"pgan_model\", \"params\", params)\n",
    "\n",
    "    # Loss function, training/eval ops, etc.\n",
    "    predictions_dict = None\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = None\n",
    "    export_outputs = None\n",
    "\n",
    "    # Instantiate generator.\n",
    "    pgan_generator = Generator(\n",
    "        kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(\n",
    "            scale_l1=params[\"generator_l1_regularization_scale\"],\n",
    "            scale_l2=params[\"generator_l2_regularization_scale\"]\n",
    "        ),\n",
    "        bias_regularizer=None,\n",
    "        params=params,\n",
    "        name=\"generator\"\n",
    "    )\n",
    "\n",
    "    # Instantiate discriminator.\n",
    "    pgan_discriminator = Discriminator(\n",
    "        kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(\n",
    "            scale_l1=params[\"discriminator_l1_regularization_scale\"],\n",
    "            scale_l2=params[\"discriminator_l2_regularization_scale\"]\n",
    "        ),\n",
    "        bias_regularizer=None,\n",
    "        params=params,\n",
    "        name=\"discriminator\"\n",
    "    )\n",
    "\n",
    "    # Create alpha variable to use for weighted sum for smooth fade-in.\n",
    "    alpha_var = tf.get_variable(\n",
    "        name=\"alpha_var\",\n",
    "        dtype=tf.float32,\n",
    "        initializer=tf.zeros(shape=[], dtype=tf.float32),\n",
    "        trainable=False\n",
    "    )\n",
    "    print_obj(\"pgan_model\", \"alpha_var\", alpha_var)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # Extract given latent vectors from features dictionary.\n",
    "        Z = tf.cast(x=features[\"Z\"], dtype=tf.float32)\n",
    "\n",
    "        # Get predictions from generator.\n",
    "        generated_images = get_predict_generator_outputs(\n",
    "            Z=Z, params=params\n",
    "        )\n",
    "\n",
    "        # Create predictions dictionary.\n",
    "        if params[\"predict_all_resolutions\"]:\n",
    "            predictions_dict = {\n",
    "                \"generated_images_{}x{}\".format(\n",
    "                    4 * 2 ** i, 4 * 2 ** i\n",
    "                ): generated_images[i]\n",
    "                for i in range(len(params[\"conv_num_filters\"]))\n",
    "            }\n",
    "        else:\n",
    "            predictions_dict = {\n",
    "                \"generated_images\": generated_images\n",
    "            }\n",
    "\n",
    "        # Create export outputs.\n",
    "        export_outputs = {\n",
    "            \"predict_export_outputs\": tf.estimator.export.PredictOutput(\n",
    "                outputs=predictions_dict)\n",
    "        }\n",
    "    else:\n",
    "        # Extract image from features dictionary.\n",
    "        X = features[\"image\"]\n",
    "\n",
    "        # Get dynamic batch size in case of partial batch.\n",
    "        cur_batch_size = tf.shape(\n",
    "            input=X,\n",
    "            out_type=tf.int32,\n",
    "            name=\"pgan_model_cur_batch_size\"\n",
    "        )[0]\n",
    "\n",
    "        # Create random noise latent vector for each batch example.\n",
    "        Z = tf.random.normal(\n",
    "            shape=[cur_batch_size, params[\"latent_size\"]],\n",
    "            mean=0.0,\n",
    "            stddev=1.0,\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        # Get generated image from generator network from gaussian noise.\n",
    "        print(\"\\nCall generator with Z = {}.\".format(Z))\n",
    "        generator_outputs = pgan_generator.get_train_eval_generator_outputs(\n",
    "            Z=Z, alpha_var=alpha_var, params=params\n",
    "        )\n",
    "\n",
    "        # Get fake logits from discriminator using generator's output image.\n",
    "        print(\n",
    "            \"\\nCall discriminator with generator_outputs = {}.\".format(\n",
    "                generator_outputs\n",
    "            )\n",
    "        )\n",
    "        fake_logits = pgan_discriminator.get_discriminator_logits(\n",
    "            X=generator_outputs, alpha_var=alpha_var, params=params\n",
    "        )\n",
    "\n",
    "        # Resize real images based on the current size of the GAN.\n",
    "        real_images = resize_real_images(X, params)\n",
    "\n",
    "        # Get real logits from discriminator using real image.\n",
    "        print(\n",
    "            \"\\nCall discriminator with real_image = {}.\".format(real_images)\n",
    "        )\n",
    "        real_logits = pgan_discriminator.get_discriminator_logits(\n",
    "            X=real_images, alpha_var=alpha_var, params=params\n",
    "        )\n",
    "\n",
    "        # Get generator total loss.\n",
    "        generator_total_loss = pgan_generator.get_generator_loss(\n",
    "            fake_logits=fake_logits, params=params\n",
    "        )\n",
    "\n",
    "        # Get discriminator total loss.\n",
    "        discriminator_total_loss = pgan_discriminator.get_discriminator_loss(\n",
    "            cur_batch_size=cur_batch_size,\n",
    "            fake_images=generator_outputs,\n",
    "            real_images=real_images,\n",
    "            fake_logits=fake_logits,\n",
    "            real_logits=real_logits,\n",
    "            alpha_var=alpha_var,\n",
    "            params=params\n",
    "        )\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            # Get global step.\n",
    "            global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "            # Determine if it is time to train generator or discriminator.\n",
    "            cycle_step = tf.mod(\n",
    "                x=global_step,\n",
    "                y=tf.cast(\n",
    "                    x=tf.add(\n",
    "                        x=params[\"generator_train_steps\"],\n",
    "                        y=params[\"discriminator_train_steps\"]\n",
    "                    ),\n",
    "                    dtype=tf.int64\n",
    "                ),\n",
    "                name=\"pgan_model_cycle_step\"\n",
    "            )\n",
    "\n",
    "            # Create choose generator condition.\n",
    "            condition = tf.less(\n",
    "                x=cycle_step, y=params[\"generator_train_steps\"]\n",
    "            )\n",
    "\n",
    "            # Needed for batch normalization, but has no effect otherwise.\n",
    "            update_ops = tf.get_collection(key=tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "            with tf.control_dependencies(control_inputs=update_ops):\n",
    "                # Conditionally choose to train generator or discriminator.\n",
    "                loss, train_op = tf.cond(\n",
    "                    pred=condition,\n",
    "                    true_fn=lambda: train_network(\n",
    "                        loss=generator_total_loss,\n",
    "                        global_step=global_step,\n",
    "                        alpha_var=alpha_var,\n",
    "                        params=params,\n",
    "                        scope=\"generator\"\n",
    "                    ),\n",
    "                    false_fn=lambda: train_network(\n",
    "                        loss=discriminator_total_loss,\n",
    "                        global_step=global_step,\n",
    "                        alpha_var=alpha_var,\n",
    "                        params=params,\n",
    "                        scope=\"discriminator\"\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            loss = discriminator_total_loss\n",
    "\n",
    "            # Concatenate discriminator logits and labels.\n",
    "            discriminator_logits = tf.concat(\n",
    "                values=[real_logits, fake_logits],\n",
    "                axis=0,\n",
    "                name=\"discriminator_concat_logits\"\n",
    "            )\n",
    "\n",
    "            discriminator_labels = tf.concat(\n",
    "                values=[\n",
    "                    tf.ones_like(tensor=real_logits),\n",
    "                    tf.zeros_like(tensor=fake_logits)\n",
    "                ],\n",
    "                axis=0,\n",
    "                name=\"discriminator_concat_labels\"\n",
    "            )\n",
    "\n",
    "            # Calculate discriminator probabilities.\n",
    "            discriminator_probabilities = tf.nn.sigmoid(\n",
    "                x=discriminator_logits, name=\"discriminator_probabilities\"\n",
    "            )\n",
    "\n",
    "            # Create eval metric ops dictionary.\n",
    "            eval_metric_ops = {\n",
    "                \"accuracy\": tf.metrics.accuracy(\n",
    "                    labels=discriminator_labels,\n",
    "                    predictions=discriminator_probabilities,\n",
    "                    name=\"pgan_model_accuracy\"\n",
    "                ),\n",
    "                \"precision\": tf.metrics.precision(\n",
    "                    labels=discriminator_labels,\n",
    "                    predictions=discriminator_probabilities,\n",
    "                    name=\"pgan_model_precision\"\n",
    "                ),\n",
    "                \"recall\": tf.metrics.recall(\n",
    "                    labels=discriminator_labels,\n",
    "                    predictions=discriminator_probabilities,\n",
    "                    name=\"pgan_model_recall\"\n",
    "                ),\n",
    "                \"auc_roc\": tf.metrics.auc(\n",
    "                    labels=discriminator_labels,\n",
    "                    predictions=discriminator_probabilities,\n",
    "                    num_thresholds=200,\n",
    "                    curve=\"ROC\",\n",
    "                    name=\"pgan_model_auc_roc\"\n",
    "                ),\n",
    "                \"auc_pr\": tf.metrics.auc(\n",
    "                    labels=discriminator_labels,\n",
    "                    predictions=discriminator_probabilities,\n",
    "                    num_thresholds=200,\n",
    "                    curve=\"PR\",\n",
    "                    name=\"pgan_model_auc_pr\"\n",
    "                )\n",
    "            }\n",
    "\n",
    "    # Return EstimatorSpec\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions_dict,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops,\n",
    "        export_outputs=export_outputs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## serving.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn(params):\n",
    "    \"\"\"Serving input function.\n",
    "\n",
    "    Args:\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        ServingInputReceiver object containing features and receiver tensors.\n",
    "    \"\"\"\n",
    "    # Create placeholders to accept data sent to the model at serving time.\n",
    "    # shape = (batch_size,)\n",
    "    feature_placeholders = {\n",
    "        \"Z\": tf.placeholder(\n",
    "            dtype=tf.float32,\n",
    "            shape=[None, params[\"latent_size\"]],\n",
    "            name=\"serving_input_placeholder_Z\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    print_obj(\n",
    "        \"\\nserving_input_fn\",\n",
    "        \"feature_placeholders\",\n",
    "        feature_placeholders\n",
    "    )\n",
    "\n",
    "    # Create clones of the feature placeholder tensors so that the SavedModel\n",
    "    # SignatureDef will point to the placeholder.\n",
    "    features = {\n",
    "        key: tf.identity(\n",
    "            input=value,\n",
    "            name=\"serving_input_fn_identity_placeholder_{}\".format(key)\n",
    "        )\n",
    "        for key, value in feature_placeholders.items()\n",
    "    }\n",
    "\n",
    "    print_obj(\n",
    "        \"serving_input_fn\",\n",
    "        \"features\",\n",
    "        features\n",
    "    )\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features=features, receiver_tensors=feature_placeholders\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(args):\n",
    "    \"\"\"Trains and evaluates custom Estimator model.\n",
    "\n",
    "    Args:\n",
    "        args: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        `Estimator` object.\n",
    "    \"\"\"\n",
    "    # Set logging to be level of INFO.\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    # Create our custom estimator using our model function.\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn=pgan_model,\n",
    "        model_dir=args[\"output_dir\"],\n",
    "        params=args\n",
    "    )\n",
    "\n",
    "    # Create train spec to read in our training data.\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"train_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.TRAIN,\n",
    "            batch_size=args[\"train_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        max_steps=args[\"train_steps\"]\n",
    "    )\n",
    "\n",
    "    # Create exporter to save out the complete model to disk.\n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        name=\"exporter\",\n",
    "        serving_input_receiver_fn=lambda: serving_input_fn(args)\n",
    "    )\n",
    "\n",
    "    # Create eval spec to read in our validation data and export our model.\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"eval_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.EVAL,\n",
    "            batch_size=args[\"eval_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        steps=args[\"eval_steps\"],\n",
    "        start_delay_secs=args[\"start_delay_secs\"],\n",
    "        throttle_secs=args[\"throttle_secs\"],\n",
    "        exporters=exporter\n",
    "    )\n",
    "\n",
    "    # Create train and evaluate loop to train and evaluate our estimator.\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'local_trained_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f284d4b7c10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "pgan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "pgan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "pgan_model: mode = train\n",
      "pgan_model: params = {'train_file_pattern': 'data/train.tfrecord', 'eval_file_pattern': 'data/eval.tfrecord', 'output_dir': 'local_trained_model', 'train_batch_size': 32, 'train_steps': 400, 'eval_batch_size': 32, 'eval_steps': 10, 'start_delay_secs': 600, 'throttle_secs': 600, 'exports_to_keep': 20, 'predict_all_resolutions': True, 'height': 32, 'width': 32, 'depth': 3, 'num_steps_until_growth': 100, 'conv_num_filters': [[512, 512], [512, 512], [512, 512], [512, 512], [256, 256]], 'conv_kernel_sizes': [[4, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'conv_strides': [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1]], 'generator_base_conv_blocks': [[[4, 4, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]]], 'generator_growth_conv_blocks': [[[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 256, 1, 1], [3, 3, 256, 256, 1, 1]]], 'generator_to_rgb_layers': [[[1, 1, 512, 3, 1, 1]], [[1, 1, 512, 3, 1, 1]], [[1, 1, 512, 3, 1, 1]], [[1, 1, 512, 3, 1, 1]], [[1, 1, 256, 3, 1, 1]]], 'discriminator_from_rgb_layers': [[[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 256, 1, 1]]], 'discriminator_base_conv_blocks': [[[3, 3, 512, 512, 1, 1], [4, 4, 512, 512, 1, 1]]], 'discriminator_growth_conv_blocks': [[[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 256, 256, 1, 1], [3, 3, 256, 512, 1, 1]]], 'latent_size': 512, 'generator_projection_dims': [4, 4, 512], 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_optimizer': 'GradientDescent', 'generator_learning_rate': 0.0001, 'generator_clip_gradients': 2.0, 'generator_train_steps': 1, 'discriminator_l1_regularization_scale': 0.01, 'discriminator_l2_regularization_scale': 0.01, 'discriminator_optimizer': 'GradientDescent', 'discriminator_learning_rate': 0.0001, 'discriminator_clip_gradients': 2.0, 'discriminator_gradient_penalty_coefficient': 10.0, 'discriminator_train_steps': 1}\n",
      "\n",
      "instantiate_generator_projection_layer: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7f283e566610>\n",
      "\n",
      "instantiate_generator_layers: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7f283e566610>\n",
      "\n",
      "instantiate_generator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566910>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566cd0>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566fd0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566810>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e5632d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563550>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563590>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e5634d0>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563bd0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563a10>]\n",
      "instantiate_generator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566910>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566cd0>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566fd0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566810>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e5632d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563550>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563590>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e5634d0>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563bd0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563a10>]]\n",
      "\n",
      "instantiate_generator_to_rgb_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e090>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e210>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e390>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e510>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e690>]\n",
      "instantiate_generator_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e090>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e210>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e390>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e510>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e690>]\n",
      "\n",
      "build_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_layers: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>]\n",
      "build_generator_layers: conv_block_tensors = [[<tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>]]\n",
      "build_generator_layers: conv_block_tensors = [<tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>]\n",
      "\n",
      "build_generator_to_rgb_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "build_generator_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "\n",
      "instantiate_discriminator_from_rgb_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e416b90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e416d50>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e416ed0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b090>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b210>]\n",
      "instantiate_discriminator_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e416b90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e416d50>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e416ed0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b090>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b210>]\n",
      "\n",
      "instantiate_discriminator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b590>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b710>]\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41ba10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41bb90>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e41be10>\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e4210d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421250>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e4214d0>\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421750>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e4218d0>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e421b50>\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421dd0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421f50>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427210>\n",
      "instantiate_discriminator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b590>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b710>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41ba10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41bb90>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e41be10>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e4210d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421250>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e4214d0>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421750>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e4218d0>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e421b50>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421dd0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421f50>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427210>]]\n",
      "\n",
      "instantiate_discriminator_growth_transition_downsample_layers: downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427550>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427690>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e4277d0>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427910>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427a50>]\n",
      "instantiate_discriminator_layers: transition_downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427550>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427690>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e4277d0>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427910>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427a50>]\n",
      "\n",
      "create_discriminator_logits_layer: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7f283e427dd0>\n",
      "create_growth_transition_discriminator_network: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7f283e427fd0>\n",
      "instantiate_discriminator_layers: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7f283e427dd0>\n",
      "instantiate_discriminator_layers: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7f283e427fd0>\n",
      "\n",
      "build_discriminator_from_rgb_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0' shape=(1, 1, 1, 256) dtype=float32>]\n",
      "\n",
      "build_discriminator_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0' shape=(1, 1, 1, 256) dtype=float32>]\n",
      "\n",
      "build_discriminator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "build_discriminator_layers: conv_block_tensors = [<tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(1, 512), dtype=float32)\n",
      "build_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "build_discriminator_layers: logits_tensor = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "pgan_model: alpha_var = <tf.Variable 'alpha_var:0' shape=() dtype=float32_ref>\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_train_eval_generator_outputs: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "create_base_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: to_rgb_conv = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 0\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_0_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_0_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_0 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_0_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_0_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_0 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_0 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_0 = Tensor(\"generator/growth_transition_weighted_sum_0:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 1\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_1_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_1_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_1_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_1_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_1_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_1 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_1_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_1_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_1 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_1 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_1 = Tensor(\"generator/growth_transition_weighted_sum_1:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 2\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_2_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_2_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_2_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_2_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_2 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_2_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_2_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_2 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_2 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_2 = Tensor(\"generator/growth_transition_weighted_sum_2:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "create_final_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_final_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "create_final_generator_network: base_block_conv = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_final_generator_network: base_block_conv_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_4 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_4_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_final_generator_network: block_conv_4_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_final_generator_network: to_rgb_conv = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "get_train_eval_generator_outputs: generated_outputs = Tensor(\"generator_switch_case_generated_outputs/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "Call discriminator with generator_outputs = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_base_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 0\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_0/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_0:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 1\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_1/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_1:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 2\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_2/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_final_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_switch_case_logits/indexed_case/Identity:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "resize_real_images: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "\n",
      "resize_real_image: block_idx = 0\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_0/ResizeNearestNeighbor:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 1\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_1/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 2\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_2/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 3\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "resize_real_images: selected resized_image = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "Call discriminator with real_image = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_base_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 0\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_0/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_0:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 1\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_1/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_1:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 2\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_2/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_final_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_switch_case_logits_1/indexed_case/Identity:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = generator\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_generator: generator_7/generator_projection_layer/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"generator_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"generator_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"generator_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_generated_loss = Tensor(\"discriminator_generated_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"discriminator/gradient_penalty/random_uniform_num:0\", shape=(?, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"discriminator/gradient_penalty/sub:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_base_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 0\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_0/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_0:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 1\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_1/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_1:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 2\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_2/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_final_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/gradient_penalty/discriminator_switch_case_logits/indexed_case/Identity:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"discriminator/gradient_penalty/discriminator_logits_identity:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"discriminator/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"discriminator/gradient_penalty/gradients/discriminator/gradient_penalty/mixed_loss_grad/Tile:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"discriminator/gradient_penalty/Sqrt:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"discriminator/gradient_penalty/squared_difference:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"discriminator/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = discriminator\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_14/discriminator_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"discriminator_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"discriminator_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"discriminator_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "train_network: loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "train_network: global_step = <tf.Variable 'global_step:0' shape=() dtype=int64_ref>\n",
      "train_network: alpha_var = <tf.Variable 'alpha_var:0' shape=() dtype=float32_ref>\n",
      "train_network: scope = generator\n",
      "train_network: optimizer = <tensorflow.python.training.gradient_descent.GradientDescentOptimizer object at 0x7f283d962ed0>\n",
      "\n",
      "train_network: variables = [<tf.Variable 'generator/generator_projection_layer/kernel:0' shape=(512, 8192) dtype=float32_ref>, <tf.Variable 'generator/generator_projection_layer/bias:0' shape=(8192,) dtype=float32_ref>, <tf.Variable 'generator/generator_base_layers_conv2d_0_4x4_512_512/kernel:0' shape=(4, 4, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_base_layers_conv2d_0_4x4_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_base_layers_conv2d_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_base_layers_conv2d_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_0_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_0_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_1_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_1_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_2_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_2_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel:0' shape=(3, 3, 512, 256) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_3_0_3x3_512_256/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_3_1_3x3_256_256/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel:0' shape=(1, 1, 512, 3) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_0_1x1_512_3/bias:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel:0' shape=(1, 1, 512, 3) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_1_1x1_512_3/bias:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel:0' shape=(1, 1, 512, 3) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_2_1x1_512_3/bias:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel:0' shape=(1, 1, 512, 3) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_3_1x1_512_3/bias:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel:0' shape=(1, 1, 256, 3) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_4_1x1_256_3/bias:0' shape=(3,) dtype=float32_ref>]\n",
      "\n",
      "train_network: gradients = [<tf.Tensor 'cond/generator_gradients/AddN_16:0' shape=(512, 8192) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_2:0' shape=(8192,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_17:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_4:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_18:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_6:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_19:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_10:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_20:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_12:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_21:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_17:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_22:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_19:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_23:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_23:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_24:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_25:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_25:0' shape=(3, 3, 512, 256) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_29:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_26:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_31:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_27:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_8:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_28:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_14:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_29:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_21:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_30:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_27:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_31:0' shape=(1, 1, 256, 3) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_33:0' shape=(3,) dtype=float32>]\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\n",
      "train_network: gradients = [<tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_0:0' shape=(512, 8192) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_1:0' shape=(8192,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_2:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_3:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_4:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_5:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_6:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_7:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_8:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_9:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_10:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_11:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_12:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_13:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_14:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_15:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_16:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_17:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_18:0' shape=(3, 3, 512, 256) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_19:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_20:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_21:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_22:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_23:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_24:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_25:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_26:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_27:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_28:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_29:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_30:0' shape=(1, 1, 256, 3) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_31:0' shape=(3,) dtype=float32>]\n",
      "train_network: grads_and_vars = <zip object at 0x7f2837b1e140>\n",
      "train_network: train_op = name: \"cond/generator_apply_gradients\"\n",
      "op: \"AssignAdd\"\n",
      "input: \"cond/generator_apply_gradients/Switch:1\"\n",
      "input: \"cond/generator_apply_gradients/value\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT64\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_class\"\n",
      "  value {\n",
      "    list {\n",
      "      s: \"loc:@global_step\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"use_locking\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "\n",
      "train_network: alpha_var_update_op = Tensor(\"cond/Assign:0\", shape=(), dtype=float32_ref)\n",
      "\n",
      "train_network: loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "train_network: global_step = <tf.Variable 'global_step:0' shape=() dtype=int64_ref>\n",
      "train_network: alpha_var = <tf.Variable 'alpha_var:0' shape=() dtype=float32_ref>\n",
      "train_network: scope = discriminator\n",
      "train_network: optimizer = <tensorflow.python.training.gradient_descent.GradientDescentOptimizer object at 0x7f2837add2d0>\n",
      "\n",
      "train_network: variables = [<tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel:0' shape=(1, 1, 3, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel:0' shape=(1, 1, 3, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel:0' shape=(1, 1, 3, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel:0' shape=(1, 1, 3, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel:0' shape=(1, 1, 3, 256) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_base_layers_conv2d_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_base_layers_conv2d_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_base_layers_conv2d_1_4x4_512_512/kernel:0' shape=(4, 4, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_base_layers_conv2d_1_4x4_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_0_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_0_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_1_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_1_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_2_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_2_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_3_0_3x3_256_256/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel:0' shape=(3, 3, 256, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_3_1_3x3_256_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_layers_dense_logits/kernel:0' shape=(512, 1) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_layers_dense_logits/bias:0' shape=(1,) dtype=float32_ref>]\n",
      "\n",
      "train_network: gradients = [<tf.Tensor 'cond/discriminator_gradients/AddN_32:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_16:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_33:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_20:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_34:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_23:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_35:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_26:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_36:0' shape=(1, 1, 3, 256) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_29:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_37:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_17:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_38:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_18:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_39:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_21:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_40:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_22:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_41:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_24:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_42:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_25:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_43:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_27:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_44:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_28:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_45:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_30:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_46:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_31:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_47:0' shape=(512, 1) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_19:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "train_network: gradients = [<tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_0:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_1:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_2:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_3:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_4:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_5:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_6:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_7:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_8:0' shape=(1, 1, 3, 256) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_9:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_10:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_11:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_12:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_13:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_14:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_15:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_16:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_17:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_18:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_19:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_20:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_21:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_22:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_23:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_24:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_25:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_26:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_27:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_28:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_29:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_30:0' shape=(512, 1) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_31:0' shape=(1,) dtype=float32>]\n",
      "train_network: grads_and_vars = <zip object at 0x7f2834f68910>\n",
      "train_network: train_op = name: \"cond/discriminator_apply_gradients\"\n",
      "op: \"AssignAdd\"\n",
      "input: \"cond/discriminator_apply_gradients/Switch:0\"\n",
      "input: \"cond/discriminator_apply_gradients/value\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT64\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_class\"\n",
      "  value {\n",
      "    list {\n",
      "      s: \"loc:@global_step\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"use_locking\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "\n",
      "train_network: alpha_var_update_op = Tensor(\"cond/Assign_1:0\", shape=(), dtype=float32_ref)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into local_trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 65374.69, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1.38105\n",
      "INFO:tensorflow:loss = 65364.15, step = 101 (72.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.96929\n",
      "INFO:tensorflow:loss = 65352.832, step = 201 (103.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.353734\n",
      "INFO:tensorflow:loss = 65341.95, step = 301 (282.698 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 315 into local_trained_model/model.ckpt.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "pgan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "pgan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "pgan_model: mode = eval\n",
      "pgan_model: params = {'train_file_pattern': 'data/train.tfrecord', 'eval_file_pattern': 'data/eval.tfrecord', 'output_dir': 'local_trained_model', 'train_batch_size': 32, 'train_steps': 400, 'eval_batch_size': 32, 'eval_steps': 10, 'start_delay_secs': 600, 'throttle_secs': 600, 'exports_to_keep': 20, 'predict_all_resolutions': True, 'height': 32, 'width': 32, 'depth': 3, 'num_steps_until_growth': 100, 'conv_num_filters': [[512, 512], [512, 512], [512, 512], [512, 512], [256, 256]], 'conv_kernel_sizes': [[4, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'conv_strides': [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1]], 'generator_base_conv_blocks': [[[4, 4, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]]], 'generator_growth_conv_blocks': [[[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 256, 1, 1], [3, 3, 256, 256, 1, 1]]], 'generator_to_rgb_layers': [[[1, 1, 512, 3, 1, 1]], [[1, 1, 512, 3, 1, 1]], [[1, 1, 512, 3, 1, 1]], [[1, 1, 512, 3, 1, 1]], [[1, 1, 256, 3, 1, 1]]], 'discriminator_from_rgb_layers': [[[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 256, 1, 1]]], 'discriminator_base_conv_blocks': [[[3, 3, 512, 512, 1, 1], [4, 4, 512, 512, 1, 1]]], 'discriminator_growth_conv_blocks': [[[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 256, 256, 1, 1], [3, 3, 256, 512, 1, 1]]], 'latent_size': 512, 'generator_projection_dims': [4, 4, 512], 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_optimizer': 'GradientDescent', 'generator_learning_rate': 0.0001, 'generator_clip_gradients': 2.0, 'generator_train_steps': 1, 'discriminator_l1_regularization_scale': 0.01, 'discriminator_l2_regularization_scale': 0.01, 'discriminator_optimizer': 'GradientDescent', 'discriminator_learning_rate': 0.0001, 'discriminator_clip_gradients': 2.0, 'discriminator_gradient_penalty_coefficient': 10.0, 'discriminator_train_steps': 1}\n",
      "\n",
      "instantiate_generator_projection_layer: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7f28342e00d0>\n",
      "\n",
      "instantiate_generator_layers: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7f28342e00d0>\n",
      "\n",
      "instantiate_generator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0750>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e08d0>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0450>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0c50>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0e90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0c10>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5a10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5090>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5950>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5310>]\n",
      "instantiate_generator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0750>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e08d0>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0450>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0c50>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0e90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0c10>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5a10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5090>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5950>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5310>]]\n",
      "\n",
      "instantiate_generator_to_rgb_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5350>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5e10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5150>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342ec290>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342ec510>]\n",
      "instantiate_generator_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5350>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5e10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5150>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342ec290>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342ec510>]\n",
      "\n",
      "build_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_layers: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>]\n",
      "build_generator_layers: conv_block_tensors = [[<tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>]]\n",
      "build_generator_layers: conv_block_tensors = [<tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>]\n",
      "\n",
      "build_generator_to_rgb_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "build_generator_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "\n",
      "instantiate_discriminator_from_rgb_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4510>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4690>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4810>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4990>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4b10>]\n",
      "instantiate_discriminator_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4510>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4690>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4810>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4990>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4b10>]\n",
      "\n",
      "instantiate_discriminator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4e90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c050>]\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c350>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c4d0>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc37c750>\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c9d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37cb50>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc37cdd0>\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381090>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381210>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381490>\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381710>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381890>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381b10>\n",
      "instantiate_discriminator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4e90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c050>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c350>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c4d0>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc37c750>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c9d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37cb50>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc37cdd0>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381090>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381210>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381490>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381710>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381890>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381b10>]]\n",
      "\n",
      "instantiate_discriminator_growth_transition_downsample_layers: downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381e50>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381f90>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc3890d0>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc389250>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc389390>]\n",
      "instantiate_discriminator_layers: transition_downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381e50>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381f90>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc3890d0>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc389250>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc389390>]\n",
      "\n",
      "create_discriminator_logits_layer: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7f27bc389710>\n",
      "create_growth_transition_discriminator_network: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7f27bc389910>\n",
      "instantiate_discriminator_layers: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7f27bc389710>\n",
      "instantiate_discriminator_layers: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7f27bc389910>\n",
      "\n",
      "build_discriminator_from_rgb_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0' shape=(1, 1, 1, 256) dtype=float32>]\n",
      "\n",
      "build_discriminator_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0' shape=(1, 1, 1, 256) dtype=float32>]\n",
      "\n",
      "build_discriminator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "build_discriminator_layers: conv_block_tensors = [<tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(1, 512), dtype=float32)\n",
      "build_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "build_discriminator_layers: logits_tensor = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "pgan_model: alpha_var = <tf.Variable 'alpha_var:0' shape=() dtype=float32_ref>\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_train_eval_generator_outputs: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "create_base_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: to_rgb_conv = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 0\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_0_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_0_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_0 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_0_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_0_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_0 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_0 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_0 = Tensor(\"generator/growth_transition_weighted_sum_0:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 1\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_1_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_1_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_1_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_1_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_1_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_1 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_1_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_1_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_1 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_1 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_1 = Tensor(\"generator/growth_transition_weighted_sum_1:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 2\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_2_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_2_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_2_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_2_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_2 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_2_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_2_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_2 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_2 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_2 = Tensor(\"generator/growth_transition_weighted_sum_2:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "create_final_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_final_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "create_final_generator_network: base_block_conv = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_final_generator_network: base_block_conv_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_4 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_4_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_final_generator_network: block_conv_4_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_final_generator_network: to_rgb_conv = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "get_train_eval_generator_outputs: generated_outputs = Tensor(\"generator_switch_case_generated_outputs/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "Call discriminator with generator_outputs = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_base_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 0\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_0/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_0:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 1\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_1/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_1:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 2\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_2/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_final_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_switch_case_logits/indexed_case/Identity:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "resize_real_images: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "\n",
      "resize_real_image: block_idx = 0\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_0/ResizeNearestNeighbor:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 1\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_1/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 2\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_2/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 3\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "resize_real_images: selected resized_image = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "Call discriminator with real_image = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_base_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 0\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_0/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_0:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 1\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_1/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_1:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 2\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_2/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_final_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_switch_case_logits_1/indexed_case/Identity:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = generator\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_generator: generator_7/generator_projection_layer/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"generator_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"generator_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"generator_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_generated_loss = Tensor(\"discriminator_generated_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"discriminator/gradient_penalty/random_uniform_num:0\", shape=(?, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"discriminator/gradient_penalty/sub:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_base_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 0\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_0/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_0:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 1\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_1/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_1:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 2\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_2/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_final_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/gradient_penalty/discriminator_switch_case_logits/indexed_case/Identity:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"discriminator/gradient_penalty/discriminator_logits_identity:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"discriminator/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"discriminator/gradient_penalty/gradients/discriminator/gradient_penalty/mixed_loss_grad/Tile:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"discriminator/gradient_penalty/Sqrt:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"discriminator/gradient_penalty/squared_difference:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"discriminator/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = discriminator\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_14/discriminator_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"discriminator_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"discriminator_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"discriminator_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-05T10:40:16Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from local_trained_model/model.ckpt-315\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree(path=arguments[\"output_dir\"], ignore_errors=True)\n",
    "estimator = train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1591353899\n"
     ]
    }
   ],
   "source": [
    "!ls trained_model/export/exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from trained_model/export/exporter/1591353899/variables/variables\n"
     ]
    }
   ],
   "source": [
    "predict_fn = tf.contrib.predictor.from_saved_model(\n",
    "    \"trained_model/export/exporter/1591353899\"\n",
    ")\n",
    "predictions = predict_fn(\n",
    "    {\n",
    "        \"Z\": np.random.normal(size=(500, 512))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['generated_images_16x16', 'generated_images_4x4', 'generated_images_8x8']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(predictions.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = {\n",
    "    k: np.clip(\n",
    "        a=((v + 1.0) * (255. / 2)).astype(np.int32),\n",
    "        a_min=0,\n",
    "        a_max=255\n",
    "    )\n",
    "    for k, v in predictions.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_4x4 (500, 4, 4, 3)\n",
      "generated_images_8x8 (500, 8, 8, 3)\n",
      "generated_images_16x16 (500, 16, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "for k, v in generated_images.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_4x4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_8x8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_16x16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for k, v in generated_images.items():\n",
    "    print(k)\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(v[i], cmap=plt.cm.binary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
