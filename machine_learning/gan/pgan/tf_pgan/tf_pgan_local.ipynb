{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2-dlenv_tfe\n",
      "1.18.1\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and modules\n",
    "import math\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_generator_discriminator_conv_layer_properties(\n",
    "        conv_num_filters, conv_kernel_sizes, conv_strides, depth):\n",
    "    \"\"\"Calculates generator and discriminator conv layer properties.\n",
    "\n",
    "    Args:\n",
    "        num_filters: list, nested list of ints of the number of filters\n",
    "            for each conv layer.\n",
    "        kernel_sizes: list, nested list of ints of the kernel sizes for\n",
    "            each conv layer.\n",
    "        strides: list, nested list of ints of the strides for each conv\n",
    "            layer.\n",
    "        depth: int, depth dimension of images.\n",
    "\n",
    "    Returns:\n",
    "        Nested lists of conv layer properties for both generator and\n",
    "            discriminator.\n",
    "    \"\"\"\n",
    "    def make_generator(num_filters, kernel_sizes, strides, depth):\n",
    "        \"\"\"Calculates generator conv layer properties.\n",
    "\n",
    "        Args:\n",
    "            num_filters: list, nested list of ints of the number of filters\n",
    "                for each conv layer.\n",
    "            kernel_sizes: list, nested list of ints of the kernel sizes for\n",
    "                each conv layer.\n",
    "            strides: list, nested list of ints of the strides for each conv\n",
    "                layer.\n",
    "            depth: int, depth dimension of images.\n",
    "\n",
    "        Returns:\n",
    "            Nested list of conv layer properties for generator.\n",
    "        \"\"\"\n",
    "        # Get the number of growths.\n",
    "        num_growths = len(num_filters) - 1\n",
    "\n",
    "        # Make base block.\n",
    "        in_out = num_filters[0]\n",
    "        base = [\n",
    "            [kernel_sizes[0][i]] * 2 + in_out + [strides[0][i]] * 2\n",
    "            for i in range(len(num_filters[0]))\n",
    "        ]\n",
    "        blocks = [base]\n",
    "\n",
    "        # Add growth blocks.\n",
    "        for i in range(1, num_growths + 1):\n",
    "            in_out = [[blocks[i - 1][-1][-3], num_filters[i][0]]]\n",
    "            block = [[kernel_sizes[i][0]] * 2 + in_out[0] + [strides[i][0]] * 2]\n",
    "            for j in range(1, len(num_filters[i])):\n",
    "                in_out.append([block[-1][-3], num_filters[i][j]])\n",
    "                block.append(\n",
    "                    [kernel_sizes[i][j]] * 2 + in_out[j] + [strides[i][j]] * 2\n",
    "                )\n",
    "            blocks.append(block)\n",
    "\n",
    "        # Add toRGB conv.\n",
    "        blocks[-1].append([1, 1, blocks[-1][-1][-3], depth] + [1] * 2)\n",
    "\n",
    "        return blocks\n",
    "\n",
    "    def make_discriminator(generator):\n",
    "        \"\"\"Calculates discriminator conv layer properties.\n",
    "\n",
    "        Args:\n",
    "            generator: list, nested list of conv layer properties for\n",
    "                generator.\n",
    "\n",
    "        Returns:\n",
    "            Nested list of conv layer properties for discriminator.\n",
    "        \"\"\"\n",
    "        # Reverse generator.\n",
    "        discriminator = generator[::-1]\n",
    "\n",
    "        # Reverse input and output shapes.\n",
    "        discriminator = [\n",
    "            [\n",
    "                conv[0:2] + conv[2:4][::-1] + conv[-2:]\n",
    "                for conv in block[::-1]\n",
    "            ]\n",
    "            for block in discriminator\n",
    "        ]\n",
    "\n",
    "        return discriminator\n",
    "\n",
    "    # Calculate conv layer properties for generator using args.\n",
    "    generator = make_generator(\n",
    "        conv_num_filters, conv_kernel_sizes, conv_strides, depth\n",
    "    )\n",
    "\n",
    "    # Calculate conv layer properties for discriminator using generator\n",
    "    # properties.\n",
    "    discriminator = make_discriminator(generator)\n",
    "\n",
    "    return generator, discriminator\n",
    "\n",
    "\n",
    "def split_up_generator_conv_layer_properties(\n",
    "        generator, num_filters, strides, depth):\n",
    "    \"\"\"Splits up generator conv layer properties into lists.\n",
    "\n",
    "    Args:\n",
    "        generator: list, nested list of conv layer properties for\n",
    "            generator.\n",
    "        num_filters: list, nested list of ints of the number of filters\n",
    "            for each conv layer.\n",
    "        strides: list, nested list of ints of the strides for each conv\n",
    "            layer.\n",
    "        depth: int, depth dimension of images.\n",
    "\n",
    "    Returns:\n",
    "        Nested lists of conv layer properties for generator.\n",
    "    \"\"\"\n",
    "    generator_base_conv_blocks = [generator[0][0:len(num_filters[0])]]\n",
    "\n",
    "    generator_growth_conv_blocks = []\n",
    "    if len(num_filters) > 1:\n",
    "        generator_growth_conv_blocks = generator[1:-1] + [generator[-1][:-1]]\n",
    "\n",
    "    generator_to_rgb_layers = [\n",
    "        [[1] * 2 + [num_filters[i][0]] + [depth] + [strides[i][0]] * 2]\n",
    "        for i in range(len(num_filters))\n",
    "    ]\n",
    "\n",
    "    return (generator_base_conv_blocks,\n",
    "            generator_growth_conv_blocks,\n",
    "            generator_to_rgb_layers)\n",
    "\n",
    "\n",
    "def split_up_discriminator_conv_layer_properties(\n",
    "        discriminator, num_filters, strides, depth):\n",
    "    \"\"\"Splits up discriminator conv layer properties into lists.\n",
    "\n",
    "    Args:\n",
    "        discriminator: list, nested list of conv layer properties for\n",
    "            discriminator.\n",
    "        num_filters: list, nested list of ints of the number of filters\n",
    "            for each conv layer.\n",
    "        strides: list, nested list of ints of the strides for each conv\n",
    "            layer.\n",
    "        depth: int, depth dimension of images.\n",
    "\n",
    "    Returns:\n",
    "        Nested lists of conv layer properties for discriminator.\n",
    "    \"\"\"\n",
    "    discriminator_from_rgb_layers = [\n",
    "        [[1] * 2 + [depth] + [num_filters[i][0]] + [strides[i][0]] * 2]\n",
    "        for i in range(len(num_filters))\n",
    "    ]\n",
    "\n",
    "    if len(num_filters) > 1:\n",
    "        discriminator_base_conv_blocks = [discriminator[-1]]\n",
    "    else:\n",
    "        discriminator_base_conv_blocks = [discriminator[-1][1:]]\n",
    "\n",
    "    discriminator_growth_conv_blocks = []\n",
    "    if len(num_filters) > 1:\n",
    "        discriminator_growth_conv_blocks = [discriminator[0][1:]] + discriminator[1:-1]\n",
    "        discriminator_growth_conv_blocks = discriminator_growth_conv_blocks[::-1]\n",
    "\n",
    "    return (discriminator_from_rgb_layers,\n",
    "            discriminator_base_conv_blocks,\n",
    "            discriminator_growth_conv_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_num_filters = [[512, 512], [512, 512], [512, 512], [512, 512], [256, 256]]\n",
      "conv_kernel_sizes = [[4, 3], [3, 3], [3, 3], [3, 3], [3, 3]]\n",
      "conv_strides = [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1]]\n"
     ]
    }
   ],
   "source": [
    "# Create arguments dictionary to hold all user passed parameters.\n",
    "arguments = {}\n",
    "# File arguments.\n",
    "arguments[\"train_file_pattern\"] = \"data/train.tfrecord\"\n",
    "arguments[\"eval_file_pattern\"] = \"data/eval.tfrecord\"\n",
    "arguments[\"output_dir\"] = \"local_trained_model\"\n",
    "\n",
    "# Training parameters.\n",
    "arguments[\"train_batch_size\"] = 32\n",
    "arguments[\"train_steps\"] = 400\n",
    "arguments[\"prev_train_steps\"] = 0\n",
    "\n",
    "# Eval parameters.\n",
    "arguments[\"eval_batch_size\"] = 32\n",
    "arguments[\"eval_steps\"] = 10\n",
    "arguments[\"start_delay_secs\"] = 600\n",
    "arguments[\"throttle_secs\"] = 600\n",
    "\n",
    "# Serving parameters.\n",
    "arguments[\"exports_to_keep\"] = 20\n",
    "arguments[\"predict_all_resolutions\"] = True\n",
    "\n",
    "# Image parameters.\n",
    "arguments[\"height\"] = 32\n",
    "arguments[\"width\"] = 32\n",
    "arguments[\"depth\"] = 3\n",
    "\n",
    "# Shared parameters.\n",
    "arguments[\"num_steps_until_growth\"] = 100\n",
    "\n",
    "# Full lists for full 1024x1024 network growth.\n",
    "full_conv_num_filters = [[512, 512], [512, 512], [512, 512], [512, 512], [256, 256], [128, 128], [64, 64], [32, 32], [16, 16]]\n",
    "full_conv_kernel_sizes = [[4, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]]\n",
    "full_conv_strides = [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]]\n",
    "\n",
    "# Set final image size as a multiple of 2, starting at 4.\n",
    "image_size = 64\n",
    "prop_list_len = max(\n",
    "    min(int(math.log(image_size, 2) - 1), len(full_conv_num_filters)), 1\n",
    ")\n",
    "\n",
    "# Get slices of lists.\n",
    "conv_num_filters = full_conv_num_filters[0:prop_list_len]\n",
    "print(\"conv_num_filters = {}\".format(conv_num_filters))\n",
    "conv_kernel_sizes = full_conv_kernel_sizes[0:prop_list_len]\n",
    "print(\"conv_kernel_sizes = {}\".format(conv_kernel_sizes))\n",
    "conv_strides = full_conv_strides[0:prop_list_len]\n",
    "print(\"conv_strides = {}\".format(conv_strides))\n",
    "\n",
    "arguments[\"conv_num_filters\"] = conv_num_filters\n",
    "arguments[\"conv_kernel_sizes\"] = conv_kernel_sizes\n",
    "arguments[\"conv_strides\"] = conv_strides\n",
    "\n",
    "# Truncate lists if over the 1024x1024 current limit.\n",
    "if len(arguments[\"conv_num_filters\"]) > 9:\n",
    "    arguments[\"conv_num_filters\"] = arguments[\"conv_num_filters\"][0:10]\n",
    "    arguments[\"conv_kernel_sizes\"] = arguments[\"conv_kernel_sizes\"][0:10]\n",
    "    arguments[\"conv_strides\"] = arguments[\"conv_strides\"][0:10]\n",
    "\n",
    "# Get conv layer properties for generator and discriminator.\n",
    "(generator,\n",
    " discriminator) = calc_generator_discriminator_conv_layer_properties(\n",
    "    arguments[\"conv_num_filters\"],\n",
    "    arguments[\"conv_kernel_sizes\"],\n",
    "    arguments[\"conv_strides\"],\n",
    "    arguments[\"depth\"]\n",
    ")\n",
    "\n",
    "# Split up generator properties into separate lists.\n",
    "(generator_base_conv_blocks,\n",
    " generator_growth_conv_blocks,\n",
    " generator_to_rgb_layers) = split_up_generator_conv_layer_properties(\n",
    "    generator,\n",
    "    arguments[\"conv_num_filters\"],\n",
    "    arguments[\"conv_strides\"],\n",
    "    arguments[\"depth\"]\n",
    ")\n",
    "arguments[\"generator_base_conv_blocks\"] = generator_base_conv_blocks\n",
    "arguments[\"generator_growth_conv_blocks\"] = generator_growth_conv_blocks\n",
    "arguments[\"generator_to_rgb_layers\"] = generator_to_rgb_layers\n",
    "\n",
    "# Split up discriminator properties into separate lists.\n",
    "(discriminator_from_rgb_layers,\n",
    " discriminator_base_conv_blocks,\n",
    " discriminator_growth_conv_blocks) = split_up_discriminator_conv_layer_properties(\n",
    "    discriminator,\n",
    "    arguments[\"conv_num_filters\"],\n",
    "    arguments[\"conv_strides\"],\n",
    "    arguments[\"depth\"]\n",
    ")\n",
    "arguments[\"discriminator_from_rgb_layers\"] = discriminator_from_rgb_layers\n",
    "arguments[\"discriminator_base_conv_blocks\"] = discriminator_base_conv_blocks\n",
    "arguments[\"discriminator_growth_conv_blocks\"] = discriminator_growth_conv_blocks\n",
    "\n",
    "# Generator parameters.\n",
    "arguments[\"latent_size\"] = 512\n",
    "arguments[\"normalize_latent\"] = True\n",
    "arguments[\"use_pixel_norm\"] = True\n",
    "arguments[\"pixel_norm_epsilon\"] = 1e-8\n",
    "arguments[\"generator_projection_dims\"] = [4, 4, 512]\n",
    "arguments[\"generator_l1_regularization_scale\"] = 0.01\n",
    "arguments[\"generator_l2_regularization_scale\"] = 0.01\n",
    "arguments[\"generator_optimizer\"] = \"GradientDescent\"\n",
    "arguments[\"generator_learning_rate\"] = 0.0001\n",
    "arguments[\"generator_clip_gradients\"] = 2.0\n",
    "arguments[\"generator_train_steps\"] = 1\n",
    "\n",
    "# Discriminator hyperparameters.\n",
    "arguments[\"discriminator_l1_regularization_scale\"] = 0.01\n",
    "arguments[\"discriminator_l2_regularization_scale\"] = 0.01\n",
    "arguments[\"discriminator_optimizer\"] = \"GradientDescent\"\n",
    "arguments[\"discriminator_learning_rate\"] = 0.0001\n",
    "arguments[\"discriminator_clip_gradients\"] = 2.0\n",
    "arguments[\"discriminator_gradient_penalty_coefficient\"] = 10.0\n",
    "arguments[\"discriminator_train_steps\"] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print_object.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_obj(function_name, object_name, object_value):\n",
    "    \"\"\"Prints enclosing function, object name, and object value.\n",
    "\n",
    "    Args:\n",
    "        function_name: str, name of function.\n",
    "        object_name: str, name of object.\n",
    "        object_value: object, value of passed object.\n",
    "    \"\"\"\n",
    "#     pass\n",
    "    print(\"{}: {} = {}\".format(function_name, object_name, object_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, params):\n",
    "    \"\"\"Preprocess image tensor.\n",
    "\n",
    "    Args:\n",
    "        image: tensor, input image with shape\n",
    "            [cur_batch_size, height, width, depth].\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Preprocessed image tensor with shape\n",
    "            [cur_batch_size, height, width, depth].\n",
    "    \"\"\"\n",
    "    # Convert from [0, 255] -> [-1.0, 1.0] floats.\n",
    "    image = tf.cast(x=image, dtype=tf.float32) * (2. / 255) - 1.0\n",
    "    print_obj(\"preprocess_image\", \"image\", image)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def resize_real_image(image, params, block_idx):\n",
    "    \"\"\"Resizes real images to match the GAN's current size.\n",
    "\n",
    "    Args:\n",
    "        image: tensor, original image.\n",
    "        params: dict, user passed parameters.\n",
    "        block_idx: int, index of current block.\n",
    "\n",
    "    Returns:\n",
    "        Resized image tensor.\n",
    "    \"\"\"\n",
    "    print_obj(\"\\nresize_real_image\", \"block_idx\", block_idx)\n",
    "    print_obj(\"resize_real_image\", \"image\", image)\n",
    "\n",
    "    # Resize image to match GAN size at current block index.\n",
    "    resized_image = tf.image.resize(\n",
    "        images=image,\n",
    "        size=[\n",
    "            params[\"generator_projection_dims\"][0] * (2 ** block_idx),\n",
    "            params[\"generator_projection_dims\"][1] * (2 ** block_idx)\n",
    "        ],\n",
    "        method=\"nearest\",\n",
    "        name=\"resize_real_images_resized_image_{}\".format(block_idx)\n",
    "    )\n",
    "    print_obj(\"resize_real_images\", \"resized_image\", resized_image)\n",
    "\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "def resize_real_images(image, params):\n",
    "    \"\"\"Resizes real images to match the GAN's current size.\n",
    "\n",
    "    Args:\n",
    "        image: tensor, original image.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Resized image tensor.\n",
    "    \"\"\"\n",
    "    print_obj(\"\\nresize_real_images\", \"image\", image)\n",
    "    # Resize real image for each block.\n",
    "    train_steps = params[\"train_steps\"] + params[\"prev_train_steps\"]\n",
    "    num_steps_until_growth = params[\"num_steps_until_growth\"]\n",
    "    num_stages = train_steps // num_steps_until_growth\n",
    "    if (num_stages <= 0 or len(params[\"conv_num_filters\"]) == 1):\n",
    "        print(\n",
    "            \"\\nresize_real_images: NEVER GOING TO GROW, SKIP SWITCH CASE!\"\n",
    "        )\n",
    "        # If we never are going to grow, no sense using the switch case.\n",
    "        # 4x4\n",
    "        resized_image = resize_real_image(\n",
    "            image=image, params=params, block_idx=0\n",
    "        )\n",
    "    else:\n",
    "        # Find growth index based on global step and growth frequency.\n",
    "        growth_index = tf.cast(\n",
    "            x=tf.floordiv(\n",
    "                x=tf.train.get_or_create_global_step(),\n",
    "                y=params[\"num_steps_until_growth\"],\n",
    "                name=\"resize_real_images_global_step_floordiv\"\n",
    "            ),\n",
    "            dtype=tf.int32,\n",
    "            name=\"resize_real_images_growth_index\"\n",
    "        )\n",
    "\n",
    "        # Switch to case based on number of steps for resized image.\n",
    "        resized_image = tf.switch_case(\n",
    "            branch_index=growth_index,\n",
    "            branch_fns=[\n",
    "                # 4x4\n",
    "                lambda: resize_real_image(\n",
    "                    image=image, params=params, block_idx=0\n",
    "                ),\n",
    "                # 8x8\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(1, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 16x16\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(2, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 32x32\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(3, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 64x64\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(4, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 128x128\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(5, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 256x256\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(6, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 512x512\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(7, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 1024x1024\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(8, len(params[\"conv_num_filters\"]) - 1)\n",
    "                )\n",
    "            ],\n",
    "            name=\"resize_real_images_switch_case_resized_image\"\n",
    "        )\n",
    "        print_obj(\n",
    "            \"resize_real_images\", \"selected resized_image\", resized_image\n",
    "        )\n",
    "\n",
    "    return resized_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_example(protos, params):\n",
    "    \"\"\"Decodes TFRecord file into tensors.\n",
    "\n",
    "    Given protobufs, decode into image and label tensors.\n",
    "\n",
    "    Args:\n",
    "        protos: protobufs from TFRecord file.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Image and label tensors.\n",
    "    \"\"\"\n",
    "    # Create feature schema map for protos.\n",
    "    features = {\n",
    "        \"image_raw\": tf.FixedLenFeature(shape=[], dtype=tf.string),\n",
    "        \"label\": tf.FixedLenFeature(shape=[], dtype=tf.int64)\n",
    "    }\n",
    "\n",
    "    # Parse features from tf.Example.\n",
    "    parsed_features = tf.parse_single_example(\n",
    "        serialized=protos, features=features\n",
    "    )\n",
    "    print_obj(\"\\ndecode_example\", \"features\", features)\n",
    "\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length height * width * depth) to a uint8 tensor with shape\n",
    "    # [height * width * depth].\n",
    "    image = tf.decode_raw(\n",
    "        input_bytes=parsed_features[\"image_raw\"], out_type=tf.uint8\n",
    "    )\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Reshape flattened image back into normal dimensions.\n",
    "    image = tf.reshape(\n",
    "        tensor=image,\n",
    "        shape=[params[\"height\"], params[\"width\"], params[\"depth\"]]\n",
    "    )\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Preprocess image.\n",
    "    image = preprocess_image(image=image, params=params)\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "    label = tf.cast(x=parsed_features[\"label\"], dtype=tf.int32)\n",
    "    print_obj(\"decode_example\", \"label\", label)\n",
    "\n",
    "    return {\"image\": image}, label\n",
    "\n",
    "\n",
    "def read_dataset(filename, mode, batch_size, params):\n",
    "    \"\"\"Reads TF Record data using tf.data, doing necessary preprocessing.\n",
    "\n",
    "    Given filename, mode, batch size, and other parameters, read TF Record\n",
    "    dataset using Dataset API, apply necessary preprocessing, and return an\n",
    "    input function to the Estimator API.\n",
    "\n",
    "    Args:\n",
    "        filename: str, file pattern that to read into our tf.data dataset.\n",
    "        mode: The estimator ModeKeys. Can be TRAIN or EVAL.\n",
    "        batch_size: int, number of examples per batch.\n",
    "        params: dict, dictionary of user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        An input function.\n",
    "    \"\"\"\n",
    "    def _input_fn():\n",
    "        \"\"\"Wrapper input function used by Estimator API to get data tensors.\n",
    "\n",
    "        Returns:\n",
    "            Batched dataset object of dictionary of feature tensors and label\n",
    "                tensor.\n",
    "        \"\"\"\n",
    "        # Create list of files that match pattern.\n",
    "        file_list = tf.gfile.Glob(filename=filename)\n",
    "\n",
    "        # Create dataset from file list.\n",
    "        dataset = tf.data.TFRecordDataset(\n",
    "            filenames=file_list, num_parallel_reads=40\n",
    "        )\n",
    "\n",
    "        # Shuffle and repeat if training with fused op.\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            dataset = dataset.apply(\n",
    "                tf.contrib.data.shuffle_and_repeat(\n",
    "                    buffer_size=50 * batch_size,\n",
    "                    count=None  # indefinitely\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Decode CSV file into a features dictionary of tensors, then batch.\n",
    "        dataset = dataset.apply(\n",
    "            tf.contrib.data.map_and_batch(\n",
    "                map_func=lambda x: decode_example(\n",
    "                    protos=x,\n",
    "                    params=params\n",
    "                ),\n",
    "                batch_size=batch_size,\n",
    "                num_parallel_calls=4\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Prefetch data to improve latency.\n",
    "        dataset = dataset.prefetch(buffer_size=2)\n",
    "\n",
    "        # Create a iterator, then get batch of features from example queue.\n",
    "        batched_dataset = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        return batched_dataset\n",
    "    return _input_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(object):\n",
    "    \"\"\"Generator that takes latent vector input and outputs image.\n",
    "\n",
    "    Fields:\n",
    "        name: str, name of `Generator`.\n",
    "        kernel_regularizer: `l1_l2_regularizer` object, regularizar for kernel\n",
    "            variables.\n",
    "        bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "            variables.\n",
    "        projection_layer: `Dense` layer for projection of noise to image.\n",
    "        conv_layer_blocks: list, lists of block layers for each block.\n",
    "        to_rgb_conv_layers: list, toRGB 1x1 conv layers.\n",
    "        build_generator_tensors: list, tensors used to build layer internals.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_regularizer, bias_regularizer, params, name):\n",
    "        \"\"\"Instantiates and builds generator network.\n",
    "\n",
    "        Args:\n",
    "            kernel_regularizer: `l1_l2_regularizer` object, regularizar for\n",
    "                kernel variables.\n",
    "            bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "                variables.\n",
    "            params: dict, user passed parameters.\n",
    "            name: str, name of generator.\n",
    "        \"\"\"\n",
    "        # Set name of generator.\n",
    "        self.name = name\n",
    "\n",
    "        # Regularizer for kernel weights.\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "\n",
    "        # Regularizer for bias weights.\n",
    "        self.bias_regularizer = bias_regularizer\n",
    "\n",
    "        # Instantiate generator layers.\n",
    "        (self.projection_layer,\n",
    "         self.conv_layer_blocks,\n",
    "         self.to_rgb_conv_layers) = self.instantiate_generator_layers(params)\n",
    "\n",
    "        # Build generator layer internals.\n",
    "        self.build_generator_tensors = self.build_generator_layers(\n",
    "            params\n",
    "        )\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def instantiate_generator_projection_layer(self, params):\n",
    "        \"\"\"Instantiates generator projection layer.\n",
    "\n",
    "        Projection layer projects latent noise vector into an image.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Latent vector projection `Dense` layer.\n",
    "        \"\"\"\n",
    "        # Project latent vectors.\n",
    "        projection_height = params[\"generator_projection_dims\"][0]\n",
    "        projection_width = params[\"generator_projection_dims\"][1]\n",
    "        projection_depth = params[\"generator_projection_dims\"][2]\n",
    "\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     projection_height * projection_width * projection_depth\n",
    "            # )\n",
    "            projection_layer = tf.layers.Dense(\n",
    "                units=projection_height * projection_width * projection_depth,\n",
    "                activation=tf.nn.leaky_relu,\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                kernel_regularizer=self.kernel_regularizer,\n",
    "                bias_regularizer=self.bias_regularizer,\n",
    "                name=\"{}_projection_layer\".format(self.name)\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_generator_projection_layer\",\n",
    "                \"projection_layer\",\n",
    "                projection_layer\n",
    "            )\n",
    "\n",
    "        return projection_layer\n",
    "\n",
    "    def instantiate_generator_base_conv_layer_block(self, params):\n",
    "        \"\"\"Instantiates generator base conv layer block.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of base block conv layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"generator_base_conv_blocks\"][0]\n",
    "\n",
    "            # Create list of base conv layers.\n",
    "            base_conv_layers = [\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=conv_block[i][3],\n",
    "                    kernel_size=conv_block[i][0:2],\n",
    "                    strides=conv_block[i][4:6],\n",
    "                    padding=\"same\",\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_base_layers_conv2d_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        i,\n",
    "                        conv_block[i][0],\n",
    "                        conv_block[i][1],\n",
    "                        conv_block[i][2],\n",
    "                        conv_block[i][3]\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_generator_base_conv_layer_block\",\n",
    "                \"base_conv_layers\",\n",
    "                base_conv_layers\n",
    "            )\n",
    "\n",
    "        return base_conv_layers\n",
    "\n",
    "    def instantiate_generator_growth_layer_block(self, params, block_idx):\n",
    "        \"\"\"Instantiates generator growth layer block.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "            block_idx: int, the current growth block's index.\n",
    "\n",
    "        Returns:\n",
    "            List of growth block conv layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"generator_growth_conv_blocks\"][block_idx]\n",
    "\n",
    "            # Create new inner convolutional layers.\n",
    "            conv_layers = [\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=conv_block[i][3],\n",
    "                    kernel_size=conv_block[i][0:2],\n",
    "                    strides=conv_block[i][4:6],\n",
    "                    padding=\"same\",\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_growth_layers_conv2d_{}_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        block_idx,\n",
    "                        i,\n",
    "                        conv_block[i][0],\n",
    "                        conv_block[i][1],\n",
    "                        conv_block[i][2],\n",
    "                        conv_block[i][3]\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_generator_growth_layer_block\",\n",
    "                \"conv_layers\",\n",
    "                conv_layers\n",
    "            )\n",
    "\n",
    "        return conv_layers\n",
    "\n",
    "    def instantiate_generator_to_rgb_layers(self, params):\n",
    "        \"\"\"Instantiates generator toRGB layers of 1x1 convs.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of toRGB 1x1 conv layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get toRGB layer properties.\n",
    "            to_rgb = [\n",
    "                params[\"generator_to_rgb_layers\"][i][0][:]\n",
    "                for i in range(len(params[\"generator_to_rgb_layers\"]))\n",
    "            ]\n",
    "\n",
    "            # Create list to hold toRGB 1x1 convs.\n",
    "            to_rgb_conv_layers = [\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=to_rgb[i][3],\n",
    "                    kernel_size=to_rgb[i][0:2],\n",
    "                    strides=to_rgb[i][4:6],\n",
    "                    padding=\"same\",\n",
    "                    # Notice there is no activation for toRGB conv layers.\n",
    "                    activation=None,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_to_rgb_layers_conv2d_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        i,\n",
    "                        to_rgb[i][0],\n",
    "                        to_rgb[i][1],\n",
    "                        to_rgb[i][2],\n",
    "                        to_rgb[i][3]\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(to_rgb))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_generator_to_rgb_layers\",\n",
    "                \"to_rgb_conv_layers\",\n",
    "                to_rgb_conv_layers\n",
    "            )\n",
    "\n",
    "        return to_rgb_conv_layers\n",
    "\n",
    "    def instantiate_generator_layers(self, params):\n",
    "        \"\"\"Instantiates layers of generator network.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            projection_layer: `Dense` layer for projection of noise to image.\n",
    "            conv_layer_blocks: list, lists of block layers for each block.\n",
    "            to_rgb_conv_layers: list, toRGB 1x1 conv layers.\n",
    "        \"\"\"\n",
    "        # Instantiate noise-image projection `Dense` layer.\n",
    "        projection_layer = self.instantiate_generator_projection_layer(\n",
    "            params=params\n",
    "        )\n",
    "        print_obj(\n",
    "            \"\\ninstantiate_generator_layers\",\n",
    "            \"projection_layer\",\n",
    "            projection_layer\n",
    "        )\n",
    "\n",
    "        # Instantiate base convolutional `Conv2D` layers, for post-growth.\n",
    "        conv_layer_blocks = [\n",
    "            self.instantiate_generator_base_conv_layer_block(\n",
    "                params=params\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Instantiate growth block `Conv2D` layers.\n",
    "        conv_layer_blocks.extend(\n",
    "            [\n",
    "                self.instantiate_generator_growth_layer_block(\n",
    "                    params=params, block_idx=block_idx\n",
    "                )\n",
    "                for block_idx in range(\n",
    "                    len(params[\"generator_growth_conv_blocks\"])\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        print_obj(\n",
    "            \"instantiate_generator_layers\",\n",
    "            \"conv_layer_blocks\",\n",
    "            conv_layer_blocks\n",
    "        )\n",
    "\n",
    "        # Instantiate toRGB 1x1 `Conv2D` layers.\n",
    "        to_rgb_conv_layers = self.instantiate_generator_to_rgb_layers(\n",
    "            params=params\n",
    "        )\n",
    "        print_obj(\n",
    "            \"instantiate_generator_layers\",\n",
    "            \"to_rgb_conv_layers\",\n",
    "            to_rgb_conv_layers\n",
    "        )\n",
    "\n",
    "        return projection_layer, conv_layer_blocks, to_rgb_conv_layers\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def build_generator_projection_layer(self, params):\n",
    "        \"\"\"Builds generator projection layer internals using call.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Latent vector projection tensor.\n",
    "        \"\"\"\n",
    "        # Project latent vectors.\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     projection_height * projection_width * projection_depth\n",
    "            # )\n",
    "            projection_tensor = self.projection_layer(\n",
    "                inputs=tf.zeros(\n",
    "                    shape=[1, params[\"latent_size\"]], dtype=tf.float32\n",
    "                )\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\nbuild_generator_projection_layer\",\n",
    "                \"projection_tensor\",\n",
    "                projection_tensor\n",
    "            )\n",
    "\n",
    "        return projection_tensor\n",
    "\n",
    "    def build_generator_base_conv_layer_block(self, params):\n",
    "        \"\"\"Builds generator base conv layer block internals using call.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of base conv tensors.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"generator_base_conv_blocks\"][0]\n",
    "\n",
    "            # Create list of base conv layers.\n",
    "            base_conv_tensors = [\n",
    "                # The base conv block is always the 0th one.\n",
    "                self.conv_layer_blocks[0][i](\n",
    "                    inputs=tf.zeros(\n",
    "                        shape=[1] + conv_block[i][0:3], dtype=tf.float32\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\nbuild_generator_base_conv_layer_block\",\n",
    "                \"base_conv_tensors\",\n",
    "                base_conv_tensors\n",
    "            )\n",
    "\n",
    "        return base_conv_tensors\n",
    "\n",
    "    def build_generator_growth_layer_block(\n",
    "            self, params, growth_block_idx):\n",
    "        \"\"\"Builds generator growth block internals through call.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "            growth_block_idx: int, the current growth block's index.\n",
    "\n",
    "        Returns:\n",
    "            List of growth block tensors.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"generator_growth_conv_blocks\"][growth_block_idx]\n",
    "\n",
    "            # Create new inner convolutional layers.\n",
    "            conv_tensors = [\n",
    "                self.conv_layer_blocks[1 + growth_block_idx][i](\n",
    "                    inputs=tf.zeros(\n",
    "                        shape=[1] + conv_block[i][0:3], dtype=tf.float32\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\nbuild_generator_growth_layer_block\",\n",
    "                \"conv_tensors\",\n",
    "                conv_tensors\n",
    "            )\n",
    "\n",
    "        return conv_tensors\n",
    "\n",
    "    def build_generator_to_rgb_layers(self, params):\n",
    "        \"\"\"Builds generator toRGB layers of 1x1 convs internals through call.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of toRGB 1x1 conv tensors.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get toRGB layer properties.\n",
    "            to_rgb = [\n",
    "                params[\"generator_to_rgb_layers\"][i][0][:]\n",
    "                for i in range(len(params[\"generator_to_rgb_layers\"]))\n",
    "            ]\n",
    "\n",
    "            # Create list to hold toRGB 1x1 convs.\n",
    "            to_rgb_conv_tensors = [\n",
    "                self.to_rgb_conv_layers[i](\n",
    "                    inputs=tf.zeros(\n",
    "                        shape=[1] + to_rgb[i][0:3], dtype=tf.float32)\n",
    "                    )\n",
    "                for i in range(len(to_rgb))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\nbuild_generator_to_rgb_layers\",\n",
    "                \"to_rgb_conv_tensors\",\n",
    "                to_rgb_conv_tensors\n",
    "            )\n",
    "\n",
    "        return to_rgb_conv_tensors\n",
    "\n",
    "    def build_generator_layers(self, params):\n",
    "        \"\"\"Builds generator layer internals.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of toRGB tensors.\n",
    "        \"\"\"\n",
    "        # Build projection layer internals using call.\n",
    "        projection_tensor = self.build_generator_projection_layer(\n",
    "            params=params\n",
    "        )\n",
    "        print_obj(\n",
    "            \"\\nbuild_generator_layers\",\n",
    "            \"projection_tensor\",\n",
    "            projection_tensor\n",
    "        )\n",
    "\n",
    "        with tf.control_dependencies(control_inputs=[projection_tensor]):\n",
    "            # Build base convolutional layer block's internals using call.\n",
    "            conv_block_tensors = [\n",
    "                self.build_generator_base_conv_layer_block(\n",
    "                    params=params\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            # Build growth block layer internals through call.\n",
    "            conv_block_tensors.extend(\n",
    "                [\n",
    "                    self.build_generator_growth_layer_block(\n",
    "                        params=params,\n",
    "                        growth_block_idx=growth_block_idx\n",
    "                    )\n",
    "                    for growth_block_idx in range(\n",
    "                        len(params[\"generator_growth_conv_blocks\"])\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            print_obj(\n",
    "                \"build_generator_layers\",\n",
    "                \"conv_block_tensors\",\n",
    "                conv_block_tensors\n",
    "            )\n",
    "\n",
    "            # Flatten block tensor lists of lists into list.\n",
    "            conv_block_tensors = [\n",
    "                item for sublist in conv_block_tensors for item in sublist\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"build_generator_layers\",\n",
    "                \"conv_block_tensors\",\n",
    "                conv_block_tensors\n",
    "            )\n",
    "\n",
    "            with tf.control_dependencies(\n",
    "                    control_inputs=conv_block_tensors):\n",
    "                # Build toRGB 1x1 conv layer internals through call.\n",
    "                to_rgb_conv_tensors = self.build_generator_to_rgb_layers(\n",
    "                    params=params\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"build_generator_layers\",\n",
    "                    \"to_rgb_conv_tensors\",\n",
    "                    to_rgb_conv_tensors\n",
    "                )\n",
    "\n",
    "        return to_rgb_conv_tensors\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def pixel_norm(self, X, epsilon=1e-8):\n",
    "        \"\"\"Normalizes the feature vector in each pixel to unit length.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, image feature vectors.\n",
    "            epsilon: float, small value to add to denominator for numerical\n",
    "                stability.\n",
    "\n",
    "        Returns:\n",
    "            Pixel normalized feature vectors.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(\"{}/pixel_norm\".format(self.name)):\n",
    "            return X * tf.rsqrt(\n",
    "                x=tf.add(\n",
    "                    x=tf.reduce_mean(\n",
    "                        input_tensor=tf.square(x=X), axis=-1, keepdims=True\n",
    "                    ),\n",
    "                    y=epsilon\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def use_pixel_norm(self, X, params, epsilon=1e-8):\n",
    "        \"\"\"Decides based on user parameter whether to use pixel norm or not.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, image feature vectors.\n",
    "            params: dict, user passed parameters.\n",
    "            epsilon: float, small value to add to denominator for numerical\n",
    "                stability.\n",
    "\n",
    "        Returns:\n",
    "            Pixel normalized feature vectors if using pixel norm, else\n",
    "                original feature vectors.\n",
    "        \"\"\"\n",
    "        if params[\"use_pixel_norm\"]:\n",
    "            return self.pixel_norm(X=X, epsilon=epsilon)\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def use_generator_projection_layer(self, Z, params):\n",
    "        \"\"\"Uses projection layer to convert random noise vector into an image.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Latent vector projection tensor.\n",
    "        \"\"\"\n",
    "        # Project latent vectors.\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            if params[\"normalize_latent\"]:\n",
    "                # shape = (cur_batch_size, latent_size)\n",
    "                Z = self.pixel_norm(X=Z, epsilon=params[\"pixel_norm_epsilon\"])\n",
    "\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     projection_height * projection_width * projection_depth\n",
    "            # )\n",
    "            projection_tensor = self.projection_layer(inputs=Z)\n",
    "            print_obj(\n",
    "                \"\\nuse_generator_projection_layer\",\n",
    "                \"projection_tensor\",\n",
    "                projection_tensor\n",
    "            )\n",
    "\n",
    "        # Reshape projection into \"image\".\n",
    "        # shape = (\n",
    "        #     cur_batch_size,\n",
    "        #     projection_height,\n",
    "        #     projection_width,\n",
    "        #     projection_depth\n",
    "        # )\n",
    "        projection_tensor_reshaped = tf.reshape(\n",
    "            tensor=projection_tensor,\n",
    "            shape=[-1] + params[\"generator_projection_dims\"],\n",
    "            name=\"{}_projection_reshaped\".format(self.name)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"use_generator_projection_layer\",\n",
    "            \"projection_tensor_reshaped\",\n",
    "            projection_tensor_reshaped\n",
    "        )\n",
    "\n",
    "        return projection_tensor_reshaped\n",
    "\n",
    "    def fused_conv2d_pixel_norm(self, input_image, conv2d_layer, params):\n",
    "        \"\"\"Fused `Conv2D` layer and pixel norm operation.\n",
    "\n",
    "        Args:\n",
    "            input_image: tensor, input image of rank 4.\n",
    "            conv2d_layer: `Conv2D` layer.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            New image tensor of rank 4.\n",
    "        \"\"\"\n",
    "        conv_output = conv2d_layer(inputs=input_image)\n",
    "        print_obj(\"\\nfused_conv2d_pixel_norm\", \"conv_output\", conv_output)\n",
    "\n",
    "        pixel_norm_output = self.use_pixel_norm(\n",
    "            X=conv_output,\n",
    "            params=params,\n",
    "            epsilon=params[\"pixel_norm_epsilon\"]\n",
    "        )\n",
    "        print_obj(\n",
    "            \"fused_conv2d_pixel_norm\", \"pixel_norm_output\", pixel_norm_output\n",
    "        )\n",
    "\n",
    "        return pixel_norm_output\n",
    "\n",
    "    def upsample_generator_image(self, image, original_image_size, block_idx):\n",
    "        \"\"\"Upsamples generator image.\n",
    "\n",
    "        Args:\n",
    "            image: tensor, image created by generator conv block.\n",
    "            original_image_size: list, the height and width dimensions of the\n",
    "                original image before any growth.\n",
    "            block_idx: int, index of the current generator growth block.\n",
    "\n",
    "        Returns:\n",
    "            Upsampled image tensor.\n",
    "        \"\"\"\n",
    "        # Upsample from s X s to 2s X 2s image.\n",
    "        upsampled_image = tf.image.resize(\n",
    "            images=image,\n",
    "            size=tf.convert_to_tensor(\n",
    "                value=original_image_size,\n",
    "                dtype=tf.int32,\n",
    "                name=\"{}_upsample_generator_image_original_image_size\".format(\n",
    "                    self.name\n",
    "                )\n",
    "            ) * 2 ** block_idx,\n",
    "            method=\"nearest\",\n",
    "            name=\"{}_growth_upsampled_image_{}_{}x{}_{}x{}\".format(\n",
    "                self.name,\n",
    "                block_idx,\n",
    "                original_image_size[0] * 2 ** (block_idx - 1),\n",
    "                original_image_size[1] * 2 ** (block_idx - 1),\n",
    "                original_image_size[0] * 2 ** block_idx,\n",
    "                original_image_size[1] * 2 ** block_idx\n",
    "            )\n",
    "        )\n",
    "        print_obj(\n",
    "            \"\\nupsample_generator_image\",\n",
    "            \"upsampled_image\",\n",
    "            upsampled_image\n",
    "        )\n",
    "\n",
    "        return upsampled_image\n",
    "\n",
    "    def create_base_generator_network(self, Z, params):\n",
    "        \"\"\"Creates base generator network.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            projection_layer: `Dense` layer for projection of noise into image.\n",
    "            to_rgb_conv_layers: list, toRGB 1x1 conv layers.\n",
    "            blocks: list, lists of block layers for each block.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Final network block conv tensor.\n",
    "        \"\"\"\n",
    "        print_obj(\"\\ncreate_base_generator_network\", \"Z\", Z)\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Project latent noise vectors into image.\n",
    "            projection = self.use_generator_projection_layer(\n",
    "                Z=Z, params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_base_generator_network\", \"projection\", projection\n",
    "            )\n",
    "\n",
    "            # Only need the first block and toRGB conv layer for base network.\n",
    "            block_layers = self.conv_layer_blocks[0]\n",
    "            to_rgb_conv_layer = self.to_rgb_conv_layers[0]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            block_conv = projection\n",
    "            for i in range(0, len(block_layers)):\n",
    "                block_conv = self.fused_conv2d_pixel_norm(\n",
    "                    input_image=block_conv,\n",
    "                    conv2d_layer=block_layers[i],\n",
    "                    params=params\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_base_generator_network\",\n",
    "                    \"block_conv_{}\".format(i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Convert convolution to RGB image.\n",
    "            to_rgb_conv = self.fused_conv2d_pixel_norm(\n",
    "                input_image=block_conv,\n",
    "                conv2d_layer=to_rgb_conv_layer,\n",
    "                params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_base_generator_network\", \"to_rgb_conv\", to_rgb_conv\n",
    "            )\n",
    "\n",
    "        return to_rgb_conv\n",
    "\n",
    "    def create_growth_transition_generator_network(\n",
    "            self, Z, original_image_size, alpha_var, params, trans_idx):\n",
    "        \"\"\"Creates growth transition generator network.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            original_image_size: list, the height and width dimensions of the\n",
    "                original image before any growth.\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "            trans_idx: int, index of current growth transition.\n",
    "\n",
    "        Returns:\n",
    "            Weighted sum tensor of growing and shrinking network paths.\n",
    "        \"\"\"\n",
    "        print_obj(\n",
    "            \"\\nEntered create_growth_transition_generator_network\",\n",
    "            \"trans_idx\",\n",
    "            trans_idx\n",
    "        )\n",
    "        print_obj(\"create_growth_transition_generator_network\", \"Z\", Z)\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Project latent noise vectors into image.\n",
    "            projection = self.use_generator_projection_layer(\n",
    "                Z=Z, params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_generator_network\",\n",
    "                \"projection\",\n",
    "                projection\n",
    "            )\n",
    "\n",
    "            # Permanent blocks.\n",
    "            permanent_blocks = self.conv_layer_blocks[0:trans_idx + 1]\n",
    "\n",
    "            # Base block doesn't need any upsampling so handle differently.\n",
    "            base_block_conv_layers = permanent_blocks[0]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            block_conv = projection\n",
    "            for i in range(0, len(base_block_conv_layers)):\n",
    "                block_conv = self.fused_conv2d_pixel_norm(\n",
    "                    input_image=block_conv,\n",
    "                    conv2d_layer=base_block_conv_layers[i],\n",
    "                    params=params\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_growth_transition_generator_network\",\n",
    "                    \"base_block_conv_{}_{}\".format(trans_idx, i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Growth blocks require first prev conv layer's image upsampled.\n",
    "            for i in range(1, len(permanent_blocks)):\n",
    "                # Upsample previous block's image.\n",
    "                block_conv = self.upsample_generator_image(\n",
    "                    image=block_conv,\n",
    "                    original_image_size=original_image_size,\n",
    "                    block_idx=i\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_growth_transition_generator_network\",\n",
    "                    \"upsample_generator_image_block_conv_{}_{}\".format(\n",
    "                        trans_idx, i\n",
    "                    ),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "                block_conv_layers = permanent_blocks[i]\n",
    "                for j in range(0, len(block_conv_layers)):\n",
    "                    block_conv = self.fused_conv2d_pixel_norm(\n",
    "                        input_image=block_conv,\n",
    "                        conv2d_layer=block_conv_layers[j],\n",
    "                        params=params\n",
    "                    )\n",
    "                    print_obj(\n",
    "                        \"create_growth_transition_generator_network\",\n",
    "                        \"block_conv_{}_{}_{}\".format(trans_idx, i, j),\n",
    "                        block_conv\n",
    "                    )\n",
    "\n",
    "            # Upsample most recent block conv image for both side chains.\n",
    "            upsampled_block_conv = self.upsample_generator_image(\n",
    "                image=block_conv,\n",
    "                original_image_size=original_image_size,\n",
    "                block_idx=len(permanent_blocks)\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_generator_network\",\n",
    "                \"upsampled_block_conv_{}\".format(trans_idx),\n",
    "                upsampled_block_conv\n",
    "            )\n",
    "\n",
    "            # Growing side chain.\n",
    "            growing_block_layers = self.conv_layer_blocks[trans_idx + 1]\n",
    "            growing_to_rgb_conv_layer = self.to_rgb_conv_layers[trans_idx + 1]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            block_conv = upsampled_block_conv\n",
    "            for i in range(0, len(growing_block_layers)):\n",
    "                block_conv = self.fused_conv2d_pixel_norm(\n",
    "                    input_image=block_conv,\n",
    "                    conv2d_layer=growing_block_layers[i],\n",
    "                    params=params\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_growth_transition_generator_network\",\n",
    "                    \"growing_block_conv_{}_{}\".format(trans_idx, i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            growing_to_rgb_conv = self.fused_conv2d_pixel_norm(\n",
    "                input_image=block_conv,\n",
    "                conv2d_layer=growing_to_rgb_conv_layer,\n",
    "                params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_generator_network\",\n",
    "                \"growing_to_rgb_conv_{}\".format(trans_idx),\n",
    "                growing_to_rgb_conv\n",
    "            )\n",
    "\n",
    "            # Shrinking side chain.\n",
    "            shrinking_to_rgb_conv_layer = self.to_rgb_conv_layers[trans_idx]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            shrinking_to_rgb_conv = self.fused_conv2d_pixel_norm(\n",
    "                input_image=upsampled_block_conv,\n",
    "                conv2d_layer=shrinking_to_rgb_conv_layer,\n",
    "                params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_generator_network\",\n",
    "                \"shrinking_to_rgb_conv_{}\".format(trans_idx),\n",
    "                shrinking_to_rgb_conv\n",
    "            )\n",
    "\n",
    "            # Weighted sum.\n",
    "            weighted_sum = tf.add(\n",
    "                x=growing_to_rgb_conv * alpha_var,\n",
    "                y=shrinking_to_rgb_conv * (1.0 - alpha_var),\n",
    "                name=\"growth_transition_weighted_sum_{}\".format(trans_idx)\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_generator_network\",\n",
    "                \"weighted_sum_{}\".format(trans_idx),\n",
    "                weighted_sum\n",
    "            )\n",
    "\n",
    "        return weighted_sum\n",
    "\n",
    "    def create_final_generator_network(self, Z, original_image_size, params):\n",
    "        \"\"\"Creates final generator network.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            original_image_size: list, the height and width dimensions of the\n",
    "                original image before any growth.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Final network block conv tensor.\n",
    "        \"\"\"\n",
    "        print_obj(\"\\ncreate_final_generator_network\", \"Z\", Z)\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Project latent noise vectors into image.\n",
    "            projection = self.use_generator_projection_layer(\n",
    "                Z=Z, params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_final_generator_network\", \"projection\", projection\n",
    "            )\n",
    "\n",
    "            # Base block doesn't need any upsampling so handle differently.\n",
    "            base_block_conv_layers = self.conv_layer_blocks[0]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            block_conv = projection\n",
    "            for i in range(0, len(base_block_conv_layers)):\n",
    "                block_conv = self.fused_conv2d_pixel_norm(\n",
    "                    input_image=block_conv,\n",
    "                    conv2d_layer=base_block_conv_layers[i],\n",
    "                    params=params\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_final_generator_network\",\n",
    "                    \"base_block_conv_{}\".format(i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Growth blocks require first prev conv layer's image upsampled.\n",
    "            for i in range(1, len(self.conv_layer_blocks)):\n",
    "                # Upsample previous block's image.\n",
    "                block_conv = self.upsample_generator_image(\n",
    "                    image=block_conv,\n",
    "                    original_image_size=original_image_size,\n",
    "                    block_idx=i\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_final_generator_network\",\n",
    "                    \"upsample_generator_image_block_conv_{}\".format(i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "                block_conv_layers = self.conv_layer_blocks[i]\n",
    "                for j in range(0, len(block_conv_layers)):\n",
    "                    block_conv = self.fused_conv2d_pixel_norm(\n",
    "                        input_image=block_conv,\n",
    "                        conv2d_layer=block_conv_layers[j],\n",
    "                        params=params\n",
    "                    )\n",
    "                    print_obj(\n",
    "                        \"create_final_generator_network\",\n",
    "                        \"block_conv_{}_{}\".format(i, j),\n",
    "                        block_conv\n",
    "                    )\n",
    "\n",
    "            # Only need the last toRGB conv layer.\n",
    "            to_rgb_conv_layer = self.to_rgb_conv_layers[-1]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            to_rgb_conv = self.fused_conv2d_pixel_norm(\n",
    "                input_image=block_conv,\n",
    "                conv2d_layer=to_rgb_conv_layer,\n",
    "                params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_final_generator_network\", \"to_rgb_conv\", to_rgb_conv\n",
    "            )\n",
    "\n",
    "        return to_rgb_conv\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def switch_case_generator_outputs(\n",
    "            self, Z, original_image_size, alpha_var, params, growth_index):\n",
    "        \"\"\"Uses switch case to use the correct network to generate images.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            original_image_size: list, the height and width dimensions of the\n",
    "                original image before any growth.\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "            growth_index: int, current growth stage.\n",
    "\n",
    "        Returns:\n",
    "            Generated image output tensor.\n",
    "        \"\"\"\n",
    "        # Switch to case based on number of steps for gen outputs.\n",
    "        generated_outputs = tf.switch_case(\n",
    "            branch_index=growth_index,\n",
    "            branch_fns=[\n",
    "                # 4x4\n",
    "                lambda: self.create_base_generator_network(\n",
    "                    Z=Z, params=params\n",
    "                ),\n",
    "                # 8x8\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(0, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 16x16\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(1, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 32x32\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(2, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 64x64\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(3, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 128x128\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(4, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 256x256\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(5, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 512x512\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(6, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 1024x1024\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(7, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 1024x1024\n",
    "                lambda: self.create_final_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    params=params\n",
    "                )\n",
    "            ],\n",
    "            name=\"{}_switch_case_generated_outputs\".format(self.name)\n",
    "        )\n",
    "\n",
    "        return generated_outputs\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def get_train_eval_generator_outputs(self, Z, alpha_var, params):\n",
    "        \"\"\"Uses generator network and returns image for train/eval.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Generated image output tensor of shape\n",
    "                [cur_batch_size, image_size, image_size, depth].\n",
    "        \"\"\"\n",
    "        print_obj(\"\\nget_train_eval_generator_outputs\", \"Z\", Z)\n",
    "\n",
    "        # Get generator's output image tensor.\n",
    "        train_steps = params[\"train_steps\"] + params[\"prev_train_steps\"]\n",
    "        num_steps_until_growth = params[\"num_steps_until_growth\"]\n",
    "        num_stages = train_steps // num_steps_until_growth\n",
    "        if (num_stages <= 0 or len(params[\"conv_num_filters\"]) == 1):\n",
    "            print(\n",
    "                \"\\nget_train_eval_generator_outputs: NOT GOING TO GROW, SKIP SWITCH CASE!\"\n",
    "            )\n",
    "            # If never going to grow, no sense using the switch case.\n",
    "            # 4x4\n",
    "            generated_outputs = self.create_base_generator_network(\n",
    "                Z=Z, params=params\n",
    "            )\n",
    "        else:\n",
    "            # Find growth index based on global step and growth frequency.\n",
    "            growth_index = tf.cast(\n",
    "                x=tf.floordiv(\n",
    "                    x=tf.train.get_or_create_global_step(),\n",
    "                    y=params[\"num_steps_until_growth\"],\n",
    "                    name=\"{}_global_step_floordiv\".format(self.name)\n",
    "                ),\n",
    "                dtype=tf.int32,\n",
    "                name=\"{}_growth_index\".format(self.name)\n",
    "            )\n",
    "\n",
    "            # Switch to case based on number of steps for gen outputs.\n",
    "            generated_outputs = self.switch_case_generator_outputs(\n",
    "                Z=Z,\n",
    "                original_image_size=params[\"generator_projection_dims\"][0:2],\n",
    "                alpha_var=alpha_var,\n",
    "                params=params,\n",
    "                growth_index=growth_index\n",
    "            )\n",
    "\n",
    "        print_obj(\n",
    "            \"\\nget_train_eval_generator_outputs\",\n",
    "            \"generated_outputs\",\n",
    "            generated_outputs\n",
    "        )\n",
    "\n",
    "        # Wrap generated outputs in a control dependency for the build\n",
    "        # generator tensors to ensure generator internals are built.\n",
    "        with tf.control_dependencies(\n",
    "                control_inputs=self.build_generator_tensors):\n",
    "            generated_outputs = tf.identity(\n",
    "                input=generated_outputs,\n",
    "                name=\"{}_generated_outputs_identity\".format(self.name)\n",
    "            )\n",
    "\n",
    "        return generated_outputs\n",
    "\n",
    "    def get_predict_generator_outputs(self, Z, params, block_idx):\n",
    "        \"\"\"Uses generator network and returns image for predict.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            params: dict, user passed parameters.\n",
    "            block_idx: int, current conv layer block's index.\n",
    "\n",
    "        Returns:\n",
    "            Generated image output tensor of shape\n",
    "                [cur_batch_size, image_size, image_size, depth] or list of\n",
    "                them for each resolution.\n",
    "        \"\"\"\n",
    "        print_obj(\"\\nget_predict_generator_outputs\", \"Z\", Z)\n",
    "\n",
    "        # Get generator's generated image.\n",
    "        if block_idx == 0:\n",
    "            # 4x4\n",
    "            generated_outputs = self.create_base_generator_network(\n",
    "                Z=Z, params=params\n",
    "            )\n",
    "        elif block_idx < len(params[\"conv_num_filters\"]) - 1:\n",
    "            # 8x8 through 512x512\n",
    "            generated_outputs = self.create_growth_transition_generator_network(\n",
    "                Z=Z,\n",
    "                original_image_size=params[\"generator_projection_dims\"][0:2],\n",
    "                alpha_var=tf.ones(shape=[], dtype=tf.float32),\n",
    "                params=params,\n",
    "                trans_idx=block_idx - 1\n",
    "            )\n",
    "        else:\n",
    "            # 1024x1024\n",
    "            generated_outputs = self.create_final_generator_network(\n",
    "                Z=Z,\n",
    "                original_image_size=params[\"generator_projection_dims\"][0:2],\n",
    "                params=params\n",
    "            )\n",
    "        print_obj(\n",
    "            \"get_predict_generator_outputs\",\n",
    "            \"generated_outputs\",\n",
    "            generated_outputs\n",
    "        )\n",
    "\n",
    "        return generated_outputs\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def get_generator_loss(self, fake_logits, params):\n",
    "        \"\"\"Gets generator loss.\n",
    "\n",
    "        Args:\n",
    "            fake_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "                discriminator having processed generator's output image.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Generator's total loss tensor of shape [].\n",
    "        \"\"\"\n",
    "        # Calculate base generator loss.\n",
    "        generator_loss = -tf.reduce_mean(\n",
    "            input_tensor=fake_logits,\n",
    "            name=\"{}_loss\".format(self.name)\n",
    "        )\n",
    "        print_obj(\"\\nget_generator_loss\", \"generator_loss\", generator_loss)\n",
    "\n",
    "        # Get generator regularization losses.\n",
    "        generator_reg_loss = get_regularization_loss(\n",
    "            lambda1=params[\"generator_l1_regularization_scale\"],\n",
    "            lambda2=params[\"generator_l2_regularization_scale\"],\n",
    "            scope=self.name\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_generator_loss\",\n",
    "            \"generator_reg_loss\",\n",
    "            generator_reg_loss\n",
    "        )\n",
    "\n",
    "        # Combine losses for total losses.\n",
    "        generator_total_loss = tf.math.add(\n",
    "            x=generator_loss,\n",
    "            y=generator_reg_loss,\n",
    "            name=\"{}_total_loss\".format(self.name)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_generator_loss\", \"generator_total_loss\", generator_total_loss\n",
    "        )\n",
    "\n",
    "        return generator_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## discriminator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(object):\n",
    "    \"\"\"Discriminator that takes image input and outputs logits.\n",
    "\n",
    "    Fields:\n",
    "        name: str, name of `Discriminator`.\n",
    "        kernel_regularizer: `l1_l2_regularizer` object, regularizar for kernel\n",
    "            variables.\n",
    "        bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "            variables.\n",
    "        from_rgb_conv_layers: list, fromRGB 1x1 `Conv2D` layers.\n",
    "        conv_layer_blocks: list, lists of `Conv2D` block layers for each\n",
    "            block.\n",
    "        transition_downsample_layers: list, `AveragePooling2D` layers for\n",
    "            downsampling shrinking transition paths.\n",
    "        flatten_layer: `Flatten` layer prior to logits layer.\n",
    "        logits_layer: `Dense` layer for logits.\n",
    "        build_discriminator_tensors: list, tensors used to build layer\n",
    "            internals.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_regularizer, bias_regularizer, params, name):\n",
    "        \"\"\"Instantiates and builds discriminator network.\n",
    "\n",
    "        Args:\n",
    "            kernel_regularizer: `l1_l2_regularizer` object, regularizar for\n",
    "                kernel variables.\n",
    "            bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "                variables.\n",
    "            params: dict, user passed parameters.\n",
    "            name: str, name of discriminator.\n",
    "        \"\"\"\n",
    "        # Set name of discriminator.\n",
    "        self.name = name\n",
    "\n",
    "        # Regularizer for kernel weights.\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "\n",
    "        # Regularizer for bias weights.\n",
    "        self.bias_regularizer = bias_regularizer\n",
    "\n",
    "        # Instantiate discriminator layers.\n",
    "        (self.from_rgb_conv_layers,\n",
    "         self.conv_layer_blocks,\n",
    "         self.transition_downsample_layers,\n",
    "         self.flatten_layer,\n",
    "         self.logits_layer) = self.instantiate_discriminator_layers(\n",
    "            params\n",
    "        )\n",
    "\n",
    "        # Build discriminator layer internals.\n",
    "        self.build_discriminator_tensors = self.build_discriminator_layers(\n",
    "            params\n",
    "        )\n",
    "\n",
    "    def instantiate_discriminator_from_rgb_layers(self, params):\n",
    "        \"\"\"Instantiates discriminator fromRGB layers of 1x1 convs.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of fromRGB 1x1 Conv2D layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get fromRGB layer properties.\n",
    "            from_rgb = [\n",
    "                params[\"discriminator_from_rgb_layers\"][i][0][:]\n",
    "                for i in range(len(params[\"discriminator_from_rgb_layers\"]))\n",
    "            ]\n",
    "\n",
    "            # Create list to hold toRGB 1x1 convs.\n",
    "            from_rgb_conv_layers = [\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=from_rgb[i][3],\n",
    "                    kernel_size=from_rgb[i][0:2],\n",
    "                    strides=from_rgb[i][4:6],\n",
    "                    padding=\"same\",\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_from_rgb_layers_conv2d_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        i,\n",
    "                        from_rgb[i][0],\n",
    "                        from_rgb[i][1],\n",
    "                        from_rgb[i][2],\n",
    "                        from_rgb[i][3]\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(from_rgb))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_discriminator_from_rgb_layers\",\n",
    "                \"from_rgb_conv_layers\",\n",
    "                from_rgb_conv_layers\n",
    "            )\n",
    "\n",
    "        return from_rgb_conv_layers\n",
    "\n",
    "    def instantiate_discriminator_base_conv_layer_block(self, params):\n",
    "        \"\"\"Instantiates discriminator base conv layer block.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of base conv layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"discriminator_base_conv_blocks\"][0]\n",
    "\n",
    "            # Create list of base conv layers.\n",
    "            base_conv_layers = [\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=conv_block[i][3],\n",
    "                    kernel_size=conv_block[i][0:2],\n",
    "                    strides=conv_block[i][4:6],\n",
    "                    padding=\"same\",\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_base_layers_conv2d_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        i,\n",
    "                        conv_block[i][0],\n",
    "                        conv_block[i][1],\n",
    "                        conv_block[i][2],\n",
    "                        conv_block[i][3]\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block) - 1)\n",
    "            ]\n",
    "\n",
    "            # Have valid padding for layer just before flatten and logits.\n",
    "            base_conv_layers.append(\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=conv_block[-1][3],\n",
    "                    kernel_size=conv_block[-1][0:2],\n",
    "                    strides=conv_block[-1][4:6],\n",
    "                    padding=\"valid\",\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_base_layers_conv2d_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        len(conv_block) - 1,\n",
    "                        conv_block[-1][0],\n",
    "                        conv_block[-1][1],\n",
    "                        conv_block[-1][2],\n",
    "                        conv_block[-1][3]\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_discriminator_base_conv_layer_block\",\n",
    "                \"base_conv_layers\",\n",
    "                base_conv_layers\n",
    "            )\n",
    "\n",
    "        return base_conv_layers\n",
    "\n",
    "    def instantiate_discriminator_growth_layer_block(self, params, block_idx):\n",
    "        \"\"\"Instantiates discriminator growth block layers.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "            block_idx: int, the current growth block's index.\n",
    "\n",
    "        Returns:\n",
    "            List of growth block layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"discriminator_growth_conv_blocks\"][block_idx]\n",
    "\n",
    "            # Create new inner convolutional layers.\n",
    "            conv_layers = [\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=conv_block[i][3],\n",
    "                    kernel_size=conv_block[i][0:2],\n",
    "                    strides=conv_block[i][4:6],\n",
    "                    padding=\"same\",\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_growth_layers_conv2d_{}_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        block_idx,\n",
    "                        i,\n",
    "                        conv_block[i][0],\n",
    "                        conv_block[i][1],\n",
    "                        conv_block[i][2],\n",
    "                        conv_block[i][3]\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_discriminator_growth_layer_block\",\n",
    "                \"conv_layers\",\n",
    "                conv_layers\n",
    "            )\n",
    "\n",
    "            # Down sample from 2s X 2s to s X s image.\n",
    "            downsampled_image_layer = tf.layers.AveragePooling2D(\n",
    "                pool_size=(2, 2),\n",
    "                strides=(2, 2),\n",
    "                name=\"{}_growth_downsampled_image_{}\".format(\n",
    "                    self.name,\n",
    "                    block_idx\n",
    "                )\n",
    "            )\n",
    "            print_obj(\n",
    "                \"instantiate_discriminator_growth_layer_block\",\n",
    "                \"downsampled_image_layer\",\n",
    "                downsampled_image_layer\n",
    "            )\n",
    "\n",
    "        return conv_layers + [downsampled_image_layer]\n",
    "\n",
    "    def instantiate_discriminator_growth_transition_downsample_layers(\n",
    "            self, params):\n",
    "        \"\"\"Instantiates discriminator growth transition downsample layers.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of growth transition downsample layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Down sample from 2s X 2s to s X s image.\n",
    "            downsample_layers = [\n",
    "                tf.layers.AveragePooling2D(\n",
    "                    pool_size=(2, 2),\n",
    "                    strides=(2, 2),\n",
    "                    name=\"{}_growth_transition_downsample_layer_{}\".format(\n",
    "                        self.name,\n",
    "                        layer_idx\n",
    "                    )\n",
    "                )\n",
    "                for layer_idx in range(\n",
    "                    1 + len(params[\"discriminator_growth_conv_blocks\"])\n",
    "                )\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_discriminator_growth_transition_downsample_layers\",\n",
    "                \"downsample_layers\",\n",
    "                downsample_layers\n",
    "            )\n",
    "\n",
    "        return downsample_layers\n",
    "\n",
    "    def instantiate_discriminator_logits_layer(self):\n",
    "        \"\"\"Instantiates discriminator flatten and logits layers.\n",
    "\n",
    "        Returns:\n",
    "            Flatten and logits layers of discriminator.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Flatten layer to ready final block conv tensor for dense layer.\n",
    "            flatten_layer = tf.layers.Flatten(\n",
    "                name=\"{}_flatten_layer\".format(self.name)\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\ncreate_discriminator_logits_layer\",\n",
    "                \"flatten_layer\",\n",
    "                flatten_layer\n",
    "            )\n",
    "\n",
    "            # Final linear layer for logits.\n",
    "            logits_layer = tf.layers.Dense(\n",
    "                units=1,\n",
    "                activation=None,\n",
    "                kernel_regularizer=self.kernel_regularizer,\n",
    "                bias_regularizer=self.bias_regularizer,\n",
    "                name=\"{}_layers_dense_logits\".format(self.name)\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_discriminator_network\",\n",
    "                \"logits_layer\",\n",
    "                logits_layer\n",
    "            )\n",
    "\n",
    "        return flatten_layer, logits_layer\n",
    "\n",
    "    def instantiate_discriminator_layers(self, params):\n",
    "        \"\"\"Instantiates layers of discriminator network.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            from_rgb_conv_layers: list, fromRGB 1x1 `Conv2D` layers.\n",
    "            conv_layer_blocks: list, lists of `Conv2D` block layers for each\n",
    "                block.\n",
    "            transition_downsample_layers: list, `AveragePooling2D` layers for\n",
    "                downsampling shrinking transition paths.\n",
    "            flatten_layer: `Flatten` layer prior to logits layer.\n",
    "            logits_layer: `Dense` layer for logits.\n",
    "        \"\"\"\n",
    "        # Instantiate fromRGB 1x1 `Conv2D` layers.\n",
    "        from_rgb_conv_layers = self.instantiate_discriminator_from_rgb_layers(\n",
    "            params=params\n",
    "        )\n",
    "        print_obj(\n",
    "            \"instantiate_discriminator_layers\",\n",
    "            \"from_rgb_conv_layers\",\n",
    "            from_rgb_conv_layers\n",
    "        )\n",
    "\n",
    "        # Instantiate base conv block's `Conv2D` layers, for post-growth.\n",
    "        conv_layer_blocks = [\n",
    "            self.instantiate_discriminator_base_conv_layer_block(\n",
    "                params=params\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Instantiate growth `Conv2D` layer blocks.\n",
    "        conv_layer_blocks.extend(\n",
    "            [\n",
    "                self.instantiate_discriminator_growth_layer_block(\n",
    "                    params=params,\n",
    "                    block_idx=block_idx\n",
    "                )\n",
    "                for block_idx in range(\n",
    "                    len(params[\"discriminator_growth_conv_blocks\"])\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        print_obj(\n",
    "            \"instantiate_discriminator_layers\",\n",
    "            \"conv_layer_blocks\",\n",
    "            conv_layer_blocks\n",
    "        )\n",
    "\n",
    "        # Instantiate transition downsample `AveragePooling2D` layers.\n",
    "        transition_downsample_layers = (\n",
    "            self.instantiate_discriminator_growth_transition_downsample_layers(\n",
    "                params=params\n",
    "            )\n",
    "        )\n",
    "        print_obj(\n",
    "            \"instantiate_discriminator_layers\",\n",
    "            \"transition_downsample_layers\",\n",
    "            transition_downsample_layers\n",
    "        )\n",
    "\n",
    "        # Instantiate `Flatten` and `Dense` logits layers.\n",
    "        (flatten_layer,\n",
    "         logits_layer) = self.instantiate_discriminator_logits_layer()\n",
    "        print_obj(\n",
    "            \"instantiate_discriminator_layers\",\n",
    "            \"flatten_layer\",\n",
    "            flatten_layer\n",
    "        )\n",
    "        print_obj(\n",
    "            \"instantiate_discriminator_layers\",\n",
    "            \"logits_layer\",\n",
    "            logits_layer\n",
    "        )\n",
    "\n",
    "        return (from_rgb_conv_layers,\n",
    "                conv_layer_blocks,\n",
    "                transition_downsample_layers,\n",
    "                flatten_layer,\n",
    "                logits_layer)\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def build_discriminator_from_rgb_layers(self, params):\n",
    "        \"\"\"Creates discriminator fromRGB layers of 1x1 convs.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of tensors from fromRGB 1x1 `Conv2D` layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get fromRGB layer properties.\n",
    "            from_rgb = [\n",
    "                params[\"discriminator_from_rgb_layers\"][i][0][:]\n",
    "                for i in range(len(params[\"discriminator_from_rgb_layers\"]))\n",
    "            ]\n",
    "\n",
    "            # Create list to hold fromRGB 1x1 convs.\n",
    "            from_rgb_conv_tensors = [\n",
    "                self.from_rgb_conv_layers[i](\n",
    "                    inputs=tf.zeros(\n",
    "                        shape=[1] + from_rgb[i][0:3], dtype=tf.float32\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(from_rgb))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\nbuild_discriminator_from_rgb_layers\",\n",
    "                \"from_rgb_conv_tensors\",\n",
    "                from_rgb_conv_tensors\n",
    "            )\n",
    "\n",
    "        return from_rgb_conv_tensors\n",
    "\n",
    "    def build_discriminator_base_conv_layer_block(self, params):\n",
    "        \"\"\"Creates discriminator base conv layer block.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of tensors from base `Conv2D` layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"discriminator_base_conv_blocks\"][0]\n",
    "\n",
    "            # The base conv block is always the 0th one.\n",
    "            base_conv_layer_block = self.conv_layer_blocks[0]\n",
    "\n",
    "            # Minibatch stddev comes before first base conv layer,\n",
    "            # creating 1 extra feature map.\n",
    "            if params[\"use_minibatch_stddev\"]:\n",
    "                # Therefore, the number of input channels will be 1 higher\n",
    "                # for first base conv block.\n",
    "                num_in_channels = conv_block[0][3] + 1\n",
    "            else:\n",
    "                num_in_channels = conv_block[0][3]\n",
    "\n",
    "            # Get first base conv layer from list.\n",
    "            first_base_conv_layer = base_conv_layer_block[0]\n",
    "\n",
    "            # Build first layer with bigger tensor.\n",
    "            base_conv_tensors = [\n",
    "                first_base_conv_layer(\n",
    "                    inputs=tf.zeros(\n",
    "                        shape=[1] + conv_block[0][0:2] + [num_in_channels],\n",
    "                        dtype=tf.float32\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            # Now build the rest of the base conv block layers, store in list.\n",
    "            base_conv_tensors.extend(\n",
    "                [\n",
    "                    base_conv_layer_block[i](\n",
    "                        inputs=tf.zeros(\n",
    "                            shape=[1] + conv_block[i][0:3], dtype=tf.float32\n",
    "                        )\n",
    "                    )\n",
    "                    for i in range(1, len(conv_block))\n",
    "                ]\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\nbuild_discriminator_base_conv_layer_block\",\n",
    "                \"base_conv_tensors\",\n",
    "                base_conv_tensors\n",
    "            )\n",
    "\n",
    "        return base_conv_tensors\n",
    "\n",
    "    def build_discriminator_growth_layer_block(self, params, block_idx):\n",
    "        \"\"\"Creates discriminator growth block.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "            block_idx: int, the current growth block's index.\n",
    "\n",
    "        Returns:\n",
    "            List of tensors from growth block `Conv2D` layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"discriminator_growth_conv_blocks\"][block_idx]\n",
    "\n",
    "            # Create new inner convolutional layers.\n",
    "            conv_tensors = [\n",
    "                self.conv_layer_blocks[1 + block_idx][i](\n",
    "                    inputs=tf.zeros(\n",
    "                        shape=[1] + conv_block[i][0:3], dtype=tf.float32\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\nbuild_discriminator_growth_layer_block\",\n",
    "                \"conv_tensors\",\n",
    "                conv_tensors\n",
    "            )\n",
    "\n",
    "        return conv_tensors\n",
    "\n",
    "    def build_discriminator_logits_layer(self, params):\n",
    "        \"\"\"Builds flatten and logits layer internals using call.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Final logits tensor of discriminator.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            block_conv_size = params[\"discriminator_base_conv_blocks\"][-1][-1][3]\n",
    "\n",
    "            # Flatten final block conv tensor.\n",
    "            block_conv_flat = self.flatten_layer(\n",
    "                inputs=tf.zeros(\n",
    "                    shape=[1, 1, 1, block_conv_size],\n",
    "                    dtype=tf.float32\n",
    "                )\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\nbuild_discriminator_logits_layer\",\n",
    "                \"block_conv_flat\",\n",
    "                block_conv_flat\n",
    "            )\n",
    "\n",
    "            # Final linear layer for logits.\n",
    "            logits = self.logits_layer(inputs=block_conv_flat)\n",
    "            print_obj(\"build_discriminator_logits_layer\", \"logits\", logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def build_discriminator_layers(self, params):\n",
    "        \"\"\"Builds discriminator layer internals.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Logits tensor.\n",
    "        \"\"\"\n",
    "        # Build fromRGB 1x1 `Conv2D` layers internals through call.\n",
    "        from_rgb_conv_tensors = self.build_discriminator_from_rgb_layers(\n",
    "            params=params\n",
    "        )\n",
    "        print_obj(\n",
    "            \"\\nbuild_discriminator_layers\",\n",
    "            \"from_rgb_conv_tensors\",\n",
    "            from_rgb_conv_tensors\n",
    "        )\n",
    "\n",
    "        with tf.control_dependencies(control_inputs=from_rgb_conv_tensors):\n",
    "            # Create base convolutional block's layer internals using call.\n",
    "            conv_block_tensors = [\n",
    "                self.build_discriminator_base_conv_layer_block(\n",
    "                    params=params\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            # Build growth `Conv2D` layer block internals through call.\n",
    "            conv_block_tensors.extend(\n",
    "                [\n",
    "                    self.build_discriminator_growth_layer_block(\n",
    "                        params=params, block_idx=block_idx\n",
    "                    )\n",
    "                    for block_idx in range(\n",
    "                       len(params[\"discriminator_growth_conv_blocks\"])\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Flatten conv block tensor lists of lists into list.\n",
    "            conv_block_tensors = [\n",
    "                item for sublist in conv_block_tensors for item in sublist\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"build_discriminator_layers\",\n",
    "                \"conv_block_tensors\",\n",
    "                conv_block_tensors\n",
    "            )\n",
    "\n",
    "            with tf.control_dependencies(control_inputs=conv_block_tensors):\n",
    "                # Build logits layer internals using call.\n",
    "                logits_tensor = self.build_discriminator_logits_layer(\n",
    "                    params=params\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"build_discriminator_layers\",\n",
    "                    \"logits_tensor\",\n",
    "                    logits_tensor\n",
    "                )\n",
    "\n",
    "        return logits_tensor\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def minibatch_stddev_common(\n",
    "            self,\n",
    "            variance,\n",
    "            tile_multiples,\n",
    "            params,\n",
    "            caller):\n",
    "        \"\"\"Adds minibatch stddev feature map to image using grouping.\n",
    "\n",
    "        This is the code that is common between the grouped and ungroup\n",
    "        minibatch stddev functions.\n",
    "\n",
    "        Args:\n",
    "            variance: tensor, variance of minibatch or minibatch groups.\n",
    "            tile_multiples: list, length 4, used to tile input to final shape\n",
    "                input_dims[i] * mutliples[i].\n",
    "            params: dict, user passed parameters.\n",
    "            caller: str, name of the calling function.\n",
    "\n",
    "        Returns:\n",
    "            Minibatch standard deviation feature map image added to\n",
    "                channels of shape\n",
    "                [cur_batch_size, image_size, image_size, 1].\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(\n",
    "                \"{}/{}_minibatch_stddev\".format(self.name, caller)):\n",
    "            # Calculate standard deviation over the group plus small epsilon.\n",
    "            # shape = (\n",
    "            #     {\"grouped\": cur_batch_size / group_size, \"ungrouped\": 1},\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     num_channels\n",
    "            # )\n",
    "            stddev = tf.sqrt(\n",
    "                x=variance + 1e-8, name=\"{}_stddev\".format(caller)\n",
    "            )\n",
    "            print_obj(\n",
    "                \"minibatch_stddev_common\", \"{}_stddev\".format(caller), stddev\n",
    "            )\n",
    "\n",
    "            # Take average over feature maps and pixels.\n",
    "            if params[\"minibatch_stddev_averaging\"]:\n",
    "                # grouped shape = (cur_batch_size / group_size, 1, 1, 1)\n",
    "                # ungrouped shape = (1, 1, 1, 1)\n",
    "                stddev = tf.reduce_mean(\n",
    "                    input_tensor=stddev,\n",
    "                    axis=[1, 2, 3],\n",
    "                    keepdims=True,\n",
    "                    name=\"{}_stddev_average\".format(caller)\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"minibatch_stddev_common\",\n",
    "                    \"{}_stddev_average\".format(caller),\n",
    "                    stddev\n",
    "                )\n",
    "\n",
    "            # Replicate over group and pixels.\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     1\n",
    "            # )\n",
    "            stddev_feature_map = tf.tile(\n",
    "                input=stddev,\n",
    "                multiples=tile_multiples,\n",
    "                name=\"{}_stddev_feature_map\".format(caller)\n",
    "            )\n",
    "            print_obj(\n",
    "                \"minibatch_stddev_common\",\n",
    "                \"{}_stddev_feature_map\".format(caller),\n",
    "                stddev_feature_map\n",
    "            )\n",
    "\n",
    "        return stddev_feature_map\n",
    "\n",
    "    def grouped_minibatch_stddev(\n",
    "            self,\n",
    "            X,\n",
    "            cur_batch_size,\n",
    "            static_image_shape,\n",
    "            params,\n",
    "            group_size):\n",
    "        \"\"\"Adds minibatch stddev feature map to image using grouping.\n",
    "\n",
    "        Args:\n",
    "            X: tf.float32 tensor, image of shape\n",
    "                [cur_batch_size, image_size, image_size, num_channels].\n",
    "            cur_batch_size: tf.int64 tensor, the dynamic batch size (in case\n",
    "                of partial batch).\n",
    "            static_image_shape: list, the static shape of each image.\n",
    "            params: dict, user passed parameters.\n",
    "            group_size: int, size of image groups.\n",
    "\n",
    "        Returns:\n",
    "            Minibatch standard deviation feature map image added to\n",
    "                channels of shape\n",
    "                [cur_batch_size, image_size, image_size, 1].\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(\n",
    "                \"{}/grouped_minibatch_stddev\".format(self.name)):\n",
    "            # The group size should be less than or equal to the batch size.\n",
    "            # shape = ()\n",
    "            group_size = tf.minimum(\n",
    "                x=group_size, y=cur_batch_size, name=\"group_size\"\n",
    "            )\n",
    "            print_obj(\"grouped_minibatch_stddev\", \"group_size\", group_size)\n",
    "\n",
    "            # Split minibatch into M groups of size group_size, rank 5 tensor.\n",
    "            # shape = (\n",
    "            #     group_size,\n",
    "            #     cur_batch_size / group_size,\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     num_channels\n",
    "            # )\n",
    "            grouped_image = tf.reshape(\n",
    "                tensor=X,\n",
    "                shape=[group_size, -1] + static_image_shape,\n",
    "                name=\"grouped_image\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"grouped_minibatch_stddev\",\n",
    "                \"grouped_image\",\n",
    "                grouped_image\n",
    "            )\n",
    "\n",
    "            # Find the mean of each group.\n",
    "            # shape = (\n",
    "            #     1,\n",
    "            #     cur_batch_size / group_size,\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     num_channels\n",
    "            # )\n",
    "            grouped_mean = tf.reduce_mean(\n",
    "                input_tensor=grouped_image,\n",
    "                axis=0,\n",
    "                keepdims=True,\n",
    "                name=\"grouped_mean\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"grouped_minibatch_stddev\", \"grouped_mean\", grouped_mean\n",
    "            )\n",
    "\n",
    "            # Center each group using the mean.\n",
    "            # shape = (\n",
    "            #     group_size,\n",
    "            #     cur_batch_size / group_size,\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     num_channels\n",
    "            # )\n",
    "            centered_grouped_image = tf.subtract(\n",
    "                x=grouped_image, y=grouped_mean, name=\"centered_grouped_image\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"grouped_minibatch_stddev\",\n",
    "                \"centered_grouped_image\",\n",
    "                centered_grouped_image\n",
    "            )\n",
    "\n",
    "            # Calculate variance over group.\n",
    "            # shape = (\n",
    "            #     cur_batch_size / group_size,\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     num_channels\n",
    "            # )\n",
    "            grouped_variance = tf.reduce_mean(\n",
    "                input_tensor=tf.square(x=centered_grouped_image),\n",
    "                axis=0,\n",
    "                name=\"grouped_variance\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"grouped_minibatch_stddev\",\n",
    "                \"grouped_variance\",\n",
    "                grouped_variance\n",
    "            )\n",
    "\n",
    "            # Get stddev image using ops common to both grouped & ungrouped.\n",
    "            stddev_feature_map = self.minibatch_stddev_common(\n",
    "                variance=grouped_variance,\n",
    "                tile_multiples=[group_size] + static_image_shape[0:2] + [1],\n",
    "                params=params,\n",
    "                caller=\"grouped\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"grouped_minibatch_stddev\",\n",
    "                \"stddev_feature_map\",\n",
    "                stddev_feature_map\n",
    "            )\n",
    "\n",
    "        return stddev_feature_map\n",
    "\n",
    "    def ungrouped_minibatch_stddev(\n",
    "            self,\n",
    "            X,\n",
    "            cur_batch_size,\n",
    "            static_image_shape,\n",
    "            params):\n",
    "        \"\"\"Adds minibatch stddev feature map added to image channels.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, image of shape\n",
    "                [cur_batch_size, image_size, image_size, num_channels].\n",
    "            cur_batch_size: tf.int64 tensor, the dynamic batch size (in case\n",
    "                of partial batch).\n",
    "            static_image_shape: list, the static shape of each image.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Minibatch standard deviation feature map image added to\n",
    "                channels of shape\n",
    "                [cur_batch_size, image_size, image_size, 1].\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(\n",
    "                \"{}/ungrouped_minibatch_stddev\".format(self.name)):\n",
    "            # Find the mean of each group.\n",
    "            # shape = (\n",
    "            #     1,\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     num_channels\n",
    "            # )\n",
    "            mean = tf.reduce_mean(\n",
    "                input_tensor=X, axis=0, keepdims=True, name=\"mean\"\n",
    "            )\n",
    "            print_obj(\"ungrouped_minibatch_stddev\", \"mean\", mean)\n",
    "\n",
    "            # Center each group using the mean.\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     num_channels\n",
    "            # )\n",
    "            centered_image = tf.subtract(\n",
    "                x=X, y=mean, name=\"centered_image\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"ungrouped_minibatch_stddev\",\n",
    "                \"centered_image\",\n",
    "                centered_image\n",
    "            )\n",
    "\n",
    "            # Calculate variance over group.\n",
    "            # shape = (\n",
    "            #     1,\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     num_channels\n",
    "            # )\n",
    "            variance = tf.reduce_mean(\n",
    "                input_tensor=tf.square(x=centered_image),\n",
    "                axis=0,\n",
    "                keepdims=True,\n",
    "                name=\"variance\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"ungrouped_minibatch_stddev\",\n",
    "                \"variance\",\n",
    "                variance\n",
    "            )\n",
    "\n",
    "            # Get stddev image using ops common to both grouped & ungrouped.\n",
    "            stddev_feature_map = self.minibatch_stddev_common(\n",
    "                variance=variance,\n",
    "                tile_multiples=[cur_batch_size] + static_image_shape[0:2] + [1],\n",
    "                params=params,\n",
    "                caller=\"ungrouped\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"ungrouped_minibatch_stddev\",\n",
    "                \"stddev_feature_map\",\n",
    "                stddev_feature_map\n",
    "            )\n",
    "\n",
    "        return stddev_feature_map\n",
    "\n",
    "    def minibatch_stddev(self, X, params, group_size=4):\n",
    "        \"\"\"Adds minibatch stddev feature map added to image.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, image of shape\n",
    "                [cur_batch_size, image_size, image_size, num_channels].\n",
    "            params: dict, user passed parameters.\n",
    "            group_size: int, size of image groups.\n",
    "\n",
    "        Returns:\n",
    "            Image with minibatch standard deviation feature map added to\n",
    "                channels of shape\n",
    "                [cur_batch_size, image_size, image_size, num_channels + 1].\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(\"{}/minibatch_stddev\".format(self.name)):\n",
    "            # Get dynamic shape of image.\n",
    "            # shape = (4,)\n",
    "            dynamic_image_shape = tf.shape(\n",
    "                input=X, name=\"dynamic_image_shape\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\nminibatch_stddev\",\n",
    "                \"dynamic_image_shape\",\n",
    "                dynamic_image_shape\n",
    "            )\n",
    "\n",
    "            # Extract current batch size (in case this is a partial batch).\n",
    "            cur_batch_size = dynamic_image_shape[0]\n",
    "\n",
    "            # Get static shape of image.\n",
    "            # shape = (3,)\n",
    "            static_image_shape = params[\"generator_projection_dims\"]\n",
    "            print_obj(\n",
    "                \"minibatch_stddev\", \"static_image_shape\", static_image_shape\n",
    "            )\n",
    "\n",
    "            # cur_batch_size must be divisible by or smaller than group_size.\n",
    "            divisbility_condition = tf.equal(\n",
    "                x=tf.mod(x=cur_batch_size, y=group_size),\n",
    "                y=0,\n",
    "                name=\"divisbility_condition\"\n",
    "            )\n",
    "\n",
    "            less_than_condition = tf.less(\n",
    "                x=cur_batch_size, y=group_size, name=\"less_than_condition\"\n",
    "            )\n",
    "\n",
    "            any_condition = tf.reduce_any(\n",
    "                input_tensor=[divisbility_condition, less_than_condition],\n",
    "                name=\"any_condition\"\n",
    "            )\n",
    "\n",
    "            # Get minibatch stddev feature map image from grouped or\n",
    "            # ungrouped branch.\n",
    "            stddev_feature_map = tf.cond(\n",
    "                pred=any_condition,\n",
    "                true_fn=lambda: self.grouped_minibatch_stddev(\n",
    "                    X=X,\n",
    "                    cur_batch_size=cur_batch_size,\n",
    "                    static_image_shape=static_image_shape,\n",
    "                    params=params,\n",
    "                    group_size=group_size\n",
    "                ),\n",
    "                false_fn=lambda: self.ungrouped_minibatch_stddev(\n",
    "                    X=X,\n",
    "                    cur_batch_size=cur_batch_size,\n",
    "                    static_image_shape=static_image_shape,\n",
    "                    params=params\n",
    "                ),\n",
    "                name=\"stddev_feature_map_cond\"\n",
    "            )\n",
    "\n",
    "            # Append to image as new feature map.\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     num_channels + 1\n",
    "            # )\n",
    "            appended_image = tf.concat(\n",
    "                values=[X, stddev_feature_map],\n",
    "                axis=-1,\n",
    "                name=\"appended_image\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"minibatch_stddev_common\",\n",
    "                \"appended_image\",\n",
    "                appended_image\n",
    "            )\n",
    "\n",
    "        return appended_image\n",
    "\n",
    "    def use_discriminator_logits_layer(self, block_conv, params):\n",
    "        \"\"\"Uses flatten and logits layers to get logits tensor.\n",
    "\n",
    "        Args:\n",
    "            block_conv: tensor, output of last conv layer of discriminator.\n",
    "            flatten_layer: `Flatten` layer.\n",
    "            logits_layer: `Dense` layer for logits.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Final logits tensor of discriminator.\n",
    "        \"\"\"\n",
    "        print_obj(\n",
    "            \"\\nuse_discriminator_logits_layer\", \"block_conv\", block_conv\n",
    "        )\n",
    "        # Set shape to remove ambiguity for dense layer.\n",
    "        height, width =  params[\"generator_projection_dims\"][0:2]\n",
    "        valid_kernel_size = (\n",
    "            params[\"discriminator_base_conv_blocks\"][0][-1][0]\n",
    "        )\n",
    "        block_conv.set_shape(\n",
    "            [\n",
    "                block_conv.get_shape()[0],\n",
    "                height - valid_kernel_size + 1,\n",
    "                width - valid_kernel_size + 1,\n",
    "                block_conv.get_shape()[-1]]\n",
    "        )\n",
    "        print_obj(\"use_discriminator_logits_layer\", \"block_conv\", block_conv)\n",
    "\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Flatten final block conv tensor.\n",
    "            block_conv_flat = self.flatten_layer(inputs=block_conv)\n",
    "            print_obj(\n",
    "                \"use_discriminator_logits_layer\",\n",
    "                \"block_conv_flat\",\n",
    "                block_conv_flat\n",
    "            )\n",
    "\n",
    "            # Final linear layer for logits.\n",
    "            logits = self.logits_layer(inputs=block_conv_flat)\n",
    "            print_obj(\"use_discriminator_logits_layer\", \"logits\", logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def create_base_discriminator_network(self, X, params):\n",
    "        \"\"\"Creates base discriminator network.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, input image to discriminator.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Final logits tensor of discriminator.\n",
    "        \"\"\"\n",
    "        print_obj(\"\\ncreate_base_discriminator_network\", \"X\", X)\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Only need the first fromRGB conv layer & block for base network.\n",
    "            from_rgb_conv_layer = self.from_rgb_conv_layers[0]\n",
    "            block_layers = self.conv_layer_blocks[0]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            from_rgb_conv = from_rgb_conv_layer(inputs=X)\n",
    "            print_obj(\n",
    "                \"create_base_discriminator_network\",\n",
    "                \"from_rgb_conv\",\n",
    "                from_rgb_conv\n",
    "            )\n",
    "\n",
    "            if params[\"use_minibatch_stddev\"]:\n",
    "                block_conv = self.minibatch_stddev(\n",
    "                    X=from_rgb_conv,\n",
    "                    params=params,\n",
    "                    group_size=params[\"minibatch_stddev_group_size\"]\n",
    "                )\n",
    "            else:\n",
    "                block_conv = from_rgb_conv\n",
    "\n",
    "            for i in range(len(block_layers)):\n",
    "                block_conv = block_layers[i](inputs=block_conv)\n",
    "                print_obj(\n",
    "                    \"create_base_discriminator_network\",\n",
    "                    \"block_conv\",\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Get logits now.\n",
    "            logits = self.use_discriminator_logits_layer(\n",
    "                block_conv=block_conv,\n",
    "                params=params\n",
    "            )\n",
    "            print_obj(\"create_base_discriminator_network\", \"logits\", logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def create_growth_transition_discriminator_network(\n",
    "            self, X, alpha_var, params, trans_idx):\n",
    "        \"\"\"Creates growth transition discriminator network.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, input image to discriminator.\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "            trans_idx: int, index of current growth transition.\n",
    "\n",
    "        Returns:\n",
    "            Final logits tensor of discriminator.\n",
    "        \"\"\"\n",
    "        print_obj(\n",
    "            \"\\nEntered create_growth_transition_discriminator_network\",\n",
    "            \"trans_idx\",\n",
    "            trans_idx\n",
    "        )\n",
    "        print_obj(\"create_growth_transition_discriminator_network\", \"X\", X)\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Growing side chain.\n",
    "            growing_from_rgb_conv_layer = self.from_rgb_conv_layers[trans_idx + 1]\n",
    "            growing_block_layers = self.conv_layer_blocks[trans_idx + 1]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            growing_block_conv = growing_from_rgb_conv_layer(inputs=X)\n",
    "            print_obj(\n",
    "                \"\\ncreate_growth_transition_discriminator_network\",\n",
    "                \"growing_block_conv\",\n",
    "                growing_block_conv\n",
    "            )\n",
    "            for i in range(len(growing_block_layers)):\n",
    "                growing_block_conv = growing_block_layers[i](\n",
    "                    inputs=growing_block_conv\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_growth_transition_discriminator_network\",\n",
    "                    \"growing_block_conv\",\n",
    "                    growing_block_conv\n",
    "                )\n",
    "\n",
    "            # Shrinking side chain.\n",
    "            transition_downsample_layer = self.transition_downsample_layers[trans_idx]\n",
    "            shrinking_from_rgb_conv_layer = self.from_rgb_conv_layers[trans_idx]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            transition_downsample = transition_downsample_layer(inputs=X)\n",
    "            print_obj(\n",
    "                \"create_growth_transition_discriminator_network\",\n",
    "                \"transition_downsample\",\n",
    "                transition_downsample\n",
    "            )\n",
    "            shrinking_from_rgb_conv = shrinking_from_rgb_conv_layer(\n",
    "                inputs=transition_downsample\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_discriminator_network\",\n",
    "                \"shrinking_from_rgb_conv\",\n",
    "                shrinking_from_rgb_conv\n",
    "            )\n",
    "\n",
    "            # Weighted sum.\n",
    "            weighted_sum = tf.add(\n",
    "                x=growing_block_conv * alpha_var,\n",
    "                y=shrinking_from_rgb_conv * (1.0 - alpha_var),\n",
    "                name=\"{}_growth_transition_weighted_sum_{}\".format(\n",
    "                    self.name, trans_idx\n",
    "                )\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_discriminator_network\",\n",
    "                \"weighted_sum\",\n",
    "                weighted_sum\n",
    "            )\n",
    "\n",
    "            # Permanent blocks.\n",
    "            permanent_blocks = self.conv_layer_blocks[0:trans_idx + 1]\n",
    "\n",
    "            # Reverse order of blocks and flatten.\n",
    "            permanent_block_layers = [\n",
    "                item for sublist in permanent_blocks[::-1] for item in sublist\n",
    "            ]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            block_conv = weighted_sum\n",
    "\n",
    "            # Find number of permanent growth conv layers.\n",
    "            num_perm_growth_conv_layers = len(permanent_block_layers)\n",
    "            num_perm_growth_conv_layers -= len(params[\"conv_num_filters\"][0])\n",
    "\n",
    "            # Loop through only the permanent growth conv layers.\n",
    "            for i in range(num_perm_growth_conv_layers):\n",
    "                block_conv = permanent_block_layers[i](inputs=block_conv)\n",
    "                print_obj(\n",
    "                    \"create_growth_transition_discriminator_network\",\n",
    "                    \"block_conv_{}\".format(i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            if params[\"use_minibatch_stddev\"]:\n",
    "                block_conv = self.minibatch_stddev(\n",
    "                    X=block_conv,\n",
    "                    params=params,\n",
    "                    group_size=params[\"minibatch_stddev_group_size\"]\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_growth_transition_discriminator_network\",\n",
    "                    \"minibatch_stddev_block_conv\",\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Loop through only the permanent base conv layers now.\n",
    "            for i in range(\n",
    "                    num_perm_growth_conv_layers, len(permanent_block_layers)):\n",
    "                block_conv = permanent_block_layers[i](inputs=block_conv)\n",
    "                print_obj(\n",
    "                    \"create_growth_transition_discriminator_network\",\n",
    "                    \"block_conv_{}\".format(i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Get logits now.\n",
    "            logits = self.use_discriminator_logits_layer(\n",
    "                block_conv=block_conv, params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_discriminator_network\",\n",
    "                \"logits\",\n",
    "                logits\n",
    "            )\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def create_final_discriminator_network(self, X, params):\n",
    "        \"\"\"Creates final discriminator network.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, input image to discriminator.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Final logits tensor of discriminator.\n",
    "        \"\"\"\n",
    "        print_obj(\"\\ncreate_final_discriminator_network\", \"X\", X)\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Only need the last fromRGB conv layer.\n",
    "            from_rgb_conv_layer = self.from_rgb_conv_layers[-1]\n",
    "\n",
    "            # Reverse order of blocks.\n",
    "            reversed_blocks = self.conv_layer_blocks[::-1]\n",
    "\n",
    "            # Flatten list of lists block layers into list.\n",
    "            block_layers = [\n",
    "                item for sublist in reversed_blocks for item in sublist\n",
    "            ]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            block_conv = from_rgb_conv_layer(inputs=X)\n",
    "            print_obj(\n",
    "                \"\\ncreate_final_discriminator_network\",\n",
    "                \"block_conv\",\n",
    "                block_conv\n",
    "            )\n",
    "\n",
    "            # Find number of permanent growth conv layers.\n",
    "            num_growth_conv_layers = len(block_layers)\n",
    "            num_growth_conv_layers -= len(params[\"conv_num_filters\"][0])\n",
    "\n",
    "            # Loop through only the permanent growth conv layers.\n",
    "            for i in range(num_growth_conv_layers):\n",
    "                block_conv = block_layers[i](inputs=block_conv)\n",
    "                print_obj(\n",
    "                    \"create_final_discriminator_network\",\n",
    "                    \"block_conv_{}\".format(i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            if params[\"use_minibatch_stddev\"]:\n",
    "                block_conv = self.minibatch_stddev(\n",
    "                    X=block_conv,\n",
    "                    params=params,\n",
    "                    group_size=params[\"minibatch_stddev_group_size\"]\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_final_discriminator_network\",\n",
    "                    \"minibatch_stddev_block_conv\",\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Loop through only the permanent base conv layers now.\n",
    "            for i in range(num_growth_conv_layers, len(block_layers)):\n",
    "                block_conv = block_layers[i](inputs=block_conv)\n",
    "                print_obj(\n",
    "                    \"create_final_discriminator_network\",\n",
    "                    \"block_conv_{}\".format(i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Get logits now.\n",
    "            logits = self.use_discriminator_logits_layer(\n",
    "                block_conv=block_conv,\n",
    "                params=params\n",
    "            )\n",
    "            print_obj(\"create_final_discriminator_network\", \"logits\", logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def switch_case_discriminator_logits(\n",
    "            self, X, alpha_var, params, growth_index):\n",
    "        \"\"\"Uses switch case to use the correct network to get logits.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, image tensors of shape\n",
    "                [cur_batch_size, image_size, image_size, depth].\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "            growth_index: int, current growth stage.\n",
    "\n",
    "        Returns:\n",
    "            Logits tensor of shape [cur_batch_size, 1].\n",
    "        \"\"\"\n",
    "        # Switch to case based on number of steps to get logits.\n",
    "        logits = tf.switch_case(\n",
    "            branch_index=growth_index,\n",
    "            branch_fns=[\n",
    "                # 4x4\n",
    "                lambda: self.create_base_discriminator_network(\n",
    "                    X=X, params=params\n",
    "                ),\n",
    "                # 8x8\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(0, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 16x16\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(1, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 32x32\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(2, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 64x64\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(3, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 128x128\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(4, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 256x256\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(5, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 512x512\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(6, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 1024x1024\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(7, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 1024x1024\n",
    "                lambda: self.create_final_discriminator_network(\n",
    "                    X=X, params=params\n",
    "                )\n",
    "            ],\n",
    "            name=\"{}_switch_case_logits\".format(self.name)\n",
    "        )\n",
    "\n",
    "        return logits\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def get_discriminator_logits(self, X, alpha_var, params):\n",
    "        \"\"\"Uses generator network and returns generated output for train/eval.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, image tensors of shape\n",
    "                [cur_batch_size, image_size, image_size, depth].\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Logits tensor of shape [cur_batch_size, 1].\n",
    "        \"\"\"\n",
    "        print_obj(\"\\nget_discriminator_logits\", \"X\", X)\n",
    "\n",
    "        # Get discriminator's logits tensor.\n",
    "        train_steps = params[\"train_steps\"] + params[\"prev_train_steps\"]\n",
    "        num_steps_until_growth = params[\"num_steps_until_growth\"]\n",
    "        num_stages = train_steps // num_steps_until_growth\n",
    "        if (num_stages <= 0 or len(params[\"conv_num_filters\"]) == 1):\n",
    "            print(\n",
    "                \"\\nget_discriminator_logits: NOT GOING TO GROW, SKIP SWITCH CASE!\"\n",
    "            )\n",
    "            # If never going to grow, no sense using the switch case.\n",
    "            # 4x4\n",
    "            logits = self.create_base_discriminator_network(\n",
    "                X=X, params=params\n",
    "            )\n",
    "        else:\n",
    "            # Find growth index based on global step and growth frequency.\n",
    "            growth_index = tf.cast(\n",
    "                x=tf.floordiv(\n",
    "                    x=tf.train.get_or_create_global_step(),\n",
    "                    y=params[\"num_steps_until_growth\"],\n",
    "                    name=\"{}_global_step_floordiv\".format(self.name)\n",
    "                ),\n",
    "                dtype=tf.int32,\n",
    "                name=\"{}_growth_index\".format(self.name)\n",
    "            )\n",
    "\n",
    "            # Switch to case based on number of steps for logits.\n",
    "            logits = self.switch_case_discriminator_logits(\n",
    "                X=X,\n",
    "                alpha_var=alpha_var,\n",
    "                params=params,\n",
    "                growth_index=growth_index\n",
    "            )\n",
    "\n",
    "        print_obj(\n",
    "            \"\\nget_discriminator_logits\", \"logits\", logits\n",
    "        )\n",
    "\n",
    "        # Wrap logits in a control dependency for the build discriminator\n",
    "        # tensors to ensure discriminator internals are built.\n",
    "        with tf.control_dependencies(\n",
    "                control_inputs=[self.build_discriminator_tensors]):\n",
    "            logits = tf.identity(\n",
    "                input=logits, name=\"{}_logits_identity\".format(self.name)\n",
    "            )\n",
    "\n",
    "        return logits\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def get_gradient_penalty_loss(\n",
    "            self,\n",
    "            cur_batch_size,\n",
    "            fake_images,\n",
    "            real_images,\n",
    "            alpha_var,\n",
    "            params):\n",
    "        \"\"\"Gets discriminator gradient penalty loss.\n",
    "\n",
    "        Args:\n",
    "            cur_batch_size: tensor, in case of a partial batch instead of\n",
    "                using the user passed int.\n",
    "            fake_images: tensor, images generated by the generator from random\n",
    "                noise of shape [cur_batch_size, image_size, image_size, 3].\n",
    "            real_images: tensor, real images from input of shape\n",
    "                [cur_batch_size, image_size, image_size, 3].\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Discriminator's gradient penalty loss of shape [].\n",
    "        \"\"\"\n",
    "        with tf.name_scope(name=\"{}/gradient_penalty\".format(self.name)):\n",
    "            # Get a random uniform number rank 4 tensor.\n",
    "            random_uniform_num = tf.random.uniform(\n",
    "                shape=[cur_batch_size, 1, 1, 1],\n",
    "                minval=0., maxval=1.,\n",
    "                dtype=tf.float32,\n",
    "                name=\"random_uniform_num\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\nget_gradient_penalty_loss\",\n",
    "                \"random_uniform_num\",\n",
    "                random_uniform_num\n",
    "            )\n",
    "\n",
    "            # Find the element-wise difference between images.\n",
    "            image_difference = real_images - fake_images\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"image_difference\",\n",
    "                image_difference\n",
    "            )\n",
    "\n",
    "            # Get random samples from this mixed image distribution.\n",
    "            mixed_images = random_uniform_num * image_difference\n",
    "            mixed_images += fake_images\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"mixed_images\",\n",
    "                mixed_images\n",
    "            )\n",
    "\n",
    "            # Send to the discriminator to get logits.\n",
    "            mixed_logits = self.get_discriminator_logits(\n",
    "                X=mixed_images, alpha_var=alpha_var, params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"mixed_logits\",\n",
    "                mixed_logits\n",
    "            )\n",
    "\n",
    "            # Get the mixed loss.\n",
    "            mixed_loss = tf.reduce_sum(\n",
    "                input_tensor=mixed_images,\n",
    "                name=\"mixed_loss\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"mixed_loss\",\n",
    "                mixed_loss\n",
    "            )\n",
    "\n",
    "            # Get gradient from returned list of length 1.\n",
    "            mixed_gradients = tf.gradients(\n",
    "                ys=mixed_loss,\n",
    "                xs=[mixed_images],\n",
    "                name=\"gradients\"\n",
    "            )[0]\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"mixed_gradients\",\n",
    "                mixed_gradients\n",
    "            )\n",
    "\n",
    "            # Get gradient's L2 norm.\n",
    "            mixed_norms = tf.sqrt(\n",
    "                x=tf.reduce_sum(\n",
    "                    input_tensor=tf.square(\n",
    "                        x=mixed_gradients,\n",
    "                        name=\"squared_grads\"\n",
    "                    ),\n",
    "                    axis=[1, 2, 3]\n",
    "                )\n",
    "            )\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"mixed_norms\",\n",
    "                mixed_norms\n",
    "            )\n",
    "\n",
    "            # Get squared difference from target of 1.0.\n",
    "            squared_difference = tf.square(\n",
    "                x=mixed_norms - 1.0,\n",
    "                name=\"squared_difference\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"squared_difference\",\n",
    "                squared_difference\n",
    "            )\n",
    "\n",
    "            # Get gradient penalty scalar.\n",
    "            gradient_penalty = tf.reduce_mean(\n",
    "                input_tensor=squared_difference, name=\"gradient_penalty\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"gradient_penalty\",\n",
    "                gradient_penalty\n",
    "            )\n",
    "\n",
    "            # Multiply with lambda to get gradient penalty loss.\n",
    "            gradient_penalty_loss = tf.multiply(\n",
    "                x=params[\"discriminator_gradient_penalty_coefficient\"],\n",
    "                y=gradient_penalty,\n",
    "                name=\"gradient_penalty_loss\"\n",
    "            )\n",
    "\n",
    "            return gradient_penalty_loss\n",
    "\n",
    "    def get_discriminator_loss(\n",
    "            self,\n",
    "            cur_batch_size,\n",
    "            fake_images,\n",
    "            real_images,\n",
    "            fake_logits,\n",
    "            real_logits,\n",
    "            alpha_var,\n",
    "            params):\n",
    "        \"\"\"Gets discriminator loss.\n",
    "\n",
    "        Args:\n",
    "            cur_batch_size: tensor, in case of a partial batch instead of\n",
    "                using the user passed int.\n",
    "            fake_images: tensor, images generated by the generator from random\n",
    "                noise of shape [cur_batch_size, image_size, image_size, 3].\n",
    "            real_images: tensor, real images from input of shape\n",
    "                [cur_batch_size, image_size, image_size, 3].\n",
    "            fake_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "                discriminator having processed generator's output image.\n",
    "            fake_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "                discriminator having processed real image.\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Discriminator's total loss tensor of shape [].\n",
    "        \"\"\"\n",
    "        # Calculate base discriminator loss.\n",
    "        discriminator_real_loss = tf.reduce_mean(\n",
    "            input_tensor=real_logits,\n",
    "            name=\"{}_real_loss\".format(self.name)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"\\nget_discriminator_loss\",\n",
    "            \"discriminator_real_loss\",\n",
    "            discriminator_real_loss\n",
    "        )\n",
    "\n",
    "        discriminator_generated_loss = tf.reduce_mean(\n",
    "            input_tensor=fake_logits,\n",
    "            name=\"{}_generated_loss\".format(self.name)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_discriminator_loss\",\n",
    "            \"discriminator_generated_loss\",\n",
    "            discriminator_generated_loss\n",
    "        )\n",
    "\n",
    "        discriminator_loss = tf.add(\n",
    "            x=discriminator_real_loss, y=-discriminator_generated_loss,\n",
    "            name=\"{}_loss\".format(self.name)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_discriminator_loss\",\n",
    "            \"discriminator_loss\",\n",
    "            discriminator_loss\n",
    "        )\n",
    "\n",
    "        # Get discriminator gradient penalty loss.\n",
    "        discriminator_gradient_penalty = self.get_gradient_penalty_loss(\n",
    "            cur_batch_size=cur_batch_size,\n",
    "            fake_images=fake_images,\n",
    "            real_images=real_images,\n",
    "            alpha_var=alpha_var,\n",
    "            params=params\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_discriminator_loss\",\n",
    "            \"discriminator_gradient_penalty\",\n",
    "            discriminator_gradient_penalty\n",
    "        )\n",
    "\n",
    "        # Get discriminator epsilon drift penalty.\n",
    "        epsilon_drift_penalty = tf.multiply(\n",
    "            x=params[\"epsilon_drift\"],\n",
    "            y=tf.reduce_mean(input_tensor=tf.square(x=real_logits)),\n",
    "            name=\"epsilon_drift_penalty\"\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_discriminator_loss\",\n",
    "            \"epsilon_drift_penalty\",\n",
    "            epsilon_drift_penalty\n",
    "        )\n",
    "\n",
    "        # Get discriminator Wasserstein GP loss.\n",
    "        discriminator_wasserstein_gp_loss = tf.add_n(\n",
    "            inputs=[\n",
    "                discriminator_loss,\n",
    "                discriminator_gradient_penalty,\n",
    "                epsilon_drift_penalty\n",
    "            ],\n",
    "            name=\"{}_wasserstein_gp_loss\".format(self.name)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_discriminator_loss\",\n",
    "            \"discriminator_wasserstein_gp_loss\",\n",
    "            discriminator_wasserstein_gp_loss\n",
    "        )\n",
    "\n",
    "        # Get discriminator regularization losses.\n",
    "        discriminator_reg_loss = get_regularization_loss(\n",
    "            lambda1=params[\"discriminator_l1_regularization_scale\"],\n",
    "            lambda2=params[\"discriminator_l2_regularization_scale\"],\n",
    "            scope=self.name\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_discriminator_loss\",\n",
    "            \"discriminator_reg_loss\",\n",
    "            discriminator_reg_loss\n",
    "        )\n",
    "\n",
    "        # Combine losses for total losses.\n",
    "        discriminator_total_loss = tf.add(\n",
    "            x=discriminator_wasserstein_gp_loss,\n",
    "            y=discriminator_reg_loss,\n",
    "            name=\"{}_total_loss\".format(self.name)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_discriminator_loss\",\n",
    "            \"discriminator_total_loss\",\n",
    "            discriminator_total_loss\n",
    "        )\n",
    "\n",
    "        return discriminator_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regularization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regularization_loss(lambda1=0., lambda2=0., scope=None):\n",
    "    \"\"\"Gets regularization losses from variables attached to a regularizer.\n",
    "\n",
    "    Args:\n",
    "        lambda1: float, L1 regularization scale parameter.\n",
    "        lambda2: float, L2 regularization scale parameter.\n",
    "        scope: str, the name of the variable scope.\n",
    "\n",
    "    Returns:\n",
    "        Scalar regularization loss tensor.\n",
    "    \"\"\"\n",
    "    def sum_nd_tensor_list_to_scalar_tensor(t_list):\n",
    "        \"\"\"Sums different shape tensors into a scalar tensor.\n",
    "\n",
    "        Args:\n",
    "            t_list: list, tensors of varying shapes.\n",
    "\n",
    "        Returns:\n",
    "            Scalar tensor.\n",
    "        \"\"\"\n",
    "        # Sum list of tensors into a list of scalars.\n",
    "        t_reduce_sum_list = [\n",
    "            tf.reduce_sum(\n",
    "                # Remove the :0 from the end of the name.\n",
    "                input_tensor=t, name=\"{}_reduce_sum\".format(t.name[:-2])\n",
    "            )\n",
    "            for t in t_list\n",
    "        ]\n",
    "        print_obj(\n",
    "            \"\\nsum_nd_tensor_list_to_scalar_tensor\",\n",
    "            \"t_reduce_sum_list\",\n",
    "            t_reduce_sum_list\n",
    "        )\n",
    "\n",
    "        # Add all scalars together into one scalar.\n",
    "        t_scalar_sum_tensor = tf.add_n(\n",
    "            inputs=t_reduce_sum_list,\n",
    "            name=\"{}_t_scalar_sum_tensor\".format(scope)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"sum_nd_tensor_list_to_scalar_tensor\",\n",
    "            \"t_scalar_sum_tensor\",\n",
    "            t_scalar_sum_tensor\n",
    "        )\n",
    "\n",
    "        return t_scalar_sum_tensor\n",
    "\n",
    "    print_obj(\"\\nget_regularization_loss\", \"scope\", scope)\n",
    "    if lambda1 <= 0. and lambda2 <= 0.:\n",
    "        # No regularization so return zero.\n",
    "        return tf.zeros(shape=[], dtype=tf.float32)\n",
    "\n",
    "    # Get list of trainable variables with a regularizer attached in scope.\n",
    "    trainable_reg_vars_list = tf.get_collection(\n",
    "        tf.GraphKeys.REGULARIZATION_LOSSES, scope=scope)\n",
    "    print_obj(\n",
    "        \"get_regularization_loss\",\n",
    "        \"trainable_reg_vars_list\",\n",
    "        trainable_reg_vars_list\n",
    "    )\n",
    "\n",
    "    for var in trainable_reg_vars_list:\n",
    "        print_obj(\n",
    "            \"get_regularization_loss_{}\".format(scope),\n",
    "            \"{}\".format(var.name),\n",
    "            var.graph\n",
    "        )\n",
    "\n",
    "    l1_loss = 0.\n",
    "    if lambda1 > 0.:\n",
    "        # For L1 regularization, take the absolute value element-wise of each.\n",
    "        trainable_reg_vars_abs_list = [\n",
    "            tf.abs(\n",
    "                x=var,\n",
    "                # Clean up regularizer scopes in variable names.\n",
    "                name=\"{}_abs\".format((\"/\").join(var.name.split(\"/\")[0:3]))\n",
    "            )\n",
    "            for var in trainable_reg_vars_list\n",
    "        ]\n",
    "\n",
    "        # Get L1 loss\n",
    "        l1_loss = tf.multiply(\n",
    "            x=lambda1,\n",
    "            y=sum_nd_tensor_list_to_scalar_tensor(\n",
    "                t_list=trainable_reg_vars_abs_list\n",
    "            ),\n",
    "            name=\"{}_l1_loss\".format(scope)\n",
    "        )\n",
    "\n",
    "    l2_loss = 0.\n",
    "    if lambda2 > 0.:\n",
    "        # For L2 regularization, square all variables element-wise.\n",
    "        trainable_reg_vars_squared_list = [\n",
    "            tf.square(\n",
    "                x=var,\n",
    "                # Clean up regularizer scopes in variable names.\n",
    "                name=\"{}_squared\".format((\"/\").join(var.name.split(\"/\")[0:3]))\n",
    "            )\n",
    "            for var in trainable_reg_vars_list\n",
    "        ]\n",
    "        print_obj(\n",
    "            \"get_regularization_loss\",\n",
    "            \"trainable_reg_vars_squared_list\",\n",
    "            trainable_reg_vars_squared_list\n",
    "        )\n",
    "\n",
    "        # Get L2 loss\n",
    "        l2_loss = tf.multiply(\n",
    "            x=lambda2,\n",
    "            y=sum_nd_tensor_list_to_scalar_tensor(\n",
    "                t_list=trainable_reg_vars_squared_list\n",
    "            ),\n",
    "            name=\"{}_l2_loss\".format(scope)\n",
    "        )\n",
    "\n",
    "    l1_l2_loss = tf.add(\n",
    "        x=l1_loss, y=l2_loss, name=\"{}_l1_l2_loss\".format(scope)\n",
    "    )\n",
    "\n",
    "    return l1_l2_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_and_eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits_and_losses(\n",
    "        features, generator, discriminator, alpha_var, params):\n",
    "    \"\"\"Gets logits and losses for both train and eval modes.\n",
    "\n",
    "    Args:\n",
    "        features: dict, feature tensors from input function.\n",
    "        generator: instance of generator.`Generator`.\n",
    "        discriminator: instance of discriminator.`Discriminator`.\n",
    "        alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Real and fake logits and generator and discriminator losses.\n",
    "    \"\"\"\n",
    "    # Extract image from features dictionary.\n",
    "    X = features[\"image\"]\n",
    "    print_obj(\"\\nget_logits_and_losses\", \"X\", X)\n",
    "\n",
    "    # Get dynamic batch size in case of partial batch.\n",
    "    cur_batch_size = tf.shape(\n",
    "        input=X,\n",
    "        out_type=tf.int32,\n",
    "        name=\"get_logits_and_losses_cur_batch_size\"\n",
    "    )[0]\n",
    "\n",
    "    # Create random noise latent vector for each batch example.\n",
    "    Z = tf.random.normal(\n",
    "        shape=[cur_batch_size, params[\"latent_size\"]],\n",
    "        mean=0.0,\n",
    "        stddev=1.0,\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "    print_obj(\"get_logits_and_losses\", \"Z\", Z)\n",
    "\n",
    "    # Get generated image from generator network from gaussian noise.\n",
    "    print(\"\\nCall generator with Z = {}.\".format(Z))\n",
    "    generator_outputs = generator.get_train_eval_generator_outputs(\n",
    "        Z=Z, alpha_var=alpha_var, params=params\n",
    "    )\n",
    "\n",
    "    # Get fake logits from discriminator using generator's output image.\n",
    "    print(\n",
    "        \"\\nCall discriminator with generator_outputs = {}.\".format(\n",
    "            generator_outputs\n",
    "        )\n",
    "    )\n",
    "    fake_logits = discriminator.get_discriminator_logits(\n",
    "        X=generator_outputs, alpha_var=alpha_var, params=params\n",
    "    )\n",
    "\n",
    "    # Resize real images based on the current size of the GAN.\n",
    "    real_images = resize_real_images(image=X, params=params)\n",
    "\n",
    "    # Get real logits from discriminator using real image.\n",
    "    print(\n",
    "        \"\\nCall discriminator with real_images = {}.\".format(real_images)\n",
    "    )\n",
    "    real_logits = discriminator.get_discriminator_logits(\n",
    "        X=real_images, alpha_var=alpha_var, params=params\n",
    "    )\n",
    "\n",
    "    # Get generator total loss.\n",
    "    generator_total_loss = generator.get_generator_loss(\n",
    "        fake_logits=fake_logits, params=params\n",
    "    )\n",
    "\n",
    "    # Get discriminator total loss.\n",
    "    discriminator_total_loss = discriminator.get_discriminator_loss(\n",
    "        cur_batch_size=cur_batch_size,\n",
    "        fake_images=generator_outputs,\n",
    "        real_images=real_images,\n",
    "        fake_logits=fake_logits,\n",
    "        real_logits=real_logits,\n",
    "        alpha_var=alpha_var,\n",
    "        params=params\n",
    "    )\n",
    "\n",
    "    return (real_logits,\n",
    "            fake_logits,\n",
    "            generator_total_loss,\n",
    "            discriminator_total_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(loss, global_step, alpha_var, params, scope):\n",
    "    \"\"\"Trains network and returns loss and train op.\n",
    "\n",
    "    Args:\n",
    "        loss: tensor, shape of [].\n",
    "        global_step: tensor, the current training step or batch in the\n",
    "            training loop.\n",
    "        alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "        params: dict, user passed parameters.\n",
    "        scope: str, the network's name to find its variables to train.\n",
    "\n",
    "    Returns:\n",
    "        Loss tensor and training op.\n",
    "    \"\"\"\n",
    "    print_obj(\"\\ntrain_network\", \"loss\", loss)\n",
    "    print_obj(\"train_network\", \"global_step\", global_step)\n",
    "    print_obj(\"train_network\", \"alpha_var\", alpha_var)\n",
    "    print_obj(\"train_network\", \"scope\", scope)\n",
    "\n",
    "    # Create optimizer map.\n",
    "    optimizers = {\n",
    "        \"Adam\": tf.train.AdamOptimizer,\n",
    "        \"Adadelta\": tf.train.AdadeltaOptimizer,\n",
    "        \"AdagradDA\": tf.train.AdagradDAOptimizer,\n",
    "        \"Adagrad\": tf.train.AdagradOptimizer,\n",
    "        \"Ftrl\": tf.train.FtrlOptimizer,\n",
    "        \"GradientDescent\": tf.train.GradientDescentOptimizer,\n",
    "        \"Momentum\": tf.train.MomentumOptimizer,\n",
    "        \"ProximalAdagrad\": tf.train.ProximalAdagradOptimizer,\n",
    "        \"ProximalGradientDescent\": tf.train.ProximalGradientDescentOptimizer,\n",
    "        \"RMSProp\": tf.train.RMSPropOptimizer\n",
    "    }\n",
    "\n",
    "    # Get optimizer and instantiate it.\n",
    "    optimizer = optimizers[params[\"{}_optimizer\".format(scope)]](\n",
    "        learning_rate=params[\"{}_learning_rate\".format(scope)]\n",
    "    )\n",
    "    print_obj(\"train_network\", \"optimizer\", optimizer)\n",
    "\n",
    "    # Get trainable variables.\n",
    "    variables = tf.trainable_variables(scope=scope)\n",
    "    print_obj(\"\\ntrain_network\", \"variables\", variables)\n",
    "\n",
    "    # Get gradients.\n",
    "    gradients = tf.gradients(\n",
    "        ys=loss,\n",
    "        xs=variables,\n",
    "        name=\"{}_gradients\".format(scope)\n",
    "    )\n",
    "    print_obj(\"\\ntrain_network\", \"gradients\", gradients)\n",
    "\n",
    "    # Clip gradients.\n",
    "    if params[\"{}_clip_gradients\".format(scope)]:\n",
    "        gradients, _ = tf.clip_by_global_norm(\n",
    "            t_list=gradients,\n",
    "            clip_norm=params[\"{}_clip_gradients\".format(scope)],\n",
    "            name=\"{}_clip_by_global_norm_gradients\".format(scope)\n",
    "        )\n",
    "        print_obj(\"\\ntrain_network\", \"gradients\", gradients)\n",
    "\n",
    "    # Zip back together gradients and variables.\n",
    "    grads_and_vars = zip(gradients, variables)\n",
    "    print_obj(\"train_network\", \"grads_and_vars\", grads_and_vars)\n",
    "\n",
    "    # Create train op by applying gradients to variables and incrementing\n",
    "    # global step.\n",
    "    train_op = optimizer.apply_gradients(\n",
    "        grads_and_vars=grads_and_vars,\n",
    "        global_step=global_step,\n",
    "        name=\"{}_apply_gradients\".format(scope)\n",
    "    )\n",
    "    print_obj(\"train_network\", \"train_op\", train_op)\n",
    "\n",
    "    # Update alpha variable to linearly scale from 0 to 1 based on steps.\n",
    "    alpha_var_update_op = tf.assign(\n",
    "        ref=alpha_var,\n",
    "        value=tf.divide(\n",
    "            x=tf.cast(\n",
    "                x=tf.mod(x=global_step, y=params[\"num_steps_until_growth\"]),\n",
    "                dtype=tf.float32\n",
    "            ),\n",
    "            y=params[\"num_steps_until_growth\"]\n",
    "        ),\n",
    "        name=\"{}_alpha_var_update_op\".format(scope)\n",
    "    )\n",
    "    print_obj(\"train_network\", \"alpha_var_update_op\", alpha_var_update_op)\n",
    "\n",
    "    # Ensure alpha variable gets updated.\n",
    "    with tf.control_dependencies(control_inputs=[alpha_var_update_op]):\n",
    "        loss = tf.identity(\n",
    "            input=loss, name=\"{}_train_network_loss_identity\".format(scope)\n",
    "        )\n",
    "\n",
    "    return loss, train_op\n",
    "\n",
    "\n",
    "def get_loss_and_train_op(\n",
    "        generator_total_loss, discriminator_total_loss, alpha_var, params):\n",
    "    \"\"\"Gets loss and train op for train mode.\n",
    "\n",
    "    Args:\n",
    "        generator_total_loss: tensor, scalar total loss of generator.\n",
    "        discriminator_total_loss: tensor, scalar total loss of discriminator.\n",
    "        alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Loss scalar tensor and train_op to be used by the EstimatorSpec.\n",
    "    \"\"\"\n",
    "    # Get global step.\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    # Determine if it is time to train generator or discriminator.\n",
    "    cycle_step = tf.mod(\n",
    "        x=global_step,\n",
    "        y=tf.cast(\n",
    "            x=tf.add(\n",
    "                x=params[\"generator_train_steps\"],\n",
    "                y=params[\"discriminator_train_steps\"]\n",
    "            ),\n",
    "            dtype=tf.int64\n",
    "        ),\n",
    "        name=\"get_loss_and_train_op_cycle_step\"\n",
    "    )\n",
    "\n",
    "    # Create choose generator condition.\n",
    "    condition = tf.less(\n",
    "        x=cycle_step, y=params[\"generator_train_steps\"]\n",
    "    )\n",
    "\n",
    "    # Needed for batch normalization, but has no effect otherwise.\n",
    "    update_ops = tf.get_collection(key=tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "    with tf.control_dependencies(control_inputs=update_ops):\n",
    "        # Conditionally choose to train generator or discriminator.\n",
    "        loss, train_op = tf.cond(\n",
    "            pred=condition,\n",
    "            true_fn=lambda: train_network(\n",
    "                loss=generator_total_loss,\n",
    "                global_step=global_step,\n",
    "                alpha_var=alpha_var,\n",
    "                params=params,\n",
    "                scope=\"generator\"\n",
    "            ),\n",
    "            false_fn=lambda: train_network(\n",
    "                loss=discriminator_total_loss,\n",
    "                global_step=global_step,\n",
    "                alpha_var=alpha_var,\n",
    "                params=params,\n",
    "                scope=\"discriminator\"\n",
    "            ),\n",
    "            name=\"train_network_cond\"\n",
    "        )\n",
    "\n",
    "    return loss, train_op\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval_metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_and_eval_metric_ops(\n",
    "        discriminator_total_loss, fake_logits, real_logits):\n",
    "    \"\"\"Gets logits and losses for both train and eval modes.\n",
    "\n",
    "    Args:\n",
    "        discriminator_total_loss: tensor, scalar total loss of discriminator.\n",
    "        fake_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "            discriminator having processed generator's output image.\n",
    "        real_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "            discriminator having processed real image.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of eval metric ops.\n",
    "    \"\"\"\n",
    "    # Get eval loss.\n",
    "    loss = discriminator_total_loss\n",
    "\n",
    "    # Concatenate discriminator logits and labels.\n",
    "    discriminator_logits = tf.concat(\n",
    "        values=[real_logits, fake_logits],\n",
    "        axis=0,\n",
    "        name=\"discriminator_concat_logits\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"\\get_eval_metric_ops\", \"discriminator_logits\", discriminator_logits\n",
    "    )\n",
    "\n",
    "    discriminator_labels = tf.concat(\n",
    "        values=[\n",
    "            tf.ones_like(tensor=real_logits),\n",
    "            tf.zeros_like(tensor=fake_logits)\n",
    "        ],\n",
    "        axis=0,\n",
    "        name=\"discriminator_concat_labels\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_eval_metric_ops\", \"discriminator_labels\", discriminator_labels\n",
    "    )\n",
    "\n",
    "    # Calculate discriminator probabilities.\n",
    "    discriminator_probabilities = tf.nn.sigmoid(\n",
    "        x=discriminator_logits, name=\"discriminator_probabilities\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_eval_metric_ops\",\n",
    "        \"discriminator_probabilities\",\n",
    "        discriminator_probabilities\n",
    "    )\n",
    "\n",
    "    # Create eval metric ops dictionary.\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            name=\"discriminator_accuracy\"\n",
    "        ),\n",
    "        \"precision\": tf.metrics.precision(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            name=\"discriminator_precision\"\n",
    "        ),\n",
    "        \"recall\": tf.metrics.recall(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            name=\"discriminator_recall\"\n",
    "        ),\n",
    "        \"auc_roc\": tf.metrics.auc(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            num_thresholds=200,\n",
    "            curve=\"ROC\",\n",
    "            name=\"discriminator_auc_roc\"\n",
    "        ),\n",
    "        \"auc_pr\": tf.metrics.auc(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            num_thresholds=200,\n",
    "            curve=\"PR\",\n",
    "            name=\"discriminator_auc_pr\"\n",
    "        )\n",
    "    }\n",
    "    print_obj(\"get_eval_metric_ops\", \"eval_metric_ops\", eval_metric_ops)\n",
    "\n",
    "    return loss, eval_metric_ops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(Z, generator, params, block_idx):\n",
    "    \"\"\"Gets predictions from latent vectors Z.\n",
    "\n",
    "    Args:\n",
    "        image: tensor, tf.float32 query image of shape\n",
    "            [None, height, width, depth].\n",
    "        generator: instance of generator.`Generator`.\n",
    "        encoder: instance of encoder.`Encoder`.\n",
    "        params: dict, user passed parameters.\n",
    "        block_idx: int, current conv layer block's index.\n",
    "\n",
    "    Returns:\n",
    "        Predictions dictionary of encoded images from generator, anomaly\n",
    "            scores, and anomaly flags.\n",
    "    \"\"\"\n",
    "    # Get predictions from generator.\n",
    "    generated_images = generator.get_predict_generator_outputs(\n",
    "        Z=Z, params=params, block_idx=block_idx\n",
    "    )\n",
    "    print_obj(\"\\nget_predictions\", \"generated_images\", generated_images)\n",
    "\n",
    "    # Calculate image size for returned dict keys.\n",
    "    image_dim = 4 * 2 ** block_idx\n",
    "    image_size = \"{}x{}\".format(image_dim, image_dim)\n",
    "\n",
    "    return {\n",
    "        \"generated_images_{}\".format(image_size): generated_images\n",
    "    }\n",
    "\n",
    "\n",
    "def get_predictions_and_export_outputs(features, generator, params):\n",
    "    \"\"\"Gets predictions and serving export outputs.\n",
    "\n",
    "    Args:\n",
    "        features: dict, feature tensors from serving input function.\n",
    "        generator: instance of generator.`Generator`.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Predictions dictionary and export outputs dictionary.\n",
    "    \"\"\"\n",
    "    # Extract given latent vectors from features dictionary.\n",
    "    Z = tf.cast(x=features[\"Z\"], dtype=tf.float32)\n",
    "    print_obj(\"\\nget_predictions_and_export_outputs\", \"Z\", Z)\n",
    "\n",
    "    loop_end = len(params[\"conv_num_filters\"])\n",
    "    loop_start = 0 if params[\"predict_all_resolutions\"] else loop_end - 1\n",
    "    print_obj(\"get_predictions_and_export_outputs\", \"loop_start\", loop_start)\n",
    "    print_obj(\"get_predictions_and_export_outputs\", \"loop_end\", loop_end)\n",
    "\n",
    "    # Create predictions dictionary.\n",
    "    predictions_dict = {}\n",
    "    for i in range(loop_start, loop_end):\n",
    "        predictions = get_predictions(\n",
    "            Z=Z,\n",
    "            generator=generator,\n",
    "            params=params,\n",
    "            block_idx=i\n",
    "        )\n",
    "        predictions_dict.update(predictions)\n",
    "    print_obj(\n",
    "        \"get_predictions_and_export_outputs\",\n",
    "        \"predictions_dict\",\n",
    "        predictions_dict\n",
    "    )\n",
    "\n",
    "    # Create export outputs.\n",
    "    export_outputs = {\n",
    "        \"predict_export_outputs\": tf.estimator.export.PredictOutput(\n",
    "            outputs=predictions_dict)\n",
    "    }\n",
    "    print_obj(\n",
    "        \"get_predictions_and_export_outputs\", \"export_outputs\", export_outputs\n",
    "    )\n",
    "\n",
    "    return predictions_dict, export_outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pgan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgan_model(features, labels, mode, params):\n",
    "    \"\"\"Progressively Growing GAN custom Estimator model function.\n",
    "\n",
    "    Args:\n",
    "        features: dict, keys are feature names and values are feature tensors.\n",
    "        labels: tensor, label data.\n",
    "        mode: tf.estimator.ModeKeys with values of either TRAIN, EVAL, or\n",
    "            PREDICT.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Instance of `tf.estimator.EstimatorSpec` class.\n",
    "    \"\"\"\n",
    "    print_obj(\"\\npgan_model\", \"features\", features)\n",
    "    print_obj(\"pgan_model\", \"labels\", labels)\n",
    "    print_obj(\"pgan_model\", \"mode\", mode)\n",
    "    print_obj(\"pgan_model\", \"params\", params)\n",
    "\n",
    "    # Loss function, training/eval ops, etc.\n",
    "    predictions_dict = None\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = None\n",
    "    export_outputs = None\n",
    "\n",
    "    # Instantiate generator.\n",
    "    pgan_generator = Generator(\n",
    "        kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(\n",
    "            scale_l1=params[\"generator_l1_regularization_scale\"],\n",
    "            scale_l2=params[\"generator_l2_regularization_scale\"]\n",
    "        ),\n",
    "        bias_regularizer=None,\n",
    "        params=params,\n",
    "        name=\"generator\"\n",
    "    )\n",
    "\n",
    "    # Instantiate discriminator.\n",
    "    pgan_discriminator = Discriminator(\n",
    "        kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(\n",
    "            scale_l1=params[\"discriminator_l1_regularization_scale\"],\n",
    "            scale_l2=params[\"discriminator_l2_regularization_scale\"]\n",
    "        ),\n",
    "        bias_regularizer=None,\n",
    "        params=params,\n",
    "        name=\"discriminator\"\n",
    "    )\n",
    "\n",
    "    # Create alpha variable to use for weighted sum for smooth fade-in.\n",
    "    alpha_var = tf.get_variable(\n",
    "        name=\"alpha_var\",\n",
    "        dtype=tf.float32,\n",
    "        initializer=tf.zeros(shape=[], dtype=tf.float32),\n",
    "        trainable=False\n",
    "    )\n",
    "    print_obj(\"pgan_model\", \"alpha_var\", alpha_var)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # Get predictions and export outputs.\n",
    "        (predictions_dict,\n",
    "         export_outputs) = predict.get_predictions_and_export_outputs(\n",
    "            features=features,\n",
    "            generator=pgan_generator,\n",
    "            params=params\n",
    "        )\n",
    "    else:\n",
    "        # Get logits and losses from networks for train and eval modes.\n",
    "        (real_logits,\n",
    "         fake_logits,\n",
    "         generator_total_loss,\n",
    "         discriminator_total_loss) = get_logits_and_losses(\n",
    "            features=features,\n",
    "            generator=pgan_generator,\n",
    "            discriminator=pgan_discriminator,\n",
    "            alpha_var=alpha_var,\n",
    "            params=params\n",
    "        )\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            # Get loss and train op for EstimatorSpec.\n",
    "            loss, train_op = get_loss_and_train_op(\n",
    "                generator_total_loss=generator_total_loss,\n",
    "                discriminator_total_loss=discriminator_total_loss,\n",
    "                alpha_var=alpha_var,\n",
    "                params=params\n",
    "            )\n",
    "        else:\n",
    "            # Get eval metric ops for EstimatorSpec.\n",
    "            loss, eval_metric_ops = get_loss_and_eval_metric_ops(\n",
    "                discriminator_total_loss=discriminator_total_loss,\n",
    "                real_logits=real_logits,\n",
    "                fake_logits=fake_logits\n",
    "            )\n",
    "\n",
    "    # Return EstimatorSpec\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions_dict,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops,\n",
    "        export_outputs=export_outputs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## serving.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn(params):\n",
    "    \"\"\"Serving input function.\n",
    "\n",
    "    Args:\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        ServingInputReceiver object containing features and receiver tensors.\n",
    "    \"\"\"\n",
    "    # Create placeholders to accept data sent to the model at serving time.\n",
    "    # shape = (batch_size,)\n",
    "    feature_placeholders = {\n",
    "        \"Z\": tf.placeholder(\n",
    "            dtype=tf.float32,\n",
    "            shape=[None, params[\"latent_size\"]],\n",
    "            name=\"serving_input_placeholder_Z\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    print_obj(\n",
    "        \"\\nserving_input_fn\",\n",
    "        \"feature_placeholders\",\n",
    "        feature_placeholders\n",
    "    )\n",
    "\n",
    "    # Create clones of the feature placeholder tensors so that the SavedModel\n",
    "    # SignatureDef will point to the placeholder.\n",
    "    features = {\n",
    "        key: tf.identity(\n",
    "            input=value,\n",
    "            name=\"serving_input_fn_identity_placeholder_{}\".format(key)\n",
    "        )\n",
    "        for key, value in feature_placeholders.items()\n",
    "    }\n",
    "\n",
    "    print_obj(\n",
    "        \"serving_input_fn\",\n",
    "        \"features\",\n",
    "        features\n",
    "    )\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features=features, receiver_tensors=feature_placeholders\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(args):\n",
    "    \"\"\"Trains and evaluates custom Estimator model.\n",
    "\n",
    "    Args:\n",
    "        args: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        `Estimator` object.\n",
    "    \"\"\"\n",
    "    # Set logging to be level of INFO.\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    # Create our custom estimator using our model function.\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn=pgan_model,\n",
    "        model_dir=args[\"output_dir\"],\n",
    "        params=args\n",
    "    )\n",
    "\n",
    "    # Create train spec to read in our training data.\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"train_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.TRAIN,\n",
    "            batch_size=args[\"train_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        max_steps=args[\"train_steps\"]\n",
    "    )\n",
    "\n",
    "    # Create exporter to save out the complete model to disk.\n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        name=\"exporter\",\n",
    "        serving_input_receiver_fn=lambda: serving_input_fn(args)\n",
    "    )\n",
    "\n",
    "    # Create eval spec to read in our validation data and export our model.\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"eval_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.EVAL,\n",
    "            batch_size=args[\"eval_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        steps=args[\"eval_steps\"],\n",
    "        start_delay_secs=args[\"start_delay_secs\"],\n",
    "        throttle_secs=args[\"throttle_secs\"],\n",
    "        exporters=exporter\n",
    "    )\n",
    "\n",
    "    # Create train and evaluate loop to train and evaluate our estimator.\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'local_trained_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f284d4b7c10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "pgan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "pgan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "pgan_model: mode = train\n",
      "pgan_model: params = {'train_file_pattern': 'data/train.tfrecord', 'eval_file_pattern': 'data/eval.tfrecord', 'output_dir': 'local_trained_model', 'train_batch_size': 32, 'train_steps': 400, 'eval_batch_size': 32, 'eval_steps': 10, 'start_delay_secs': 600, 'throttle_secs': 600, 'exports_to_keep': 20, 'predict_all_resolutions': True, 'height': 32, 'width': 32, 'depth': 3, 'num_steps_until_growth': 100, 'conv_num_filters': [[512, 512], [512, 512], [512, 512], [512, 512], [256, 256]], 'conv_kernel_sizes': [[4, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'conv_strides': [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1]], 'generator_base_conv_blocks': [[[4, 4, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]]], 'generator_growth_conv_blocks': [[[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 256, 1, 1], [3, 3, 256, 256, 1, 1]]], 'generator_to_rgb_layers': [[[1, 1, 512, 3, 1, 1]], [[1, 1, 512, 3, 1, 1]], [[1, 1, 512, 3, 1, 1]], [[1, 1, 512, 3, 1, 1]], [[1, 1, 256, 3, 1, 1]]], 'discriminator_from_rgb_layers': [[[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 256, 1, 1]]], 'discriminator_base_conv_blocks': [[[3, 3, 512, 512, 1, 1], [4, 4, 512, 512, 1, 1]]], 'discriminator_growth_conv_blocks': [[[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 256, 256, 1, 1], [3, 3, 256, 512, 1, 1]]], 'latent_size': 512, 'generator_projection_dims': [4, 4, 512], 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_optimizer': 'GradientDescent', 'generator_learning_rate': 0.0001, 'generator_clip_gradients': 2.0, 'generator_train_steps': 1, 'discriminator_l1_regularization_scale': 0.01, 'discriminator_l2_regularization_scale': 0.01, 'discriminator_optimizer': 'GradientDescent', 'discriminator_learning_rate': 0.0001, 'discriminator_clip_gradients': 2.0, 'discriminator_gradient_penalty_coefficient': 10.0, 'discriminator_train_steps': 1}\n",
      "\n",
      "instantiate_generator_projection_layer: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7f283e566610>\n",
      "\n",
      "instantiate_generator_layers: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7f283e566610>\n",
      "\n",
      "instantiate_generator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566910>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566cd0>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566fd0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566810>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e5632d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563550>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563590>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e5634d0>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563bd0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563a10>]\n",
      "instantiate_generator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566910>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566cd0>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566fd0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566810>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e5632d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563550>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563590>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e5634d0>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563bd0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563a10>]]\n",
      "\n",
      "instantiate_generator_to_rgb_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e090>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e210>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e390>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e510>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e690>]\n",
      "instantiate_generator_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e090>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e210>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e390>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e510>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e690>]\n",
      "\n",
      "build_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_layers: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>]\n",
      "build_generator_layers: conv_block_tensors = [[<tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>]]\n",
      "build_generator_layers: conv_block_tensors = [<tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>]\n",
      "\n",
      "build_generator_to_rgb_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "build_generator_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "\n",
      "instantiate_discriminator_from_rgb_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e416b90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e416d50>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e416ed0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b090>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b210>]\n",
      "instantiate_discriminator_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e416b90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e416d50>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e416ed0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b090>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b210>]\n",
      "\n",
      "instantiate_discriminator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b590>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b710>]\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41ba10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41bb90>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e41be10>\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e4210d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421250>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e4214d0>\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421750>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e4218d0>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e421b50>\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421dd0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421f50>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427210>\n",
      "instantiate_discriminator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b590>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b710>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41ba10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41bb90>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e41be10>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e4210d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421250>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e4214d0>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421750>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e4218d0>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e421b50>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421dd0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421f50>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427210>]]\n",
      "\n",
      "instantiate_discriminator_growth_transition_downsample_layers: downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427550>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427690>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e4277d0>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427910>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427a50>]\n",
      "instantiate_discriminator_layers: transition_downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427550>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427690>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e4277d0>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427910>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427a50>]\n",
      "\n",
      "create_discriminator_logits_layer: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7f283e427dd0>\n",
      "create_growth_transition_discriminator_network: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7f283e427fd0>\n",
      "instantiate_discriminator_layers: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7f283e427dd0>\n",
      "instantiate_discriminator_layers: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7f283e427fd0>\n",
      "\n",
      "build_discriminator_from_rgb_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0' shape=(1, 1, 1, 256) dtype=float32>]\n",
      "\n",
      "build_discriminator_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0' shape=(1, 1, 1, 256) dtype=float32>]\n",
      "\n",
      "build_discriminator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "build_discriminator_layers: conv_block_tensors = [<tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(1, 512), dtype=float32)\n",
      "build_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "build_discriminator_layers: logits_tensor = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "pgan_model: alpha_var = <tf.Variable 'alpha_var:0' shape=() dtype=float32_ref>\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_train_eval_generator_outputs: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "create_base_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: to_rgb_conv = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 0\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_0_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_0_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_0 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_0_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_0_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_0 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_0 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_0 = Tensor(\"generator/growth_transition_weighted_sum_0:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 1\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_1_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_1_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_1_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_1_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_1_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_1 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_1_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_1_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_1 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_1 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_1 = Tensor(\"generator/growth_transition_weighted_sum_1:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 2\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_2_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_2_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_2_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_2_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_2 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_2_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_2_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_2 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_2 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_2 = Tensor(\"generator/growth_transition_weighted_sum_2:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "create_final_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_final_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "create_final_generator_network: base_block_conv = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_final_generator_network: base_block_conv_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_4 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_4_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_final_generator_network: block_conv_4_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_final_generator_network: to_rgb_conv = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "get_train_eval_generator_outputs: generated_outputs = Tensor(\"generator_switch_case_generated_outputs/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "Call discriminator with generator_outputs = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_base_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 0\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_0/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_0:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 1\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_1/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_1:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 2\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_2/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_final_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_switch_case_logits/indexed_case/Identity:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "resize_real_images: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "\n",
      "resize_real_image: block_idx = 0\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_0/ResizeNearestNeighbor:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 1\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_1/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 2\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_2/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 3\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "resize_real_images: selected resized_image = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "Call discriminator with real_image = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_base_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 0\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_0/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_0:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 1\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_1/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_1:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 2\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_2/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_final_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_switch_case_logits_1/indexed_case/Identity:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = generator\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_generator: generator_7/generator_projection_layer/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"generator_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"generator_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"generator_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_generated_loss = Tensor(\"discriminator_generated_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"discriminator/gradient_penalty/random_uniform_num:0\", shape=(?, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"discriminator/gradient_penalty/sub:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_base_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 0\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_0/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_0:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 1\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_1/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_1:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 2\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_2/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_final_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/gradient_penalty/discriminator_switch_case_logits/indexed_case/Identity:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"discriminator/gradient_penalty/discriminator_logits_identity:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"discriminator/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"discriminator/gradient_penalty/gradients/discriminator/gradient_penalty/mixed_loss_grad/Tile:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"discriminator/gradient_penalty/Sqrt:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"discriminator/gradient_penalty/squared_difference:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"discriminator/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = discriminator\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_14/discriminator_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"discriminator_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"discriminator_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"discriminator_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "train_network: loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "train_network: global_step = <tf.Variable 'global_step:0' shape=() dtype=int64_ref>\n",
      "train_network: alpha_var = <tf.Variable 'alpha_var:0' shape=() dtype=float32_ref>\n",
      "train_network: scope = generator\n",
      "train_network: optimizer = <tensorflow.python.training.gradient_descent.GradientDescentOptimizer object at 0x7f283d962ed0>\n",
      "\n",
      "train_network: variables = [<tf.Variable 'generator/generator_projection_layer/kernel:0' shape=(512, 8192) dtype=float32_ref>, <tf.Variable 'generator/generator_projection_layer/bias:0' shape=(8192,) dtype=float32_ref>, <tf.Variable 'generator/generator_base_layers_conv2d_0_4x4_512_512/kernel:0' shape=(4, 4, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_base_layers_conv2d_0_4x4_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_base_layers_conv2d_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_base_layers_conv2d_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_0_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_0_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_1_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_1_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_2_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_2_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel:0' shape=(3, 3, 512, 256) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_3_0_3x3_512_256/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_3_1_3x3_256_256/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel:0' shape=(1, 1, 512, 3) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_0_1x1_512_3/bias:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel:0' shape=(1, 1, 512, 3) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_1_1x1_512_3/bias:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel:0' shape=(1, 1, 512, 3) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_2_1x1_512_3/bias:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel:0' shape=(1, 1, 512, 3) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_3_1x1_512_3/bias:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel:0' shape=(1, 1, 256, 3) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_4_1x1_256_3/bias:0' shape=(3,) dtype=float32_ref>]\n",
      "\n",
      "train_network: gradients = [<tf.Tensor 'cond/generator_gradients/AddN_16:0' shape=(512, 8192) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_2:0' shape=(8192,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_17:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_4:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_18:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_6:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_19:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_10:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_20:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_12:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_21:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_17:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_22:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_19:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_23:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_23:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_24:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_25:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_25:0' shape=(3, 3, 512, 256) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_29:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_26:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_31:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_27:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_8:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_28:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_14:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_29:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_21:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_30:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_27:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_31:0' shape=(1, 1, 256, 3) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_33:0' shape=(3,) dtype=float32>]\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\n",
      "train_network: gradients = [<tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_0:0' shape=(512, 8192) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_1:0' shape=(8192,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_2:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_3:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_4:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_5:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_6:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_7:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_8:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_9:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_10:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_11:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_12:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_13:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_14:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_15:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_16:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_17:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_18:0' shape=(3, 3, 512, 256) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_19:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_20:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_21:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_22:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_23:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_24:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_25:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_26:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_27:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_28:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_29:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_30:0' shape=(1, 1, 256, 3) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_31:0' shape=(3,) dtype=float32>]\n",
      "train_network: grads_and_vars = <zip object at 0x7f2837b1e140>\n",
      "train_network: train_op = name: \"cond/generator_apply_gradients\"\n",
      "op: \"AssignAdd\"\n",
      "input: \"cond/generator_apply_gradients/Switch:1\"\n",
      "input: \"cond/generator_apply_gradients/value\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT64\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_class\"\n",
      "  value {\n",
      "    list {\n",
      "      s: \"loc:@global_step\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"use_locking\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "\n",
      "train_network: alpha_var_update_op = Tensor(\"cond/Assign:0\", shape=(), dtype=float32_ref)\n",
      "\n",
      "train_network: loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "train_network: global_step = <tf.Variable 'global_step:0' shape=() dtype=int64_ref>\n",
      "train_network: alpha_var = <tf.Variable 'alpha_var:0' shape=() dtype=float32_ref>\n",
      "train_network: scope = discriminator\n",
      "train_network: optimizer = <tensorflow.python.training.gradient_descent.GradientDescentOptimizer object at 0x7f2837add2d0>\n",
      "\n",
      "train_network: variables = [<tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel:0' shape=(1, 1, 3, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel:0' shape=(1, 1, 3, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel:0' shape=(1, 1, 3, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel:0' shape=(1, 1, 3, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel:0' shape=(1, 1, 3, 256) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_base_layers_conv2d_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_base_layers_conv2d_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_base_layers_conv2d_1_4x4_512_512/kernel:0' shape=(4, 4, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_base_layers_conv2d_1_4x4_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_0_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_0_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_1_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_1_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_2_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_2_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_3_0_3x3_256_256/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel:0' shape=(3, 3, 256, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_3_1_3x3_256_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_layers_dense_logits/kernel:0' shape=(512, 1) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_layers_dense_logits/bias:0' shape=(1,) dtype=float32_ref>]\n",
      "\n",
      "train_network: gradients = [<tf.Tensor 'cond/discriminator_gradients/AddN_32:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_16:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_33:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_20:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_34:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_23:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_35:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_26:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_36:0' shape=(1, 1, 3, 256) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_29:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_37:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_17:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_38:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_18:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_39:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_21:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_40:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_22:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_41:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_24:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_42:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_25:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_43:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_27:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_44:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_28:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_45:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_30:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_46:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_31:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_47:0' shape=(512, 1) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_19:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "train_network: gradients = [<tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_0:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_1:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_2:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_3:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_4:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_5:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_6:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_7:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_8:0' shape=(1, 1, 3, 256) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_9:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_10:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_11:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_12:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_13:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_14:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_15:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_16:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_17:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_18:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_19:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_20:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_21:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_22:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_23:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_24:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_25:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_26:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_27:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_28:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_29:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_30:0' shape=(512, 1) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_31:0' shape=(1,) dtype=float32>]\n",
      "train_network: grads_and_vars = <zip object at 0x7f2834f68910>\n",
      "train_network: train_op = name: \"cond/discriminator_apply_gradients\"\n",
      "op: \"AssignAdd\"\n",
      "input: \"cond/discriminator_apply_gradients/Switch:0\"\n",
      "input: \"cond/discriminator_apply_gradients/value\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT64\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_class\"\n",
      "  value {\n",
      "    list {\n",
      "      s: \"loc:@global_step\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"use_locking\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "\n",
      "train_network: alpha_var_update_op = Tensor(\"cond/Assign_1:0\", shape=(), dtype=float32_ref)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into local_trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 65374.69, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1.38105\n",
      "INFO:tensorflow:loss = 65364.15, step = 101 (72.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.96929\n",
      "INFO:tensorflow:loss = 65352.832, step = 201 (103.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.353734\n",
      "INFO:tensorflow:loss = 65341.95, step = 301 (282.698 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 315 into local_trained_model/model.ckpt.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "pgan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "pgan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "pgan_model: mode = eval\n",
      "pgan_model: params = {'train_file_pattern': 'data/train.tfrecord', 'eval_file_pattern': 'data/eval.tfrecord', 'output_dir': 'local_trained_model', 'train_batch_size': 32, 'train_steps': 400, 'eval_batch_size': 32, 'eval_steps': 10, 'start_delay_secs': 600, 'throttle_secs': 600, 'exports_to_keep': 20, 'predict_all_resolutions': True, 'height': 32, 'width': 32, 'depth': 3, 'num_steps_until_growth': 100, 'conv_num_filters': [[512, 512], [512, 512], [512, 512], [512, 512], [256, 256]], 'conv_kernel_sizes': [[4, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'conv_strides': [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1]], 'generator_base_conv_blocks': [[[4, 4, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]]], 'generator_growth_conv_blocks': [[[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 256, 1, 1], [3, 3, 256, 256, 1, 1]]], 'generator_to_rgb_layers': [[[1, 1, 512, 3, 1, 1]], [[1, 1, 512, 3, 1, 1]], [[1, 1, 512, 3, 1, 1]], [[1, 1, 512, 3, 1, 1]], [[1, 1, 256, 3, 1, 1]]], 'discriminator_from_rgb_layers': [[[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 256, 1, 1]]], 'discriminator_base_conv_blocks': [[[3, 3, 512, 512, 1, 1], [4, 4, 512, 512, 1, 1]]], 'discriminator_growth_conv_blocks': [[[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 256, 256, 1, 1], [3, 3, 256, 512, 1, 1]]], 'latent_size': 512, 'generator_projection_dims': [4, 4, 512], 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_optimizer': 'GradientDescent', 'generator_learning_rate': 0.0001, 'generator_clip_gradients': 2.0, 'generator_train_steps': 1, 'discriminator_l1_regularization_scale': 0.01, 'discriminator_l2_regularization_scale': 0.01, 'discriminator_optimizer': 'GradientDescent', 'discriminator_learning_rate': 0.0001, 'discriminator_clip_gradients': 2.0, 'discriminator_gradient_penalty_coefficient': 10.0, 'discriminator_train_steps': 1}\n",
      "\n",
      "instantiate_generator_projection_layer: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7f28342e00d0>\n",
      "\n",
      "instantiate_generator_layers: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7f28342e00d0>\n",
      "\n",
      "instantiate_generator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0750>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e08d0>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0450>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0c50>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0e90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0c10>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5a10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5090>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5950>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5310>]\n",
      "instantiate_generator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0750>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e08d0>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0450>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0c50>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0e90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0c10>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5a10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5090>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5950>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5310>]]\n",
      "\n",
      "instantiate_generator_to_rgb_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5350>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5e10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5150>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342ec290>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342ec510>]\n",
      "instantiate_generator_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5350>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5e10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5150>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342ec290>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342ec510>]\n",
      "\n",
      "build_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_layers: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>]\n",
      "build_generator_layers: conv_block_tensors = [[<tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>]]\n",
      "build_generator_layers: conv_block_tensors = [<tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>]\n",
      "\n",
      "build_generator_to_rgb_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "build_generator_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "\n",
      "instantiate_discriminator_from_rgb_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4510>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4690>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4810>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4990>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4b10>]\n",
      "instantiate_discriminator_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4510>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4690>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4810>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4990>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4b10>]\n",
      "\n",
      "instantiate_discriminator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4e90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c050>]\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c350>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c4d0>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc37c750>\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c9d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37cb50>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc37cdd0>\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381090>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381210>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381490>\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381710>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381890>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381b10>\n",
      "instantiate_discriminator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4e90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c050>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c350>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c4d0>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc37c750>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c9d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37cb50>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc37cdd0>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381090>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381210>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381490>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381710>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381890>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381b10>]]\n",
      "\n",
      "instantiate_discriminator_growth_transition_downsample_layers: downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381e50>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381f90>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc3890d0>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc389250>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc389390>]\n",
      "instantiate_discriminator_layers: transition_downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381e50>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381f90>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc3890d0>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc389250>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc389390>]\n",
      "\n",
      "create_discriminator_logits_layer: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7f27bc389710>\n",
      "create_growth_transition_discriminator_network: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7f27bc389910>\n",
      "instantiate_discriminator_layers: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7f27bc389710>\n",
      "instantiate_discriminator_layers: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7f27bc389910>\n",
      "\n",
      "build_discriminator_from_rgb_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0' shape=(1, 1, 1, 256) dtype=float32>]\n",
      "\n",
      "build_discriminator_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0' shape=(1, 1, 1, 256) dtype=float32>]\n",
      "\n",
      "build_discriminator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "build_discriminator_layers: conv_block_tensors = [<tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(1, 512), dtype=float32)\n",
      "build_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "build_discriminator_layers: logits_tensor = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "pgan_model: alpha_var = <tf.Variable 'alpha_var:0' shape=() dtype=float32_ref>\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_train_eval_generator_outputs: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "create_base_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: to_rgb_conv = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 0\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_0_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_0_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_0 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_0_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_0_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_0 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_0 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_0 = Tensor(\"generator/growth_transition_weighted_sum_0:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 1\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_1_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_1_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_1_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_1_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_1_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_1 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_1_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_1_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_1 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_1 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_1 = Tensor(\"generator/growth_transition_weighted_sum_1:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 2\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_2_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_2_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_2_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_2_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_2 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_2_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_2_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_2 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_2 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_2 = Tensor(\"generator/growth_transition_weighted_sum_2:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "create_final_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_final_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "create_final_generator_network: base_block_conv = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_final_generator_network: base_block_conv_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_4 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_4_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_final_generator_network: block_conv_4_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_final_generator_network: to_rgb_conv = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "get_train_eval_generator_outputs: generated_outputs = Tensor(\"generator_switch_case_generated_outputs/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "Call discriminator with generator_outputs = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_base_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 0\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_0/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_0:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 1\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_1/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_1:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 2\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_2/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_final_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_switch_case_logits/indexed_case/Identity:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "resize_real_images: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "\n",
      "resize_real_image: block_idx = 0\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_0/ResizeNearestNeighbor:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 1\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_1/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 2\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_2/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 3\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "resize_real_images: selected resized_image = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "Call discriminator with real_image = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_base_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 0\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_0/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_0:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 1\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_1/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_1:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 2\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_2/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_final_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_switch_case_logits_1/indexed_case/Identity:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = generator\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_generator: generator_7/generator_projection_layer/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"generator_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"generator_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"generator_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_generated_loss = Tensor(\"discriminator_generated_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"discriminator/gradient_penalty/random_uniform_num:0\", shape=(?, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"discriminator/gradient_penalty/sub:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_base_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 0\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_0/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_0:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 1\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_1/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_1:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 2\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_2/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_final_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/gradient_penalty/discriminator_switch_case_logits/indexed_case/Identity:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"discriminator/gradient_penalty/discriminator_logits_identity:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"discriminator/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"discriminator/gradient_penalty/gradients/discriminator/gradient_penalty/mixed_loss_grad/Tile:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"discriminator/gradient_penalty/Sqrt:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"discriminator/gradient_penalty/squared_difference:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"discriminator/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = discriminator\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_14/discriminator_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"discriminator_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"discriminator_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"discriminator_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-05T10:40:16Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from local_trained_model/model.ckpt-315\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree(path=arguments[\"output_dir\"], ignore_errors=True)\n",
    "estimator = train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1591379258\n"
     ]
    }
   ],
   "source": [
    "!ls trained_model/export/exporter | tail -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from trained_model/export/exporter/1591379258/variables/variables\n"
     ]
    }
   ],
   "source": [
    "predict_fn = tf.contrib.predictor.from_saved_model(\n",
    "    \"trained_model/export/exporter/1591379258\"\n",
    ")\n",
    "predictions = predict_fn(\n",
    "    {\n",
    "        \"Z\": np.random.normal(size=(500, 512))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['generated_images_16x16',\n",
       " 'generated_images_32x32',\n",
       " 'generated_images_4x4',\n",
       " 'generated_images_8x8']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(predictions.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = {\n",
    "    k: np.clip(\n",
    "        a=((v + 1.0) * (255. / 2)).astype(np.int32),\n",
    "        a_min=0,\n",
    "        a_max=255\n",
    "    )\n",
    "    for k, v in predictions.items()\n",
    "}\n",
    "\n",
    "sorted_generated_images = [\n",
    "    x[0:2]\n",
    "    for x in sorted(\n",
    "        [\n",
    "            (\n",
    "                k,\n",
    "                generated_images[k],\n",
    "                generated_images[k].shape[-2]\n",
    "            )\n",
    "            for k in generated_images.keys()\n",
    "        ],\n",
    "        key=lambda tup: tup[2]\n",
    "    )\n",
    "]\n",
    "\n",
    "for k, v in sorted_generated_images:\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_4x4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAAByCAYAAAC89bCsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAGG0lEQVR4nO3ZX6jfdR3H8ddxcx2c29o6R6Mj7GcRmskqGjQiCvp3oURIQvinkoJcUYQoQl0IDbWLVWSUWIcEnWDUhdWNCGrRVZMjC4soJ/NM5mruHHE7tdn+fbvoZv06UCc+nyzfj8fl4cvr+2Wf33d77ncmhmEIAEAV57zSDwAA8N8kfgCAUsQPAFCK+AEAShE/AEAp4gcAKGX1Si7euG5qmJkedXqUZHJysdt2kuQv8333kzy5YX2/8QPHM7x4YqLF1NTU+cNotKnF1LJezmu7bSfJ5Kk/dt1PkpPHFrptHziULB4ZmpxlkqybmhqmR6NWc/9kY7flv/vrwc43SLLwhn7bR+bnc3xhoc27OTk1jNaOWkwt69jS4W7bSXLelhX9s/If+V02dNs+Mf9cTrU6y6lzhtGo35/Hqbyu23aS7F+Y6bqfJJs2HO26v++pvQvDMEyP/3xFpzIzPcqP7tzd7qnGXHbpA922kyS7b+i7n2Tiym39xq/4VbOp0WhT5uZubrY37vf5WLftJLl0cUfX/SQ5tGe22/aHP992b3o0yo4n5tqOnuXjnb8j3ndb3/0kme34kXlg69ZmW6O1o8xd2e8s9/z8e922k+Qdc33/45Mkb8tHum3v3fqeZluj0erMzV3QbG/cC/lUt+0kuXH2jq77SXL9FY923b/6og/tX+7nfu0FAJQifgCAUsQPAFCK+AEAShE/AEAp4gcAKEX8AACliB8AoBTxAwCUIn4AgFLEDwBQivgBAEoRPwBAKeIHAChF/AAApYgfAKAU8QMAlCJ+AIBSxA8AUIr4AQBKET8AQCmrV3Lx5LPJZdes6vUseX64r9t2kswcG7ruJ8muiya6bd+2pt3WYi7I/flSu8Exn3x/t+kkybHHv9/3Bkku/OCPu22fu36p6d6mF5Lr7246+Y8u7/e5TpJLHun/bn7r4uu6bZ9eeLbd2It/SHa9r93emLuHX3bbTpJ33dt1Pkly0/yWbttfPbi32daZbMnxzDXbG/fYkX5/hyfJg599c9f9JJkcnul+j+X45gcAKEX8AACliB8AoBTxAwCUIn4AgFLEDwBQivgBAEoRPwBAKeIHAChF/AAApYgfAKAU8QMAlCJ+AIBSxA8AUIr4AQBKET8AQCniBwAoRfwAAKWIHwCgFPEDAJQifgCAUsQPAFCK+AEASlm9kosPXLInt86u7/UsOZylbttJcvOqLV33k+QDb7yl2/bO53c129p4+Mlcdc9Es71xLz886radJLdfuKrrfpLceWhHx/WdTddOnpzPwT99punm2c5791u7bSfJ9if6vvtJcmr3m7ptb/3ua9qNvfNYMvfrdntjZvd/pdt2knz0hvO77ifJXZu/3G37mwtbm22d2b8vS9uvabY37tp9D3bbTpIDw7e77ifJzG/+3PkOy38effMDAJQifgCAUsQPAFCK+AEAShE/AEAp4gcAKEX8AACliB8AoBTxAwCUIn4AgFLEDwBQivgBAEoRPwBAKeIHAChF/AAApYgfAKAU8QMAlCJ+AIBSxA8AUIr4AQBKET8AQCniBwAoRfwAAKWIHwCglNUruXjNmsszc/EjvZ4ln/7667ttJ8nOW67qup8kP7jn0W7b537haLOtpefW5Ref29Zsb9x7t9/YbTtJbjp0ddf9JDn69i922z799H1N956aWczM7fc23TzbQ7m123aS/HB4uut+kjw+/5Nu20snXmq2dej0mXzjaLt3fdyRzZ/otp0kP/3tW7ruJ0m23dFtes1jx5ttLR59Kfc//FCzvXE7vjPZbTtJZr72TNf9JLnrZ2u732M5vvkBAEoRPwBAKeIHAChF/AAApYgfAKAU8QMAlCJ+AIBSxA8AUIr4AQBKET8AQCniBwAoRfwAAKWIHwCgFPEDAJQifgCAUsQPAFCK+AEAShE/AEAp4gcAKEX8AACliB8AoBTxAwCUIn4AgFImhmH49y+emDicZH+/x+Ff2DwMw3SLIWf5imt2lonz/B/g3Xz1cJavLsue54riBwDg/51fewEApYgfAKAU8QMAlCJ+AIBSxA8AUIr4AQBKET8AQCniBwAoRfwAAKX8De0FAtvp/fgnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_8x8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_16x16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_32x32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_images = 10\n",
    "\n",
    "for k, v in sorted_generated_images:\n",
    "    print(k)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(v[i], cmap=plt.cm.binary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1591525697\n"
     ]
    }
   ],
   "source": [
    "!ls trained_model/export/exporter | tail -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from trained_model/export/exporter/1591525697/variables/variables\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predict_fn = tf.contrib.predictor.from_saved_model(\n",
    "    \"trained_model/export/exporter/1591525697\"\n",
    ")\n",
    "predictions = predict_fn(\n",
    "    {\n",
    "        \"Z\": np.random.normal(size=(500, 512))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_4x4 (500, 4, 4, 3)\n",
      "generated_images_8x8 (500, 8, 8, 3)\n",
      "generated_images_16x16 (500, 16, 16, 3)\n",
      "generated_images_32x32 (500, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "generated_images = {\n",
    "    k: np.clip(\n",
    "        a=((v + 1.0) * (255. / 2)).astype(np.int32),\n",
    "        a_min=0,\n",
    "        a_max=255\n",
    "    )\n",
    "    for k, v in predictions.items()\n",
    "}\n",
    "\n",
    "sorted_generated_images = [\n",
    "    x[0:2]\n",
    "    for x in sorted(\n",
    "        [\n",
    "            (\n",
    "                k,\n",
    "                generated_images[k],\n",
    "                generated_images[k].shape[-2]\n",
    "            )\n",
    "            for k in generated_images.keys()\n",
    "        ],\n",
    "        key=lambda tup: tup[2]\n",
    "    )\n",
    "]\n",
    "\n",
    "for k, v in sorted_generated_images:\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_4x4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_8x8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_16x16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_32x32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_images = 10\n",
    "\n",
    "for k, v in sorted_generated_images:\n",
    "    print(k)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(v[i], cmap=plt.cm.binary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
