{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model module GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_num_filters = 512,512;512,512;512,512;512,512;256,256;128,128;64,64;32,32;16,16\n",
      "conv_kernel_sizes = 4,3;3,3;3,3;3,3;3,3;3,3;3,3;3,3;3,3\n",
      "conv_strides = 1,1;1,1;1,1;1,1;1,1;1,1;1,1;1,1;1,1\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "def convert_conv_layer_property_lists_to_string(property_list, prop_list_len):\n",
    "    \"\"\"Convert conv layer property list to string.\n",
    "\n",
    "    Args:\n",
    "        property_list: list, nested list of blocks of a conv layer property.\n",
    "        prop_list_len: int, length of list to process.\n",
    "\n",
    "    Returns:\n",
    "        Doubly delimited string of conv layer property values.\n",
    "    \"\"\"\n",
    "    return (\";\").join(\n",
    "        [\n",
    "            (\",\").join([str(val) for val in block])\n",
    "            for block in property_list[0:prop_list_len]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "\n",
    "# Import os environment variables for file hyperparameters.\n",
    "os.environ[\"TRAIN_FILE_PATTERN\"] = \"gs://machine-learning-1234-bucket/gan/pgan/data/train*.tfrecord\"\n",
    "os.environ[\"EVAL_FILE_PATTERN\"] = \"gs://machine-learning-1234-bucket/gan/pgan/data/test*.tfrecord\"\n",
    "os.environ[\"OUTPUT_DIR\"] = \"gs://machine-learning-1234-bucket/gan/pgan/trained_model\"\n",
    "\n",
    "# Import os environment variables for train hyperparameters.\n",
    "os.environ[\"TRAIN_BATCH_SIZE\"] = str(16)\n",
    "os.environ[\"TRAIN_STEPS\"] = str(100000)\n",
    "\n",
    "# Import os environment variables for eval hyperparameters.\n",
    "os.environ[\"EVAL_BATCH_SIZE\"] = str(1)\n",
    "os.environ[\"EVAL_STEPS\"] = str(1)\n",
    "os.environ[\"START_DELAY_SECS\"] = str(600)\n",
    "os.environ[\"THROTTLE_SECS\"] = str(600)\n",
    "\n",
    "# Import os environment variables for serving hyperparameters.\n",
    "os.environ[\"EXPORTS_TO_KEEP\"] = str(144)\n",
    "os.environ[\"PREDICT_ALL_RESOLUTIONS\"] = \"True\"\n",
    "\n",
    "# Import os environment variables for image hyperparameters.\n",
    "os.environ[\"HEIGHT\"] = str(32)\n",
    "os.environ[\"WIDTH\"] = str(32)\n",
    "os.environ[\"DEPTH\"] = str(3)\n",
    "\n",
    "# Import os environment variables for shared hyperparameters.\n",
    "os.environ[\"NUM_STEPS_UNTIL_GROWTH\"] = str(10)\n",
    "\n",
    "# Full lists for full 1024x1024 network growth.\n",
    "full_conv_num_filters = [[512, 512], [512, 512], [512, 512], [512, 512], [256, 256], [128, 128], [64, 64], [32, 32], [16, 16]]\n",
    "full_conv_kernel_sizes = [[4, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]]\n",
    "full_conv_strides = [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]]\n",
    "\n",
    "# Set final image size as a multiple of 2, starting at 4.\n",
    "image_size = 1024\n",
    "os.environ[\"IMAGE_SIZE\"] = str(image_size)\n",
    "prop_list_len = max(\n",
    "    min(int(math.log(image_size, 2) - 1), len(full_conv_num_filters)), 1\n",
    ")\n",
    "\n",
    "# Get slices of lists.\n",
    "conv_num_filters = convert_conv_layer_property_lists_to_string(\n",
    "    full_conv_num_filters, prop_list_len\n",
    ")\n",
    "print(\"conv_num_filters = {}\".format(conv_num_filters))\n",
    "conv_kernel_sizes = convert_conv_layer_property_lists_to_string(\n",
    "    full_conv_kernel_sizes, prop_list_len\n",
    ")\n",
    "print(\"conv_kernel_sizes = {}\".format(conv_kernel_sizes))\n",
    "conv_strides = convert_conv_layer_property_lists_to_string(\n",
    "    full_conv_strides, prop_list_len\n",
    ")\n",
    "print(\"conv_strides = {}\".format(conv_strides))\n",
    "\n",
    "os.environ[\"CONV_NUM_FILTERS\"] = conv_num_filters\n",
    "os.environ[\"CONV_KERNEL_SIZES\"] = conv_kernel_sizes\n",
    "os.environ[\"CONV_STRIDES\"] = conv_strides\n",
    "\n",
    "# Import os environment variables for generator hyperparameters.\n",
    "os.environ[\"LATENT_SIZE\"] = str(512)\n",
    "os.environ[\"NORMALIZE_LATENT\"] = \"True\"\n",
    "os.environ[\"USE_PIXEL_NORM\"] = \"True\"\n",
    "os.environ[\"PIXEL_NORM_EPSILON\"] = str(1e-8)\n",
    "os.environ[\"GENERATOR_PROJECTION_DIMS\"] = \"4,4,512\"\n",
    "os.environ[\"GENERATOR_L1_REGULARIZATION_SCALE\"] = str(0.01)\n",
    "os.environ[\"GENERATOR_L2_REGULARIZATION_SCALE\"] = str(0.01)\n",
    "os.environ[\"GENERATOR_OPTIMIZER\"] = \"Adam\"\n",
    "os.environ[\"GENERATOR_LEARNING_RATE\"] = str(0.0001)\n",
    "os.environ[\"GENERATOR_CLIP_GRADIENTS\"] = str(5.0)\n",
    "os.environ[\"GENERATOR_TRAIN_STEPS\"] = str(1)\n",
    "\n",
    "# Import os environment variables for discriminator hyperparameters.\n",
    "os.environ[\"USE_MINIBATCH_STDDEV\"] = \"True\"\n",
    "os.environ[\"MINIBATCH_STDDEV_GROUP_SIZE\"] = str(4)\n",
    "os.environ[\"MINIBATCH_STDDEV_AVERAGING\"] = \"True\"\n",
    "os.environ[\"DISCRIMINATOR_L1_REGULARIZATION_SCALE\"] = str(0.01)\n",
    "os.environ[\"DISCRIMINATOR_L2_REGULARIZATION_SCALE\"] = str(0.01)\n",
    "os.environ[\"DISCRIMINATOR_OPTIMIZER\"] = \"Adam\"\n",
    "os.environ[\"DISCRIMINATOR_LEARNING_RATE\"] = str(0.0001)\n",
    "os.environ[\"DISCRIMINATOR_CLIP_GRADIENTS\"] = str(5.0)\n",
    "os.environ[\"DISCRIMINATOR_GRADIENT_PENALTY_COEFFICIENT\"] = str(10.0)\n",
    "os.environ[\"EPSILON_DRIFT\"] = str(0.001)\n",
    "os.environ[\"DISCRIMINATOR_TRAIN_STEPS\"] = str(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"machine-learning-1234\"\n",
    "BUCKET = \"machine-learning-1234-bucket\"\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "# Import os environment variables\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] =  BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"TFVERSION\"] = \"1.15\"\n",
    "os.environ[\"PYTHON_VERSION\"] = \"3.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train pGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://machine-learning-1234-bucket/gan/pgan/trained_model us-central1 pgan_8x8_200606_075016\n",
      "jobId: pgan_8x8_200606_075016\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://machine-learning-1234-bucket/gan/pgan/trained_model/#1591422484300972...\n",
      "Removing gs://machine-learning-1234-bucket/gan/pgan/trained_model/checkpoint#1591422895227531...\n",
      "Removing gs://machine-learning-1234-bucket/gan/pgan/trained_model/eval/#1591422934615173...\n",
      "Removing gs://machine-learning-1234-bucket/gan/pgan/trained_model/eval/events.out.tfevents.1591422934.tf-1-15#1591422936651135...\n",
      "Removing gs://machine-learning-1234-bucket/gan/pgan/trained_model/events.out.tfevents.1591422486.tf-1-15#1591422898710352...\n",
      "Removing gs://machine-learning-1234-bucket/gan/pgan/trained_model/export/#1591422937865982...\n",
      "Removing gs://machine-learning-1234-bucket/gan/pgan/trained_model/export/exporter/#1591422938187720...\n",
      "Removing gs://machine-learning-1234-bucket/gan/pgan/trained_model/export/exporter/1591422936/#1591422952142281...\n",
      "Removing gs://machine-learning-1234-bucket/gan/pgan/trained_model/export/exporter/1591422936/saved_model.pb#1591422952364535...\n",
      "Removing gs://machine-learning-1234-bucket/gan/pgan/trained_model/export/exporter/1591422936/variables/#1591422952607857...\n",
      "Removing gs://machine-learning-1234-bucket/gan/pgan/trained_model/export/exporter/1591422936/variables/variables.data-00000-of-00001#1591422952859533...\n",
      "Removing gs://machine-learning-1234-bucket/gan/pgan/trained_model/export/exporter/1591422936/variables/variables.index#1591422953129400...\n",
      "Removing gs://machine-learning-1234-bucket/gan/pgan/trained_model/graph.pbtxt#1591422509438122...\n",
      "Removing gs://machine-learning-1234-bucket/gan/pgan/trained_model/model.ckpt-0.data-00000-of-00001#1591422520674371...\n",
      "Removing gs://machine-learning-1234-bucket/gan/pgan/trained_model/model.ckpt-0.index#1591422521052230...\n",
      "Removing gs://machine-learning-1234-bucket/gan/pgan/trained_model/model.ckpt-0.meta#1591422524314077...\n",
      "Removing gs://machine-learning-1234-bucket/gan/pgan/trained_model/model.ckpt-100.data-00000-of-00001#1591422894024631...\n",
      "Removing gs://machine-learning-1234-bucket/gan/pgan/trained_model/model.ckpt-100.index#1591422894348999...\n",
      "Removing gs://machine-learning-1234-bucket/gan/pgan/trained_model/model.ckpt-100.meta#1591422897833443...\n",
      "/ [19/19 objects] 100% Done                                                     \n",
      "Operation completed over 19 objects.                                             \n",
      "Job [pgan_8x8_200606_075016] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe pgan_8x8_200606_075016\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs pgan_8x8_200606_075016\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "JOBNAME=pgan_${IMAGE_SIZE}x${IMAGE_SIZE}_$(date -u +%y%m%d_%H%M%S)\n",
    "echo ${OUTPUT_DIR} ${REGION} ${JOBNAME}\n",
    "gsutil -m rm -rf ${OUTPUT_DIR}\n",
    "gcloud ai-platform jobs submit training ${JOBNAME} \\\n",
    "    --region=${REGION} \\\n",
    "    --module-name=trainer.task \\\n",
    "    --package-path=$PWD/pgan_module/trainer \\\n",
    "    --job-dir=${OUTPUT_DIR} \\\n",
    "    --staging-bucket=gs://${BUCKET} \\\n",
    "    --scale-tier=BASIC_TPU \\\n",
    "    --runtime-version=${TFVERSION} \\\n",
    "    --python-version=${PYTHON_VERSION} \\\n",
    "    -- \\\n",
    "    --train_file_pattern=${TRAIN_FILE_PATTERN} \\\n",
    "    --eval_file_pattern=${EVAL_FILE_PATTERN} \\\n",
    "    --output_dir=${OUTPUT_DIR} \\\n",
    "    --job-dir=./tmp \\\n",
    "    \\\n",
    "    --train_batch_size=${TRAIN_BATCH_SIZE} \\\n",
    "    --train_steps=${TRAIN_STEPS} \\\n",
    "    \\\n",
    "    --eval_batch_size=${EVAL_BATCH_SIZE} \\\n",
    "    --eval_steps=${EVAL_STEPS} \\\n",
    "    --start_delay_secs=${START_DELAY_SECS} \\\n",
    "    --throttle_secs=${THROTTLE_SECS} \\\n",
    "    \\\n",
    "    --exports_to_keep=${EXPORTS_TO_KEEP} \\\n",
    "    --predict_all_resolutions=${PREDICT_ALL_RESOLUTIONS} \\\n",
    "    \\\n",
    "    --height=${HEIGHT} \\\n",
    "    --width=${WIDTH} \\\n",
    "    --depth=${DEPTH} \\\n",
    "    \\\n",
    "    --num_steps_until_growth=${NUM_STEPS_UNTIL_GROWTH} \\\n",
    "    --conv_num_filters=${CONV_NUM_FILTERS} \\\n",
    "    --conv_kernel_sizes=${CONV_KERNEL_SIZES} \\\n",
    "    --conv_strides=${CONV_STRIDES} \\\n",
    "    \\\n",
    "    --latent_size=${LATENT_SIZE} \\\n",
    "    --normalize_latent=${NORMALIZE_LATENT} \\\n",
    "    --use_pixel_norm=${USE_PIXEL_NORM} \\\n",
    "    --pixel_norm_epsilon=${PIXEL_NORM_EPSILON} \\\n",
    "    --generator_projection_dims=${GENERATOR_PROJECTION_DIMS} \\\n",
    "    --generator_l1_regularization_scale=${GENERATOR_L1_REGULARIZATION_SCALE} \\\n",
    "    --generator_l2_regularization_scale=${GENERATOR_L2_REGULARIZATION_SCALE} \\\n",
    "    --generator_optimizer=${GENERATOR_OPTIMIZER} \\\n",
    "    --generator_learning_rate=${GENERATOR_LEARNING_RATE} \\\n",
    "    --generator_clip_gradients=${GENERATOR_CLIP_GRADIENTS} \\\n",
    "    --generator_train_steps=${GENERATOR_TRAIN_STEPS} \\\n",
    "    \\\n",
    "    --use_minibatch_stddev=${USE_MINIBATCH_STDDEV} \\\n",
    "    --minibatch_stddev_group_size=${MINIBATCH_STDDEV_GROUP_SIZE} \\\n",
    "    --minibatch_stddev_averaging=${MINIBATCH_STDDEV_AVERAGING} \\\n",
    "    --discriminator_l1_regularization_scale=${DISCRIMINATOR_L1_REGULARIZATION_SCALE} \\\n",
    "    --discriminator_l2_regularization_scale=${DISCRIMINATOR_L2_REGULARIZATION_SCALE} \\\n",
    "    --discriminator_optimizer=${DISCRIMINATOR_OPTIMIZER} \\\n",
    "    --discriminator_learning_rate=${DISCRIMINATOR_LEARNING_RATE} \\\n",
    "    --discriminator_clip_gradients=${DISCRIMINATOR_CLIP_GRADIENTS} \\\n",
    "    --discriminator_gradient_penalty_coefficient=${DISCRIMINATOR_GRADIENT_PENALTY_COEFFICIENT} \\\n",
    "    --epsilon_drift=${EPSILON_DRIFT} \\\n",
    "    --discriminator_train_steps=${DISCRIMINATOR_TRAIN_STEPS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 hours of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://machine-learning-1234-bucket/gan/pgan/gcp_trained_model_tpu/export/exporter/1591285051/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls ${OUTPUT_DIR}/export/exporter | tail -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/pgan/gcp_trained_model_tpu/export/exporter/1591285051/variables/variables\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "predict_fn = tf.contrib.predictor.from_saved_model(\n",
    "    \"gs://machine-learning-1234-bucket/gan/pgan/gcp_trained_model_tpu/export/exporter/1591285051/\"\n",
    ")\n",
    "predictions = predict_fn(\n",
    "    {\n",
    "        \"Z\": np.random.normal(size=(500, 512))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 4, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "generated_images = predictions[\"generated_images\"]\n",
    "print(generated_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(generated_images[i], cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images_scaled = np.clip(\n",
    "    a=((predictions[\"generated_images\"] + 1.0) * (255. / 2)).astype(np.int32),\n",
    "    a_min=0,\n",
    "    a_max=255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 4, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "print(generated_images_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(generated_images_scaled[i], cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 hours of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://machine-learning-1234-bucket/gan/pgan/gcp_trained_model_tpu/export/exporter/\n",
      "gs://machine-learning-1234-bucket/gan/pgan/gcp_trained_model_tpu/export/exporter/1591285051/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls ${OUTPUT_DIR}/export/exporter | tail -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "predict_fn = tf.contrib.predictor.from_saved_model(\n",
    "    \"gs://machine-learning-1234-bucket/gan/pgan/gcp_trained_model_tpu/export/exporter/1591285051/\"\n",
    ")\n",
    "predictions = predict_fn(\n",
    "    {\n",
    "        \"Z\": np.random.normal(size=(500, 512))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ano_gan\t\t\t\tdata   vanilla_gan\n",
      "create_tfrecords_cifar10.ipynb\tdcgan  wgan\n",
      "create_tfrecords_cifar10.py\tpgan   wgan_gp\n"
     ]
    }
   ],
   "source": [
    "!ls ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../../f_anogan_simultaneous_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../../f_anogan_simultaneous_encoder/tf_f_anogan_simultaneous_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t\t\t\t tf_pgan_loop_module.ipynb\n",
      "demand_forecasting_run_module_gcp.ipynb  tf_pgan_loop_run_module_local.ipynb\n",
      "local_trained_model\t\t\t tf_pgan_module.ipynb\n",
      "pgan_loop_module\t\t\t tf_pgan_run_module_gcp.ipynb\n",
      "pgan_module\t\t\t\t tf_pgan_run_module_local.ipynb\n",
      "tf_pgan_local.ipynb\t\t\t trained_model\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp tf_pgan_local.ipynb ../../f_anogan_simultaneous_encoder/tf_f_anogan_simultaneous_encoder\n",
    "cp tf_pgan_module.ipynb ../../f_anogan_simultaneous_encoder/tf_f_anogan_simultaneous_encoder\n",
    "cp tf_pgan_run_module_local.ipynb ../../f_anogan_simultaneous_encoder/tf_f_anogan_simultaneous_encoder\n",
    "cp -r pgan_module ../../f_anogan_simultaneous_encoder/tf_f_anogan_simultaneous_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
