{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2-dlenv_tfe\n",
      "1.18.1\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and modules\n",
    "import math\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_generator_discriminator_conv_layer_properties(\n",
    "        conv_num_filters, conv_kernel_sizes, conv_strides, depth):\n",
    "    \"\"\"Calculates generator and discriminator conv layer properties.\n",
    "\n",
    "    Args:\n",
    "        num_filters: list, nested list of ints of the number of filters\n",
    "            for each conv layer.\n",
    "        kernel_sizes: list, nested list of ints of the kernel sizes for\n",
    "            each conv layer.\n",
    "        strides: list, nested list of ints of the strides for each conv\n",
    "            layer.\n",
    "        depth: int, depth dimension of images.\n",
    "\n",
    "    Returns:\n",
    "        Nested lists of conv layer properties for both generator and\n",
    "            discriminator.\n",
    "    \"\"\"\n",
    "    def make_generator(num_filters, kernel_sizes, strides, depth):\n",
    "        \"\"\"Calculates generator conv layer properties.\n",
    "\n",
    "        Args:\n",
    "            num_filters: list, nested list of ints of the number of filters\n",
    "                for each conv layer.\n",
    "            kernel_sizes: list, nested list of ints of the kernel sizes for\n",
    "                each conv layer.\n",
    "            strides: list, nested list of ints of the strides for each conv\n",
    "                layer.\n",
    "            depth: int, depth dimension of images.\n",
    "\n",
    "        Returns:\n",
    "            Nested list of conv layer properties for generator.\n",
    "        \"\"\"\n",
    "        # Get the number of growths.\n",
    "        num_growths = len(num_filters) - 1\n",
    "\n",
    "        # Make base block.\n",
    "        in_out = num_filters[0]\n",
    "        base = [\n",
    "            [kernel_sizes[0][i]] * 2 + in_out + [strides[0][i]] * 2\n",
    "            for i in range(len(num_filters[0]))\n",
    "        ]\n",
    "        blocks = [base]\n",
    "\n",
    "        # Add growth blocks.\n",
    "        for i in range(1, num_growths + 1):\n",
    "            in_out = [[blocks[i - 1][-1][-3], num_filters[i][0]]]\n",
    "            block = [[kernel_sizes[i][0]] * 2 + in_out[0] + [strides[i][0]] * 2]\n",
    "            for j in range(1, len(num_filters[i])):\n",
    "                in_out.append([block[-1][-3], num_filters[i][j]])\n",
    "                block.append(\n",
    "                    [kernel_sizes[i][j]] * 2 + in_out[j] + [strides[i][j]] * 2\n",
    "                )\n",
    "            blocks.append(block)\n",
    "\n",
    "        # Add toRGB conv.\n",
    "        blocks[-1].append([1, 1, blocks[-1][-1][-3], depth] + [1] * 2)\n",
    "\n",
    "        return blocks\n",
    "\n",
    "    def make_discriminator(generator):\n",
    "        \"\"\"Calculates discriminator conv layer properties.\n",
    "\n",
    "        Args:\n",
    "            generator: list, nested list of conv layer properties for\n",
    "                generator.\n",
    "\n",
    "        Returns:\n",
    "            Nested list of conv layer properties for discriminator.\n",
    "        \"\"\"\n",
    "        # Reverse generator.\n",
    "        discriminator = generator[::-1]\n",
    "\n",
    "        # Reverse input and output shapes.\n",
    "        discriminator = [\n",
    "            [\n",
    "                conv[0:2] + conv[2:4][::-1] + conv[-2:]\n",
    "                for conv in block[::-1]\n",
    "            ]\n",
    "            for block in discriminator\n",
    "        ]\n",
    "\n",
    "        return discriminator\n",
    "\n",
    "    # Calculate conv layer properties for generator using args.\n",
    "    generator = make_generator(\n",
    "        conv_num_filters, conv_kernel_sizes, conv_strides, depth\n",
    "    )\n",
    "\n",
    "    # Calculate conv layer properties for discriminator using generator\n",
    "    # properties.\n",
    "    discriminator = make_discriminator(generator)\n",
    "\n",
    "    return generator, discriminator\n",
    "\n",
    "\n",
    "def split_up_generator_conv_layer_properties(\n",
    "        generator, num_filters, strides, depth):\n",
    "    \"\"\"Splits up generator conv layer properties into lists.\n",
    "\n",
    "    Args:\n",
    "        generator: list, nested list of conv layer properties for\n",
    "            generator.\n",
    "        num_filters: list, nested list of ints of the number of filters\n",
    "            for each conv layer.\n",
    "        strides: list, nested list of ints of the strides for each conv\n",
    "            layer.\n",
    "        depth: int, depth dimension of images.\n",
    "\n",
    "    Returns:\n",
    "        Nested lists of conv layer properties for generator.\n",
    "    \"\"\"\n",
    "    generator_base_conv_blocks = [generator[0][0:len(num_filters[0])]]\n",
    "\n",
    "    generator_growth_conv_blocks = []\n",
    "    if len(num_filters) > 1:\n",
    "        generator_growth_conv_blocks = generator[1:-1] + [generator[-1][:-1]]\n",
    "\n",
    "    generator_to_rgb_layers = [\n",
    "        [[1] * 2 + [num_filters[i][0]] + [depth] + [strides[i][0]] * 2]\n",
    "        for i in range(len(num_filters))\n",
    "    ]\n",
    "\n",
    "    return (generator_base_conv_blocks,\n",
    "            generator_growth_conv_blocks,\n",
    "            generator_to_rgb_layers)\n",
    "\n",
    "\n",
    "def split_up_discriminator_conv_layer_properties(\n",
    "        discriminator, num_filters, strides, depth):\n",
    "    \"\"\"Splits up discriminator conv layer properties into lists.\n",
    "\n",
    "    Args:\n",
    "        discriminator: list, nested list of conv layer properties for\n",
    "            discriminator.\n",
    "        num_filters: list, nested list of ints of the number of filters\n",
    "            for each conv layer.\n",
    "        strides: list, nested list of ints of the strides for each conv\n",
    "            layer.\n",
    "        depth: int, depth dimension of images.\n",
    "\n",
    "    Returns:\n",
    "        Nested lists of conv layer properties for discriminator.\n",
    "    \"\"\"\n",
    "    discriminator_from_rgb_layers = [\n",
    "        [[1] * 2 + [depth] + [num_filters[i][0]] + [strides[i][0]] * 2]\n",
    "        for i in range(len(num_filters))\n",
    "    ]\n",
    "\n",
    "    if len(num_filters) > 1:\n",
    "        discriminator_base_conv_blocks = [discriminator[-1]]\n",
    "    else:\n",
    "        discriminator_base_conv_blocks = [discriminator[-1][1:]]\n",
    "\n",
    "    discriminator_growth_conv_blocks = []\n",
    "    if len(num_filters) > 1:\n",
    "        discriminator_growth_conv_blocks = [discriminator[0][1:]] + discriminator[1:-1]\n",
    "        discriminator_growth_conv_blocks = discriminator_growth_conv_blocks[::-1]\n",
    "\n",
    "    return (discriminator_from_rgb_layers,\n",
    "            discriminator_base_conv_blocks,\n",
    "            discriminator_growth_conv_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_num_filters = [[512, 512], [512, 512], [512, 512], [512, 512], [256, 256]]\n",
      "conv_kernel_sizes = [[4, 3], [3, 3], [3, 3], [3, 3], [3, 3]]\n",
      "conv_strides = [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1]]\n"
     ]
    }
   ],
   "source": [
    "# Create arguments dictionary to hold all user passed parameters.\n",
    "arguments = {}\n",
    "# File arguments.\n",
    "arguments[\"train_file_pattern\"] = \"data/train.tfrecord\"\n",
    "arguments[\"eval_file_pattern\"] = \"data/eval.tfrecord\"\n",
    "arguments[\"output_dir\"] = \"local_trained_model\"\n",
    "\n",
    "# Training parameters.\n",
    "arguments[\"train_batch_size\"] = 32\n",
    "arguments[\"train_steps\"] = 400\n",
    "\n",
    "# Eval parameters.\n",
    "arguments[\"eval_batch_size\"] = 32\n",
    "arguments[\"eval_steps\"] = 10\n",
    "arguments[\"start_delay_secs\"] = 600\n",
    "arguments[\"throttle_secs\"] = 600\n",
    "\n",
    "# Serving parameters.\n",
    "arguments[\"exports_to_keep\"] = 20\n",
    "arguments[\"predict_all_resolutions\"] = True\n",
    "\n",
    "# Image parameters.\n",
    "arguments[\"height\"] = 32\n",
    "arguments[\"width\"] = 32\n",
    "arguments[\"depth\"] = 3\n",
    "\n",
    "# Shared parameters.\n",
    "arguments[\"num_steps_until_growth\"] = 100\n",
    "\n",
    "# Full lists for full 1024x1024 network growth.\n",
    "full_conv_num_filters = [[512, 512], [512, 512], [512, 512], [512, 512], [256, 256], [128, 128], [64, 64], [32, 32], [16, 16]]\n",
    "full_conv_kernel_sizes = [[4, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]]\n",
    "full_conv_strides = [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]]\n",
    "\n",
    "# Set final image size as a multiple of 2, starting at 4.\n",
    "image_size = 64\n",
    "prop_list_len = max(\n",
    "    min(int(math.log(image_size, 2) - 1), len(full_conv_num_filters)), 1\n",
    ")\n",
    "\n",
    "# Get slices of lists.\n",
    "conv_num_filters = full_conv_num_filters[0:prop_list_len]\n",
    "print(\"conv_num_filters = {}\".format(conv_num_filters))\n",
    "conv_kernel_sizes = full_conv_kernel_sizes[0:prop_list_len]\n",
    "print(\"conv_kernel_sizes = {}\".format(conv_kernel_sizes))\n",
    "conv_strides = full_conv_strides[0:prop_list_len]\n",
    "print(\"conv_strides = {}\".format(conv_strides))\n",
    "\n",
    "arguments[\"conv_num_filters\"] = conv_num_filters\n",
    "arguments[\"conv_kernel_sizes\"] = conv_kernel_sizes\n",
    "arguments[\"conv_strides\"] = conv_strides\n",
    "\n",
    "# Truncate lists if over the 1024x1024 current limit.\n",
    "if len(arguments[\"conv_num_filters\"]) > 9:\n",
    "    arguments[\"conv_num_filters\"] = arguments[\"conv_num_filters\"][0:10]\n",
    "    arguments[\"conv_kernel_sizes\"] = arguments[\"conv_kernel_sizes\"][0:10]\n",
    "    arguments[\"conv_strides\"] = arguments[\"conv_strides\"][0:10]\n",
    "\n",
    "# Get conv layer properties for generator and discriminator.\n",
    "(generator,\n",
    " discriminator) = calc_generator_discriminator_conv_layer_properties(\n",
    "    arguments[\"conv_num_filters\"],\n",
    "    arguments[\"conv_kernel_sizes\"],\n",
    "    arguments[\"conv_strides\"],\n",
    "    arguments[\"depth\"]\n",
    ")\n",
    "\n",
    "# Split up generator properties into separate lists.\n",
    "(generator_base_conv_blocks,\n",
    " generator_growth_conv_blocks,\n",
    " generator_to_rgb_layers) = split_up_generator_conv_layer_properties(\n",
    "    generator,\n",
    "    arguments[\"conv_num_filters\"],\n",
    "    arguments[\"conv_strides\"],\n",
    "    arguments[\"depth\"]\n",
    ")\n",
    "arguments[\"generator_base_conv_blocks\"] = generator_base_conv_blocks\n",
    "arguments[\"generator_growth_conv_blocks\"] = generator_growth_conv_blocks\n",
    "arguments[\"generator_to_rgb_layers\"] = generator_to_rgb_layers\n",
    "\n",
    "# Split up discriminator properties into separate lists.\n",
    "(discriminator_from_rgb_layers,\n",
    " discriminator_base_conv_blocks,\n",
    " discriminator_growth_conv_blocks) = split_up_discriminator_conv_layer_properties(\n",
    "    discriminator,\n",
    "    arguments[\"conv_num_filters\"],\n",
    "    arguments[\"conv_strides\"],\n",
    "    arguments[\"depth\"]\n",
    ")\n",
    "arguments[\"discriminator_from_rgb_layers\"] = discriminator_from_rgb_layers\n",
    "arguments[\"discriminator_base_conv_blocks\"] = discriminator_base_conv_blocks\n",
    "arguments[\"discriminator_growth_conv_blocks\"] = discriminator_growth_conv_blocks\n",
    "\n",
    "# Generator parameters.\n",
    "arguments[\"latent_size\"] = 512\n",
    "arguments[\"normalize_latent\"] = True\n",
    "arguments[\"use_pixel_norm\"] = True\n",
    "arguments[\"pixel_norm_epsilon\"] = 1e-8\n",
    "arguments[\"generator_projection_dims\"] = [4, 4, 512]\n",
    "arguments[\"generator_l1_regularization_scale\"] = 0.01\n",
    "arguments[\"generator_l2_regularization_scale\"] = 0.01\n",
    "arguments[\"generator_optimizer\"] = \"GradientDescent\"\n",
    "arguments[\"generator_learning_rate\"] = 0.0001\n",
    "arguments[\"generator_clip_gradients\"] = 2.0\n",
    "arguments[\"generator_train_steps\"] = 1\n",
    "\n",
    "# Discriminator hyperparameters.\n",
    "arguments[\"discriminator_l1_regularization_scale\"] = 0.01\n",
    "arguments[\"discriminator_l2_regularization_scale\"] = 0.01\n",
    "arguments[\"discriminator_optimizer\"] = \"GradientDescent\"\n",
    "arguments[\"discriminator_learning_rate\"] = 0.0001\n",
    "arguments[\"discriminator_clip_gradients\"] = 2.0\n",
    "arguments[\"discriminator_gradient_penalty_coefficient\"] = 10.0\n",
    "arguments[\"discriminator_train_steps\"] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print_object.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_obj(function_name, object_name, object_value):\n",
    "    \"\"\"Prints enclosing function, object name, and object value.\n",
    "\n",
    "    Args:\n",
    "        function_name: str, name of function.\n",
    "        object_name: str, name of object.\n",
    "        object_value: object, value of passed object.\n",
    "    \"\"\"\n",
    "#     pass\n",
    "    print(\"{}: {} = {}\".format(function_name, object_name, object_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_example(protos, params):\n",
    "    \"\"\"Decodes TFRecord file into tensors.\n",
    "\n",
    "    Given protobufs, decode into image and label tensors.\n",
    "\n",
    "    Args:\n",
    "        protos: protobufs from TFRecord file.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Image and label tensors.\n",
    "    \"\"\"\n",
    "    # Create feature schema map for protos.\n",
    "    features = {\n",
    "        \"image_raw\": tf.FixedLenFeature(shape=[], dtype=tf.string),\n",
    "        \"label\": tf.FixedLenFeature(shape=[], dtype=tf.int64)\n",
    "    }\n",
    "\n",
    "    # Parse features from tf.Example.\n",
    "    parsed_features = tf.parse_single_example(\n",
    "        serialized=protos, features=features\n",
    "    )\n",
    "    print_obj(\"\\ndecode_example\", \"features\", features)\n",
    "\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length height * width * depth) to a uint8 tensor with shape\n",
    "    # [height * width * depth].\n",
    "    image = tf.decode_raw(\n",
    "        input_bytes=parsed_features[\"image_raw\"], out_type=tf.uint8\n",
    "    )\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Reshape flattened image back into normal dimensions.\n",
    "    image = tf.reshape(\n",
    "        tensor=image,\n",
    "        shape=[params[\"height\"], params[\"width\"], params[\"depth\"]]\n",
    "    )\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Convert from [0, 255] -> [-1.0, 1.0] floats.\n",
    "    image = tf.cast(x=image, dtype=tf.float32) * (2. / 255) - 1.0\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "    label = tf.cast(x=parsed_features[\"label\"], dtype=tf.int32)\n",
    "    print_obj(\"decode_example\", \"label\", label)\n",
    "\n",
    "    return {\"image\": image}, label\n",
    "\n",
    "\n",
    "def read_dataset(filename, mode, batch_size, params):\n",
    "    \"\"\"Reads CSV time series data using tf.data, doing necessary preprocessing.\n",
    "\n",
    "    Given filename, mode, batch size, and other parameters, read CSV dataset\n",
    "    using Dataset API, apply necessary preprocessing, and return an input\n",
    "    function to the Estimator API.\n",
    "\n",
    "    Args:\n",
    "        filename: str, file pattern that to read into our tf.data dataset.\n",
    "        mode: The estimator ModeKeys. Can be TRAIN or EVAL.\n",
    "        batch_size: int, number of examples per batch.\n",
    "        params: dict, dictionary of user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        An input function.\n",
    "    \"\"\"\n",
    "    def _input_fn():\n",
    "        \"\"\"Wrapper input function used by Estimator API to get data tensors.\n",
    "\n",
    "        Returns:\n",
    "            Batched dataset object of dictionary of feature tensors and label\n",
    "                tensor.\n",
    "        \"\"\"\n",
    "        # Create list of files that match pattern.\n",
    "        file_list = tf.gfile.Glob(filename=filename)\n",
    "\n",
    "        # Create dataset from file list.\n",
    "        dataset = tf.data.TFRecordDataset(\n",
    "            filenames=file_list, num_parallel_reads=40\n",
    "        )\n",
    "\n",
    "        # Shuffle and repeat if training with fused op.\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            dataset = dataset.apply(\n",
    "                tf.contrib.data.shuffle_and_repeat(\n",
    "                    buffer_size=50 * batch_size,\n",
    "                    count=None  # indefinitely\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Decode CSV file into a features dictionary of tensors, then batch.\n",
    "        dataset = dataset.apply(\n",
    "            tf.contrib.data.map_and_batch(\n",
    "                map_func=lambda x: decode_example(\n",
    "                    protos=x,\n",
    "                    params=params\n",
    "                ),\n",
    "                batch_size=batch_size,\n",
    "                num_parallel_calls=4\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Prefetch data to improve latency.\n",
    "        dataset = dataset.prefetch(buffer_size=2)\n",
    "\n",
    "        # Create a iterator, then get batch of features from example queue.\n",
    "        batched_dataset = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        return batched_dataset\n",
    "    return _input_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(object):\n",
    "    \"\"\"\n",
    "    Fields:\n",
    "        name: str, name of `Generator`.\n",
    "        kernel_regularizer: `l1_l2_regularizer` object, regularizar for kernel\n",
    "            variables.\n",
    "        bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "            variables.\n",
    "        projection_layer: `Dense` layer for projection of noise to image.\n",
    "        conv_layer_blocks: list, lists of block layers for each block.\n",
    "        to_rgb_conv_layers: list, toRGB 1x1 conv layers.\n",
    "        build_generator_tensors: list, tensors used to build layer internals.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_regularizer, bias_regularizer, params, name):\n",
    "        \"\"\"Creates generator network and returns generated output.\n",
    "\n",
    "        Args:\n",
    "            kernel_regularizer: `l1_l2_regularizer` object, regularizar for\n",
    "                kernel variables.\n",
    "            bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "                variables.\n",
    "            params: dict, user passed parameters.\n",
    "            name: str, name of generator.\n",
    "        \"\"\"\n",
    "        # Set name of generator.\n",
    "        self.name = name\n",
    "\n",
    "        # Regularizer for kernel weights.\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "\n",
    "        # Regularizer for bias weights.\n",
    "        self.bias_regularizer = bias_regularizer\n",
    "\n",
    "        # Instantiate generator layers.\n",
    "        (self.projection_layer,\n",
    "         self.conv_layer_blocks,\n",
    "         self.to_rgb_conv_layers) = self.instantiate_generator_layers(params)\n",
    "\n",
    "        # Build generator layer internals.\n",
    "        self.build_generator_tensors = self.build_generator_layers(\n",
    "            params\n",
    "        )\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def instantiate_generator_projection_layer(self, params):\n",
    "        \"\"\"Instantiates generator projection layer.\n",
    "\n",
    "        Projection layer projects latent noise vector into an image.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Latent vector projection `Dense` layer.\n",
    "        \"\"\"\n",
    "        # Project latent vectors.\n",
    "        projection_height = params[\"generator_projection_dims\"][0]\n",
    "        projection_width = params[\"generator_projection_dims\"][1]\n",
    "        projection_depth = params[\"generator_projection_dims\"][2]\n",
    "\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     projection_height * projection_width * projection_depth\n",
    "            # )\n",
    "            projection_layer = tf.layers.Dense(\n",
    "                units=projection_height * projection_width * projection_depth,\n",
    "                activation=tf.nn.leaky_relu,\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                kernel_regularizer=self.kernel_regularizer,\n",
    "                bias_regularizer=self.bias_regularizer,\n",
    "                name=\"{}_projection_layer\".format(self.name)\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_generator_projection_layer\",\n",
    "                \"projection_layer\",\n",
    "                projection_layer\n",
    "            )\n",
    "\n",
    "        return projection_layer\n",
    "\n",
    "    def instantiate_generator_base_conv_layer_block(self, params):\n",
    "        \"\"\"Instantiates generator base conv layer block.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of base block conv layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"generator_base_conv_blocks\"][0]\n",
    "\n",
    "            # Create list of base conv layers.\n",
    "            base_conv_layers = [\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=conv_block[i][3],\n",
    "                    kernel_size=conv_block[i][0:2],\n",
    "                    strides=conv_block[i][4:6],\n",
    "                    padding=\"same\",\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_base_layers_conv2d_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        i,\n",
    "                        conv_block[i][0],\n",
    "                        conv_block[i][1],\n",
    "                        conv_block[i][2],\n",
    "                        conv_block[i][3]\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_generator_base_conv_layer_block\",\n",
    "                \"base_conv_layers\",\n",
    "                base_conv_layers\n",
    "            )\n",
    "\n",
    "        return base_conv_layers\n",
    "\n",
    "    def instantiate_generator_growth_layer_block(self, params, block_idx):\n",
    "        \"\"\"Instantiates generator growth layer block.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "            block_idx: int, the current growth block's index.\n",
    "\n",
    "        Returns:\n",
    "            List of growth block conv layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"generator_growth_conv_blocks\"][block_idx]\n",
    "\n",
    "            # Create new inner convolutional layers.\n",
    "            conv_layers = [\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=conv_block[i][3],\n",
    "                    kernel_size=conv_block[i][0:2],\n",
    "                    strides=conv_block[i][4:6],\n",
    "                    padding=\"same\",\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_growth_layers_conv2d_{}_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        block_idx,\n",
    "                        i,\n",
    "                        conv_block[i][0],\n",
    "                        conv_block[i][1],\n",
    "                        conv_block[i][2],\n",
    "                        conv_block[i][3]\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_generator_growth_layer_block\",\n",
    "                \"conv_layers\",\n",
    "                conv_layers\n",
    "            )\n",
    "\n",
    "        return conv_layers\n",
    "\n",
    "    def instantiate_generator_to_rgb_layers(self, params):\n",
    "        \"\"\"Instantiates generator toRGB layers of 1x1 convs.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of toRGB 1x1 conv layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get toRGB layer properties.\n",
    "            to_rgb = [\n",
    "                params[\"generator_to_rgb_layers\"][i][0][:]\n",
    "                for i in range(len(params[\"generator_to_rgb_layers\"]))\n",
    "            ]\n",
    "\n",
    "            # Create list to hold toRGB 1x1 convs.\n",
    "            to_rgb_conv_layers = [\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=to_rgb[i][3],\n",
    "                    kernel_size=to_rgb[i][0:2],\n",
    "                    strides=to_rgb[i][4:6],\n",
    "                    padding=\"same\",\n",
    "                    # Notice there is no activation for toRGB conv layers.\n",
    "                    activation=None,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_to_rgb_layers_conv2d_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        i,\n",
    "                        to_rgb[i][0],\n",
    "                        to_rgb[i][1],\n",
    "                        to_rgb[i][2],\n",
    "                        to_rgb[i][3]\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(to_rgb))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_generator_to_rgb_layers\",\n",
    "                \"to_rgb_conv_layers\",\n",
    "                to_rgb_conv_layers\n",
    "            )\n",
    "\n",
    "        return to_rgb_conv_layers\n",
    "\n",
    "    def instantiate_generator_layers(self, params):\n",
    "        \"\"\"Instantiates layers of generator network.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            projection_layer: `Dense` layer for projection of noise to image.\n",
    "            conv_layer_blocks: list, lists of block layers for each block.\n",
    "            to_rgb_conv_layers: list, toRGB 1x1 conv layers.\n",
    "        \"\"\"\n",
    "        # Instantiate noise-image projection `Dense` layer.\n",
    "        projection_layer = self.instantiate_generator_projection_layer(\n",
    "            params=params\n",
    "        )\n",
    "        print_obj(\n",
    "            \"\\ninstantiate_generator_layers\",\n",
    "            \"projection_layer\",\n",
    "            projection_layer\n",
    "        )\n",
    "\n",
    "        # Instantiate base convolutional `Conv2D` layers, for post-growth.\n",
    "        conv_layer_blocks = [\n",
    "            self.instantiate_generator_base_conv_layer_block(\n",
    "                params=params\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Instantiate growth block `Conv2D` layers.\n",
    "        conv_layer_blocks.extend(\n",
    "            [\n",
    "                self.instantiate_generator_growth_layer_block(\n",
    "                    params=params, block_idx=block_idx\n",
    "                )\n",
    "                for block_idx in range(\n",
    "                    len(params[\"generator_growth_conv_blocks\"])\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        print_obj(\n",
    "            \"instantiate_generator_layers\",\n",
    "            \"conv_layer_blocks\",\n",
    "            conv_layer_blocks\n",
    "        )\n",
    "\n",
    "        # Instantiate toRGB 1x1 `Conv2D` layers.\n",
    "        to_rgb_conv_layers = self.instantiate_generator_to_rgb_layers(\n",
    "            params=params\n",
    "        )\n",
    "        print_obj(\n",
    "            \"instantiate_generator_layers\",\n",
    "            \"to_rgb_conv_layers\",\n",
    "            to_rgb_conv_layers\n",
    "        )\n",
    "\n",
    "        return projection_layer, conv_layer_blocks, to_rgb_conv_layers\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def build_generator_projection_layer(self, params):\n",
    "        \"\"\"Builds generator projection layer internals using call.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Latent vector projection tensor.\n",
    "        \"\"\"\n",
    "        # Project latent vectors.\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     projection_height * projection_width * projection_depth\n",
    "            # )\n",
    "            projection_tensor = self.projection_layer(\n",
    "                inputs=tf.zeros(\n",
    "                    shape=[1, params[\"latent_size\"]], dtype=tf.float32\n",
    "                )\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\nbuild_generator_projection_layer\",\n",
    "                \"projection_tensor\",\n",
    "                projection_tensor\n",
    "            )\n",
    "\n",
    "        return projection_tensor\n",
    "\n",
    "    def build_generator_base_conv_layer_block(self, params):\n",
    "        \"\"\"Builds generator base conv layer block internals using call.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of base conv tensors.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"generator_base_conv_blocks\"][0]\n",
    "\n",
    "            # Create list of base conv layers.\n",
    "            base_conv_tensors = [\n",
    "                # The base conv block is always the 0th one.\n",
    "                self.conv_layer_blocks[0][i](\n",
    "                    inputs=tf.zeros(\n",
    "                        shape=[1] + conv_block[i][0:3], dtype=tf.float32\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\nbuild_generator_base_conv_layer_block\",\n",
    "                \"base_conv_tensors\",\n",
    "                base_conv_tensors\n",
    "            )\n",
    "\n",
    "        return base_conv_tensors\n",
    "\n",
    "    def build_generator_growth_layer_block(\n",
    "            self, params, growth_block_idx):\n",
    "        \"\"\"Builds generator growth block internals through call.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "            growth_block_idx: int, the current growth block's index.\n",
    "\n",
    "        Returns:\n",
    "            List of growth block tensors.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"generator_growth_conv_blocks\"][growth_block_idx]\n",
    "\n",
    "            # Create new inner convolutional layers.\n",
    "            conv_tensors = [\n",
    "                self.conv_layer_blocks[1 + growth_block_idx][i](\n",
    "                    inputs=tf.zeros(\n",
    "                        shape=[1] + conv_block[i][0:3], dtype=tf.float32\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\nbuild_generator_growth_layer_block\",\n",
    "                \"conv_tensors\",\n",
    "                conv_tensors\n",
    "            )\n",
    "\n",
    "        return conv_tensors\n",
    "\n",
    "    def build_generator_to_rgb_layers(self, params):\n",
    "        \"\"\"Builds generator toRGB layers of 1x1 convs internals through call.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of toRGB 1x1 conv tensors.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get toRGB layer properties.\n",
    "            to_rgb = [\n",
    "                params[\"generator_to_rgb_layers\"][i][0][:]\n",
    "                for i in range(len(params[\"generator_to_rgb_layers\"]))\n",
    "            ]\n",
    "\n",
    "            # Create list to hold toRGB 1x1 convs.\n",
    "            to_rgb_conv_tensors = [\n",
    "                self.to_rgb_conv_layers[i](\n",
    "                    inputs=tf.zeros(\n",
    "                        shape=[1] + to_rgb[i][0:3], dtype=tf.float32)\n",
    "                    )\n",
    "                for i in range(len(to_rgb))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\nbuild_generator_to_rgb_layers\",\n",
    "                \"to_rgb_conv_tensors\",\n",
    "                to_rgb_conv_tensors\n",
    "            )\n",
    "\n",
    "        return to_rgb_conv_tensors\n",
    "\n",
    "    def build_generator_layers(self, params):\n",
    "        \"\"\"Builds generator layer internals.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of toRGB tensors.\n",
    "        \"\"\"\n",
    "        # Build projection layer internals using call.\n",
    "        projection_tensor = self.build_generator_projection_layer(\n",
    "            params=params\n",
    "        )\n",
    "        print_obj(\n",
    "            \"\\nbuild_generator_layers\",\n",
    "            \"projection_tensor\",\n",
    "            projection_tensor\n",
    "        )\n",
    "\n",
    "        with tf.control_dependencies(control_inputs=[projection_tensor]):\n",
    "            # Build base convolutional layer block's internals using call.\n",
    "            conv_block_tensors = [\n",
    "                self.build_generator_base_conv_layer_block(\n",
    "                    params=params\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            # Build growth block layer internals through call.\n",
    "            conv_block_tensors.extend(\n",
    "                [\n",
    "                    self.build_generator_growth_layer_block(\n",
    "                        params=params,\n",
    "                        growth_block_idx=growth_block_idx\n",
    "                    )\n",
    "                    for growth_block_idx in range(\n",
    "                        len(params[\"generator_growth_conv_blocks\"])\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            print_obj(\n",
    "                \"build_generator_layers\",\n",
    "                \"conv_block_tensors\",\n",
    "                conv_block_tensors\n",
    "            )\n",
    "\n",
    "            # Flatten block tensor lists of lists into list.\n",
    "            conv_block_tensors = [\n",
    "                item for sublist in conv_block_tensors for item in sublist\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"build_generator_layers\",\n",
    "                \"conv_block_tensors\",\n",
    "                conv_block_tensors\n",
    "            )\n",
    "\n",
    "            with tf.control_dependencies(\n",
    "                    control_inputs=conv_block_tensors):\n",
    "                # Build toRGB 1x1 conv layer internals through call.\n",
    "                to_rgb_conv_tensors = self.build_generator_to_rgb_layers(\n",
    "                    params=params\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"build_generator_layers\",\n",
    "                    \"to_rgb_conv_tensors\",\n",
    "                    to_rgb_conv_tensors\n",
    "                )\n",
    "\n",
    "        return to_rgb_conv_tensors\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def pixel_norm(self, X, epsilon=1e-8):\n",
    "        \"\"\"Normalizes the feature vector in each pixel to unit length.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, image feature vectors.\n",
    "            epsilon: float, small value to add to denominator for numerical\n",
    "                stability.\n",
    "\n",
    "        Returns:\n",
    "            Pixel normalized feature vectors.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(\"{}/pixel_norm\".format(self.name)):\n",
    "            return X * tf.rsqrt(\n",
    "                x=tf.add(\n",
    "                    x=tf.reduce_mean(\n",
    "                        input_tensor=tf.square(x=X), axis=1, keepdims=True\n",
    "                    ),\n",
    "                    y=epsilon\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def use_pixel_norm(self, X, params, epsilon=1e-8):\n",
    "        \"\"\"Decides based on user parameter whether to use pixel norm or not.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, image feature vectors.\n",
    "            params: dict, user passed parameters.\n",
    "            epsilon: float, small value to add to denominator for numerical\n",
    "                stability.\n",
    "\n",
    "        Returns:\n",
    "            Pixel normalized feature vectors if using pixel norm, else\n",
    "                original feature vectors.\n",
    "        \"\"\"\n",
    "        if params[\"use_pixel_norm\"]:\n",
    "            return self.pixel_norm(X=X, epsilon=epsilon)\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def use_generator_projection_layer(self, Z, params):\n",
    "        \"\"\"Uses projection layer to convert random noise vector into an image.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Latent vector projection tensor.\n",
    "        \"\"\"\n",
    "        # Project latent vectors.\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            if params[\"normalize_latent\"]:\n",
    "                # shape = (cur_batch_size, latent_size)\n",
    "                Z = self.pixel_norm(X=Z, epsilon=params[\"pixel_norm_epsilon\"])\n",
    "\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     projection_height * projection_width * projection_depth\n",
    "            # )\n",
    "            projection_tensor = self.projection_layer(inputs=Z)\n",
    "            print_obj(\n",
    "                \"\\nuse_generator_projection_layer\",\n",
    "                \"projection_tensor\",\n",
    "                projection_tensor\n",
    "            )\n",
    "\n",
    "        # Reshape projection into \"image\".\n",
    "        # shape = (\n",
    "        #     cur_batch_size,\n",
    "        #     projection_height,\n",
    "        #     projection_width,\n",
    "        #     projection_depth\n",
    "        # )\n",
    "        projection_tensor_reshaped = tf.reshape(\n",
    "            tensor=projection_tensor,\n",
    "            shape=[-1] + params[\"generator_projection_dims\"],\n",
    "            name=\"{}_projection_reshaped\".format(self.name)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"use_generator_projection_layer\",\n",
    "            \"projection_tensor_reshaped\",\n",
    "            projection_tensor_reshaped\n",
    "        )\n",
    "\n",
    "        return projection_tensor_reshaped\n",
    "\n",
    "    def fused_conv2d_pixel_norm(self, input_image, conv2d_layer, params):\n",
    "        \"\"\"Fused `Conv2D` layer and pixel norm operation.\n",
    "\n",
    "        Args:\n",
    "            input_image: tensor, input image of rank 4.\n",
    "            conv2d_layer: `Conv2D` layer.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            New image tensor of rank 4.\n",
    "        \"\"\"\n",
    "        conv_output = conv2d_layer(inputs=input_image)\n",
    "        print_obj(\"\\nfused_conv2d_pixel_norm\", \"conv_output\", conv_output)\n",
    "\n",
    "        pixel_norm_output = self.use_pixel_norm(\n",
    "            X=conv_output,\n",
    "            params=params,\n",
    "            epsilon=params[\"pixel_norm_epsilon\"]\n",
    "        )\n",
    "        print_obj(\n",
    "            \"fused_conv2d_pixel_norm\", \"pixel_norm_output\", pixel_norm_output\n",
    "        )\n",
    "\n",
    "        return pixel_norm_output\n",
    "\n",
    "    def upsample_generator_image(self, image, original_image_size, block_idx):\n",
    "        \"\"\"Upsamples generator image.\n",
    "\n",
    "        Args:\n",
    "            image: tensor, image created by generator conv block.\n",
    "            original_image_size: list, the height and width dimensions of the\n",
    "                original image before any growth.\n",
    "            block_idx: int, index of the current generator growth block.\n",
    "\n",
    "        Returns:\n",
    "            Upsampled image tensor.\n",
    "        \"\"\"\n",
    "        # Upsample from s X s to 2s X 2s image.\n",
    "        upsampled_image = tf.image.resize(\n",
    "            images=image,\n",
    "            size=tf.convert_to_tensor(\n",
    "                value=original_image_size,\n",
    "                dtype=tf.int32,\n",
    "                name=\"{}_upsample_generator_image_original_image_size\".format(\n",
    "                    self.name\n",
    "                )\n",
    "            ) * 2 ** block_idx,\n",
    "            method=\"nearest\",\n",
    "            name=\"{}_growth_upsampled_image_{}_{}x{}_{}x{}\".format(\n",
    "                self.name,\n",
    "                block_idx,\n",
    "                original_image_size[0] * 2 ** (block_idx - 1),\n",
    "                original_image_size[1] * 2 ** (block_idx - 1),\n",
    "                original_image_size[0] * 2 ** block_idx,\n",
    "                original_image_size[1] * 2 ** block_idx\n",
    "            )\n",
    "        )\n",
    "        print_obj(\n",
    "            \"\\nupsample_generator_image\",\n",
    "            \"upsampled_image\",\n",
    "            upsampled_image\n",
    "        )\n",
    "\n",
    "        return upsampled_image\n",
    "\n",
    "    def create_base_generator_network(self, Z, params):\n",
    "        \"\"\"Creates base generator network.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            projection_layer: `Dense` layer for projection of noise into image.\n",
    "            to_rgb_conv_layers: list, toRGB 1x1 conv layers.\n",
    "            blocks: list, lists of block layers for each block.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Final network block conv tensor.\n",
    "        \"\"\"\n",
    "        print_obj(\"\\ncreate_base_generator_network\", \"Z\", Z)\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Project latent noise vectors into image.\n",
    "            projection = self.use_generator_projection_layer(\n",
    "                Z=Z, params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_base_generator_network\", \"projection\", projection\n",
    "            )\n",
    "\n",
    "            # Only need the first block and toRGB conv layer for base network.\n",
    "            block_layers = self.conv_layer_blocks[0]\n",
    "            to_rgb_conv_layer = self.to_rgb_conv_layers[0]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            block_conv = projection\n",
    "            for i in range(0, len(block_layers)):\n",
    "                block_conv = self.fused_conv2d_pixel_norm(\n",
    "                    input_image=block_conv,\n",
    "                    conv2d_layer=block_layers[i],\n",
    "                    params=params\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_base_generator_network\",\n",
    "                    \"block_conv_{}\".format(i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Convert convolution to RGB image.\n",
    "            to_rgb_conv = self.fused_conv2d_pixel_norm(\n",
    "                input_image=block_conv,\n",
    "                conv2d_layer=to_rgb_conv_layer,\n",
    "                params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_base_generator_network\", \"to_rgb_conv\", to_rgb_conv\n",
    "            )\n",
    "\n",
    "        return to_rgb_conv\n",
    "\n",
    "    def create_growth_transition_generator_network(\n",
    "            self, Z, original_image_size, alpha_var, params, trans_idx):\n",
    "        \"\"\"Creates growth transition generator network.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            original_image_size: list, the height and width dimensions of the\n",
    "                original image before any growth.\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "            trans_idx: int, index of current growth transition.\n",
    "\n",
    "        Returns:\n",
    "            Weighted sum tensor of growing and shrinking network paths.\n",
    "        \"\"\"\n",
    "        print_obj(\n",
    "            \"\\nEntered create_growth_transition_generator_network\",\n",
    "            \"trans_idx\",\n",
    "            trans_idx\n",
    "        )\n",
    "        print_obj(\"create_growth_transition_generator_network\", \"Z\", Z)\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Project latent noise vectors into image.\n",
    "            projection = self.use_generator_projection_layer(\n",
    "                Z=Z, params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_generator_network\",\n",
    "                \"projection\",\n",
    "                projection\n",
    "            )\n",
    "\n",
    "            # Permanent blocks.\n",
    "            permanent_blocks = self.conv_layer_blocks[0:trans_idx + 1]\n",
    "\n",
    "            # Base block doesn't need any upsampling so handle differently.\n",
    "            base_block_conv_layers = permanent_blocks[0]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            block_conv = projection\n",
    "            for i in range(0, len(base_block_conv_layers)):\n",
    "                block_conv = self.fused_conv2d_pixel_norm(\n",
    "                    input_image=block_conv,\n",
    "                    conv2d_layer=base_block_conv_layers[i],\n",
    "                    params=params\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_growth_transition_generator_network\",\n",
    "                    \"base_block_conv_{}_{}\".format(trans_idx, i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Growth blocks require first prev conv layer's image upsampled.\n",
    "            for i in range(1, len(permanent_blocks)):\n",
    "                # Upsample previous block's image.\n",
    "                block_conv = self.upsample_generator_image(\n",
    "                    image=block_conv,\n",
    "                    original_image_size=original_image_size,\n",
    "                    block_idx=i\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_growth_transition_generator_network\",\n",
    "                    \"upsample_generator_image_block_conv_{}_{}\".format(\n",
    "                        trans_idx, i\n",
    "                    ),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "                block_conv_layers = permanent_blocks[i]\n",
    "                for j in range(0, len(block_conv_layers)):\n",
    "                    block_conv = self.fused_conv2d_pixel_norm(\n",
    "                        input_image=block_conv,\n",
    "                        conv2d_layer=block_conv_layers[j],\n",
    "                        params=params\n",
    "                    )\n",
    "                    print_obj(\n",
    "                        \"create_growth_transition_generator_network\",\n",
    "                        \"block_conv_{}_{}_{}\".format(trans_idx, i, j),\n",
    "                        block_conv\n",
    "                    )\n",
    "\n",
    "            # Upsample most recent block conv image for both side chains.\n",
    "            upsampled_block_conv = self.upsample_generator_image(\n",
    "                image=block_conv,\n",
    "                original_image_size=original_image_size,\n",
    "                block_idx=len(permanent_blocks)\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_generator_network\",\n",
    "                \"upsampled_block_conv_{}\".format(trans_idx),\n",
    "                upsampled_block_conv\n",
    "            )\n",
    "\n",
    "            # Growing side chain.\n",
    "            growing_block_layers = self.conv_layer_blocks[trans_idx + 1]\n",
    "            growing_to_rgb_conv_layer = self.to_rgb_conv_layers[trans_idx + 1]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            block_conv = upsampled_block_conv\n",
    "            for i in range(0, len(growing_block_layers)):\n",
    "                block_conv = self.fused_conv2d_pixel_norm(\n",
    "                    input_image=block_conv,\n",
    "                    conv2d_layer=growing_block_layers[i],\n",
    "                    params=params\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_growth_transition_generator_network\",\n",
    "                    \"growing_block_conv_{}_{}\".format(trans_idx, i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            growing_to_rgb_conv = self.fused_conv2d_pixel_norm(\n",
    "                input_image=block_conv,\n",
    "                conv2d_layer=growing_to_rgb_conv_layer,\n",
    "                params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_generator_network\",\n",
    "                \"growing_to_rgb_conv_{}\".format(trans_idx),\n",
    "                growing_to_rgb_conv\n",
    "            )\n",
    "\n",
    "            # Shrinking side chain.\n",
    "            shrinking_to_rgb_conv_layer = self.to_rgb_conv_layers[trans_idx]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            shrinking_to_rgb_conv = self.fused_conv2d_pixel_norm(\n",
    "                input_image=upsampled_block_conv,\n",
    "                conv2d_layer=shrinking_to_rgb_conv_layer,\n",
    "                params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_generator_network\",\n",
    "                \"shrinking_to_rgb_conv_{}\".format(trans_idx),\n",
    "                shrinking_to_rgb_conv\n",
    "            )\n",
    "\n",
    "            # Weighted sum.\n",
    "            weighted_sum = tf.add(\n",
    "                x=growing_to_rgb_conv * alpha_var,\n",
    "                y=shrinking_to_rgb_conv * (1.0 - alpha_var),\n",
    "                name=\"growth_transition_weighted_sum_{}\".format(trans_idx)\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_generator_network\",\n",
    "                \"weighted_sum_{}\".format(trans_idx),\n",
    "                weighted_sum\n",
    "            )\n",
    "\n",
    "        return weighted_sum\n",
    "\n",
    "    def create_final_generator_network(self, Z, original_image_size, params):\n",
    "        \"\"\"Creates final generator network.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            original_image_size: list, the height and width dimensions of the\n",
    "                original image before any growth.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Final network block conv tensor.\n",
    "        \"\"\"\n",
    "        print_obj(\"\\ncreate_final_generator_network\", \"Z\", Z)\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Project latent noise vectors into image.\n",
    "            projection = self.use_generator_projection_layer(\n",
    "                Z=Z, params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_final_generator_network\", \"projection\", projection\n",
    "            )\n",
    "\n",
    "            # Base block doesn't need any upsampling so handle differently.\n",
    "            base_block_conv_layers = self.conv_layer_blocks[0]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            block_conv = projection\n",
    "            for i in range(0, len(base_block_conv_layers)):\n",
    "                block_conv = self.fused_conv2d_pixel_norm(\n",
    "                    input_image=block_conv,\n",
    "                    conv2d_layer=base_block_conv_layers[i],\n",
    "                    params=params\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_final_generator_network\",\n",
    "                    \"base_block_conv_{}\".format(i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Growth blocks require first prev conv layer's image upsampled.\n",
    "            for i in range(1, len(self.conv_layer_blocks)):\n",
    "                # Upsample previous block's image.\n",
    "                block_conv = self.upsample_generator_image(\n",
    "                    image=block_conv,\n",
    "                    original_image_size=original_image_size,\n",
    "                    block_idx=i\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_final_generator_network\",\n",
    "                    \"upsample_generator_image_block_conv_{}\".format(i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "                block_conv_layers = self.conv_layer_blocks[i]\n",
    "                for j in range(0, len(block_conv_layers)):\n",
    "                    block_conv = self.fused_conv2d_pixel_norm(\n",
    "                        input_image=block_conv,\n",
    "                        conv2d_layer=block_conv_layers[j],\n",
    "                        params=params\n",
    "                    )\n",
    "                    print_obj(\n",
    "                        \"create_final_generator_network\",\n",
    "                        \"block_conv_{}_{}\".format(i, j),\n",
    "                        block_conv\n",
    "                    )\n",
    "\n",
    "            # Only need the last toRGB conv layer.\n",
    "            to_rgb_conv_layer = self.to_rgb_conv_layers[-1]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            to_rgb_conv = self.fused_conv2d_pixel_norm(\n",
    "                input_image=block_conv,\n",
    "                conv2d_layer=to_rgb_conv_layer,\n",
    "                params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_final_generator_network\", \"to_rgb_conv\", to_rgb_conv\n",
    "            )\n",
    "\n",
    "        return to_rgb_conv\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def switch_case_generator_outputs(\n",
    "            self, Z, original_image_size, alpha_var, params, growth_index):\n",
    "        \"\"\"Uses switch case to use the correct network to generate images.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            original_image_size: list, the height and width dimensions of the\n",
    "                original image before any growth.\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "            growth_index: int, current growth stage.\n",
    "\n",
    "        Returns:\n",
    "            Generated image output tensor.\n",
    "        \"\"\"\n",
    "        # Switch to case based on number of steps for gen outputs.\n",
    "        generated_outputs = tf.switch_case(\n",
    "            branch_index=growth_index,\n",
    "            branch_fns=[\n",
    "                # 4x4\n",
    "                lambda: self.create_base_generator_network(\n",
    "                    Z=Z, params=params\n",
    "                ),\n",
    "                # 8x8\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(0, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 16x16\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(1, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 32x32\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(2, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 64x64\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(3, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 128x128\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(4, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 256x256\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(5, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 512x512\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(6, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 1024x1024\n",
    "                lambda: self.create_growth_transition_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(7, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 1024x1024\n",
    "                lambda: self.create_final_generator_network(\n",
    "                    Z=Z,\n",
    "                    original_image_size=original_image_size,\n",
    "                    params=params\n",
    "                )\n",
    "            ],\n",
    "            name=\"{}_switch_case_generated_outputs\".format(self.name)\n",
    "        )\n",
    "\n",
    "        return generated_outputs\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def get_train_eval_generator_outputs(self, Z, alpha_var, params):\n",
    "        \"\"\"Uses generator network and returns generated output for train/eval.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Generated image output tensor of shape\n",
    "                [cur_batch_size, image_size, image_size, depth].\n",
    "        \"\"\"\n",
    "        print_obj(\"\\nget_train_eval_generator_outputs\", \"Z\", Z)\n",
    "\n",
    "        # Get generator's output image tensor.\n",
    "        train_steps = params[\"train_steps\"]\n",
    "        num_steps_until_growth = params[\"num_steps_until_growth\"]\n",
    "        num_stages = train_steps // num_steps_until_growth\n",
    "        if (num_stages <= 0 or len(params[\"conv_num_filters\"]) == 1):\n",
    "            print(\n",
    "                \"\\nget_train_eval_generator_outputs: NOT GOING TO GROW, SKIP SWITCH CASE!\"\n",
    "            )\n",
    "            # If never going to grow, no sense using the switch case.\n",
    "            # 4x4\n",
    "            generated_outputs = self.create_base_generator_network(\n",
    "                Z=Z, params=params\n",
    "            )\n",
    "        else:\n",
    "            # Find growth index based on global step and growth frequency.\n",
    "            growth_index = tf.cast(\n",
    "                x=tf.floordiv(\n",
    "                    x=tf.train.get_or_create_global_step(),\n",
    "                    y=params[\"num_steps_until_growth\"],\n",
    "                    name=\"{}_global_step_floordiv\".format(self.name)\n",
    "                ),\n",
    "                dtype=tf.int32,\n",
    "                name=\"{}_growth_index\".format(self.name)\n",
    "            )\n",
    "\n",
    "            # Switch to case based on number of steps for gen outputs.\n",
    "            generated_outputs = self.switch_case_generator_outputs(\n",
    "                Z=Z,\n",
    "                original_image_size=params[\"generator_projection_dims\"][0:2],\n",
    "                alpha_var=alpha_var,\n",
    "                params=params,\n",
    "                growth_index=growth_index\n",
    "            )\n",
    "\n",
    "        print_obj(\n",
    "            \"\\nget_train_eval_generator_outputs\",\n",
    "            \"generated_outputs\",\n",
    "            generated_outputs\n",
    "        )\n",
    "\n",
    "        # Wrap generated outputs in a control dependency for the build\n",
    "        # generator tensors to ensure generator internals are built.\n",
    "        with tf.control_dependencies(\n",
    "                control_inputs=self.build_generator_tensors):\n",
    "            generated_outputs = tf.identity(\n",
    "                input=generated_outputs,\n",
    "                name=\"{}_generated_outputs_identity\".format(self.name)\n",
    "            )\n",
    "\n",
    "        return generated_outputs\n",
    "\n",
    "    def get_predict_generator_outputs(self, Z, params):\n",
    "        \"\"\"Uses generator network and returns generated output for predict.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Generated image output tensor of shape\n",
    "                [cur_batch_size, image_size, image_size, depth].\n",
    "        \"\"\"\n",
    "        print_obj(\"\\nget_predict_generator_outputs\", \"Z\", Z)\n",
    "\n",
    "        if params[\"predict_all_resolutions\"]:\n",
    "            generated_outputs = [\n",
    "                # 4x4\n",
    "                self.create_base_generator_network(Z=Z, params=params)\n",
    "            ]\n",
    "\n",
    "            generated_outputs.extend(\n",
    "                [\n",
    "                    # 8x8 through 1024x1024\n",
    "                    self.create_growth_transition_generator_network(\n",
    "                        Z=Z,\n",
    "                        original_image_size=params[\"generator_projection_dims\"][0:2],\n",
    "                        alpha_var=tf.ones(shape=[], dtype=tf.float32),\n",
    "                        params=params,\n",
    "                        trans_idx=i\n",
    "                    )\n",
    "                    for i in range(len(params[\"conv_num_filters\"]) - 1)\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            # 1024x1024\n",
    "            generated_outputs = self.create_final_generator_network(\n",
    "                Z=Z,\n",
    "                original_image_size=params[\"generator_projection_dims\"][0:2],\n",
    "                params=params\n",
    "            )\n",
    "        print_obj(\n",
    "            \"get_predict_generator_outputs\",\n",
    "            \"generated_outputs\",\n",
    "            generated_outputs\n",
    "        )\n",
    "\n",
    "        return generated_outputs\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def get_generator_loss(self, fake_logits, params):\n",
    "        \"\"\"Gets generator loss.\n",
    "\n",
    "        Args:\n",
    "            fake_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "                discriminator having processed generator's output image.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Generator's total loss tensor of shape [].\n",
    "        \"\"\"\n",
    "        # Calculate base generator loss.\n",
    "        generator_loss = -tf.reduce_mean(\n",
    "            input_tensor=fake_logits,\n",
    "            name=\"{}_loss\".format(self.name)\n",
    "        )\n",
    "        print_obj(\"\\nget_generator_loss\", \"generator_loss\", generator_loss)\n",
    "\n",
    "        # Get generator regularization losses.\n",
    "        generator_reg_loss = get_regularization_loss(\n",
    "            params=params, scope=self.name\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_generator_loss\",\n",
    "            \"generator_reg_loss\",\n",
    "            generator_reg_loss\n",
    "        )\n",
    "\n",
    "        # Combine losses for total losses.\n",
    "        generator_total_loss = tf.math.add(\n",
    "            x=generator_loss,\n",
    "            y=generator_reg_loss,\n",
    "            name=\"{}_total_loss\".format(self.name)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_generator_loss\", \"generator_total_loss\", generator_total_loss\n",
    "        )\n",
    "\n",
    "        return generator_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## discriminator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(object):\n",
    "    \"\"\"\n",
    "    Fields:\n",
    "        name: str, name of `Discriminator`.\n",
    "        kernel_regularizer: `l1_l2_regularizer` object, regularizar for kernel\n",
    "            variables.\n",
    "        bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "            variables.\n",
    "        from_rgb_conv_layers: list, fromRGB 1x1 `Conv2D` layers.\n",
    "        conv_layer_blocks: list, lists of `Conv2D` block layers for each\n",
    "            block.\n",
    "        transition_downsample_layers: list, `AveragePooling2D` layers for\n",
    "            downsampling shrinking transition paths.\n",
    "        flatten_layer: `Flatten` layer prior to logits layer.\n",
    "        logits_layer: `Dense` layer for logits.\n",
    "        build_discriminator_tensors: list, tensors used to build layer\n",
    "            internals.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_regularizer, bias_regularizer, params, name):\n",
    "        \"\"\"Creates generator network and returns generated output.\n",
    "\n",
    "        Args:\n",
    "            kernel_regularizer: `l1_l2_regularizer` object, regularizar for\n",
    "                kernel variables.\n",
    "            bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "                variables.\n",
    "            params: dict, user passed parameters.\n",
    "            name: str, name of discriminator.\n",
    "        \"\"\"\n",
    "        # Set name of discriminator.\n",
    "        self.name = name\n",
    "\n",
    "        # Regularizer for kernel weights.\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "\n",
    "        # Regularizer for bias weights.\n",
    "        self.bias_regularizer = bias_regularizer\n",
    "\n",
    "        # Instantiate discriminator layers.\n",
    "        (self.from_rgb_conv_layers,\n",
    "         self.conv_layer_blocks,\n",
    "         self.transition_downsample_layers,\n",
    "         self.flatten_layer,\n",
    "         self.logits_layer) = self.instantiate_discriminator_layers(\n",
    "            params\n",
    "        )\n",
    "\n",
    "        # Build discriminator layer internals.\n",
    "        self.build_discriminator_tensors = self.build_discriminator_layers(\n",
    "            params\n",
    "        )\n",
    "\n",
    "    def instantiate_discriminator_from_rgb_layers(self, params):\n",
    "        \"\"\"Instantiates discriminator fromRGB layers of 1x1 convs.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of fromRGB 1x1 Conv2D layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get fromRGB layer properties.\n",
    "            from_rgb = [\n",
    "                params[\"discriminator_from_rgb_layers\"][i][0][:]\n",
    "                for i in range(len(params[\"discriminator_from_rgb_layers\"]))\n",
    "            ]\n",
    "\n",
    "            # Create list to hold toRGB 1x1 convs.\n",
    "            from_rgb_conv_layers = [\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=from_rgb[i][3],\n",
    "                    kernel_size=from_rgb[i][0:2],\n",
    "                    strides=from_rgb[i][4:6],\n",
    "                    padding=\"same\",\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_from_rgb_layers_conv2d_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        i,\n",
    "                        from_rgb[i][0],\n",
    "                        from_rgb[i][1],\n",
    "                        from_rgb[i][2],\n",
    "                        from_rgb[i][3]\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(from_rgb))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_discriminator_from_rgb_layers\",\n",
    "                \"from_rgb_conv_layers\",\n",
    "                from_rgb_conv_layers\n",
    "            )\n",
    "\n",
    "        return from_rgb_conv_layers\n",
    "\n",
    "    def instantiate_discriminator_base_conv_layer_block(self, params):\n",
    "        \"\"\"Instantiates discriminator base conv layer block.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of base conv layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"discriminator_base_conv_blocks\"][0]\n",
    "\n",
    "            # Create list of base conv layers.\n",
    "            base_conv_layers = [\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=conv_block[i][3],\n",
    "                    kernel_size=conv_block[i][0:2],\n",
    "                    strides=conv_block[i][4:6],\n",
    "                    padding=\"same\",\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_base_layers_conv2d_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        i,\n",
    "                        conv_block[i][0],\n",
    "                        conv_block[i][1],\n",
    "                        conv_block[i][2],\n",
    "                        conv_block[i][3]\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block) - 1)\n",
    "            ]\n",
    "\n",
    "            # Have valid padding for layer just before flatten and logits.\n",
    "            base_conv_layers.append(\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=conv_block[-1][3],\n",
    "                    kernel_size=conv_block[-1][0:2],\n",
    "                    strides=conv_block[-1][4:6],\n",
    "                    padding=\"valid\",\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_base_layers_conv2d_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        len(conv_block) - 1,\n",
    "                        conv_block[-1][0],\n",
    "                        conv_block[-1][1],\n",
    "                        conv_block[-1][2],\n",
    "                        conv_block[-1][3]\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_discriminator_base_conv_layer_block\",\n",
    "                \"base_conv_layers\",\n",
    "                base_conv_layers\n",
    "            )\n",
    "\n",
    "        return base_conv_layers\n",
    "\n",
    "    def instantiate_discriminator_growth_layer_block(self, params, block_idx):\n",
    "        \"\"\"Instantiates discriminator growth block layers.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "            block_idx: int, the current growth block's index.\n",
    "\n",
    "        Returns:\n",
    "            List of growth block layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"discriminator_growth_conv_blocks\"][block_idx]\n",
    "\n",
    "            # Create new inner convolutional layers.\n",
    "            conv_layers = [\n",
    "                tf.layers.Conv2D(\n",
    "                    filters=conv_block[i][3],\n",
    "                    kernel_size=conv_block[i][0:2],\n",
    "                    strides=conv_block[i][4:6],\n",
    "                    padding=\"same\",\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"{}_growth_layers_conv2d_{}_{}_{}x{}_{}_{}\".format(\n",
    "                        self.name,\n",
    "                        block_idx,\n",
    "                        i,\n",
    "                        conv_block[i][0],\n",
    "                        conv_block[i][1],\n",
    "                        conv_block[i][2],\n",
    "                        conv_block[i][3]\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_discriminator_growth_layer_block\",\n",
    "                \"conv_layers\",\n",
    "                conv_layers\n",
    "            )\n",
    "\n",
    "            # Down sample from 2s X 2s to s X s image.\n",
    "            downsampled_image_layer = tf.layers.AveragePooling2D(\n",
    "                pool_size=(2, 2),\n",
    "                strides=(2, 2),\n",
    "                name=\"{}_growth_downsampled_image_{}\".format(\n",
    "                    self.name,\n",
    "                    block_idx\n",
    "                )\n",
    "            )\n",
    "            print_obj(\n",
    "                \"instantiate_discriminator_growth_layer_block\",\n",
    "                \"downsampled_image_layer\",\n",
    "                downsampled_image_layer\n",
    "            )\n",
    "\n",
    "        return conv_layers + [downsampled_image_layer]\n",
    "\n",
    "    def instantiate_discriminator_growth_transition_downsample_layers(\n",
    "            self, params):\n",
    "        \"\"\"Instantiates discriminator growth transition downsample layers.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of growth transition downsample layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Down sample from 2s X 2s to s X s image.\n",
    "            downsample_layers = [\n",
    "                tf.layers.AveragePooling2D(\n",
    "                    pool_size=(2, 2),\n",
    "                    strides=(2, 2),\n",
    "                    name=\"{}_growth_transition_downsample_layer_{}\".format(\n",
    "                        self.name,\n",
    "                        layer_idx\n",
    "                    )\n",
    "                )\n",
    "                for layer_idx in range(\n",
    "                    1 + len(params[\"discriminator_growth_conv_blocks\"])\n",
    "                )\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\ninstantiate_discriminator_growth_transition_downsample_layers\",\n",
    "                \"downsample_layers\",\n",
    "                downsample_layers\n",
    "            )\n",
    "\n",
    "        return downsample_layers\n",
    "\n",
    "    def instantiate_discriminator_logits_layer(self):\n",
    "        \"\"\"Instantiates discriminator flatten and logits layers.\n",
    "\n",
    "        Returns:\n",
    "            Flatten and logits layers of discriminator.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Flatten layer to ready final block conv tensor for dense layer.\n",
    "            flatten_layer = tf.layers.Flatten(\n",
    "                name=\"{}_flatten_layer\".format(self.name)\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\ncreate_discriminator_logits_layer\",\n",
    "                \"flatten_layer\",\n",
    "                flatten_layer\n",
    "            )\n",
    "\n",
    "            # Final linear layer for logits.\n",
    "            logits_layer = tf.layers.Dense(\n",
    "                units=1,\n",
    "                activation=None,\n",
    "                kernel_regularizer=self.kernel_regularizer,\n",
    "                bias_regularizer=self.bias_regularizer,\n",
    "                name=\"{}_layers_dense_logits\".format(self.name)\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_discriminator_network\",\n",
    "                \"logits_layer\",\n",
    "                logits_layer\n",
    "            )\n",
    "\n",
    "        return flatten_layer, logits_layer\n",
    "\n",
    "    def instantiate_discriminator_layers(self, params):\n",
    "        \"\"\"Instantiates layers of discriminator network.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            from_rgb_conv_layers: list, fromRGB 1x1 `Conv2D` layers.\n",
    "            conv_layer_blocks: list, lists of `Conv2D` block layers for each\n",
    "                block.\n",
    "            transition_downsample_layers: list, `AveragePooling2D` layers for\n",
    "                downsampling shrinking transition paths.\n",
    "            flatten_layer: `Flatten` layer prior to logits layer.\n",
    "            logits_layer: `Dense` layer for logits.\n",
    "        \"\"\"\n",
    "        # Instantiate fromRGB 1x1 `Conv2D` layers.\n",
    "        from_rgb_conv_layers = self.instantiate_discriminator_from_rgb_layers(\n",
    "            params=params\n",
    "        )\n",
    "        print_obj(\n",
    "            \"instantiate_discriminator_layers\",\n",
    "            \"from_rgb_conv_layers\",\n",
    "            from_rgb_conv_layers\n",
    "        )\n",
    "\n",
    "        # Instantiate base conv block's `Conv2D` layers, for post-growth.\n",
    "        conv_layer_blocks = [\n",
    "            self.instantiate_discriminator_base_conv_layer_block(\n",
    "                params=params\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Instantiate growth `Conv2D` layer blocks.\n",
    "        conv_layer_blocks.extend(\n",
    "            [\n",
    "                self.instantiate_discriminator_growth_layer_block(\n",
    "                    params=params,\n",
    "                    block_idx=block_idx\n",
    "                )\n",
    "                for block_idx in range(\n",
    "                    len(params[\"discriminator_growth_conv_blocks\"])\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        print_obj(\n",
    "            \"instantiate_discriminator_layers\",\n",
    "            \"conv_layer_blocks\",\n",
    "            conv_layer_blocks\n",
    "        )\n",
    "\n",
    "        # Instantiate transition downsample `AveragePooling2D` layers.\n",
    "        transition_downsample_layers = (\n",
    "            self.instantiate_discriminator_growth_transition_downsample_layers(\n",
    "                params=params\n",
    "            )\n",
    "        )\n",
    "        print_obj(\n",
    "            \"instantiate_discriminator_layers\",\n",
    "            \"transition_downsample_layers\",\n",
    "            transition_downsample_layers\n",
    "        )\n",
    "\n",
    "        # Instantiate `Flatten` and `Dense` logits layers.\n",
    "        (flatten_layer,\n",
    "         logits_layer) = self.instantiate_discriminator_logits_layer()\n",
    "        print_obj(\n",
    "            \"instantiate_discriminator_layers\",\n",
    "            \"flatten_layer\",\n",
    "            flatten_layer\n",
    "        )\n",
    "        print_obj(\n",
    "            \"instantiate_discriminator_layers\",\n",
    "            \"logits_layer\",\n",
    "            logits_layer\n",
    "        )\n",
    "\n",
    "        return (from_rgb_conv_layers,\n",
    "                conv_layer_blocks,\n",
    "                transition_downsample_layers,\n",
    "                flatten_layer,\n",
    "                logits_layer)\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def build_discriminator_from_rgb_layers(self, params):\n",
    "        \"\"\"Creates discriminator fromRGB layers of 1x1 convs.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of tensors from fromRGB 1x1 `Conv2D` layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get fromRGB layer properties.\n",
    "            from_rgb = [\n",
    "                params[\"discriminator_from_rgb_layers\"][i][0][:]\n",
    "                for i in range(len(params[\"discriminator_from_rgb_layers\"]))\n",
    "            ]\n",
    "\n",
    "            # Create list to hold fromRGB 1x1 convs.\n",
    "            from_rgb_conv_tensors = [\n",
    "                self.from_rgb_conv_layers[i](\n",
    "                    inputs=tf.zeros(\n",
    "                        shape=[1] + from_rgb[i][0:3], dtype=tf.float32\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(from_rgb))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\nbuild_discriminator_from_rgb_layers\",\n",
    "                \"from_rgb_conv_tensors\",\n",
    "                from_rgb_conv_tensors\n",
    "            )\n",
    "\n",
    "        return from_rgb_conv_tensors\n",
    "\n",
    "    def build_discriminator_base_conv_layer_block(self, params):\n",
    "        \"\"\"Creates discriminator base conv layer block.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of tensors from base `Conv2D` layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"discriminator_base_conv_blocks\"][0]\n",
    "\n",
    "            # The base conv block is always the 0th one.\n",
    "            base_conv_layer_block = self.conv_layer_blocks[0]\n",
    "\n",
    "            # Minibatch stddev comes before first base conv layer,\n",
    "            # creating 1 extra feature map.\n",
    "            if params[\"use_minibatch_stddev\"]:\n",
    "                # Therefore, the number of input channels will be 1 higher\n",
    "                # for first base conv block.\n",
    "                num_in_channels = conv_block[0][3] + 1\n",
    "            else:\n",
    "                num_in_channels = conv_block[0][3]\n",
    "\n",
    "            # Get first base conv layer from list.\n",
    "            first_base_conv_layer = base_conv_layer_block[0]\n",
    "\n",
    "            # Build first layer with bigger tensor.\n",
    "            base_conv_tensors = [\n",
    "                first_base_conv_layer(\n",
    "                    inputs=tf.zeros(\n",
    "                        shape=[1] + conv_block[0][0:2] + [num_in_channels],\n",
    "                        dtype=tf.float32\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            # Now build the rest of the base conv block layers, store in list.\n",
    "            base_conv_tensors.extend(\n",
    "                [\n",
    "                    base_conv_layer_block[i](\n",
    "                        inputs=tf.zeros(\n",
    "                            shape=[1] + conv_block[i][0:3], dtype=tf.float32\n",
    "                        )\n",
    "                    )\n",
    "                    for i in range(1, len(conv_block))\n",
    "                ]\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\nbuild_discriminator_base_conv_layer_block\",\n",
    "                \"base_conv_tensors\",\n",
    "                base_conv_tensors\n",
    "            )\n",
    "\n",
    "        return base_conv_tensors\n",
    "\n",
    "    def build_discriminator_growth_layer_block(self, params, block_idx):\n",
    "        \"\"\"Creates discriminator growth block.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "            block_idx: int, the current growth block's index.\n",
    "\n",
    "        Returns:\n",
    "            List of tensors from growth block `Conv2D` layers.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Get conv block layer properties.\n",
    "            conv_block = params[\"discriminator_growth_conv_blocks\"][block_idx]\n",
    "\n",
    "            # Create new inner convolutional layers.\n",
    "            conv_tensors = [\n",
    "                self.conv_layer_blocks[1 + block_idx][i](\n",
    "                    inputs=tf.zeros(\n",
    "                        shape=[1] + conv_block[i][0:3], dtype=tf.float32\n",
    "                    )\n",
    "                )\n",
    "                for i in range(len(conv_block))\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"\\nbuild_discriminator_growth_layer_block\",\n",
    "                \"conv_tensors\",\n",
    "                conv_tensors\n",
    "            )\n",
    "\n",
    "        return conv_tensors\n",
    "\n",
    "    def build_discriminator_logits_layer(self, params):\n",
    "        \"\"\"Builds flatten and logits layer internals using call.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Final logits tensor of discriminator.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            block_conv_size = params[\"discriminator_base_conv_blocks\"][-1][-1][3]\n",
    "\n",
    "            # Flatten final block conv tensor.\n",
    "            block_conv_flat = self.flatten_layer(\n",
    "                inputs=tf.zeros(\n",
    "                    shape=[1, 1, 1, block_conv_size],\n",
    "                    dtype=tf.float32\n",
    "                )\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\nbuild_discriminator_logits_layer\",\n",
    "                \"block_conv_flat\",\n",
    "                block_conv_flat\n",
    "            )\n",
    "\n",
    "            # Final linear layer for logits.\n",
    "            logits = self.logits_layer(inputs=block_conv_flat)\n",
    "            print_obj(\"build_discriminator_logits_layer\", \"logits\", logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def build_discriminator_layers(self, params):\n",
    "        \"\"\"Builds discriminator layer internals.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Logits tensor.\n",
    "        \"\"\"\n",
    "        # Build fromRGB 1x1 `Conv2D` layers internals through call.\n",
    "        from_rgb_conv_tensors = self.build_discriminator_from_rgb_layers(\n",
    "            params=params\n",
    "        )\n",
    "        print_obj(\n",
    "            \"\\nbuild_discriminator_layers\",\n",
    "            \"from_rgb_conv_tensors\",\n",
    "            from_rgb_conv_tensors\n",
    "        )\n",
    "\n",
    "        with tf.control_dependencies(control_inputs=from_rgb_conv_tensors):\n",
    "            # Create base convolutional block's layer internals using call.\n",
    "            conv_block_tensors = [\n",
    "                self.build_discriminator_base_conv_layer_block(\n",
    "                    params=params\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            # Build growth `Conv2D` layer block internals through call.\n",
    "            conv_block_tensors.extend(\n",
    "                [\n",
    "                    self.build_discriminator_growth_layer_block(\n",
    "                        params=params, block_idx=block_idx\n",
    "                    )\n",
    "                    for block_idx in range(\n",
    "                       len(params[\"discriminator_growth_conv_blocks\"])\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Flatten conv block tensor lists of lists into list.\n",
    "            conv_block_tensors = [\n",
    "                item for sublist in conv_block_tensors for item in sublist\n",
    "            ]\n",
    "            print_obj(\n",
    "                \"build_discriminator_layers\",\n",
    "                \"conv_block_tensors\",\n",
    "                conv_block_tensors\n",
    "            )\n",
    "\n",
    "            with tf.control_dependencies(control_inputs=conv_block_tensors):\n",
    "                # Build logits layer internals using call.\n",
    "                logits_tensor = self.build_discriminator_logits_layer(\n",
    "                    params=params\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"build_discriminator_layers\",\n",
    "                    \"logits_tensor\",\n",
    "                    logits_tensor\n",
    "                )\n",
    "\n",
    "        return logits_tensor\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def minibatch_stddev_common(\n",
    "            self,\n",
    "            variance,\n",
    "            tile_multiples,\n",
    "            params,\n",
    "            caller):\n",
    "        \"\"\"Adds minibatch stddev feature map to image using grouping.\n",
    "\n",
    "        This is the code that is common between the grouped and ungroup\n",
    "        minibatch stddev functions.\n",
    "\n",
    "        Args:\n",
    "            variance: tensor, variance of minibatch or minibatch groups.\n",
    "            tile_multiples: list, length 4, used to tile input to final shape\n",
    "                input_dims[i] * mutliples[i].\n",
    "            params: dict, user passed parameters.\n",
    "            caller: str, name of the calling function.\n",
    "\n",
    "        Returns:\n",
    "            Minibatch standard deviation feature map image added to\n",
    "                channels of shape\n",
    "                [cur_batch_size, image_size, image_size, 1].\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(\n",
    "                \"{}/{}_minibatch_stddev\".format(self.name, caller)):\n",
    "            # Calculate standard deviation over the group plus small epsilon.\n",
    "            # shape = (\n",
    "            #     {\"grouped\": cur_batch_size / group_size, \"ungrouped\": 1},\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     num_channels\n",
    "            # )\n",
    "            stddev = tf.sqrt(\n",
    "                x=variance + 1e-8, name=\"{}_stddev\".format(caller)\n",
    "            )\n",
    "            print_obj(\n",
    "                \"minibatch_stddev_common\", \"{}_stddev\".format(caller), stddev\n",
    "            )\n",
    "\n",
    "            # Take average over feature maps and pixels.\n",
    "            if params[\"minibatch_stddev_averaging\"]:\n",
    "                # grouped shape = (cur_batch_size / group_size, 1, 1, 1)\n",
    "                # ungrouped shape = (1, 1, 1, 1)\n",
    "                stddev = tf.reduce_mean(\n",
    "                    input_tensor=stddev,\n",
    "                    axis=[1, 2, 3],\n",
    "                    keepdims=True,\n",
    "                    name=\"{}_stddev_average\".format(caller)\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"minibatch_stddev_common\",\n",
    "                    \"{}_stddev_average\".format(caller),\n",
    "                    stddev\n",
    "                )\n",
    "\n",
    "            # Replicate over group and pixels.\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     1\n",
    "            # )\n",
    "            stddev_feature_map = tf.tile(\n",
    "                input=stddev,\n",
    "                multiples=tile_multiples,\n",
    "                name=\"{}_stddev_feature_map\".format(caller)\n",
    "            )\n",
    "            print_obj(\n",
    "                \"minibatch_stddev_common\",\n",
    "                \"{}_stddev_feature_map\".format(caller),\n",
    "                stddev_feature_map\n",
    "            )\n",
    "\n",
    "        return stddev_feature_map\n",
    "\n",
    "    def grouped_minibatch_stddev(\n",
    "            self,\n",
    "            X,\n",
    "            cur_batch_size,\n",
    "            static_image_shape,\n",
    "            params,\n",
    "            group_size):\n",
    "        \"\"\"Adds minibatch stddev feature map to image using grouping.\n",
    "\n",
    "        Args:\n",
    "            X: tf.float32 tensor, image of shape\n",
    "                [cur_batch_size, image_size, image_size, num_channels].\n",
    "            cur_batch_size: tf.int64 tensor, the dynamic batch size (in case\n",
    "                of partial batch).\n",
    "            static_image_shape: list, the static shape of each image.\n",
    "            params: dict, user passed parameters.\n",
    "            group_size: int, size of image groups.\n",
    "\n",
    "        Returns:\n",
    "            Minibatch standard deviation feature map image added to\n",
    "                channels of shape\n",
    "                [cur_batch_size, image_size, image_size, 1].\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(\n",
    "                \"{}/grouped_minibatch_stddev\".format(self.name)):\n",
    "            # The group size should be less than or equal to the batch size.\n",
    "            # shape = ()\n",
    "            group_size = tf.minimum(\n",
    "                x=group_size, y=cur_batch_size, name=\"group_size\"\n",
    "            )\n",
    "            print_obj(\"grouped_minibatch_stddev\", \"group_size\", group_size)\n",
    "\n",
    "            # Split minibatch into M groups of size group_size, rank 5 tensor.\n",
    "            # shape = (\n",
    "            #     group_size,\n",
    "            #     cur_batch_size / group_size,\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     num_channels\n",
    "            # )\n",
    "            grouped_image = tf.reshape(\n",
    "                tensor=X,\n",
    "                shape=[group_size, -1] + static_image_shape,\n",
    "                name=\"grouped_image\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"grouped_minibatch_stddev\",\n",
    "                \"grouped_image\",\n",
    "                grouped_image\n",
    "            )\n",
    "\n",
    "            # Find the mean of each group.\n",
    "            # shape = (\n",
    "            #     1,\n",
    "            #     cur_batch_size / group_size,\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     num_channels\n",
    "            # )\n",
    "            grouped_mean = tf.reduce_mean(\n",
    "                input_tensor=grouped_image,\n",
    "                axis=0,\n",
    "                keepdims=True,\n",
    "                name=\"grouped_mean\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"grouped_minibatch_stddev\", \"grouped_mean\", grouped_mean\n",
    "            )\n",
    "\n",
    "            # Center each group using the mean.\n",
    "            # shape = (\n",
    "            #     group_size,\n",
    "            #     cur_batch_size / group_size,\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     num_channels\n",
    "            # )\n",
    "            centered_grouped_image = tf.subtract(\n",
    "                x=grouped_image, y=grouped_mean, name=\"centered_grouped_image\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"grouped_minibatch_stddev\",\n",
    "                \"centered_grouped_image\",\n",
    "                centered_grouped_image\n",
    "            )\n",
    "\n",
    "            # Calculate variance over group.\n",
    "            # shape = (\n",
    "            #     cur_batch_size / group_size,\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     num_channels\n",
    "            # )\n",
    "            grouped_variance = tf.reduce_mean(\n",
    "                input_tensor=tf.square(x=centered_grouped_image),\n",
    "                axis=0,\n",
    "                name=\"grouped_variance\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"grouped_minibatch_stddev\",\n",
    "                \"grouped_variance\",\n",
    "                grouped_variance\n",
    "            )\n",
    "\n",
    "            # Get stddev image using ops common to both grouped & ungrouped.\n",
    "            stddev_feature_map = self.minibatch_stddev_common(\n",
    "                variance=grouped_variance,\n",
    "                tile_multiples=[group_size] + static_image_shape[0:2] + [1],\n",
    "                params=params,\n",
    "                caller=\"grouped\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"grouped_minibatch_stddev\",\n",
    "                \"stddev_feature_map\",\n",
    "                stddev_feature_map\n",
    "            )\n",
    "\n",
    "        return stddev_feature_map\n",
    "\n",
    "    def ungrouped_minibatch_stddev(\n",
    "            self,\n",
    "            X,\n",
    "            cur_batch_size,\n",
    "            static_image_shape,\n",
    "            params):\n",
    "        \"\"\"Adds minibatch stddev feature map added to image channels.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, image of shape\n",
    "                [cur_batch_size, image_size, image_size, num_channels].\n",
    "            cur_batch_size: tf.int64 tensor, the dynamic batch size (in case\n",
    "                of partial batch).\n",
    "            static_image_shape: list, the static shape of each image.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Minibatch standard deviation feature map image added to\n",
    "                channels of shape\n",
    "                [cur_batch_size, image_size, image_size, 1].\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(\n",
    "                \"{}/ungrouped_minibatch_stddev\".format(self.name)):\n",
    "            # Find the mean of each group.\n",
    "            # shape = (\n",
    "            #     1,\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     num_channels\n",
    "            # )\n",
    "            mean = tf.reduce_mean(\n",
    "                input_tensor=X, axis=0, keepdims=True, name=\"mean\"\n",
    "            )\n",
    "            print_obj(\"ungrouped_minibatch_stddev\", \"mean\", mean)\n",
    "\n",
    "            # Center each group using the mean.\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     num_channels\n",
    "            # )\n",
    "            centered_image = tf.subtract(\n",
    "                x=X, y=mean, name=\"centered_image\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"ungrouped_minibatch_stddev\",\n",
    "                \"centered_image\",\n",
    "                centered_image\n",
    "            )\n",
    "\n",
    "            # Calculate variance over group.\n",
    "            # shape = (\n",
    "            #     1,\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     num_channels\n",
    "            # )\n",
    "            variance = tf.reduce_mean(\n",
    "                input_tensor=tf.square(x=centered_image),\n",
    "                axis=0,\n",
    "                keepdims=True,\n",
    "                name=\"variance\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"ungrouped_minibatch_stddev\",\n",
    "                \"variance\",\n",
    "                variance\n",
    "            )\n",
    "\n",
    "            # Get stddev image using ops common to both grouped & ungrouped.\n",
    "            stddev_feature_map = self.minibatch_stddev_common(\n",
    "                variance=variance,\n",
    "                tile_multiples=[cur_batch_size] + static_image_shape[0:2] + [1],\n",
    "                params=params,\n",
    "                caller=\"ungrouped\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"ungrouped_minibatch_stddev\",\n",
    "                \"stddev_feature_map\",\n",
    "                stddev_feature_map\n",
    "            )\n",
    "\n",
    "        return stddev_feature_map\n",
    "\n",
    "    def minibatch_stddev(self, X, params, group_size=4):\n",
    "        \"\"\"Adds minibatch stddev feature map added to image.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, image of shape\n",
    "                [cur_batch_size, image_size, image_size, num_channels].\n",
    "            params: dict, user passed parameters.\n",
    "            group_size: int, size of image groups.\n",
    "\n",
    "        Returns:\n",
    "            Image with minibatch standard deviation feature map added to\n",
    "                channels of shape\n",
    "                [cur_batch_size, image_size, image_size, num_channels + 1].\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(\"{}/minibatch_stddev\".format(self.name)):\n",
    "            # Get dynamic shape of image.\n",
    "            # shape = (4,)\n",
    "            dynamic_image_shape = tf.shape(\n",
    "                input=X, name=\"dynamic_image_shape\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\nminibatch_stddev\",\n",
    "                \"dynamic_image_shape\",\n",
    "                dynamic_image_shape\n",
    "            )\n",
    "\n",
    "            # Extract current batch size (in case this is a partial batch).\n",
    "            cur_batch_size = dynamic_image_shape[0]\n",
    "\n",
    "            # Get static shape of image.\n",
    "            # shape = (3,)\n",
    "            static_image_shape = params[\"generator_projection_dims\"]\n",
    "            print_obj(\n",
    "                \"minibatch_stddev\", \"static_image_shape\", static_image_shape\n",
    "            )\n",
    "\n",
    "            # cur_batch_size must be divisible by or smaller than group_size.\n",
    "            divisbility_condition = tf.equal(\n",
    "                x=tf.mod(x=cur_batch_size, y=group_size),\n",
    "                y=0,\n",
    "                name=\"divisbility_condition\"\n",
    "            )\n",
    "\n",
    "            less_than_condition = tf.less(\n",
    "                x=cur_batch_size, y=group_size, name=\"less_than_condition\"\n",
    "            )\n",
    "\n",
    "            any_condition = tf.reduce_any(\n",
    "                input_tensor=[divisbility_condition, less_than_condition],\n",
    "                name=\"any_condition\"\n",
    "            )\n",
    "\n",
    "            # Get minibatch stddev feature map image from grouped or\n",
    "            # ungrouped branch.\n",
    "            stddev_feature_map = tf.cond(\n",
    "                pred=any_condition,\n",
    "                true_fn=lambda: self.grouped_minibatch_stddev(\n",
    "                    X=X,\n",
    "                    cur_batch_size=cur_batch_size,\n",
    "                    static_image_shape=static_image_shape,\n",
    "                    params=params,\n",
    "                    group_size=group_size\n",
    "                ),\n",
    "                false_fn=lambda: self.ungrouped_minibatch_stddev(\n",
    "                    X=X,\n",
    "                    cur_batch_size=cur_batch_size,\n",
    "                    static_image_shape=static_image_shape,\n",
    "                    params=params\n",
    "                ),\n",
    "                name=\"stddev_feature_map_cond\"\n",
    "            )\n",
    "\n",
    "            # Append to image as new feature map.\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     image_size,\n",
    "            #     image_size,\n",
    "            #     num_channels + 1\n",
    "            # )\n",
    "            appended_image = tf.concat(\n",
    "                values=[X, stddev_feature_map],\n",
    "                axis=-1,\n",
    "                name=\"appended_image\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"minibatch_stddev_common\",\n",
    "                \"appended_image\",\n",
    "                appended_image\n",
    "            )\n",
    "\n",
    "        return appended_image\n",
    "\n",
    "    def use_discriminator_logits_layer(self, block_conv, params):\n",
    "        \"\"\"Uses flatten and logits layers to get logits tensor.\n",
    "\n",
    "        Args:\n",
    "            block_conv: tensor, output of last conv layer of discriminator.\n",
    "            flatten_layer: `Flatten` layer.\n",
    "            logits_layer: `Dense` layer for logits.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Final logits tensor of discriminator.\n",
    "        \"\"\"\n",
    "        print_obj(\n",
    "            \"\\nuse_discriminator_logits_layer\", \"block_conv\", block_conv\n",
    "        )\n",
    "        # Set shape to remove ambiguity for dense layer.\n",
    "        block_conv.set_shape(\n",
    "            [\n",
    "                block_conv.get_shape()[0],\n",
    "                params[\"generator_projection_dims\"][0] / 4,\n",
    "                params[\"generator_projection_dims\"][1] / 4,\n",
    "                block_conv.get_shape()[-1]]\n",
    "        )\n",
    "        print_obj(\"use_discriminator_logits_layer\", \"block_conv\", block_conv)\n",
    "\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Flatten final block conv tensor.\n",
    "            block_conv_flat = self.flatten_layer(inputs=block_conv)\n",
    "            print_obj(\n",
    "                \"use_discriminator_logits_layer\",\n",
    "                \"block_conv_flat\",\n",
    "                block_conv_flat\n",
    "            )\n",
    "\n",
    "            # Final linear layer for logits.\n",
    "            logits = self.logits_layer(inputs=block_conv_flat)\n",
    "            print_obj(\"use_discriminator_logits_layer\", \"logits\", logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def create_base_discriminator_network(self, X, params):\n",
    "        \"\"\"Creates base discriminator network.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, input image to discriminator.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Final logits tensor of discriminator.\n",
    "        \"\"\"\n",
    "        print_obj(\"\\ncreate_base_discriminator_network\", \"X\", X)\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Only need the first fromRGB conv layer & block for base network.\n",
    "            from_rgb_conv_layer = self.from_rgb_conv_layers[0]\n",
    "            block_layers = self.conv_layer_blocks[0]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            from_rgb_conv = from_rgb_conv_layer(inputs=X)\n",
    "            print_obj(\n",
    "                \"create_base_discriminator_network\",\n",
    "                \"from_rgb_conv\",\n",
    "                from_rgb_conv\n",
    "            )\n",
    "\n",
    "            if params[\"use_minibatch_stddev\"]:\n",
    "                block_conv = self.minibatch_stddev(\n",
    "                    X=from_rgb_conv,\n",
    "                    params=params,\n",
    "                    group_size=params[\"minibatch_stddev_group_size\"]\n",
    "                )\n",
    "            else:\n",
    "                block_conv = from_rgb_conv\n",
    "\n",
    "            for i in range(len(block_layers)):\n",
    "                block_conv = block_layers[i](inputs=block_conv)\n",
    "                print_obj(\n",
    "                    \"create_base_discriminator_network\",\n",
    "                    \"block_conv\",\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Get logits now.\n",
    "            logits = self.use_discriminator_logits_layer(\n",
    "                block_conv=block_conv,\n",
    "                params=params\n",
    "            )\n",
    "            print_obj(\"create_base_discriminator_network\", \"logits\", logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def create_growth_transition_discriminator_network(\n",
    "            self, X, alpha_var, params, trans_idx):\n",
    "        \"\"\"Creates growth transition discriminator network.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, input image to discriminator.\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "            trans_idx: int, index of current growth transition.\n",
    "\n",
    "        Returns:\n",
    "            Final logits tensor of discriminator.\n",
    "        \"\"\"\n",
    "        print_obj(\n",
    "            \"\\nEntered create_growth_transition_discriminator_network\",\n",
    "            \"trans_idx\",\n",
    "            trans_idx\n",
    "        )\n",
    "        print_obj(\"create_growth_transition_discriminator_network\", \"X\", X)\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Growing side chain.\n",
    "            growing_from_rgb_conv_layer = self.from_rgb_conv_layers[trans_idx + 1]\n",
    "            growing_block_layers = self.conv_layer_blocks[trans_idx + 1]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            growing_block_conv = growing_from_rgb_conv_layer(inputs=X)\n",
    "            print_obj(\n",
    "                \"\\ncreate_growth_transition_discriminator_network\",\n",
    "                \"growing_block_conv\",\n",
    "                growing_block_conv\n",
    "            )\n",
    "            for i in range(len(growing_block_layers)):\n",
    "                growing_block_conv = growing_block_layers[i](\n",
    "                    inputs=growing_block_conv\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_growth_transition_discriminator_network\",\n",
    "                    \"growing_block_conv\",\n",
    "                    growing_block_conv\n",
    "                )\n",
    "\n",
    "            # Shrinking side chain.\n",
    "            transition_downsample_layer = self.transition_downsample_layers[trans_idx]\n",
    "            shrinking_from_rgb_conv_layer = self.from_rgb_conv_layers[trans_idx]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            transition_downsample = transition_downsample_layer(inputs=X)\n",
    "            print_obj(\n",
    "                \"create_growth_transition_discriminator_network\",\n",
    "                \"transition_downsample\",\n",
    "                transition_downsample\n",
    "            )\n",
    "            shrinking_from_rgb_conv = shrinking_from_rgb_conv_layer(\n",
    "                inputs=transition_downsample\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_discriminator_network\",\n",
    "                \"shrinking_from_rgb_conv\",\n",
    "                shrinking_from_rgb_conv\n",
    "            )\n",
    "\n",
    "            # Weighted sum.\n",
    "            weighted_sum = tf.add(\n",
    "                x=growing_block_conv * alpha_var,\n",
    "                y=shrinking_from_rgb_conv * (1.0 - alpha_var),\n",
    "                name=\"{}_growth_transition_weighted_sum_{}\".format(\n",
    "                    self.name, trans_idx\n",
    "                )\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_discriminator_network\",\n",
    "                \"weighted_sum\",\n",
    "                weighted_sum\n",
    "            )\n",
    "\n",
    "            # Permanent blocks.\n",
    "            permanent_blocks = self.conv_layer_blocks[0:trans_idx + 1]\n",
    "\n",
    "            # Reverse order of blocks and flatten.\n",
    "            permanent_block_layers = [\n",
    "                item for sublist in permanent_blocks[::-1] for item in sublist\n",
    "            ]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            block_conv = weighted_sum\n",
    "\n",
    "            # Find number of permanent growth conv layers.\n",
    "            num_perm_growth_conv_layers = len(permanent_block_layers)\n",
    "            num_perm_growth_conv_layers -= len(params[\"conv_num_filters\"][0])\n",
    "\n",
    "            # Loop through only the permanent growth conv layers.\n",
    "            for i in range(num_perm_growth_conv_layers):\n",
    "                block_conv = permanent_block_layers[i](inputs=block_conv)\n",
    "                print_obj(\n",
    "                    \"create_growth_transition_discriminator_network\",\n",
    "                    \"block_conv_{}\".format(i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            if params[\"use_minibatch_stddev\"]:\n",
    "                block_conv = self.minibatch_stddev(\n",
    "                    X=block_conv,\n",
    "                    params=params,\n",
    "                    group_size=params[\"minibatch_stddev_group_size\"]\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_growth_transition_discriminator_network\",\n",
    "                    \"minibatch_stddev_block_conv\",\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Loop through only the permanent base conv layers now.\n",
    "            for i in range(\n",
    "                    num_perm_growth_conv_layers, len(permanent_block_layers)):\n",
    "                block_conv = permanent_block_layers[i](inputs=block_conv)\n",
    "                print_obj(\n",
    "                    \"create_growth_transition_discriminator_network\",\n",
    "                    \"block_conv_{}\".format(i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Get logits now.\n",
    "            logits = self.use_discriminator_logits_layer(\n",
    "                block_conv=block_conv, params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"create_growth_transition_discriminator_network\",\n",
    "                \"logits\",\n",
    "                logits\n",
    "            )\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def create_final_discriminator_network(self, X, params):\n",
    "        \"\"\"Creates final discriminator network.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, input image to discriminator.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Final logits tensor of discriminator.\n",
    "        \"\"\"\n",
    "        print_obj(\"\\ncreate_final_discriminator_network\", \"X\", X)\n",
    "        with tf.variable_scope(name_or_scope=self.name, reuse=tf.AUTO_REUSE):\n",
    "            # Only need the last fromRGB conv layer.\n",
    "            from_rgb_conv_layer = self.from_rgb_conv_layers[-1]\n",
    "\n",
    "            # Reverse order of blocks.\n",
    "            reversed_blocks = self.conv_layer_blocks[::-1]\n",
    "\n",
    "            # Flatten list of lists block layers into list.\n",
    "            block_layers = [\n",
    "                item for sublist in reversed_blocks for item in sublist\n",
    "            ]\n",
    "\n",
    "            # Pass inputs through layer chain.\n",
    "            block_conv = from_rgb_conv_layer(inputs=X)\n",
    "            print_obj(\n",
    "                \"\\ncreate_final_discriminator_network\",\n",
    "                \"block_conv\",\n",
    "                block_conv\n",
    "            )\n",
    "\n",
    "            # Find number of permanent growth conv layers.\n",
    "            num_growth_conv_layers = len(block_layers)\n",
    "            num_growth_conv_layers -= len(params[\"conv_num_filters\"][0])\n",
    "\n",
    "            # Loop through only the permanent growth conv layers.\n",
    "            for i in range(num_growth_conv_layers):\n",
    "                block_conv = block_layers[i](inputs=block_conv)\n",
    "                print_obj(\n",
    "                    \"create_final_discriminator_network\",\n",
    "                    \"block_conv_{}\".format(i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            if params[\"use_minibatch_stddev\"]:\n",
    "                block_conv = self.minibatch_stddev(\n",
    "                    X=block_conv,\n",
    "                    params=params,\n",
    "                    group_size=params[\"minibatch_stddev_group_size\"]\n",
    "                )\n",
    "                print_obj(\n",
    "                    \"create_final_discriminator_network\",\n",
    "                    \"minibatch_stddev_block_conv\",\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Loop through only the permanent base conv layers now.\n",
    "            for i in range(num_growth_conv_layers, len(block_layers)):\n",
    "                block_conv = block_layers[i](inputs=block_conv)\n",
    "                print_obj(\n",
    "                    \"create_final_discriminator_network\",\n",
    "                    \"block_conv_{}\".format(i),\n",
    "                    block_conv\n",
    "                )\n",
    "\n",
    "            # Get logits now.\n",
    "            logits = self.use_discriminator_logits_layer(\n",
    "                block_conv=block_conv,\n",
    "                params=params\n",
    "            )\n",
    "            print_obj(\"create_final_discriminator_network\", \"logits\", logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def switch_case_discriminator_logits(\n",
    "            self, X, alpha_var, params, growth_index):\n",
    "        \"\"\"Uses switch case to use the correct network to get logits.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, image tensors of shape\n",
    "                [cur_batch_size, image_size, image_size, depth].\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "            growth_index: int, current growth stage.\n",
    "\n",
    "        Returns:\n",
    "            Logits tensor of shape [cur_batch_size, 1].\n",
    "        \"\"\"\n",
    "        # Switch to case based on number of steps to get logits.\n",
    "        logits = tf.switch_case(\n",
    "            branch_index=growth_index,\n",
    "            branch_fns=[\n",
    "                # 4x4\n",
    "                lambda: self.create_base_discriminator_network(\n",
    "                    X=X, params=params\n",
    "                ),\n",
    "                # 8x8\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(0, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 16x16\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(1, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 32x32\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(2, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 64x64\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(3, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 128x128\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(4, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 256x256\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(5, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 512x512\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(6, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 1024x1024\n",
    "                lambda: self.create_growth_transition_discriminator_network(\n",
    "                    X=X,\n",
    "                    alpha_var=alpha_var,\n",
    "                    params=params,\n",
    "                    trans_idx=min(7, len(params[\"conv_num_filters\"]) - 2)\n",
    "                ),\n",
    "                # 1024x1024\n",
    "                lambda: self.create_final_discriminator_network(\n",
    "                    X=X, params=params\n",
    "                )\n",
    "            ],\n",
    "            name=\"{}_switch_case_logits\".format(self.name)\n",
    "        )\n",
    "\n",
    "        return logits\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def get_discriminator_logits(self, X, alpha_var, params):\n",
    "        \"\"\"Uses generator network and returns generated output for train/eval.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, image tensors of shape\n",
    "                [cur_batch_size, image_size, image_size, depth].\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Logits tensor of shape [cur_batch_size, 1].\n",
    "        \"\"\"\n",
    "        print_obj(\"\\nget_discriminator_logits\", \"X\", X)\n",
    "\n",
    "        # Get discriminator's logits tensor.\n",
    "        train_steps = params[\"train_steps\"]\n",
    "        num_steps_until_growth = params[\"num_steps_until_growth\"]\n",
    "        num_stages = train_steps // num_steps_until_growth\n",
    "        if (num_stages <= 0 or len(params[\"conv_num_filters\"]) == 1):\n",
    "            print(\n",
    "                \"\\nget_discriminator_logits: NOT GOING TO GROW, SKIP SWITCH CASE!\"\n",
    "            )\n",
    "            # If never going to grow, no sense using the switch case.\n",
    "            # 4x4\n",
    "            logits = self.create_base_discriminator_network(\n",
    "                X=X, params=params\n",
    "            )\n",
    "        else:\n",
    "            # Find growth index based on global step and growth frequency.\n",
    "            growth_index = tf.cast(\n",
    "                x=tf.floordiv(\n",
    "                    x=tf.train.get_or_create_global_step(),\n",
    "                    y=params[\"num_steps_until_growth\"],\n",
    "                    name=\"{}_global_step_floordiv\".format(self.name)\n",
    "                ),\n",
    "                dtype=tf.int32,\n",
    "                name=\"{}_growth_index\".format(self.name)\n",
    "            )\n",
    "\n",
    "            # Switch to case based on number of steps for logits.\n",
    "            logits = self.switch_case_discriminator_logits(\n",
    "                X=X,\n",
    "                alpha_var=alpha_var,\n",
    "                params=params,\n",
    "                growth_index=growth_index\n",
    "            )\n",
    "\n",
    "        print_obj(\n",
    "            \"\\nget_discriminator_logits\", \"logits\", logits\n",
    "        )\n",
    "\n",
    "        # Wrap logits in a control dependency for the build discriminator\n",
    "        # tensors to ensure discriminator internals are built.\n",
    "        with tf.control_dependencies(\n",
    "                control_inputs=[self.build_discriminator_tensors]):\n",
    "            logits = tf.identity(\n",
    "                input=logits, name=\"{}_logits_identity\".format(self.name)\n",
    "            )\n",
    "\n",
    "        return logits\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "\n",
    "    def get_gradient_penalty_loss(\n",
    "            self,\n",
    "            cur_batch_size,\n",
    "            fake_images,\n",
    "            real_images,\n",
    "            alpha_var,\n",
    "            params):\n",
    "        \"\"\"Gets discriminator gradient penalty loss.\n",
    "\n",
    "        Args:\n",
    "            cur_batch_size: tensor, in case of a partial batch instead of\n",
    "                using the user passed int.\n",
    "            fake_images: tensor, images generated by the generator from random\n",
    "                noise of shape [cur_batch_size, image_size, image_size, 3].\n",
    "            real_images: tensor, real images from input of shape\n",
    "                [cur_batch_size, image_size, image_size, 3].\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Discriminator's gradient penalty loss of shape [].\n",
    "        \"\"\"\n",
    "        with tf.name_scope(name=\"{}/gradient_penalty\".format(self.name)):\n",
    "            # Get a random uniform number rank 4 tensor.\n",
    "            random_uniform_num = tf.random.uniform(\n",
    "                shape=[cur_batch_size, 1, 1, 1],\n",
    "                minval=0., maxval=1.,\n",
    "                dtype=tf.float32,\n",
    "                name=\"random_uniform_num\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\nget_gradient_penalty_loss\",\n",
    "                \"random_uniform_num\",\n",
    "                random_uniform_num\n",
    "            )\n",
    "\n",
    "            # Find the element-wise difference between images.\n",
    "            image_difference = real_images - fake_images\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"image_difference\",\n",
    "                image_difference\n",
    "            )\n",
    "\n",
    "            # Get random samples from this mixed image distribution.\n",
    "            mixed_images = random_uniform_num * image_difference\n",
    "            mixed_images += fake_images\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"mixed_images\",\n",
    "                mixed_images\n",
    "            )\n",
    "\n",
    "            # Send to the discriminator to get logits.\n",
    "            mixed_logits = self.get_discriminator_logits(\n",
    "                X=mixed_images, alpha_var=alpha_var, params=params\n",
    "            )\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"mixed_logits\",\n",
    "                mixed_logits\n",
    "            )\n",
    "\n",
    "            # Get the mixed loss.\n",
    "            mixed_loss = tf.reduce_sum(\n",
    "                input_tensor=mixed_images,\n",
    "                name=\"mixed_loss\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"mixed_loss\",\n",
    "                mixed_loss\n",
    "            )\n",
    "\n",
    "            # Get gradient from returned list of length 1.\n",
    "            mixed_gradients = tf.gradients(\n",
    "                ys=mixed_loss,\n",
    "                xs=[mixed_images],\n",
    "                name=\"gradients\"\n",
    "            )[0]\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"mixed_gradients\",\n",
    "                mixed_gradients\n",
    "            )\n",
    "\n",
    "            # Get gradient's L2 norm.\n",
    "            mixed_norms = tf.sqrt(\n",
    "                x=tf.reduce_sum(\n",
    "                    input_tensor=tf.square(\n",
    "                        x=mixed_gradients,\n",
    "                        name=\"squared_grads\"\n",
    "                    ),\n",
    "                    axis=[1, 2, 3]\n",
    "                )\n",
    "            )\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"mixed_norms\",\n",
    "                mixed_norms\n",
    "            )\n",
    "\n",
    "            # Get squared difference from target of 1.0.\n",
    "            squared_difference = tf.square(\n",
    "                x=mixed_norms - 1.0,\n",
    "                name=\"squared_difference\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"squared_difference\",\n",
    "                squared_difference\n",
    "            )\n",
    "\n",
    "            # Get gradient penalty scalar.\n",
    "            gradient_penalty = tf.reduce_mean(\n",
    "                input_tensor=squared_difference, name=\"gradient_penalty\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"get_gradient_penalty_loss\",\n",
    "                \"gradient_penalty\",\n",
    "                gradient_penalty\n",
    "            )\n",
    "\n",
    "            # Multiply with lambda to get gradient penalty loss.\n",
    "            gradient_penalty_loss = tf.multiply(\n",
    "                x=params[\"discriminator_gradient_penalty_coefficient\"],\n",
    "                y=gradient_penalty,\n",
    "                name=\"gradient_penalty_loss\"\n",
    "            )\n",
    "\n",
    "            return gradient_penalty_loss\n",
    "\n",
    "    def get_discriminator_loss(\n",
    "            self,\n",
    "            cur_batch_size,\n",
    "            fake_images,\n",
    "            real_images,\n",
    "            fake_logits,\n",
    "            real_logits,\n",
    "            alpha_var,\n",
    "            params):\n",
    "        \"\"\"Gets discriminator loss.\n",
    "\n",
    "        Args:\n",
    "            cur_batch_size: tensor, in case of a partial batch instead of\n",
    "                using the user passed int.\n",
    "            fake_images: tensor, images generated by the generator from random\n",
    "                noise of shape [cur_batch_size, image_size, image_size, 3].\n",
    "            real_images: tensor, real images from input of shape\n",
    "                [cur_batch_size, image_size, image_size, 3].\n",
    "            fake_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "                discriminator having processed generator's output image.\n",
    "            fake_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "                discriminator having processed real image.\n",
    "            alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Discriminator's total loss tensor of shape [].\n",
    "        \"\"\"\n",
    "        # Calculate base discriminator loss.\n",
    "        discriminator_real_loss = tf.reduce_mean(\n",
    "            input_tensor=real_logits,\n",
    "            name=\"{}_real_loss\".format(self.name)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"\\nget_discriminator_loss\",\n",
    "            \"discriminator_real_loss\",\n",
    "            discriminator_real_loss\n",
    "        )\n",
    "\n",
    "        discriminator_generated_loss = tf.reduce_mean(\n",
    "            input_tensor=fake_logits,\n",
    "            name=\"{}_generated_loss\".format(self.name)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_discriminator_loss\",\n",
    "            \"discriminator_generated_loss\",\n",
    "            discriminator_generated_loss\n",
    "        )\n",
    "\n",
    "        discriminator_loss = tf.add(\n",
    "            x=discriminator_real_loss, y=-discriminator_generated_loss,\n",
    "            name=\"{}_loss\".format(self.name)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_discriminator_loss\",\n",
    "            \"discriminator_loss\",\n",
    "            discriminator_loss\n",
    "        )\n",
    "\n",
    "        # Get discriminator gradient penalty loss.\n",
    "        discriminator_gradient_penalty = self.get_gradient_penalty_loss(\n",
    "            cur_batch_size=cur_batch_size,\n",
    "            fake_images=fake_images,\n",
    "            real_images=real_images,\n",
    "            alpha_var=alpha_var,\n",
    "            params=params\n",
    "        )\n",
    "\n",
    "        # Get discriminator Wasserstein GP loss.\n",
    "        discriminator_wasserstein_gp_loss = tf.add(\n",
    "            x=discriminator_loss,\n",
    "            y=discriminator_gradient_penalty,\n",
    "            name=\"{}_wasserstein_gp_loss\".format(self.name)\n",
    "        )\n",
    "\n",
    "        # Get discriminator regularization losses.\n",
    "        discriminator_reg_loss = regularization.get_regularization_loss(\n",
    "            params=params, scope=self.name\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_discriminator_loss\",\n",
    "            \"discriminator_reg_loss\",\n",
    "            discriminator_reg_loss\n",
    "        )\n",
    "\n",
    "        # Combine losses for total losses.\n",
    "        discriminator_total_loss = tf.math.add(\n",
    "            x=discriminator_wasserstein_gp_loss,\n",
    "            y=discriminator_reg_loss,\n",
    "            name=\"{}_total_loss\".format(self.name)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_discriminator_loss\",\n",
    "            \"discriminator_total_loss\",\n",
    "            discriminator_total_loss\n",
    "        )\n",
    "\n",
    "        return discriminator_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regularization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regularization_loss(params, scope=None):\n",
    "    \"\"\"Gets regularization losses from variables attached to a regularizer.\n",
    "\n",
    "    Args:\n",
    "        params: dict, user passed parameters.\n",
    "        scope: str, the name of the variable scope.\n",
    "\n",
    "    Returns:\n",
    "        Scalar regularization loss tensor.\n",
    "    \"\"\"\n",
    "    def sum_nd_tensor_list_to_scalar_tensor(t_list):\n",
    "        \"\"\"Sums different shape tensors into a scalar tensor.\n",
    "\n",
    "        Args:\n",
    "            t_list: list, tensors of varying shapes.\n",
    "\n",
    "        Returns:\n",
    "            Scalar tensor.\n",
    "        \"\"\"\n",
    "        # Sum list of tensors into a list of scalars.\n",
    "        t_reduce_sum_list = [\n",
    "            tf.reduce_sum(\n",
    "                # Remove the :0 from the end of the name.\n",
    "                input_tensor=t, name=\"{}_reduce_sum\".format(t.name[:-2])\n",
    "            )\n",
    "            for t in t_list\n",
    "        ]\n",
    "        print_obj(\n",
    "            \"\\nsum_nd_tensor_list_to_scalar_tensor\",\n",
    "            \"t_reduce_sum_list\",\n",
    "            t_reduce_sum_list\n",
    "        )\n",
    "\n",
    "        # Add all scalars together into one scalar.\n",
    "        t_scalar_sum_tensor = tf.add_n(\n",
    "            inputs=t_reduce_sum_list,\n",
    "            name=\"{}_t_scalar_sum_tensor\".format(scope)\n",
    "        )\n",
    "        print_obj(\n",
    "            \"sum_nd_tensor_list_to_scalar_tensor\",\n",
    "            \"t_scalar_sum_tensor\",\n",
    "            t_scalar_sum_tensor\n",
    "        )\n",
    "\n",
    "        return t_scalar_sum_tensor\n",
    "\n",
    "    print_obj(\"\\nget_regularization_loss\", \"scope\", scope)\n",
    "    lambda1 = params[\"discriminator_l1_regularization_scale\"]\n",
    "    lambda2 = params[\"discriminator_l2_regularization_scale\"]\n",
    "    if lambda1 <= 0. and lambda2 <= 0.:\n",
    "        # No regularization so return zero.\n",
    "        return tf.zeros(shape=[], dtype=tf.float32)\n",
    "\n",
    "    # Get list of trainable variables with a regularizer attached in scope.\n",
    "    trainable_reg_vars_list = tf.get_collection(\n",
    "        tf.GraphKeys.REGULARIZATION_LOSSES, scope=scope)\n",
    "    print_obj(\n",
    "        \"get_regularization_loss\",\n",
    "        \"trainable_reg_vars_list\",\n",
    "        trainable_reg_vars_list\n",
    "    )\n",
    "    \n",
    "    for var in trainable_reg_vars_list:\n",
    "        print_obj(\n",
    "            \"get_regularization_loss_{}\".format(scope),\n",
    "            \"{}\".format(var.name),\n",
    "            var.graph\n",
    "        )\n",
    "\n",
    "    l1_loss = 0.\n",
    "    if lambda1 > 0.:\n",
    "        # For L1 regularization, take the absolute value element-wise of each.\n",
    "        trainable_reg_vars_abs_list = [\n",
    "            tf.abs(\n",
    "                x=var,\n",
    "                # Clean up regularizer scopes in variable names.\n",
    "                name=\"{}_abs\".format((\"/\").join(var.name.split(\"/\")[0:3]))\n",
    "            )\n",
    "            for var in trainable_reg_vars_list\n",
    "        ]\n",
    "\n",
    "        # Get L1 loss\n",
    "        l1_loss = tf.multiply(\n",
    "            x=lambda1,\n",
    "            y=sum_nd_tensor_list_to_scalar_tensor(\n",
    "                t_list=trainable_reg_vars_abs_list\n",
    "            ),\n",
    "            name=\"{}_l1_loss\".format(scope)\n",
    "        )\n",
    "\n",
    "    l2_loss = 0.\n",
    "    if lambda2 > 0.:\n",
    "        # For L2 regularization, square all variables element-wise.\n",
    "        trainable_reg_vars_squared_list = [\n",
    "            tf.square(\n",
    "                x=var,\n",
    "                # Clean up regularizer scopes in variable names.\n",
    "                name=\"{}_squared\".format((\"/\").join(var.name.split(\"/\")[0:3]))\n",
    "            )\n",
    "            for var in trainable_reg_vars_list\n",
    "        ]\n",
    "        print_obj(\n",
    "            \"get_regularization_loss\",\n",
    "            \"trainable_reg_vars_squared_list\",\n",
    "            trainable_reg_vars_squared_list\n",
    "        )\n",
    "\n",
    "        # Get L2 loss\n",
    "        l2_loss = tf.multiply(\n",
    "            x=lambda2,\n",
    "            y=sum_nd_tensor_list_to_scalar_tensor(\n",
    "                t_list=trainable_reg_vars_squared_list\n",
    "            ),\n",
    "            name=\"{}_l2_loss\".format(scope)\n",
    "        )\n",
    "\n",
    "    l1_l2_loss = tf.add(\n",
    "        x=l1_loss, y=l2_loss, name=\"{}_l1_l2_loss\".format(scope)\n",
    "    )\n",
    "\n",
    "    return l1_l2_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pgan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(loss, global_step, alpha_var, params, scope):\n",
    "    \"\"\"Trains network and returns loss and train op.\n",
    "\n",
    "    Args:\n",
    "        loss: tensor, shape of [].\n",
    "        global_step: tensor, the current training step or batch in the\n",
    "            training loop.\n",
    "        alpha_var: variable, alpha for weighted sum of fade-in of layers.\n",
    "        params: dict, user passed parameters.\n",
    "        scope: str, the variables that to train.\n",
    "\n",
    "    Returns:\n",
    "        Loss tensor and training op.\n",
    "    \"\"\"\n",
    "    print_obj(\"\\ntrain_network\", \"loss\", loss)\n",
    "    print_obj(\"train_network\", \"global_step\", global_step)\n",
    "    print_obj(\"train_network\", \"alpha_var\", alpha_var)\n",
    "    print_obj(\"train_network\", \"scope\", scope)\n",
    "\n",
    "    # Create optimizer map.\n",
    "    optimizers = {\n",
    "        \"Adam\": tf.train.AdamOptimizer,\n",
    "        \"Adadelta\": tf.train.AdadeltaOptimizer,\n",
    "        \"AdagradDA\": tf.train.AdagradDAOptimizer,\n",
    "        \"Adagrad\": tf.train.AdagradOptimizer,\n",
    "        \"Ftrl\": tf.train.FtrlOptimizer,\n",
    "        \"GradientDescent\": tf.train.GradientDescentOptimizer,\n",
    "        \"Momentum\": tf.train.MomentumOptimizer,\n",
    "        \"ProximalAdagrad\": tf.train.ProximalAdagradOptimizer,\n",
    "        \"ProximalGradientDescent\": tf.train.ProximalGradientDescentOptimizer,\n",
    "        \"RMSProp\": tf.train.RMSPropOptimizer\n",
    "    }\n",
    "\n",
    "    # Get optimizer and instantiate it.\n",
    "    optimizer = optimizers[params[\"{}_optimizer\".format(scope)]](\n",
    "        learning_rate=params[\"{}_learning_rate\".format(scope)]\n",
    "    )\n",
    "    print_obj(\"train_network\", \"optimizer\", optimizer)\n",
    "\n",
    "    # Get trainable variables.\n",
    "    variables = tf.trainable_variables(scope=scope)\n",
    "    print_obj(\"\\ntrain_network\", \"variables\", variables)\n",
    "\n",
    "    # Get gradients.\n",
    "    gradients = tf.gradients(\n",
    "        ys=loss,\n",
    "        xs=variables,\n",
    "        name=\"{}_gradients\".format(scope)\n",
    "    )\n",
    "    print_obj(\"\\ntrain_network\", \"gradients\", gradients)\n",
    "\n",
    "    # Clip gradients.\n",
    "    if params[\"{}_clip_gradients\".format(scope)]:\n",
    "        gradients, _ = tf.clip_by_global_norm(\n",
    "            t_list=gradients,\n",
    "            clip_norm=params[\"{}_clip_gradients\".format(scope)],\n",
    "            name=\"{}_clip_by_global_norm_gradients\".format(scope)\n",
    "        )\n",
    "        print_obj(\"\\ntrain_network\", \"gradients\", gradients)\n",
    "\n",
    "    # Zip back together gradients and variables.\n",
    "    grads_and_vars = zip(gradients, variables)\n",
    "    print_obj(\"train_network\", \"grads_and_vars\", grads_and_vars)\n",
    "\n",
    "    # Create train op by applying gradients to variables and incrementing\n",
    "    # global step.\n",
    "    train_op = optimizer.apply_gradients(\n",
    "        grads_and_vars=grads_and_vars,\n",
    "        global_step=global_step,\n",
    "        name=\"{}_apply_gradients\".format(scope)\n",
    "    )\n",
    "    print_obj(\"train_network\", \"train_op\", train_op)\n",
    "\n",
    "    # Update alpha variable to linearly scale from 0 to 1 based on steps.\n",
    "    alpha_var_update_op = tf.assign(\n",
    "        ref=alpha_var,\n",
    "        value=tf.divide(\n",
    "            x=tf.cast(\n",
    "                x=tf.mod(x=global_step, y=params[\"num_steps_until_growth\"]),\n",
    "                dtype=tf.float32\n",
    "            ),\n",
    "            y=params[\"num_steps_until_growth\"]\n",
    "        )\n",
    "    )\n",
    "    print_obj(\"train_network\", \"alpha_var_update_op\", alpha_var_update_op)\n",
    "\n",
    "    # Ensure alpha variable gets updated.\n",
    "    with tf.control_dependencies(control_inputs=[alpha_var_update_op]):\n",
    "        loss = tf.identity(\n",
    "            input=loss, name=\"{}_train_network_loss_identity\".format(scope)\n",
    "        )\n",
    "\n",
    "    return loss, train_op\n",
    "\n",
    "\n",
    "def resize_real_image(image, params, block_idx):\n",
    "    \"\"\"Resizes real images to match the GAN's current size.\n",
    "\n",
    "    Args:\n",
    "        image: tensor, original image.\n",
    "        params: dict, user passed parameters.\n",
    "        block_idx: int, index of current block.\n",
    "\n",
    "    Returns:\n",
    "        Resized image tensor.\n",
    "    \"\"\"\n",
    "    print_obj(\"\\nresize_real_image\", \"block_idx\", block_idx)\n",
    "    print_obj(\"resize_real_image\", \"image\", image)\n",
    "\n",
    "    # Resize image to match GAN size at current block index.\n",
    "    resized_image = tf.image.resize(\n",
    "        images=image,\n",
    "        size=[\n",
    "            params[\"generator_projection_dims\"][0] * (2 ** block_idx),\n",
    "            params[\"generator_projection_dims\"][1] * (2 ** block_idx)\n",
    "        ],\n",
    "        method=\"nearest\",\n",
    "        name=\"resize_real_images_resized_image_{}\".format(block_idx)\n",
    "    )\n",
    "    print_obj(\"resize_real_images\", \"resized_image\", resized_image)\n",
    "\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "def resize_real_images(image, params):\n",
    "    \"\"\"Resizes real images to match the GAN's current size.\n",
    "\n",
    "    Args:\n",
    "        image: tensor, original image.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Resized image tensor.\n",
    "    \"\"\"\n",
    "    print_obj(\"\\nresize_real_images\", \"image\", image)\n",
    "    # Resize real image for each block.\n",
    "    num_stages = params[\"train_steps\"] // params[\"num_steps_until_growth\"]\n",
    "    if (num_stages <= 0 or len(params[\"conv_num_filters\"]) == 1):\n",
    "        print(\n",
    "            \"\\nresize_real_images: NEVER GOING TO GROW, SKIP SWITCH CASE!\"\n",
    "        )\n",
    "        # If we never are going to grow, no sense using the switch case.\n",
    "        # 4x4\n",
    "        resized_image = resize_real_image(\n",
    "            image=image, params=params, block_idx=0\n",
    "        )\n",
    "    else:\n",
    "        # Find growth index based on global step and growth frequency.\n",
    "        growth_index = tf.cast(\n",
    "            x=tf.floordiv(\n",
    "                x=tf.train.get_or_create_global_step(),\n",
    "                y=params[\"num_steps_until_growth\"],\n",
    "                name=\"resize_real_images_global_step_floordiv\"\n",
    "            ),\n",
    "            dtype=tf.int32,\n",
    "            name=\"resize_real_images_growth_index\"\n",
    "        )\n",
    "\n",
    "        # Switch to case based on number of steps for resized image.\n",
    "        resized_image = tf.switch_case(\n",
    "            branch_index=growth_index,\n",
    "            branch_fns=[\n",
    "                # 4x4\n",
    "                lambda: resize_real_image(\n",
    "                    image=image, params=params, block_idx=0\n",
    "                ),\n",
    "                # 8x8\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(1, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 16x16\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(2, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 32x32\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(3, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 64x64\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(4, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 128x128\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(5, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 256x256\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(6, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 512x512\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(7, len(params[\"conv_num_filters\"]) - 1)\n",
    "                ),\n",
    "                # 1024x1024\n",
    "                lambda: resize_real_image(\n",
    "                    image=image,\n",
    "                    params=params,\n",
    "                    block_idx=min(8, len(params[\"conv_num_filters\"]) - 1)\n",
    "                )\n",
    "            ],\n",
    "            name=\"resize_real_images_switch_case_resized_image\"\n",
    "        )\n",
    "        print_obj(\n",
    "            \"resize_real_images\", \"selected resized_image\", resized_image\n",
    "        )\n",
    "\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "def pgan_model(features, labels, mode, params):\n",
    "    \"\"\"Progressively Growing GAN custom Estimator model function.\n",
    "\n",
    "    Args:\n",
    "        features: dict, keys are feature names and values are feature tensors.\n",
    "        labels: tensor, label data.\n",
    "        mode: tf.estimator.ModeKeys with values of either TRAIN, EVAL, or\n",
    "            PREDICT.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Instance of `tf.estimator.EstimatorSpec` class.\n",
    "    \"\"\"\n",
    "    print_obj(\"\\npgan_model\", \"features\", features)\n",
    "    print_obj(\"pgan_model\", \"labels\", labels)\n",
    "    print_obj(\"pgan_model\", \"mode\", mode)\n",
    "    print_obj(\"pgan_model\", \"params\", params)\n",
    "\n",
    "    # Loss function, training/eval ops, etc.\n",
    "    predictions_dict = None\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = None\n",
    "    export_outputs = None\n",
    "\n",
    "    # Instantiate generator.\n",
    "    pgan_generator = Generator(\n",
    "        kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(\n",
    "            scale_l1=params[\"generator_l1_regularization_scale\"],\n",
    "            scale_l2=params[\"generator_l2_regularization_scale\"]\n",
    "        ),\n",
    "        bias_regularizer=None,\n",
    "        params=params,\n",
    "        name=\"generator\"\n",
    "    )\n",
    "\n",
    "    # Instantiate discriminator.\n",
    "    pgan_discriminator = Discriminator(\n",
    "        kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(\n",
    "            scale_l1=params[\"discriminator_l1_regularization_scale\"],\n",
    "            scale_l2=params[\"discriminator_l2_regularization_scale\"]\n",
    "        ),\n",
    "        bias_regularizer=None,\n",
    "        params=params,\n",
    "        name=\"discriminator\"\n",
    "    )\n",
    "\n",
    "    # Create alpha variable to use for weighted sum for smooth fade-in.\n",
    "    alpha_var = tf.get_variable(\n",
    "        name=\"alpha_var\",\n",
    "        dtype=tf.float32,\n",
    "        initializer=tf.zeros(shape=[], dtype=tf.float32),\n",
    "        trainable=False\n",
    "    )\n",
    "    print_obj(\"pgan_model\", \"alpha_var\", alpha_var)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # Extract given latent vectors from features dictionary.\n",
    "        Z = tf.cast(x=features[\"Z\"], dtype=tf.float32)\n",
    "\n",
    "        # Get predictions from generator.\n",
    "        generated_images = get_predict_generator_outputs(\n",
    "            Z=Z, params=params\n",
    "        )\n",
    "\n",
    "        # Create predictions dictionary.\n",
    "        if params[\"predict_all_resolutions\"]:\n",
    "            predictions_dict = {\n",
    "                \"generated_images_{}x{}\".format(\n",
    "                    4 * 2 ** i, 4 * 2 ** i\n",
    "                ): generated_images[i]\n",
    "                for i in range(len(params[\"conv_num_filters\"]))\n",
    "            }\n",
    "        else:\n",
    "            predictions_dict = {\n",
    "                \"generated_images\": generated_images\n",
    "            }\n",
    "\n",
    "        # Create export outputs.\n",
    "        export_outputs = {\n",
    "            \"predict_export_outputs\": tf.estimator.export.PredictOutput(\n",
    "                outputs=predictions_dict)\n",
    "        }\n",
    "    else:\n",
    "        # Extract image from features dictionary.\n",
    "        X = features[\"image\"]\n",
    "\n",
    "        # Get dynamic batch size in case of partial batch.\n",
    "        cur_batch_size = tf.shape(\n",
    "            input=X,\n",
    "            out_type=tf.int32,\n",
    "            name=\"pgan_model_cur_batch_size\"\n",
    "        )[0]\n",
    "\n",
    "        # Create random noise latent vector for each batch example.\n",
    "        Z = tf.random.normal(\n",
    "            shape=[cur_batch_size, params[\"latent_size\"]],\n",
    "            mean=0.0,\n",
    "            stddev=1.0,\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        # Get generated image from generator network from gaussian noise.\n",
    "        print(\"\\nCall generator with Z = {}.\".format(Z))\n",
    "        generator_outputs = pgan_generator.get_train_eval_generator_outputs(\n",
    "            Z=Z, alpha_var=alpha_var, params=params\n",
    "        )\n",
    "\n",
    "        # Get fake logits from discriminator using generator's output image.\n",
    "        print(\n",
    "            \"\\nCall discriminator with generator_outputs = {}.\".format(\n",
    "                generator_outputs\n",
    "            )\n",
    "        )\n",
    "        fake_logits = pgan_discriminator.get_discriminator_logits(\n",
    "            X=generator_outputs, alpha_var=alpha_var, params=params\n",
    "        )\n",
    "\n",
    "        # Resize real images based on the current size of the GAN.\n",
    "        real_images = resize_real_images(image=X, params=params)\n",
    "\n",
    "        # Get real logits from discriminator using real image.\n",
    "        print(\n",
    "            \"\\nCall discriminator with real_image = {}.\".format(real_images)\n",
    "        )\n",
    "        real_logits = pgan_discriminator.get_discriminator_logits(\n",
    "            X=real_images, alpha_var=alpha_var, params=params\n",
    "        )\n",
    "\n",
    "        # Get generator total loss.\n",
    "        generator_total_loss = pgan_generator.get_generator_loss(\n",
    "            fake_logits=fake_logits, params=params\n",
    "        )\n",
    "\n",
    "        # Get discriminator total loss.\n",
    "        discriminator_total_loss = pgan_discriminator.get_discriminator_loss(\n",
    "            cur_batch_size=cur_batch_size,\n",
    "            fake_images=generator_outputs,\n",
    "            real_images=real_images,\n",
    "            fake_logits=fake_logits,\n",
    "            real_logits=real_logits,\n",
    "            alpha_var=alpha_var,\n",
    "            params=params\n",
    "        )\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            # Get global step.\n",
    "            global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "            # Determine if it is time to train generator or discriminator.\n",
    "            cycle_step = tf.mod(\n",
    "                x=global_step,\n",
    "                y=tf.cast(\n",
    "                    x=tf.add(\n",
    "                        x=params[\"generator_train_steps\"],\n",
    "                        y=params[\"discriminator_train_steps\"]\n",
    "                    ),\n",
    "                    dtype=tf.int64\n",
    "                ),\n",
    "                name=\"pgan_model_cycle_step\"\n",
    "            )\n",
    "\n",
    "            # Create choose generator condition.\n",
    "            condition = tf.less(\n",
    "                x=cycle_step, y=params[\"generator_train_steps\"]\n",
    "            )\n",
    "\n",
    "            # Needed for batch normalization, but has no effect otherwise.\n",
    "            update_ops = tf.get_collection(key=tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "            with tf.control_dependencies(control_inputs=update_ops):\n",
    "                # Conditionally choose to train generator or discriminator.\n",
    "                loss, train_op = tf.cond(\n",
    "                    pred=condition,\n",
    "                    true_fn=lambda: train_network(\n",
    "                        loss=generator_total_loss,\n",
    "                        global_step=global_step,\n",
    "                        alpha_var=alpha_var,\n",
    "                        params=params,\n",
    "                        scope=\"generator\"\n",
    "                    ),\n",
    "                    false_fn=lambda: train_network(\n",
    "                        loss=discriminator_total_loss,\n",
    "                        global_step=global_step,\n",
    "                        alpha_var=alpha_var,\n",
    "                        params=params,\n",
    "                        scope=\"discriminator\"\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            loss = discriminator_total_loss\n",
    "\n",
    "            # Concatenate discriminator logits and labels.\n",
    "            discriminator_logits = tf.concat(\n",
    "                values=[real_logits, fake_logits],\n",
    "                axis=0,\n",
    "                name=\"discriminator_concat_logits\"\n",
    "            )\n",
    "\n",
    "            discriminator_labels = tf.concat(\n",
    "                values=[\n",
    "                    tf.ones_like(tensor=real_logits),\n",
    "                    tf.zeros_like(tensor=fake_logits)\n",
    "                ],\n",
    "                axis=0,\n",
    "                name=\"discriminator_concat_labels\"\n",
    "            )\n",
    "\n",
    "            # Calculate discriminator probabilities.\n",
    "            discriminator_probabilities = tf.nn.sigmoid(\n",
    "                x=discriminator_logits, name=\"discriminator_probabilities\"\n",
    "            )\n",
    "\n",
    "            # Create eval metric ops dictionary.\n",
    "            eval_metric_ops = {\n",
    "                \"accuracy\": tf.metrics.accuracy(\n",
    "                    labels=discriminator_labels,\n",
    "                    predictions=discriminator_probabilities,\n",
    "                    name=\"pgan_model_accuracy\"\n",
    "                ),\n",
    "                \"precision\": tf.metrics.precision(\n",
    "                    labels=discriminator_labels,\n",
    "                    predictions=discriminator_probabilities,\n",
    "                    name=\"pgan_model_precision\"\n",
    "                ),\n",
    "                \"recall\": tf.metrics.recall(\n",
    "                    labels=discriminator_labels,\n",
    "                    predictions=discriminator_probabilities,\n",
    "                    name=\"pgan_model_recall\"\n",
    "                ),\n",
    "                \"auc_roc\": tf.metrics.auc(\n",
    "                    labels=discriminator_labels,\n",
    "                    predictions=discriminator_probabilities,\n",
    "                    num_thresholds=200,\n",
    "                    curve=\"ROC\",\n",
    "                    name=\"pgan_model_auc_roc\"\n",
    "                ),\n",
    "                \"auc_pr\": tf.metrics.auc(\n",
    "                    labels=discriminator_labels,\n",
    "                    predictions=discriminator_probabilities,\n",
    "                    num_thresholds=200,\n",
    "                    curve=\"PR\",\n",
    "                    name=\"pgan_model_auc_pr\"\n",
    "                )\n",
    "            }\n",
    "\n",
    "    # Return EstimatorSpec\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions_dict,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops,\n",
    "        export_outputs=export_outputs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## serving.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn(params):\n",
    "    \"\"\"Serving input function.\n",
    "\n",
    "    Args:\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        ServingInputReceiver object containing features and receiver tensors.\n",
    "    \"\"\"\n",
    "    # Create placeholders to accept data sent to the model at serving time.\n",
    "    # shape = (batch_size,)\n",
    "    feature_placeholders = {\n",
    "        \"Z\": tf.placeholder(\n",
    "            dtype=tf.float32,\n",
    "            shape=[None, params[\"latent_size\"]],\n",
    "            name=\"serving_input_placeholder_Z\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    print_obj(\n",
    "        \"\\nserving_input_fn\",\n",
    "        \"feature_placeholders\",\n",
    "        feature_placeholders\n",
    "    )\n",
    "\n",
    "    # Create clones of the feature placeholder tensors so that the SavedModel\n",
    "    # SignatureDef will point to the placeholder.\n",
    "    features = {\n",
    "        key: tf.identity(\n",
    "            input=value,\n",
    "            name=\"serving_input_fn_identity_placeholder_{}\".format(key)\n",
    "        )\n",
    "        for key, value in feature_placeholders.items()\n",
    "    }\n",
    "\n",
    "    print_obj(\n",
    "        \"serving_input_fn\",\n",
    "        \"features\",\n",
    "        features\n",
    "    )\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features=features, receiver_tensors=feature_placeholders\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(args):\n",
    "    \"\"\"Trains and evaluates custom Estimator model.\n",
    "\n",
    "    Args:\n",
    "        args: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        `Estimator` object.\n",
    "    \"\"\"\n",
    "    # Set logging to be level of INFO.\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    # Create our custom estimator using our model function.\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn=pgan_model,\n",
    "        model_dir=args[\"output_dir\"],\n",
    "        params=args\n",
    "    )\n",
    "\n",
    "    # Create train spec to read in our training data.\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"train_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.TRAIN,\n",
    "            batch_size=args[\"train_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        max_steps=args[\"train_steps\"]\n",
    "    )\n",
    "\n",
    "    # Create exporter to save out the complete model to disk.\n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        name=\"exporter\",\n",
    "        serving_input_receiver_fn=lambda: serving_input_fn(args)\n",
    "    )\n",
    "\n",
    "    # Create eval spec to read in our validation data and export our model.\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"eval_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.EVAL,\n",
    "            batch_size=args[\"eval_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        steps=args[\"eval_steps\"],\n",
    "        start_delay_secs=args[\"start_delay_secs\"],\n",
    "        throttle_secs=args[\"throttle_secs\"],\n",
    "        exporters=exporter\n",
    "    )\n",
    "\n",
    "    # Create train and evaluate loop to train and evaluate our estimator.\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'local_trained_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f284d4b7c10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "pgan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "pgan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "pgan_model: mode = train\n",
      "pgan_model: params = {'train_file_pattern': 'data/train.tfrecord', 'eval_file_pattern': 'data/eval.tfrecord', 'output_dir': 'local_trained_model', 'train_batch_size': 32, 'train_steps': 400, 'eval_batch_size': 32, 'eval_steps': 10, 'start_delay_secs': 600, 'throttle_secs': 600, 'exports_to_keep': 20, 'predict_all_resolutions': True, 'height': 32, 'width': 32, 'depth': 3, 'num_steps_until_growth': 100, 'conv_num_filters': [[512, 512], [512, 512], [512, 512], [512, 512], [256, 256]], 'conv_kernel_sizes': [[4, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'conv_strides': [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1]], 'generator_base_conv_blocks': [[[4, 4, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]]], 'generator_growth_conv_blocks': [[[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 256, 1, 1], [3, 3, 256, 256, 1, 1]]], 'generator_to_rgb_layers': [[[1, 1, 512, 3, 1, 1]], [[1, 1, 512, 3, 1, 1]], [[1, 1, 512, 3, 1, 1]], [[1, 1, 512, 3, 1, 1]], [[1, 1, 256, 3, 1, 1]]], 'discriminator_from_rgb_layers': [[[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 256, 1, 1]]], 'discriminator_base_conv_blocks': [[[3, 3, 512, 512, 1, 1], [4, 4, 512, 512, 1, 1]]], 'discriminator_growth_conv_blocks': [[[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 256, 256, 1, 1], [3, 3, 256, 512, 1, 1]]], 'latent_size': 512, 'generator_projection_dims': [4, 4, 512], 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_optimizer': 'GradientDescent', 'generator_learning_rate': 0.0001, 'generator_clip_gradients': 2.0, 'generator_train_steps': 1, 'discriminator_l1_regularization_scale': 0.01, 'discriminator_l2_regularization_scale': 0.01, 'discriminator_optimizer': 'GradientDescent', 'discriminator_learning_rate': 0.0001, 'discriminator_clip_gradients': 2.0, 'discriminator_gradient_penalty_coefficient': 10.0, 'discriminator_train_steps': 1}\n",
      "\n",
      "instantiate_generator_projection_layer: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7f283e566610>\n",
      "\n",
      "instantiate_generator_layers: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7f283e566610>\n",
      "\n",
      "instantiate_generator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566910>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566cd0>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566fd0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566810>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e5632d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563550>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563590>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e5634d0>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563bd0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563a10>]\n",
      "instantiate_generator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566910>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566cd0>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566fd0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e566810>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e5632d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563550>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563590>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e5634d0>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563bd0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e563a10>]]\n",
      "\n",
      "instantiate_generator_to_rgb_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e090>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e210>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e390>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e510>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e690>]\n",
      "instantiate_generator_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e090>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e210>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e390>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e510>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e57e690>]\n",
      "\n",
      "build_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_layers: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>]\n",
      "build_generator_layers: conv_block_tensors = [[<tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>]]\n",
      "build_generator_layers: conv_block_tensors = [<tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>]\n",
      "\n",
      "build_generator_to_rgb_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "build_generator_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "\n",
      "instantiate_discriminator_from_rgb_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e416b90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e416d50>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e416ed0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b090>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b210>]\n",
      "instantiate_discriminator_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e416b90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e416d50>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e416ed0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b090>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b210>]\n",
      "\n",
      "instantiate_discriminator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b590>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b710>]\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41ba10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41bb90>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e41be10>\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e4210d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421250>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e4214d0>\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421750>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e4218d0>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e421b50>\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421dd0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421f50>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427210>\n",
      "instantiate_discriminator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b590>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41b710>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41ba10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e41bb90>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e41be10>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e4210d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421250>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e4214d0>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421750>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e4218d0>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e421b50>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421dd0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f283e421f50>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427210>]]\n",
      "\n",
      "instantiate_discriminator_growth_transition_downsample_layers: downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427550>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427690>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e4277d0>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427910>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427a50>]\n",
      "instantiate_discriminator_layers: transition_downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427550>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427690>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e4277d0>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427910>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f283e427a50>]\n",
      "\n",
      "create_discriminator_logits_layer: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7f283e427dd0>\n",
      "create_growth_transition_discriminator_network: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7f283e427fd0>\n",
      "instantiate_discriminator_layers: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7f283e427dd0>\n",
      "instantiate_discriminator_layers: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7f283e427fd0>\n",
      "\n",
      "build_discriminator_from_rgb_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0' shape=(1, 1, 1, 256) dtype=float32>]\n",
      "\n",
      "build_discriminator_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0' shape=(1, 1, 1, 256) dtype=float32>]\n",
      "\n",
      "build_discriminator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "build_discriminator_layers: conv_block_tensors = [<tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(1, 512), dtype=float32)\n",
      "build_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "build_discriminator_layers: logits_tensor = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "pgan_model: alpha_var = <tf.Variable 'alpha_var:0' shape=() dtype=float32_ref>\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_train_eval_generator_outputs: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "create_base_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: to_rgb_conv = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 0\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_0_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_0_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_0 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_0_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_0_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_0 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_0 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_0 = Tensor(\"generator/growth_transition_weighted_sum_0:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 1\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_1_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_1_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_1_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_1_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_1_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_1 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_1_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_1_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_1 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_1 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_1 = Tensor(\"generator/growth_transition_weighted_sum_1:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 2\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_2_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_2_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_2_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_2_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_2 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_2_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_2_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_2 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_2 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_2 = Tensor(\"generator/growth_transition_weighted_sum_2:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "create_final_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_final_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "create_final_generator_network: base_block_conv = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_final_generator_network: base_block_conv_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_4 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_4_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_final_generator_network: block_conv_4_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_final_generator_network: to_rgb_conv = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "get_train_eval_generator_outputs: generated_outputs = Tensor(\"generator_switch_case_generated_outputs/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "Call discriminator with generator_outputs = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_base_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 0\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_0/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_0:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 1\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_1/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_1:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 2\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_2/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_final_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_switch_case_logits/indexed_case/Identity:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "resize_real_images: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "\n",
      "resize_real_image: block_idx = 0\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_0/ResizeNearestNeighbor:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 1\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_1/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 2\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_2/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 3\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "resize_real_images: selected resized_image = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "Call discriminator with real_image = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_base_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 0\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_0/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_0:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 1\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_1/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_1:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 2\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_2/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_final_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_switch_case_logits_1/indexed_case/Identity:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = generator\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_generator: generator_7/generator_projection_layer/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"generator_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"generator_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"generator_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_generated_loss = Tensor(\"discriminator_generated_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"discriminator/gradient_penalty/random_uniform_num:0\", shape=(?, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"discriminator/gradient_penalty/sub:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_base_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 0\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_0/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_0:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 1\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_1/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_1:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 2\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_2/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_final_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/gradient_penalty/discriminator_switch_case_logits/indexed_case/Identity:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"discriminator/gradient_penalty/discriminator_logits_identity:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"discriminator/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"discriminator/gradient_penalty/gradients/discriminator/gradient_penalty/mixed_loss_grad/Tile:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"discriminator/gradient_penalty/Sqrt:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"discriminator/gradient_penalty/squared_difference:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"discriminator/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = discriminator\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "get_regularization_loss_discriminator: discriminator_14/discriminator_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f284d4aa990>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"discriminator_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"discriminator_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"discriminator_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "train_network: loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "train_network: global_step = <tf.Variable 'global_step:0' shape=() dtype=int64_ref>\n",
      "train_network: alpha_var = <tf.Variable 'alpha_var:0' shape=() dtype=float32_ref>\n",
      "train_network: scope = generator\n",
      "train_network: optimizer = <tensorflow.python.training.gradient_descent.GradientDescentOptimizer object at 0x7f283d962ed0>\n",
      "\n",
      "train_network: variables = [<tf.Variable 'generator/generator_projection_layer/kernel:0' shape=(512, 8192) dtype=float32_ref>, <tf.Variable 'generator/generator_projection_layer/bias:0' shape=(8192,) dtype=float32_ref>, <tf.Variable 'generator/generator_base_layers_conv2d_0_4x4_512_512/kernel:0' shape=(4, 4, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_base_layers_conv2d_0_4x4_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_base_layers_conv2d_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_base_layers_conv2d_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_0_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_0_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_1_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_1_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_2_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_2_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel:0' shape=(3, 3, 512, 256) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_3_0_3x3_512_256/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'generator/generator_growth_layers_conv2d_3_1_3x3_256_256/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel:0' shape=(1, 1, 512, 3) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_0_1x1_512_3/bias:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel:0' shape=(1, 1, 512, 3) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_1_1x1_512_3/bias:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel:0' shape=(1, 1, 512, 3) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_2_1x1_512_3/bias:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel:0' shape=(1, 1, 512, 3) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_3_1x1_512_3/bias:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel:0' shape=(1, 1, 256, 3) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_4_1x1_256_3/bias:0' shape=(3,) dtype=float32_ref>]\n",
      "\n",
      "train_network: gradients = [<tf.Tensor 'cond/generator_gradients/AddN_16:0' shape=(512, 8192) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_2:0' shape=(8192,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_17:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_4:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_18:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_6:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_19:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_10:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_20:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_12:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_21:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_17:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_22:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_19:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_23:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_23:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_24:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_25:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_25:0' shape=(3, 3, 512, 256) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_29:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_26:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_31:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_27:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_8:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_28:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_14:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_29:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_21:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_30:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_27:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/AddN_31:0' shape=(1, 1, 256, 3) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator_switch_case_generated_outputs/indexed_case_grad/Identity_33:0' shape=(3,) dtype=float32>]\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\n",
      "train_network: gradients = [<tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_0:0' shape=(512, 8192) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_1:0' shape=(8192,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_2:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_3:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_4:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_5:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_6:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_7:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_8:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_9:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_10:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_11:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_12:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_13:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_14:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_15:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_16:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_17:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_18:0' shape=(3, 3, 512, 256) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_19:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_20:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_21:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_22:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_23:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_24:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_25:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_26:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_27:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_28:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_29:0' shape=(3,) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_30:0' shape=(1, 1, 256, 3) dtype=float32>, <tf.Tensor 'cond/generator_clip_by_global_norm_gradients_1/cond/generator_clip_by_global_norm_gradients_1/_31:0' shape=(3,) dtype=float32>]\n",
      "train_network: grads_and_vars = <zip object at 0x7f2837b1e140>\n",
      "train_network: train_op = name: \"cond/generator_apply_gradients\"\n",
      "op: \"AssignAdd\"\n",
      "input: \"cond/generator_apply_gradients/Switch:1\"\n",
      "input: \"cond/generator_apply_gradients/value\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT64\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_class\"\n",
      "  value {\n",
      "    list {\n",
      "      s: \"loc:@global_step\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"use_locking\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "\n",
      "train_network: alpha_var_update_op = Tensor(\"cond/Assign:0\", shape=(), dtype=float32_ref)\n",
      "\n",
      "train_network: loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "train_network: global_step = <tf.Variable 'global_step:0' shape=() dtype=int64_ref>\n",
      "train_network: alpha_var = <tf.Variable 'alpha_var:0' shape=() dtype=float32_ref>\n",
      "train_network: scope = discriminator\n",
      "train_network: optimizer = <tensorflow.python.training.gradient_descent.GradientDescentOptimizer object at 0x7f2837add2d0>\n",
      "\n",
      "train_network: variables = [<tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel:0' shape=(1, 1, 3, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel:0' shape=(1, 1, 3, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel:0' shape=(1, 1, 3, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel:0' shape=(1, 1, 3, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel:0' shape=(1, 1, 3, 256) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_base_layers_conv2d_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_base_layers_conv2d_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_base_layers_conv2d_1_4x4_512_512/kernel:0' shape=(4, 4, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_base_layers_conv2d_1_4x4_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_0_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_0_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_1_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_1_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_2_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_2_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_3_0_3x3_256_256/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel:0' shape=(3, 3, 256, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_growth_layers_conv2d_3_1_3x3_256_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_layers_dense_logits/kernel:0' shape=(512, 1) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_layers_dense_logits/bias:0' shape=(1,) dtype=float32_ref>]\n",
      "\n",
      "train_network: gradients = [<tf.Tensor 'cond/discriminator_gradients/AddN_32:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_16:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_33:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_20:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_34:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_23:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_35:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_26:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_36:0' shape=(1, 1, 3, 256) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_29:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_37:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_17:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_38:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_18:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_39:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_21:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_40:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_22:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_41:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_24:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_42:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_25:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_43:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_27:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_44:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_28:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_45:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_30:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_46:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_31:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_47:0' shape=(512, 1) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_19:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "train_network: gradients = [<tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_0:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_1:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_2:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_3:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_4:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_5:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_6:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_7:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_8:0' shape=(1, 1, 3, 256) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_9:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_10:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_11:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_12:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_13:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_14:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_15:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_16:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_17:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_18:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_19:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_20:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_21:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_22:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_23:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_24:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_25:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_26:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_27:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_28:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_29:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_30:0' shape=(512, 1) dtype=float32>, <tf.Tensor 'cond/discriminator_clip_by_global_norm_gradients_1/cond/discriminator_clip_by_global_norm_gradients_1/_31:0' shape=(1,) dtype=float32>]\n",
      "train_network: grads_and_vars = <zip object at 0x7f2834f68910>\n",
      "train_network: train_op = name: \"cond/discriminator_apply_gradients\"\n",
      "op: \"AssignAdd\"\n",
      "input: \"cond/discriminator_apply_gradients/Switch:0\"\n",
      "input: \"cond/discriminator_apply_gradients/value\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT64\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_class\"\n",
      "  value {\n",
      "    list {\n",
      "      s: \"loc:@global_step\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"use_locking\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "\n",
      "train_network: alpha_var_update_op = Tensor(\"cond/Assign_1:0\", shape=(), dtype=float32_ref)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into local_trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 65374.69, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1.38105\n",
      "INFO:tensorflow:loss = 65364.15, step = 101 (72.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.96929\n",
      "INFO:tensorflow:loss = 65352.832, step = 201 (103.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.353734\n",
      "INFO:tensorflow:loss = 65341.95, step = 301 (282.698 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 315 into local_trained_model/model.ckpt.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "pgan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "pgan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "pgan_model: mode = eval\n",
      "pgan_model: params = {'train_file_pattern': 'data/train.tfrecord', 'eval_file_pattern': 'data/eval.tfrecord', 'output_dir': 'local_trained_model', 'train_batch_size': 32, 'train_steps': 400, 'eval_batch_size': 32, 'eval_steps': 10, 'start_delay_secs': 600, 'throttle_secs': 600, 'exports_to_keep': 20, 'predict_all_resolutions': True, 'height': 32, 'width': 32, 'depth': 3, 'num_steps_until_growth': 100, 'conv_num_filters': [[512, 512], [512, 512], [512, 512], [512, 512], [256, 256]], 'conv_kernel_sizes': [[4, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'conv_strides': [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1]], 'generator_base_conv_blocks': [[[4, 4, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]]], 'generator_growth_conv_blocks': [[[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 256, 1, 1], [3, 3, 256, 256, 1, 1]]], 'generator_to_rgb_layers': [[[1, 1, 512, 3, 1, 1]], [[1, 1, 512, 3, 1, 1]], [[1, 1, 512, 3, 1, 1]], [[1, 1, 512, 3, 1, 1]], [[1, 1, 256, 3, 1, 1]]], 'discriminator_from_rgb_layers': [[[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 512, 1, 1]], [[1, 1, 3, 256, 1, 1]]], 'discriminator_base_conv_blocks': [[[3, 3, 512, 512, 1, 1], [4, 4, 512, 512, 1, 1]]], 'discriminator_growth_conv_blocks': [[[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]], [[3, 3, 256, 256, 1, 1], [3, 3, 256, 512, 1, 1]]], 'latent_size': 512, 'generator_projection_dims': [4, 4, 512], 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_optimizer': 'GradientDescent', 'generator_learning_rate': 0.0001, 'generator_clip_gradients': 2.0, 'generator_train_steps': 1, 'discriminator_l1_regularization_scale': 0.01, 'discriminator_l2_regularization_scale': 0.01, 'discriminator_optimizer': 'GradientDescent', 'discriminator_learning_rate': 0.0001, 'discriminator_clip_gradients': 2.0, 'discriminator_gradient_penalty_coefficient': 10.0, 'discriminator_train_steps': 1}\n",
      "\n",
      "instantiate_generator_projection_layer: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7f28342e00d0>\n",
      "\n",
      "instantiate_generator_layers: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7f28342e00d0>\n",
      "\n",
      "instantiate_generator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0750>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e08d0>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0450>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0c50>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0e90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0c10>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5a10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5090>]\n",
      "\n",
      "instantiate_generator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5950>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5310>]\n",
      "instantiate_generator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0750>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e08d0>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0450>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0c50>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0e90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e0c10>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5a10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5090>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5950>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5310>]]\n",
      "\n",
      "instantiate_generator_to_rgb_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5350>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5e10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5150>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342ec290>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342ec510>]\n",
      "instantiate_generator_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5350>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5e10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342e5150>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342ec290>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f28342ec510>]\n",
      "\n",
      "build_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_layers: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_growth_layer_block: conv_tensors = [<tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>]\n",
      "build_generator_layers: conv_block_tensors = [[<tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>], [<tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>]]\n",
      "build_generator_layers: conv_block_tensors = [<tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>]\n",
      "\n",
      "build_generator_to_rgb_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "build_generator_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "\n",
      "instantiate_discriminator_from_rgb_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4510>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4690>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4810>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4990>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4b10>]\n",
      "instantiate_discriminator_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4510>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4690>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4810>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4990>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4b10>]\n",
      "\n",
      "instantiate_discriminator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4e90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c050>]\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c350>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c4d0>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc37c750>\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c9d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37cb50>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc37cdd0>\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381090>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381210>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381490>\n",
      "\n",
      "instantiate_discriminator_growth_layer_block: conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381710>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381890>]\n",
      "instantiate_discriminator_growth_layer_block: downsampled_image_layer = <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381b10>\n",
      "instantiate_discriminator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc3f4e90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c050>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c350>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c4d0>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc37c750>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37c9d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc37cb50>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc37cdd0>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381090>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381210>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381490>], [<tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381710>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7f27bc381890>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381b10>]]\n",
      "\n",
      "instantiate_discriminator_growth_transition_downsample_layers: downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381e50>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381f90>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc3890d0>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc389250>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc389390>]\n",
      "instantiate_discriminator_layers: transition_downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381e50>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc381f90>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc3890d0>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc389250>, <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f27bc389390>]\n",
      "\n",
      "create_discriminator_logits_layer: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7f27bc389710>\n",
      "create_growth_transition_discriminator_network: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7f27bc389910>\n",
      "instantiate_discriminator_layers: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7f27bc389710>\n",
      "instantiate_discriminator_layers: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7f27bc389910>\n",
      "\n",
      "build_discriminator_from_rgb_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0' shape=(1, 1, 1, 256) dtype=float32>]\n",
      "\n",
      "build_discriminator_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0' shape=(1, 1, 1, 256) dtype=float32>]\n",
      "\n",
      "build_discriminator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_growth_layer_block: conv_tensors = [<tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "build_discriminator_layers: conv_block_tensors = [<tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0' shape=(1, 1, 1, 512) dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0' shape=(1, 3, 3, 256) dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(1, 512), dtype=float32)\n",
      "build_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "build_discriminator_layers: logits_tensor = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "pgan_model: alpha_var = <tf.Variable 'alpha_var:0' shape=() dtype=float32_ref>\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_train_eval_generator_outputs: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "create_base_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: to_rgb_conv = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 0\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_0_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_0_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_0 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_0_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_0_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_0 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_0 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/LeakyRelu:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_0 = Tensor(\"generator/growth_transition_weighted_sum_0:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 1\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_1_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_1_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_1_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_1_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_1_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_1 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_1_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_1_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_1 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_1 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/LeakyRelu:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_1 = Tensor(\"generator/growth_transition_weighted_sum_1:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 2\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_2_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_2_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_2_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_2_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_2_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_2 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_2_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_2_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_2 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_2 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/LeakyRelu:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_2 = Tensor(\"generator/growth_transition_weighted_sum_2:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_generator_network: trans_idx = 3\n",
      "create_growth_transition_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_0 = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: base_block_conv_3_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsample_generator_image_block_conv_3_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: block_conv_3_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: upsampled_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_block_conv_3_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_growth_transition_generator_network: growing_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: shrinking_to_rgb_conv_3 = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "create_growth_transition_generator_network: weighted_sum_3 = Tensor(\"generator/growth_transition_weighted_sum_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "create_final_generator_network: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_7/generator_projection_layer/LeakyRelu:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_final_generator_network: projection = Tensor(\"generator/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "create_final_generator_network: base_block_conv = Tensor(\"generator_8/generator_base_layers_conv2d_0_4x4_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_final_generator_network: base_block_conv_1 = Tensor(\"generator_8/generator_base_layers_conv2d_1_3x3_512_512/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_1 = Tensor(\"generator/generator_growth_upsampled_image_1_4x4_8x8/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_1_0 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_1_1 = Tensor(\"generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_2 = Tensor(\"generator/generator_growth_upsampled_image_2_8x8_16x16/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_2_0 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_2_1 = Tensor(\"generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, 16, 16, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_3 = Tensor(\"generator/generator_growth_upsampled_image_3_16x16_32x32/ResizeNearestNeighbor:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_3_0 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_3_1 = Tensor(\"generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "\n",
      "upsample_generator_image: upsampled_image = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_final_generator_network: upsample_generator_image_block_conv_4 = Tensor(\"generator/generator_growth_upsampled_image_4_32x32_64x64/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "create_final_generator_network: block_conv_4_0 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_final_generator_network: block_conv_4_1 = Tensor(\"generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/LeakyRelu:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "create_final_generator_network: to_rgb_conv = Tensor(\"generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/LeakyRelu:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "get_train_eval_generator_outputs: generated_outputs = Tensor(\"generator_switch_case_generated_outputs/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "Call discriminator with generator_outputs = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_base_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 0\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_0/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_0:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 1\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_1/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_1:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 2\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_2/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_final_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_switch_case_logits/indexed_case/Identity:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "resize_real_images: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "\n",
      "resize_real_image: block_idx = 0\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_0/ResizeNearestNeighbor:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 1\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_1/ResizeNearestNeighbor:0\", shape=(?, 8, 8, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 2\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_2/ResizeNearestNeighbor:0\", shape=(?, 16, 16, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 3\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 4\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_images_resized_image_4/ResizeNearestNeighbor:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "resize_real_images: selected resized_image = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "Call discriminator with real_image = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_base_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 0\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_0/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_0:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 1\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_1/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_1:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 2\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_2/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: X = Tensor(\"resize_real_images_switch_case_resized_image/indexed_case/Identity:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_final_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_switch_case_logits_1/indexed_case/Identity:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = generator\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_generator: generator_7/generator_projection_layer/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_generator: generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"generator_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'generator_7/generator_projection_layer/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_0_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_8/generator_base_layers_conv2d_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_9/generator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_10/generator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_11/generator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_0_3x3_512_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_12/generator_growth_layers_conv2d_3_1_3x3_256_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_1_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_2_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_3_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_13/generator_to_rgb_layers_conv2d_4_1x1_256_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"generator_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"generator_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_generated_loss = Tensor(\"discriminator_generated_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"discriminator/gradient_penalty/random_uniform_num:0\", shape=(?, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"discriminator/gradient_penalty/sub:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_base_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_base_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 0\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_0/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_0:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 1\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_1/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_1:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 2\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_2/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Entered create_growth_transition_discriminator_network: trans_idx = 3\n",
      "create_growth_transition_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: growing_block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: transition_downsample = Tensor(\"discriminator/discriminator_growth_transition_downsample_layer_3/AvgPool:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "create_growth_transition_discriminator_network: shrinking_from_rgb_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: weighted_sum = Tensor(\"discriminator/discriminator_growth_transition_weighted_sum_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_growth_transition_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_growth_transition_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/LeakyRelu:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_3/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_2/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_1/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator/discriminator_growth_downsampled_image_0/AvgPool:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "create_final_discriminator_network: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/LeakyRelu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_14/discriminator_flatten_layer/Reshape:0\", shape=(?, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "create_final_discriminator_network: logits = Tensor(\"discriminator_14/discriminator_layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/gradient_penalty/discriminator_switch_case_logits/indexed_case/Identity:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"discriminator/gradient_penalty/discriminator_logits_identity:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"discriminator/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"discriminator/gradient_penalty/gradients/discriminator/gradient_penalty/mixed_loss_grad/Tile:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"discriminator/gradient_penalty/Sqrt:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"discriminator/gradient_penalty/squared_difference:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"discriminator/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = discriminator\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "get_regularization_loss_discriminator: discriminator_14/discriminator_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7f28345ec890>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"discriminator_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_1_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_2_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_3_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_8/discriminator_from_rgb_layers_conv2d_4_1x1_3_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_9/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_10/discriminator_growth_layers_conv2d_0_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_11/discriminator_growth_layers_conv2d_1_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_12/discriminator_growth_layers_conv2d_2_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_0_3x3_256_256/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_13/discriminator_growth_layers_conv2d_3_1_3x3_256_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_14/discriminator_layers_dense_logits/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"discriminator_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"discriminator_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-05T10:40:16Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from local_trained_model/model.ckpt-315\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree(path=arguments[\"output_dir\"], ignore_errors=True)\n",
    "estimator = train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1591379258\n"
     ]
    }
   ],
   "source": [
    "!ls trained_model/export/exporter | tail -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from trained_model/export/exporter/1591379258/variables/variables\n"
     ]
    }
   ],
   "source": [
    "predict_fn = tf.contrib.predictor.from_saved_model(\n",
    "    \"trained_model/export/exporter/1591379258\"\n",
    ")\n",
    "predictions = predict_fn(\n",
    "    {\n",
    "        \"Z\": np.random.normal(size=(500, 512))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['generated_images_16x16',\n",
       " 'generated_images_32x32',\n",
       " 'generated_images_4x4',\n",
       " 'generated_images_8x8']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(predictions.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = {\n",
    "    k: np.clip(\n",
    "        a=((v + 1.0) * (255. / 2)).astype(np.int32),\n",
    "        a_min=0,\n",
    "        a_max=255\n",
    "    )\n",
    "    for k, v in predictions.items()\n",
    "}\n",
    "\n",
    "sorted_generated_images = [\n",
    "    x[0:2]\n",
    "    for x in sorted(\n",
    "        [\n",
    "            (\n",
    "                k,\n",
    "                generated_images[k],\n",
    "                generated_images[k].shape[-2]\n",
    "            )\n",
    "            for k in generated_images.keys()\n",
    "        ],\n",
    "        key=lambda tup: tup[2]\n",
    "    )\n",
    "]\n",
    "\n",
    "for k, v in sorted_generated_images:\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_4x4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_8x8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_16x16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_32x32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_images = 10\n",
    "\n",
    "for k, v in sorted_generated_images:\n",
    "    print(k)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(v[i], cmap=plt.cm.binary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1591422936\n"
     ]
    }
   ],
   "source": [
    "!ls trained_model/export/exporter | tail -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from trained_model/export/exporter/1591422936/variables/variables\n"
     ]
    }
   ],
   "source": [
    "predict_fn = tf.contrib.predictor.from_saved_model(\n",
    "    \"trained_model/export/exporter/1591422936\"\n",
    ")\n",
    "predictions = predict_fn(\n",
    "    {\n",
    "        \"Z\": np.random.normal(size=(500, 512))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_4x4 (500, 4, 4, 3)\n",
      "generated_images_8x8 (500, 8, 8, 3)\n",
      "generated_images_16x16 (500, 16, 16, 3)\n",
      "generated_images_32x32 (500, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "generated_images = {\n",
    "    k: np.clip(\n",
    "        a=((v + 1.0) * (255. / 2)).astype(np.int32),\n",
    "        a_min=0,\n",
    "        a_max=255\n",
    "    )\n",
    "    for k, v in predictions.items()\n",
    "}\n",
    "\n",
    "sorted_generated_images = [\n",
    "    x[0:2]\n",
    "    for x in sorted(\n",
    "        [\n",
    "            (\n",
    "                k,\n",
    "                generated_images[k],\n",
    "                generated_images[k].shape[-2]\n",
    "            )\n",
    "            for k in generated_images.keys()\n",
    "        ],\n",
    "        key=lambda tup: tup[2]\n",
    "    )\n",
    "]\n",
    "\n",
    "for k, v in sorted_generated_images:\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_4x4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_8x8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_16x16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images_32x32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_images = 10\n",
    "\n",
    "for k, v in sorted_generated_images:\n",
    "    print(k)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(v[i], cmap=plt.cm.binary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
