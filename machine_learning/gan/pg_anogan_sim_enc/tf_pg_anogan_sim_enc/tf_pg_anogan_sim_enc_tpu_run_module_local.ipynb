{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model module locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_num_filters = 512,512\n",
      "conv_kernel_sizes = 4,3\n",
      "conv_strides = 1,1\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "def convert_conv_layer_property_lists_to_string(property_list, prop_list_len):\n",
    "    \"\"\"Convert conv layer property list to string.\n",
    "\n",
    "    Args:\n",
    "        property_list: list, nested list of blocks of a conv layer property.\n",
    "        prop_list_len: int, length of list to process.\n",
    "\n",
    "    Returns:\n",
    "        Doubly delimited string of conv layer property values.\n",
    "    \"\"\"\n",
    "    return (\";\").join(\n",
    "        [\n",
    "            (\",\").join([str(val) for val in block])\n",
    "            for block in property_list[0:prop_list_len]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "\n",
    "# Import os environment variables for file hyperparameters.\n",
    "os.environ[\"TRAIN_FILE_PATTERN\"] = \"gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/data/cifar10_car/train*.tfrecord\"\n",
    "os.environ[\"EVAL_FILE_PATTERN\"] = \"gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/data/cifar10_car/test*.tfrecord\"\n",
    "os.environ[\"OUTPUT_DIR\"] = \"gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model\"\n",
    "\n",
    "# Import os environment variables for train hyperparameters.\n",
    "os.environ[\"TRAIN_BATCH_SIZE\"] = str(16)\n",
    "os.environ[\"TRAIN_STEPS\"] = str(3000)\n",
    "os.environ[\"USE_TPU\"] = \"False\"\n",
    "\n",
    "# Import os environment variables for eval hyperparameters.\n",
    "os.environ[\"EVAL_BATCH_SIZE\"] = str(8)\n",
    "os.environ[\"EVAL_STEPS\"] = str(10)\n",
    "os.environ[\"START_DELAY_SECS\"] = str(6000)\n",
    "os.environ[\"THROTTLE_SECS\"] = str(6000)\n",
    "os.environ[\"EVAL_ON_TPU\"] = \"False\"\n",
    "\n",
    "# Import os environment variables for serving hyperparameters.\n",
    "os.environ[\"EXPORTS_TO_KEEP\"] = str(20)\n",
    "os.environ[\"EXPORT_TO_TPU\"] = \"False\"\n",
    "os.environ[\"EXPORT_TO_CPU\"] = \"True\"\n",
    "os.environ[\"PREDICT_ALL_RESOLUTIONS\"] = \"True\"\n",
    "os.environ[\"ANOMALY_THRESHOLD\"] = str(5.0)\n",
    "os.environ[\"ANOM_CONVEX_COMBO_FACTOR\"] = str(0.05)\n",
    "\n",
    "# Import os environment variables for image hyperparameters.\n",
    "os.environ[\"HEIGHT\"] = str(32)\n",
    "os.environ[\"WIDTH\"] = str(32)\n",
    "os.environ[\"DEPTH\"] = str(3)\n",
    "\n",
    "# Import os environment variables for shared hyperparameters.\n",
    "os.environ[\"NUM_STEPS_UNTIL_GROWTH\"] = str(1000)\n",
    "\n",
    "# Full lists for full 1024x1024 network growth.\n",
    "full_conv_num_filters = [[512, 512], [512, 512], [512, 512], [512, 512], [256, 256], [128, 128], [64, 64], [32, 32], [16, 16]]\n",
    "full_conv_kernel_sizes = [[4, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]]\n",
    "full_conv_strides = [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]]\n",
    "\n",
    "# Set final image size as a multiple of 2, starting at 4.\n",
    "image_size = 4\n",
    "prop_list_len = max(\n",
    "    min(int(math.log(image_size, 2) - 1), len(full_conv_num_filters)), 1\n",
    ")\n",
    "\n",
    "# Get slices of lists.\n",
    "conv_num_filters = convert_conv_layer_property_lists_to_string(\n",
    "    full_conv_num_filters, prop_list_len\n",
    ")\n",
    "print(\"conv_num_filters = {}\".format(conv_num_filters))\n",
    "conv_kernel_sizes = convert_conv_layer_property_lists_to_string(\n",
    "    full_conv_kernel_sizes, prop_list_len\n",
    ")\n",
    "print(\"conv_kernel_sizes = {}\".format(conv_kernel_sizes))\n",
    "conv_strides = convert_conv_layer_property_lists_to_string(\n",
    "    full_conv_strides, prop_list_len\n",
    ")\n",
    "print(\"conv_strides = {}\".format(conv_strides))\n",
    "\n",
    "os.environ[\"CONV_NUM_FILTERS\"] = conv_num_filters\n",
    "os.environ[\"CONV_KERNEL_SIZES\"] = conv_kernel_sizes\n",
    "os.environ[\"CONV_STRIDES\"] = conv_strides\n",
    "\n",
    "# Import os environment variables for generator hyperparameters.\n",
    "os.environ[\"LATENT_SIZE\"] = str(512)\n",
    "os.environ[\"NORMALIZE_LATENT\"] = \"True\"\n",
    "os.environ[\"USE_PIXEL_NORM\"] = \"True\"\n",
    "os.environ[\"PIXEL_NORM_EPSILON\"] = str(1e-8)\n",
    "os.environ[\"GENERATOR_PROJECTION_DIMS\"] = \"4,4,512\"\n",
    "os.environ[\"GENERATOR_LEAKY_RELU_ALPHA\"] = str(0.2)\n",
    "os.environ[\"GENERATOR_TO_RGB_ACTIVATION\"] = \"None\"\n",
    "os.environ[\"GENERATOR_L1_REGULARIZATION_SCALE\"] = str(0.01)\n",
    "os.environ[\"GENERATOR_L2_REGULARIZATION_SCALE\"] = str(0.01)\n",
    "os.environ[\"GENERATOR_OPTIMIZER\"] = \"Adam\"\n",
    "os.environ[\"GENERATOR_LEARNING_RATE\"] = str(0.0001)\n",
    "os.environ[\"GENERATOR_ADAM_BETA1\"] = str(0.)\n",
    "os.environ[\"GENERATOR_ADAM_BETA2\"] = str(0.99)\n",
    "os.environ[\"GENERATOR_ADAM_EPSILON\"] = str(1e-8)\n",
    "os.environ[\"GENERATOR_CLIP_GRADIENTS\"] = str(5.0)\n",
    "os.environ[\"GENERATOR_TRAIN_STEPS\"] = str(1)\n",
    "\n",
    "# Import os environment variables for discriminator hyperparameters.\n",
    "os.environ[\"USE_MINIBATCH_STDDEV\"] = \"True\"\n",
    "os.environ[\"MINIBATCH_STDDEV_GROUP_SIZE\"] = str(4)\n",
    "os.environ[\"MINIBATCH_STDDEV_AVERAGING\"] = \"True\"\n",
    "os.environ[\"DISCRIMINATOR_LEAKY_RELU_ALPHA\"] = str(0.2)\n",
    "os.environ[\"DISCRIMINATOR_L1_REGULARIZATION_SCALE\"] = str(0.01)\n",
    "os.environ[\"DISCRIMINATOR_L2_REGULARIZATION_SCALE\"] = str(0.01)\n",
    "os.environ[\"DISCRIMINATOR_OPTIMIZER\"] = \"Adam\"\n",
    "os.environ[\"DISCRIMINATOR_LEARNING_RATE\"] = str(0.0001)\n",
    "os.environ[\"DISCRIMINATOR_ADAM_BETA1\"] = str(0.)\n",
    "os.environ[\"DISCRIMINATOR_ADAM_BETA2\"] = str(0.99)\n",
    "os.environ[\"DISCRIMINATOR_ADAM_EPSILON\"] = str(1e-8)\n",
    "os.environ[\"DISCRIMINATOR_CLIP_GRADIENTS\"] = str(5.0)\n",
    "os.environ[\"DISCRIMINATOR_GRADIENT_PENALTY_COEFFICIENT\"] = str(10.0)\n",
    "os.environ[\"EPSILON_DRIFT\"] = str(0.001)\n",
    "os.environ[\"DISCRIMINATOR_TRAIN_STEPS\"] = str(1)\n",
    "\n",
    "# Import os environment variables for encoder hyperparameters.\n",
    "os.environ[\"ENCODER_LEAKY_RELU_ALPHA\"] = str(0.2)\n",
    "os.environ[\"ENCODER_L1_REGULARIZATION_SCALE\"] = str(0.01)\n",
    "os.environ[\"ENCODER_L2_REGULARIZATION_SCALE\"] = str(0.01)\n",
    "os.environ[\"ENCODER_OPTIMIZER\"] = \"Adam\"\n",
    "os.environ[\"ENCODER_LEARNING_RATE\"] = str(0.0001)\n",
    "os.environ[\"ENCODER_ADAM_BETA1\"] = str(0.)\n",
    "os.environ[\"ENCODER_ADAM_BETA2\"] = str(0.99)\n",
    "os.environ[\"ENCODER_ADAM_EPSILON\"] = str(1e-8)\n",
    "os.environ[\"ENCODER_CLIP_GRADIENTS\"] = str(5.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train pg_AnoGAN_Sim_Enc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_and_evaluate: args = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/', 'train_batch_size': 16, 'train_steps': 3000, 'prev_train_steps': 0, 'use_tpu': False, 'eval_batch_size': 8, 'eval_steps': 10, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'eval_on_tpu': False, 'exports_to_keep': 20, 'export_to_tpu': False, 'export_to_cpu': True, 'predict_all_resolutions': True, 'anomaly_threshold': 5.0, 'anom_convex_combo_factor': 0.05, 'height': 32, 'width': 32, 'depth': 3, 'num_steps_until_growth': 1000, 'conv_num_filters': [[512, 512]], 'conv_kernel_sizes': [[4, 3]], 'conv_strides': [[1, 1]], 'latent_size': 512, 'use_pixel_norm': True, 'pixel_norm_epsilon': 1e-08, 'normalize_latent': True, 'generator_projection_dims': [4, 4, 512], 'generator_leaky_relu_alpha': 0.2, 'generator_to_rgb_activation': 'tanh', 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.99, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': 5.0, 'generator_train_steps': 1, 'use_minibatch_stddev': True, 'minibatch_stddev_group_size': 4, 'minibatch_stddev_averaging': 'True', 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.01, 'discriminator_l2_regularization_scale': 0.01, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0001, 'discriminator_adam_beta1': 0.0, 'discriminator_adam_beta2': 0.99, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': 5.0, 'discriminator_gradient_penalty_coefficient': 10.0, 'epsilon_drift': 0.001, 'discriminator_train_steps': 1, 'encoder_leaky_relu_alpha': 0.2, 'encoder_l1_regularization_scale': 0.01, 'encoder_l2_regularization_scale': 0.01, 'encoder_optimizer': 'Adam', 'encoder_learning_rate': 0.0001, 'encoder_adam_beta1': 0.0, 'encoder_adam_beta2': 0.99, 'encoder_adam_epsilon': 1e-08, 'encoder_clip_gradients': 5.0, 'generator_base_conv_blocks': [[[4, 4, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]]], 'generator_growth_conv_blocks': [], 'generator_to_rgb_layers': [[[1, 1, 512, 3, 1, 1]]], 'discriminator_from_rgb_layers': [[[1, 1, 3, 512, 1, 1]]], 'discriminator_base_conv_blocks': [[[3, 3, 512, 512, 1, 1], [4, 4, 512, 512, 1, 1]]], 'discriminator_growth_conv_blocks': [], 'encoder_from_rgb_layers': [[[1, 1, 3, 512, 1, 1]]], 'encoder_base_conv_blocks': [[[3, 3, 512, 512, 1, 1], [4, 4, 512, 512, 1, 1]]], 'encoder_growth_conv_blocks': []}\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "\n",
      "pg_anogan_sim_enc_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(16, 32, 32, 3) dtype=float32>}\n",
      "pg_anogan_sim_enc_model: labels = Tensor(\"IteratorGetNext:1\", shape=(16,), dtype=int32, device=/device:CPU:0)\n",
      "pg_anogan_sim_enc_model: mode = train\n",
      "pg_anogan_sim_enc_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/', 'train_batch_size': 16, 'train_steps': 3000, 'prev_train_steps': 0, 'use_tpu': False, 'eval_batch_size': 8, 'eval_steps': 10, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'eval_on_tpu': False, 'exports_to_keep': 20, 'export_to_tpu': False, 'export_to_cpu': True, 'predict_all_resolutions': True, 'anomaly_threshold': 5.0, 'anom_convex_combo_factor': 0.05, 'height': 32, 'width': 32, 'depth': 3, 'num_steps_until_growth': 1000, 'conv_num_filters': [[512, 512]], 'conv_kernel_sizes': [[4, 3]], 'conv_strides': [[1, 1]], 'latent_size': 512, 'use_pixel_norm': True, 'pixel_norm_epsilon': 1e-08, 'normalize_latent': True, 'generator_projection_dims': [4, 4, 512], 'generator_leaky_relu_alpha': 0.2, 'generator_to_rgb_activation': 'tanh', 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.99, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': 5.0, 'generator_train_steps': 1, 'use_minibatch_stddev': True, 'minibatch_stddev_group_size': 4, 'minibatch_stddev_averaging': 'True', 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.01, 'discriminator_l2_regularization_scale': 0.01, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0001, 'discriminator_adam_beta1': 0.0, 'discriminator_adam_beta2': 0.99, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': 5.0, 'discriminator_gradient_penalty_coefficient': 10.0, 'epsilon_drift': 0.001, 'discriminator_train_steps': 1, 'encoder_leaky_relu_alpha': 0.2, 'encoder_l1_regularization_scale': 0.01, 'encoder_l2_regularization_scale': 0.01, 'encoder_optimizer': 'Adam', 'encoder_learning_rate': 0.0001, 'encoder_adam_beta1': 0.0, 'encoder_adam_beta2': 0.99, 'encoder_adam_epsilon': 1e-08, 'encoder_clip_gradients': 5.0, 'generator_base_conv_blocks': [[[4, 4, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]]], 'generator_growth_conv_blocks': [], 'generator_to_rgb_layers': [[[1, 1, 512, 3, 1, 1]]], 'discriminator_from_rgb_layers': [[[1, 1, 3, 512, 1, 1]]], 'discriminator_base_conv_blocks': [[[3, 3, 512, 512, 1, 1], [4, 4, 512, 512, 1, 1]]], 'discriminator_growth_conv_blocks': [], 'encoder_from_rgb_layers': [[[1, 1, 3, 512, 1, 1]]], 'encoder_base_conv_blocks': [[[3, 3, 512, 512, 1, 1], [4, 4, 512, 512, 1, 1]]], 'encoder_growth_conv_blocks': [], 'batch_size': 16}\n",
      "\n",
      "instantiate_generator_projection_layer: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3d6e8ccd0>\n",
      "\n",
      "instantiate_generator_layers: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3d6e8ccd0>\n",
      "\n",
      "instantiate_generator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d6e8cc10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d6e8c2d0>]\n",
      "instantiate_generator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d6e8cc10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d6e8c2d0>]]\n",
      "\n",
      "instantiate_generator_to_rgb_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d6ec0250>]\n",
      "instantiate_generator_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d6ec0250>]\n",
      "\n",
      "build_generator_projection_layer: projection_tensor = Tensor(\"generator_3/generator_projection_layer/BiasAdd:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_layers: projection_tensor = Tensor(\"generator_3/generator_projection_layer/BiasAdd:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "build_generator_layers: conv_block_tensors = [[<tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>]]\n",
      "build_generator_layers: conv_block_tensors = [<tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_to_rgb_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "build_generator_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "\n",
      "instantiate_discriminator_from_rgb_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d6efee10>]\n",
      "\n",
      "instantiate_discriminator_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d6efee10>]\n",
      "\n",
      "instantiate_discriminator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d6e8c350>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d6e7fdd0>]\n",
      "instantiate_discriminator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d6e8c350>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d6e7fdd0>]]\n",
      "\n",
      "instantiate_discriminator_growth_transition_downsample_layers: downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa3d6e06550>]\n",
      "instantiate_discriminator_layers: transition_downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa3d6e06550>]\n",
      "instantiate_img_to_vec_logits_layer: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa3d6e060d0>\n",
      "instantiate_img_to_vec_logits_layer: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3d6e06750>\n",
      "instantiate_discriminator_layers: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa3d6e060d0>\n",
      "instantiate_discriminator_layers: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3d6e06750>\n",
      "\n",
      "build_discriminator_from_rgb_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "build_discriminator_layers: conv_block_tensors = [<tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_6/discriminator_flatten_layer/Reshape:0\", shape=(1, 512), dtype=float32)\n",
      "build_discriminator_logits_layer: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "build_discriminator_layers: logits_tensor = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "\n",
      "instantiate_encoder_from_rgb_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d6170f10>]\n",
      "\n",
      "instantiate_encoder_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d6170f10>]\n",
      "\n",
      "instantiate_encoder_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d6f300d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d6f11850>]\n",
      "instantiate_encoder_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d6f300d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d6f11850>]]\n",
      "\n",
      "instantiate_encoder_growth_transition_downsample_layers: downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa3d6eb06d0>]\n",
      "instantiate_encoder_layers: transition_downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa3d6eb06d0>]\n",
      "instantiate_img_to_vec_logits_layer: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa3d6ed3650>\n",
      "instantiate_img_to_vec_logits_layer: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3d6ed3e10>\n",
      "instantiate_encoder_layers: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa3d6ed3650>\n",
      "instantiate_encoder_layers: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3d6ed3e10>\n",
      "\n",
      "build_encoder_from_rgb_layers: from_rgb_conv_tensors = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_encoder_layers: from_rgb_conv_tensors = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_img_to_vec_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "build_encoder_layers: conv_block_tensors = [<tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_encoder_logits_layer: block_conv_flat = Tensor(\"encoder_6/encoder_flatten_layer/Reshape:0\", shape=(1, 512), dtype=float32)\n",
      "build_encoder_logits_layer: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd:0\", shape=(1, 512), dtype=float32)\n",
      "build_encoder_layers: logits_tensor = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd:0\", shape=(1, 512), dtype=float32)\n",
      "pg_anogan_sim_enc_model: alpha_var = <tf.Variable 'alpha_var:0' shape=() dtype=float32_ref>\n",
      "\n",
      "get_logits_and_losses: X = Tensor(\"IteratorGetNext:0\", shape=(16, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(16, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(16, 512), dtype=float32).\n",
      "\n",
      "get_train_eval_generator_outputs: Z = Tensor(\"random_normal:0\", shape=(16, 512), dtype=float32)\n",
      "\n",
      "get_train_eval_generator_outputs: NOT GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "create_base_generator_network: Z = Tensor(\"random_normal:0\", shape=(16, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_3/generator_projection_layer/BiasAdd_1:0\", shape=(16, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator_6/generator_projection_reshaped:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_leaky = Tensor(\"generator_6/generator_projection_tensor_reshaped_leaky_relu:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "use_generator_projection_layer: pixel_norm_output = Tensor(\"generator_6/generator/pixel_norm/mul:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: projection = Tensor(\"generator_6/generator/pixel_norm/mul:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "\n",
      "fused_conv2d_pixel_norm: conv_output = Tensor(\"generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd_1:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: conv_output_leaky = Tensor(\"generator_6/generator_fused_conv2d_pixel_norm_leaky_relu:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: pixel_norm_output = Tensor(\"generator_6/generator/pixel_norm_1/mul:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_0 = Tensor(\"generator_6/generator/pixel_norm_1/mul:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "\n",
      "fused_conv2d_pixel_norm: conv_output = Tensor(\"generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd_1:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: conv_output_leaky = Tensor(\"generator_6/generator_fused_conv2d_pixel_norm_leaky_relu_1:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: pixel_norm_output = Tensor(\"generator_6/generator/pixel_norm_2/mul:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_1 = Tensor(\"generator_6/generator/pixel_norm_2/mul:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: to_rgb_conv = Tensor(\"generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_1:0\", shape=(16, 4, 4, 3), dtype=float32)\n",
      "\n",
      "get_train_eval_generator_outputs: generated_outputs = Tensor(\"generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_1:0\", shape=(16, 4, 4, 3), dtype=float32)\n",
      "\n",
      "Call discriminator with generator_outputs = Tensor(\"generator_generated_outputs_identity:0\", shape=(16, 4, 4, 3), dtype=float32).\n",
      "\n",
      "get_train_eval_discriminator_logits: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(16, 4, 4, 3), dtype=float32)\n",
      "\n",
      " get_train_eval_discriminator_logits: NOT GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(16, 4, 4, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_1:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv_leaky = Tensor(\"discriminator_7/discriminator_from_rgb_conv_2d_leaky_relu:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "\n",
      "minibatch_stddev: static_image_shape = [4, 4, 512]\n",
      "minibatch_stddev: dynamic_image_shape = Tensor(\"discriminator_7/discriminator/minibatch_stddev/dynamic_image_shape:0\", shape=(4,), dtype=int32)\n",
      "\n",
      "grouped_minibatch_stddev: group_size = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/group_size:0\", shape=(), dtype=int32)\n",
      "grouped_minibatch_stddev: grouped_image = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_image:0\", shape=(4, 4, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: grouped_mean = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_mean:0\", shape=(1, 4, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: centered_grouped_image = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/centered_grouped_image:0\", shape=(4, 4, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: grouped_variance = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_variance:0\", shape=(4, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev:0\", shape=(4, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev_average = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_average:0\", shape=(4, 1, 1, 1), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev_feature_map = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_feature_map:0\", shape=(16, 4, 4, 1), dtype=float32)\n",
      "grouped_minibatch_stddev: stddev_feature_map = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_feature_map:0\", shape=(16, 4, 4, 1), dtype=float32)\n",
      "\n",
      "ungrouped_minibatch_stddev: mean = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/mean:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "ungrouped_minibatch_stddev: centered_image = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/centered_image:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "ungrouped_minibatch_stddev: variance = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/variance:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev_average = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_average:0\", shape=(1, 1, 1, 1), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev_feature_map = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_feature_map:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "ungrouped_minibatch_stddev: stddev_feature_map = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_feature_map:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "minibatch_stddev: stddev_feature_map = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/Merge:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "minibatch_stddev: appended_image = Tensor(\"discriminator_7/discriminator/minibatch_stddev/appended_image:0\", shape=(16, 4, 4, 513), dtype=float32)\n",
      "\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_7/discriminator/minibatch_stddev/appended_image:0\", shape=(16, 4, 4, 513), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/BiasAdd_1:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv_leaky = Tensor(\"discriminator_7/discriminator/discriminator_base_layers_conv2d_0_leaky_relu:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/BiasAdd_1:0\", shape=(16, 1, 1, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv_leaky = Tensor(\"discriminator_7/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(16, 1, 1, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_7/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(16, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_7/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(16, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_6/discriminator_flatten_layer/Reshape_1:0\", shape=(16, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_1:0\", shape=(16, 1), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_1:0\", shape=(16, 1), dtype=float32)\n",
      "\n",
      "get_train_eval_discriminator_logits: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_1:0\", shape=(16, 1), dtype=float32)\n",
      "\n",
      "resize_real_images: image = Tensor(\"IteratorGetNext:0\", shape=(16, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "\n",
      ": NEVER GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "resize_real_image: block_idx = 0\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(16, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_image: resized_image = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(16, 4, 4, 3), dtype=float32)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(16, 4, 4, 3), dtype=float32)\n",
      "\n",
      "Call discriminator with real_images = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(16, 4, 4, 3), dtype=float32).\n",
      "\n",
      "get_train_eval_discriminator_logits: X = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(16, 4, 4, 3), dtype=float32)\n",
      "\n",
      " get_train_eval_discriminator_logits: NOT GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(16, 4, 4, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_2:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv_leaky = Tensor(\"discriminator_8/discriminator_from_rgb_conv_2d_leaky_relu:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "\n",
      "minibatch_stddev: static_image_shape = [4, 4, 512]\n",
      "minibatch_stddev: dynamic_image_shape = Tensor(\"discriminator_8/discriminator/minibatch_stddev/dynamic_image_shape:0\", shape=(4,), dtype=int32)\n",
      "\n",
      "grouped_minibatch_stddev: group_size = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/group_size:0\", shape=(), dtype=int32)\n",
      "grouped_minibatch_stddev: grouped_image = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_image:0\", shape=(4, 4, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: grouped_mean = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_mean:0\", shape=(1, 4, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: centered_grouped_image = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/centered_grouped_image:0\", shape=(4, 4, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: grouped_variance = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_variance:0\", shape=(4, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev:0\", shape=(4, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev_average = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_average:0\", shape=(4, 1, 1, 1), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev_feature_map = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_feature_map:0\", shape=(16, 4, 4, 1), dtype=float32)\n",
      "grouped_minibatch_stddev: stddev_feature_map = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_feature_map:0\", shape=(16, 4, 4, 1), dtype=float32)\n",
      "\n",
      "ungrouped_minibatch_stddev: mean = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/mean:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "ungrouped_minibatch_stddev: centered_image = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/centered_image:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "ungrouped_minibatch_stddev: variance = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/variance:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev_average = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_average:0\", shape=(1, 1, 1, 1), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev_feature_map = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_feature_map:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "ungrouped_minibatch_stddev: stddev_feature_map = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_feature_map:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "minibatch_stddev: stddev_feature_map = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/Merge:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "minibatch_stddev: appended_image = Tensor(\"discriminator_8/discriminator/minibatch_stddev/appended_image:0\", shape=(16, 4, 4, 513), dtype=float32)\n",
      "\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_8/discriminator/minibatch_stddev/appended_image:0\", shape=(16, 4, 4, 513), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/BiasAdd_2:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv_leaky = Tensor(\"discriminator_8/discriminator/discriminator_base_layers_conv2d_0_leaky_relu:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/BiasAdd_2:0\", shape=(16, 1, 1, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv_leaky = Tensor(\"discriminator_8/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(16, 1, 1, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_8/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(16, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_8/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(16, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_6/discriminator_flatten_layer/Reshape_2:0\", shape=(16, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_2:0\", shape=(16, 1), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_2:0\", shape=(16, 1), dtype=float32)\n",
      "\n",
      "get_train_eval_discriminator_logits: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_2:0\", shape=(16, 1), dtype=float32)\n",
      "\n",
      "Call encoder with generator_outputs = Tensor(\"generator_generated_outputs_identity:0\", shape=(16, 4, 4, 3), dtype=float32).\n",
      "\n",
      "get_train_eval_encoder_logits: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(16, 4, 4, 3), dtype=float32)\n",
      "\n",
      " get_train_eval_encoder_logits: NOT GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "create_base_img_to_vec_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(16, 4, 4, 3), dtype=float32)\n",
      "create_base_img_to_vec_network: from_rgb_conv = Tensor(\"encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_1:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "\n",
      "create_base_encoder_block_and_logits: block_conv = Tensor(\"encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_1:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv = Tensor(\"encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/BiasAdd_1:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv_leaky = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_0_leaky_relu:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv = Tensor(\"encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/BiasAdd_1:0\", shape=(16, 1, 1, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv_leaky = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_1_leaky_relu:0\", shape=(16, 1, 1, 512), dtype=float32)\n",
      "\n",
      "use_encoder_logits_layer: block_conv = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_1_leaky_relu:0\", shape=(16, 1, 1, 512), dtype=float32)\n",
      "use_encoder_logits_layer: block_conv = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_1_leaky_relu:0\", shape=(16, 1, 1, 512), dtype=float32)\n",
      "use_encoder_logits_layer: block_conv_flat = Tensor(\"encoder_6/encoder_flatten_layer/Reshape_1:0\", shape=(16, 512), dtype=float32)\n",
      "use_encoder_logits_layer: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(16, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(16, 512), dtype=float32)\n",
      "\n",
      "get_train_eval_encoder_logits: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(16, 512), dtype=float32)\n",
      "\n",
      "Call generator with encoder_logits = Tensor(\"encoder_logits_identity:0\", shape=(16, 512), dtype=float32).\n",
      "\n",
      "get_train_eval_generator_outputs: Z = Tensor(\"encoder_logits_identity:0\", shape=(16, 512), dtype=float32)\n",
      "\n",
      "get_train_eval_generator_outputs: NOT GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "create_base_generator_network: Z = Tensor(\"encoder_logits_identity:0\", shape=(16, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_3/generator_projection_layer/BiasAdd_2:0\", shape=(16, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator_7/generator_projection_reshaped:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_leaky = Tensor(\"generator_7/generator_projection_tensor_reshaped_leaky_relu:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "use_generator_projection_layer: pixel_norm_output = Tensor(\"generator_7/generator/pixel_norm/mul:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: projection = Tensor(\"generator_7/generator/pixel_norm/mul:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "\n",
      "fused_conv2d_pixel_norm: conv_output = Tensor(\"generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd_2:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: conv_output_leaky = Tensor(\"generator_7/generator_fused_conv2d_pixel_norm_leaky_relu:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: pixel_norm_output = Tensor(\"generator_7/generator/pixel_norm_1/mul:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_0 = Tensor(\"generator_7/generator/pixel_norm_1/mul:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "\n",
      "fused_conv2d_pixel_norm: conv_output = Tensor(\"generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd_2:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: conv_output_leaky = Tensor(\"generator_7/generator_fused_conv2d_pixel_norm_leaky_relu_1:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: pixel_norm_output = Tensor(\"generator_7/generator/pixel_norm_2/mul:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_1 = Tensor(\"generator_7/generator/pixel_norm_2/mul:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: to_rgb_conv = Tensor(\"generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_2:0\", shape=(16, 4, 4, 3), dtype=float32)\n",
      "\n",
      "get_train_eval_generator_outputs: generated_outputs = Tensor(\"generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_2:0\", shape=(16, 4, 4, 3), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = generator\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'generator_3/generator_projection_layer/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_generator: generator_3/generator_projection_layer/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d7efad90>\n",
      "get_regularization_loss_generator: generator_4/generator_base_layers_conv2d_0_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d7efad90>\n",
      "get_regularization_loss_generator: generator_4/generator_base_layers_conv2d_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d7efad90>\n",
      "get_regularization_loss_generator: generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d7efad90>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'generator_3/generator_projection_layer/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"generator_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'generator_3/generator_projection_layer/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'generator_3/generator_projection_layer/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"generator_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"generator_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_generated_loss = Tensor(\"discriminator_generated_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"discriminator/gradient_penalty/random_uniform_num:0\", shape=(16, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"discriminator/gradient_penalty/sub:0\", shape=(16, 4, 4, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(16, 4, 4, 3), dtype=float32)\n",
      "\n",
      "get_train_eval_discriminator_logits: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(16, 4, 4, 3), dtype=float32)\n",
      "\n",
      " get_train_eval_discriminator_logits: NOT GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(16, 4, 4, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_3:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv_leaky = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator_from_rgb_conv_2d_leaky_relu:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "\n",
      "minibatch_stddev: static_image_shape = [4, 4, 512]\n",
      "minibatch_stddev: dynamic_image_shape = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/dynamic_image_shape:0\", shape=(4,), dtype=int32)\n",
      "\n",
      "grouped_minibatch_stddev: group_size = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/group_size:0\", shape=(), dtype=int32)\n",
      "grouped_minibatch_stddev: grouped_image = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_image:0\", shape=(4, 4, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: grouped_mean = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_mean:0\", shape=(1, 4, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: centered_grouped_image = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/centered_grouped_image:0\", shape=(4, 4, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: grouped_variance = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_variance:0\", shape=(4, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev:0\", shape=(4, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev_average = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_average:0\", shape=(4, 1, 1, 1), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev_feature_map = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_feature_map:0\", shape=(16, 4, 4, 1), dtype=float32)\n",
      "grouped_minibatch_stddev: stddev_feature_map = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_feature_map:0\", shape=(16, 4, 4, 1), dtype=float32)\n",
      "\n",
      "ungrouped_minibatch_stddev: mean = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/mean:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "ungrouped_minibatch_stddev: centered_image = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/centered_image:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "ungrouped_minibatch_stddev: variance = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/variance:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev_average = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_average:0\", shape=(1, 1, 1, 1), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev_feature_map = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_feature_map:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "ungrouped_minibatch_stddev: stddev_feature_map = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_feature_map:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "minibatch_stddev: stddev_feature_map = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/Merge:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "minibatch_stddev: appended_image = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/appended_image:0\", shape=(16, 4, 4, 513), dtype=float32)\n",
      "\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/appended_image:0\", shape=(16, 4, 4, 513), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/BiasAdd_3:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv_leaky = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/discriminator_base_layers_conv2d_0_leaky_relu:0\", shape=(16, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/BiasAdd_3:0\", shape=(16, 1, 1, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv_leaky = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(16, 1, 1, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(16, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(16, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_6/discriminator_flatten_layer/Reshape_3:0\", shape=(16, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_3:0\", shape=(16, 1), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_3:0\", shape=(16, 1), dtype=float32)\n",
      "\n",
      "get_train_eval_discriminator_logits: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_3:0\", shape=(16, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"discriminator/gradient_penalty/discriminator_logits_identity:0\", shape=(16, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"discriminator/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"discriminator/gradient_penalty/gradients/discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/Conv2D_3_grad/Conv2DBackpropInput:0\", shape=(16, 4, 4, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"discriminator/gradient_penalty/Sqrt:0\", shape=(16,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"discriminator/gradient_penalty/squared_difference:0\", shape=(16,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"discriminator/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_gradient_penalty = Tensor(\"discriminator/gradient_penalty/gradient_penalty_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: epsilon_drift_penalty = Tensor(\"epsilon_drift_penalty:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_wasserstein_gp_loss = Tensor(\"discriminator_wasserstein_gp_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = discriminator\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_6/discriminator_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_discriminator: discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d7efad90>\n",
      "get_regularization_loss_discriminator: discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d7efad90>\n",
      "get_regularization_loss_discriminator: discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d7efad90>\n",
      "get_regularization_loss_discriminator: discriminator_6/discriminator_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d7efad90>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_6/discriminator_layers_dense_logits/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"discriminator_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_6/discriminator_layers_dense_logits/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_6/discriminator_layers_dense_logits/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"discriminator_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"discriminator_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "get_encoder_loss: generator_encoder_image_diff = Tensor(\"generator_encoder_image_diff:0\", shape=(16, 4, 4, 3), dtype=float32)\n",
      "get_encoder_loss: image_diff_l1_norm = Tensor(\"Sum:0\", shape=(16,), dtype=float32)\n",
      "get_encoder_loss: encoder_loss = Tensor(\"encoder_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = encoder\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'encoder_6/encoder_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_encoder: encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d7efad90>\n",
      "get_regularization_loss_encoder: encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d7efad90>\n",
      "get_regularization_loss_encoder: encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d7efad90>\n",
      "get_regularization_loss_encoder: encoder_6/encoder_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d7efad90>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'encoder_6/encoder_layers_dense_logits/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"encoder_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'encoder_6/encoder_layers_dense_logits/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'encoder_6/encoder_layers_dense_logits/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"encoder_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_encoder_loss: encoder_reg_loss = Tensor(\"encoder_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_encoder_loss: encoder_total_loss = Tensor(\"encoder_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "train_network: loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "train_network: global_step = <tf.Variable 'global_step:0' shape=() dtype=int64>\n",
      "train_network: alpha_var = <tf.Variable 'alpha_var:0' shape=() dtype=float32_ref>\n",
      "train_network: scope = discriminator\n",
      "train_network_discriminator: optimizer = <tensorflow.python.training.adam.AdamOptimizer object at 0x7fa3d5efbad0>\n",
      "\n",
      "train_network_discriminator: variables = [<tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel:0' shape=(1, 1, 3, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_base_layers_conv2d_0_3x3_512_512/kernel:0' shape=(3, 3, 513, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_base_layers_conv2d_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_base_layers_conv2d_1_4x4_512_512/kernel:0' shape=(4, 4, 512, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_base_layers_conv2d_1_4x4_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_layers_dense_logits/kernel:0' shape=(512, 1) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_layers_dense_logits/bias:0' shape=(1,) dtype=float32_ref>]\n",
      "\n",
      "train_network_discriminator: gradients = [<tf.Tensor 'get_loss_and_train_op_cond/discriminator_gradients/AddN_30:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/discriminator_gradients/AddN_29:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/discriminator_gradients/AddN_20:0' shape=(3, 3, 513, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/discriminator_gradients/AddN_19:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/discriminator_gradients/AddN_17:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/discriminator_gradients/AddN_15:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/discriminator_gradients/AddN_16:0' shape=(512, 1) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/discriminator_gradients/AddN_5:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "train_network_discriminator: gradients = [<tf.Tensor 'get_loss_and_train_op_cond/train_network_discriminator/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_gradients:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_discriminator/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/bias_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_discriminator/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_gradients:0' shape=(3, 3, 513, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_discriminator/discriminator_base_layers_conv2d_0_3x3_512_512/bias_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_discriminator/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_gradients:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_discriminator/discriminator_base_layers_conv2d_1_4x4_512_512/bias_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_discriminator/discriminator_layers_dense_logits/kernel_gradients:0' shape=(512, 1) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_discriminator/discriminator_layers_dense_logits/bias_gradients:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "train_network_discriminator: gradients = [<tf.Tensor 'get_loss_and_train_op_cond/discriminator_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/discriminator_clip_by_global_norm_gradients_1/_0:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/discriminator_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/discriminator_clip_by_global_norm_gradients_1/_1:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/discriminator_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/discriminator_clip_by_global_norm_gradients_1/_2:0' shape=(3, 3, 513, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/discriminator_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/discriminator_clip_by_global_norm_gradients_1/_3:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/discriminator_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/discriminator_clip_by_global_norm_gradients_1/_4:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/discriminator_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/discriminator_clip_by_global_norm_gradients_1/_5:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/discriminator_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/discriminator_clip_by_global_norm_gradients_1/_6:0' shape=(512, 1) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/discriminator_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/discriminator_clip_by_global_norm_gradients_1/_7:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "train_network_discriminator: gradients = [<tf.Tensor 'get_loss_and_train_op_cond/train_network_discriminator/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_clip_gradients:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_discriminator/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/bias_clip_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_discriminator/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_clip_gradients:0' shape=(3, 3, 513, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_discriminator/discriminator_base_layers_conv2d_0_3x3_512_512/bias_clip_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_discriminator/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_clip_gradients:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_discriminator/discriminator_base_layers_conv2d_1_4x4_512_512/bias_clip_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_discriminator/discriminator_layers_dense_logits/kernel_clip_gradients:0' shape=(512, 1) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_discriminator/discriminator_layers_dense_logits/bias_clip_gradients:0' shape=(1,) dtype=float32>]\n",
      "train_network_discriminator: grads_and_vars = <zip object at 0x7fa3d5d9bcd0>\n",
      "instantiate_optimizer_slots_discriminator: zero_gradients = [<tf.Tensor 'get_loss_and_train_op_cond/cond/instantiate_optimizer_slots_discriminator_discriminator/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_zeros_like:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond/instantiate_optimizer_slots_discriminator_discriminator/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/bias_zeros_like:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond/instantiate_optimizer_slots_discriminator_discriminator/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_zeros_like:0' shape=(3, 3, 513, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond/instantiate_optimizer_slots_discriminator_discriminator/discriminator_base_layers_conv2d_0_3x3_512_512/bias_zeros_like:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond/instantiate_optimizer_slots_discriminator_discriminator/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_zeros_like:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond/instantiate_optimizer_slots_discriminator_discriminator/discriminator_base_layers_conv2d_1_4x4_512_512/bias_zeros_like:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond/instantiate_optimizer_slots_discriminator_discriminator/discriminator_layers_dense_logits/kernel_zeros_like:0' shape=(512, 1) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond/instantiate_optimizer_slots_discriminator_discriminator/discriminator_layers_dense_logits/bias_zeros_like:0' shape=(1,) dtype=float32>]\n",
      "instantiate_optimizer_slots_discriminator: grads_and_vars = <zip object at 0x7fa3d5b42640>\n",
      "instantiate_optimizer_slots_discriminator: instantiate_optimizer_op = name: \"get_loss_and_train_op_cond/cond/instantiate_optimizer_slots_discriminator_apply_gradients\"\n",
      "op: \"NoOp\"\n",
      "input: \"^get_loss_and_train_op_cond/cond/instantiate_optimizer_slots_discriminator_apply_gradients/update_discriminator/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond/instantiate_optimizer_slots_discriminator_apply_gradients/update_discriminator/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/bias/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond/instantiate_optimizer_slots_discriminator_apply_gradients/update_discriminator/discriminator_base_layers_conv2d_0_3x3_512_512/kernel/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond/instantiate_optimizer_slots_discriminator_apply_gradients/update_discriminator/discriminator_base_layers_conv2d_0_3x3_512_512/bias/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond/instantiate_optimizer_slots_discriminator_apply_gradients/update_discriminator/discriminator_base_layers_conv2d_1_4x4_512_512/kernel/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond/instantiate_optimizer_slots_discriminator_apply_gradients/update_discriminator/discriminator_base_layers_conv2d_1_4x4_512_512/bias/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond/instantiate_optimizer_slots_discriminator_apply_gradients/update_discriminator/discriminator_layers_dense_logits/kernel/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond/instantiate_optimizer_slots_discriminator_apply_gradients/update_discriminator/discriminator_layers_dense_logits/bias/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond/instantiate_optimizer_slots_discriminator_apply_gradients/Assign\"\n",
      "input: \"^get_loss_and_train_op_cond/cond/instantiate_optimizer_slots_discriminator_apply_gradients/Assign_1\"\n",
      "\n",
      "instantiate_optimizer_slots_discriminator: add_to_collection_ops = []\n",
      "train_network_discriminator: train_op = name: \"get_loss_and_train_op_cond/discriminator_apply_gradients\"\n",
      "op: \"AssignAddVariableOp\"\n",
      "input: \"get_loss_and_train_op_cond/instantiate_optimizer_op_pred/ReadVariableOp/Switch:1\"\n",
      "input: \"get_loss_and_train_op_cond/discriminator_apply_gradients/Const\"\n",
      "attr {\n",
      "  key: \"_class\"\n",
      "  value {\n",
      "    list {\n",
      "      s: \"loc:@global_step\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_INT64\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "train_network: loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "train_network: global_step = <tf.Variable 'global_step:0' shape=() dtype=int64>\n",
      "train_network: alpha_var = <tf.Variable 'alpha_var:0' shape=() dtype=float32_ref>\n",
      "train_network: scope = generator\n",
      "train_network_generator: optimizer = <tensorflow.python.training.adam.AdamOptimizer object at 0x7fa3d5ba9650>\n",
      "\n",
      "train_network_generator: variables = [<tf.Variable 'generator/generator_projection_layer/kernel:0' shape=(512, 8192) dtype=float32_ref>, <tf.Variable 'generator/generator_projection_layer/bias:0' shape=(8192,) dtype=float32_ref>, <tf.Variable 'generator/generator_base_layers_conv2d_0_4x4_512_512/kernel:0' shape=(4, 4, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_base_layers_conv2d_0_4x4_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_base_layers_conv2d_1_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'generator/generator_base_layers_conv2d_1_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel:0' shape=(1, 1, 512, 3) dtype=float32_ref>, <tf.Variable 'generator/generator_to_rgb_layers_conv2d_0_1x1_512_3/bias:0' shape=(3,) dtype=float32_ref>]\n",
      "\n",
      "train_network_generator: gradients = [<tf.Tensor 'get_loss_and_train_op_cond/generator_gradients/AddN_13:0' shape=(512, 8192) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/generator_gradients/generator_3/generator_projection_layer/BiasAdd_1_grad/BiasAddGrad:0' shape=(8192,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/generator_gradients/AddN_11:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/generator_gradients/generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd_1_grad/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/generator_gradients/AddN_9:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/generator_gradients/generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd_1_grad/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/generator_gradients/AddN_7:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/generator_gradients/generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_1_grad/BiasAddGrad:0' shape=(3,) dtype=float32>]\n",
      "\n",
      "train_network_generator: gradients = [<tf.Tensor 'get_loss_and_train_op_cond/train_network_generator/generator_projection_layer/kernel_gradients:0' shape=(512, 8192) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_generator/generator_projection_layer/bias_gradients:0' shape=(8192,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_generator/generator_base_layers_conv2d_0_4x4_512_512/kernel_gradients:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_generator/generator_base_layers_conv2d_0_4x4_512_512/bias_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_generator/generator_base_layers_conv2d_1_3x3_512_512/kernel_gradients:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_generator/generator_base_layers_conv2d_1_3x3_512_512/bias_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_generator/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_gradients:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_generator/generator_to_rgb_layers_conv2d_0_1x1_512_3/bias_gradients:0' shape=(3,) dtype=float32>]\n",
      "\n",
      "train_network_generator: gradients = [<tf.Tensor 'get_loss_and_train_op_cond/generator_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/generator_clip_by_global_norm_gradients_1/_0:0' shape=(512, 8192) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/generator_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/generator_clip_by_global_norm_gradients_1/_1:0' shape=(8192,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/generator_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/generator_clip_by_global_norm_gradients_1/_2:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/generator_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/generator_clip_by_global_norm_gradients_1/_3:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/generator_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/generator_clip_by_global_norm_gradients_1/_4:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/generator_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/generator_clip_by_global_norm_gradients_1/_5:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/generator_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/generator_clip_by_global_norm_gradients_1/_6:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/generator_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/generator_clip_by_global_norm_gradients_1/_7:0' shape=(3,) dtype=float32>]\n",
      "\n",
      "train_network_generator: gradients = [<tf.Tensor 'get_loss_and_train_op_cond/train_network_generator/generator_projection_layer/kernel_clip_gradients:0' shape=(512, 8192) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_generator/generator_projection_layer/bias_clip_gradients:0' shape=(8192,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_generator/generator_base_layers_conv2d_0_4x4_512_512/kernel_clip_gradients:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_generator/generator_base_layers_conv2d_0_4x4_512_512/bias_clip_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_generator/generator_base_layers_conv2d_1_3x3_512_512/kernel_clip_gradients:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_generator/generator_base_layers_conv2d_1_3x3_512_512/bias_clip_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_generator/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_clip_gradients:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_generator/generator_to_rgb_layers_conv2d_0_1x1_512_3/bias_clip_gradients:0' shape=(3,) dtype=float32>]\n",
      "train_network_generator: grads_and_vars = <zip object at 0x7fa3d5a562d0>\n",
      "instantiate_optimizer_slots_generator: zero_gradients = [<tf.Tensor 'get_loss_and_train_op_cond/cond_1/instantiate_optimizer_slots_generator_generator/generator_projection_layer/kernel_zeros_like:0' shape=(512, 8192) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond_1/instantiate_optimizer_slots_generator_generator/generator_projection_layer/bias_zeros_like:0' shape=(8192,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond_1/instantiate_optimizer_slots_generator_generator/generator_base_layers_conv2d_0_4x4_512_512/kernel_zeros_like:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond_1/instantiate_optimizer_slots_generator_generator/generator_base_layers_conv2d_0_4x4_512_512/bias_zeros_like:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond_1/instantiate_optimizer_slots_generator_generator/generator_base_layers_conv2d_1_3x3_512_512/kernel_zeros_like:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond_1/instantiate_optimizer_slots_generator_generator/generator_base_layers_conv2d_1_3x3_512_512/bias_zeros_like:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond_1/instantiate_optimizer_slots_generator_generator/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_zeros_like:0' shape=(1, 1, 512, 3) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond_1/instantiate_optimizer_slots_generator_generator/generator_to_rgb_layers_conv2d_0_1x1_512_3/bias_zeros_like:0' shape=(3,) dtype=float32>]\n",
      "instantiate_optimizer_slots_generator: grads_and_vars = <zip object at 0x7fa3d5ae7d20>\n",
      "instantiate_optimizer_slots_generator: instantiate_optimizer_op = name: \"get_loss_and_train_op_cond/cond_1/instantiate_optimizer_slots_generator_apply_gradients\"\n",
      "op: \"NoOp\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_1/instantiate_optimizer_slots_generator_apply_gradients/update_generator/generator_projection_layer/kernel/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_1/instantiate_optimizer_slots_generator_apply_gradients/update_generator/generator_projection_layer/bias/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_1/instantiate_optimizer_slots_generator_apply_gradients/update_generator/generator_base_layers_conv2d_0_4x4_512_512/kernel/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_1/instantiate_optimizer_slots_generator_apply_gradients/update_generator/generator_base_layers_conv2d_0_4x4_512_512/bias/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_1/instantiate_optimizer_slots_generator_apply_gradients/update_generator/generator_base_layers_conv2d_1_3x3_512_512/kernel/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_1/instantiate_optimizer_slots_generator_apply_gradients/update_generator/generator_base_layers_conv2d_1_3x3_512_512/bias/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_1/instantiate_optimizer_slots_generator_apply_gradients/update_generator/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_1/instantiate_optimizer_slots_generator_apply_gradients/update_generator/generator_to_rgb_layers_conv2d_0_1x1_512_3/bias/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_1/instantiate_optimizer_slots_generator_apply_gradients/Assign\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_1/instantiate_optimizer_slots_generator_apply_gradients/Assign_1\"\n",
      "\n",
      "instantiate_optimizer_slots_generator: add_to_collection_ops = []\n",
      "train_network_generator: train_op = name: \"get_loss_and_train_op_cond/generator_apply_gradients\"\n",
      "op: \"AssignAddVariableOp\"\n",
      "input: \"get_loss_and_train_op_cond/instantiate_optimizer_op_pred_1/ReadVariableOp/Switch:0\"\n",
      "input: \"get_loss_and_train_op_cond/generator_apply_gradients/Const\"\n",
      "attr {\n",
      "  key: \"_class\"\n",
      "  value {\n",
      "    list {\n",
      "      s: \"loc:@global_step\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_INT64\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "train_network: loss = Tensor(\"encoder_total_loss:0\", shape=(), dtype=float32)\n",
      "train_network: global_step = <tf.Variable 'global_step:0' shape=() dtype=int64>\n",
      "train_network: alpha_var = None\n",
      "train_network: scope = encoder\n",
      "train_network_encoder: optimizer = <tensorflow.python.training.adam.AdamOptimizer object at 0x7fa3d5967710>\n",
      "\n",
      "train_network_encoder: variables = [<tf.Variable 'encoder/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel:0' shape=(1, 1, 3, 512) dtype=float32_ref>, <tf.Variable 'encoder/encoder_from_rgb_layers_conv2d_0_1x1_3_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'encoder/encoder_base_layers_conv2d_0_3x3_512_512/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'encoder/encoder_base_layers_conv2d_0_3x3_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'encoder/encoder_base_layers_conv2d_1_4x4_512_512/kernel:0' shape=(4, 4, 512, 512) dtype=float32_ref>, <tf.Variable 'encoder/encoder_base_layers_conv2d_1_4x4_512_512/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'encoder/encoder_layers_dense_logits/kernel:0' shape=(512, 512) dtype=float32_ref>, <tf.Variable 'encoder/encoder_layers_dense_logits/bias:0' shape=(512,) dtype=float32_ref>]\n",
      "\n",
      "train_network_encoder: gradients = [<tf.Tensor 'get_loss_and_train_op_cond/encoder_gradients/AddN_11:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/encoder_gradients/encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_1_grad/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/encoder_gradients/AddN_10:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/encoder_gradients/encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/BiasAdd_1_grad/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/encoder_gradients/AddN_9:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/encoder_gradients/encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/BiasAdd_1_grad/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/encoder_gradients/AddN_8:0' shape=(512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/encoder_gradients/encoder_6/encoder_layers_dense_logits/BiasAdd_1_grad/BiasAddGrad:0' shape=(512,) dtype=float32>]\n",
      "\n",
      "train_network_encoder: gradients = [<tf.Tensor 'get_loss_and_train_op_cond/train_network_encoder/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel_gradients:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_encoder/encoder_from_rgb_layers_conv2d_0_1x1_3_512/bias_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_encoder/encoder_base_layers_conv2d_0_3x3_512_512/kernel_gradients:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_encoder/encoder_base_layers_conv2d_0_3x3_512_512/bias_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_encoder/encoder_base_layers_conv2d_1_4x4_512_512/kernel_gradients:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_encoder/encoder_base_layers_conv2d_1_4x4_512_512/bias_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_encoder/encoder_layers_dense_logits/kernel_gradients:0' shape=(512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_encoder/encoder_layers_dense_logits/bias_gradients:0' shape=(512,) dtype=float32>]\n",
      "\n",
      "train_network_encoder: gradients = [<tf.Tensor 'get_loss_and_train_op_cond/encoder_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/encoder_clip_by_global_norm_gradients_1/_0:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/encoder_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/encoder_clip_by_global_norm_gradients_1/_1:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/encoder_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/encoder_clip_by_global_norm_gradients_1/_2:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/encoder_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/encoder_clip_by_global_norm_gradients_1/_3:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/encoder_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/encoder_clip_by_global_norm_gradients_1/_4:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/encoder_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/encoder_clip_by_global_norm_gradients_1/_5:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/encoder_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/encoder_clip_by_global_norm_gradients_1/_6:0' shape=(512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/encoder_clip_by_global_norm_gradients_1/get_loss_and_train_op_cond/encoder_clip_by_global_norm_gradients_1/_7:0' shape=(512,) dtype=float32>]\n",
      "\n",
      "train_network_encoder: gradients = [<tf.Tensor 'get_loss_and_train_op_cond/train_network_encoder/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel_clip_gradients:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_encoder/encoder_from_rgb_layers_conv2d_0_1x1_3_512/bias_clip_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_encoder/encoder_base_layers_conv2d_0_3x3_512_512/kernel_clip_gradients:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_encoder/encoder_base_layers_conv2d_0_3x3_512_512/bias_clip_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_encoder/encoder_base_layers_conv2d_1_4x4_512_512/kernel_clip_gradients:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_encoder/encoder_base_layers_conv2d_1_4x4_512_512/bias_clip_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_encoder/encoder_layers_dense_logits/kernel_clip_gradients:0' shape=(512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/train_network_encoder/encoder_layers_dense_logits/bias_clip_gradients:0' shape=(512,) dtype=float32>]\n",
      "train_network_encoder: grads_and_vars = <zip object at 0x7fa3d588c640>\n",
      "instantiate_optimizer_slots_encoder: zero_gradients = [<tf.Tensor 'get_loss_and_train_op_cond/cond_2/instantiate_optimizer_slots_encoder_encoder/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel_zeros_like:0' shape=(1, 1, 3, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond_2/instantiate_optimizer_slots_encoder_encoder/encoder_from_rgb_layers_conv2d_0_1x1_3_512/bias_zeros_like:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond_2/instantiate_optimizer_slots_encoder_encoder/encoder_base_layers_conv2d_0_3x3_512_512/kernel_zeros_like:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond_2/instantiate_optimizer_slots_encoder_encoder/encoder_base_layers_conv2d_0_3x3_512_512/bias_zeros_like:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond_2/instantiate_optimizer_slots_encoder_encoder/encoder_base_layers_conv2d_1_4x4_512_512/kernel_zeros_like:0' shape=(4, 4, 512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond_2/instantiate_optimizer_slots_encoder_encoder/encoder_base_layers_conv2d_1_4x4_512_512/bias_zeros_like:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond_2/instantiate_optimizer_slots_encoder_encoder/encoder_layers_dense_logits/kernel_zeros_like:0' shape=(512, 512) dtype=float32>, <tf.Tensor 'get_loss_and_train_op_cond/cond_2/instantiate_optimizer_slots_encoder_encoder/encoder_layers_dense_logits/bias_zeros_like:0' shape=(512,) dtype=float32>]\n",
      "instantiate_optimizer_slots_encoder: grads_and_vars = <zip object at 0x7fa3d575dbe0>\n",
      "instantiate_optimizer_slots_encoder: instantiate_optimizer_op = name: \"get_loss_and_train_op_cond/cond_2/instantiate_optimizer_slots_encoder_apply_gradients\"\n",
      "op: \"NoOp\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_2/instantiate_optimizer_slots_encoder_apply_gradients/update_encoder/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_2/instantiate_optimizer_slots_encoder_apply_gradients/update_encoder/encoder_from_rgb_layers_conv2d_0_1x1_3_512/bias/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_2/instantiate_optimizer_slots_encoder_apply_gradients/update_encoder/encoder_base_layers_conv2d_0_3x3_512_512/kernel/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_2/instantiate_optimizer_slots_encoder_apply_gradients/update_encoder/encoder_base_layers_conv2d_0_3x3_512_512/bias/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_2/instantiate_optimizer_slots_encoder_apply_gradients/update_encoder/encoder_base_layers_conv2d_1_4x4_512_512/kernel/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_2/instantiate_optimizer_slots_encoder_apply_gradients/update_encoder/encoder_base_layers_conv2d_1_4x4_512_512/bias/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_2/instantiate_optimizer_slots_encoder_apply_gradients/update_encoder/encoder_layers_dense_logits/kernel/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_2/instantiate_optimizer_slots_encoder_apply_gradients/update_encoder/encoder_layers_dense_logits/bias/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_2/instantiate_optimizer_slots_encoder_apply_gradients/Assign\"\n",
      "input: \"^get_loss_and_train_op_cond/cond_2/instantiate_optimizer_slots_encoder_apply_gradients/Assign_1\"\n",
      "\n",
      "instantiate_optimizer_slots_encoder: add_to_collection_ops = []\n",
      "train_network_encoder: train_op = name: \"get_loss_and_train_op_cond/encoder_apply_gradients\"\n",
      "op: \"NoOp\"\n",
      "input: \"^get_loss_and_train_op_cond/encoder_apply_gradients/update_encoder/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/encoder_apply_gradients/update_encoder/encoder_from_rgb_layers_conv2d_0_1x1_3_512/bias/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/encoder_apply_gradients/update_encoder/encoder_base_layers_conv2d_0_3x3_512_512/kernel/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/encoder_apply_gradients/update_encoder/encoder_base_layers_conv2d_0_3x3_512_512/bias/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/encoder_apply_gradients/update_encoder/encoder_base_layers_conv2d_1_4x4_512_512/kernel/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/encoder_apply_gradients/update_encoder/encoder_base_layers_conv2d_1_4x4_512_512/bias/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/encoder_apply_gradients/update_encoder/encoder_layers_dense_logits/kernel/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/encoder_apply_gradients/update_encoder/encoder_layers_dense_logits/bias/ApplyAdam\"\n",
      "input: \"^get_loss_and_train_op_cond/encoder_apply_gradients/Assign\"\n",
      "input: \"^get_loss_and_train_op_cond/encoder_apply_gradients/Assign_1\"\n",
      "\n",
      "\n",
      "jointly_train_generator_encoder: loss = Tensor(\"get_loss_and_train_op_cond/jointly_train_generator_encoder_add_loss:0\", shape=(), dtype=float32)\n",
      "jointly_train_generator_encoder: train_op = name: \"get_loss_and_train_op_cond/jointly_train_generator_encoder_group_train_op\"\n",
      "op: \"NoOp\"\n",
      "input: \"^get_loss_and_train_op_cond/generator_apply_gradients\"\n",
      "input: \"^get_loss_and_train_op_cond/encoder_apply_gradients\"\n",
      "\n",
      "update_alpha: alpha_var_update_op = name: \"alpha_var_update_op_no_op\"\n",
      "op: \"NoOp\"\n",
      "\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "\n",
      "pg_anogan_sim_enc_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(8, 32, 32, 3) dtype=float32>}\n",
      "pg_anogan_sim_enc_model: labels = Tensor(\"IteratorGetNext:1\", shape=(8,), dtype=int32, device=/device:CPU:0)\n",
      "pg_anogan_sim_enc_model: mode = eval\n",
      "pg_anogan_sim_enc_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/', 'train_batch_size': 16, 'train_steps': 3000, 'prev_train_steps': 0, 'use_tpu': False, 'eval_batch_size': 8, 'eval_steps': 10, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'eval_on_tpu': False, 'exports_to_keep': 20, 'export_to_tpu': False, 'export_to_cpu': True, 'predict_all_resolutions': True, 'anomaly_threshold': 5.0, 'anom_convex_combo_factor': 0.05, 'height': 32, 'width': 32, 'depth': 3, 'num_steps_until_growth': 1000, 'conv_num_filters': [[512, 512]], 'conv_kernel_sizes': [[4, 3]], 'conv_strides': [[1, 1]], 'latent_size': 512, 'use_pixel_norm': True, 'pixel_norm_epsilon': 1e-08, 'normalize_latent': True, 'generator_projection_dims': [4, 4, 512], 'generator_leaky_relu_alpha': 0.2, 'generator_to_rgb_activation': 'tanh', 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.99, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': 5.0, 'generator_train_steps': 1, 'use_minibatch_stddev': True, 'minibatch_stddev_group_size': 4, 'minibatch_stddev_averaging': 'True', 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.01, 'discriminator_l2_regularization_scale': 0.01, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0001, 'discriminator_adam_beta1': 0.0, 'discriminator_adam_beta2': 0.99, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': 5.0, 'discriminator_gradient_penalty_coefficient': 10.0, 'epsilon_drift': 0.001, 'discriminator_train_steps': 1, 'encoder_leaky_relu_alpha': 0.2, 'encoder_l1_regularization_scale': 0.01, 'encoder_l2_regularization_scale': 0.01, 'encoder_optimizer': 'Adam', 'encoder_learning_rate': 0.0001, 'encoder_adam_beta1': 0.0, 'encoder_adam_beta2': 0.99, 'encoder_adam_epsilon': 1e-08, 'encoder_clip_gradients': 5.0, 'generator_base_conv_blocks': [[[4, 4, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]]], 'generator_growth_conv_blocks': [], 'generator_to_rgb_layers': [[[1, 1, 512, 3, 1, 1]]], 'discriminator_from_rgb_layers': [[[1, 1, 3, 512, 1, 1]]], 'discriminator_base_conv_blocks': [[[3, 3, 512, 512, 1, 1], [4, 4, 512, 512, 1, 1]]], 'discriminator_growth_conv_blocks': [], 'encoder_from_rgb_layers': [[[1, 1, 3, 512, 1, 1]]], 'encoder_base_conv_blocks': [[[3, 3, 512, 512, 1, 1], [4, 4, 512, 512, 1, 1]]], 'encoder_growth_conv_blocks': [], 'batch_size': 8}\n",
      "\n",
      "instantiate_generator_projection_layer: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3d404c9d0>\n",
      "\n",
      "instantiate_generator_layers: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3d404c9d0>\n",
      "\n",
      "instantiate_generator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d404cc10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d404cd90>]\n",
      "instantiate_generator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d404cc10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d404cd90>]]\n",
      "\n",
      "instantiate_generator_to_rgb_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d404cf50>]\n",
      "instantiate_generator_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3d404cf50>]\n",
      "\n",
      "build_generator_projection_layer: projection_tensor = Tensor(\"generator_3/generator_projection_layer/BiasAdd:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_layers: projection_tensor = Tensor(\"generator_3/generator_projection_layer/BiasAdd:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "build_generator_layers: conv_block_tensors = [[<tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>]]\n",
      "build_generator_layers: conv_block_tensors = [<tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_to_rgb_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "build_generator_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "\n",
      "instantiate_discriminator_from_rgb_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3cc7e2f50>]\n",
      "\n",
      "instantiate_discriminator_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3cc7e2f50>]\n",
      "\n",
      "instantiate_discriminator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3cc7ef850>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a80facd0>]\n",
      "instantiate_discriminator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3cc7ef850>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a80facd0>]]\n",
      "\n",
      "instantiate_discriminator_growth_transition_downsample_layers: downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa3a80fae90>]\n",
      "instantiate_discriminator_layers: transition_downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa3a80fae90>]\n",
      "instantiate_img_to_vec_logits_layer: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa3a80faed0>\n",
      "instantiate_img_to_vec_logits_layer: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3a81014d0>\n",
      "instantiate_discriminator_layers: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa3a80faed0>\n",
      "instantiate_discriminator_layers: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3a81014d0>\n",
      "\n",
      "build_discriminator_from_rgb_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "build_discriminator_layers: conv_block_tensors = [<tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_6/discriminator_flatten_layer/Reshape:0\", shape=(1, 512), dtype=float32)\n",
      "build_discriminator_logits_layer: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "build_discriminator_layers: logits_tensor = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "\n",
      "instantiate_encoder_from_rgb_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a80beb10>]\n",
      "\n",
      "instantiate_encoder_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a80beb10>]\n",
      "\n",
      "instantiate_encoder_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a80c5390>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a80c5cd0>]\n",
      "instantiate_encoder_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a80c5390>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a80c5cd0>]]\n",
      "\n",
      "instantiate_encoder_growth_transition_downsample_layers: downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa3a80c5ad0>]\n",
      "instantiate_encoder_layers: transition_downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa3a80c5ad0>]\n",
      "instantiate_img_to_vec_logits_layer: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa3a80d1bd0>\n",
      "instantiate_img_to_vec_logits_layer: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3a80d1f10>\n",
      "instantiate_encoder_layers: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa3a80d1bd0>\n",
      "instantiate_encoder_layers: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3a80d1f10>\n",
      "\n",
      "build_encoder_from_rgb_layers: from_rgb_conv_tensors = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_encoder_layers: from_rgb_conv_tensors = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_img_to_vec_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "build_encoder_layers: conv_block_tensors = [<tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_encoder_logits_layer: block_conv_flat = Tensor(\"encoder_6/encoder_flatten_layer/Reshape:0\", shape=(1, 512), dtype=float32)\n",
      "build_encoder_logits_layer: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd:0\", shape=(1, 512), dtype=float32)\n",
      "build_encoder_layers: logits_tensor = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd:0\", shape=(1, 512), dtype=float32)\n",
      "pg_anogan_sim_enc_model: alpha_var = <tf.Variable 'alpha_var:0' shape=() dtype=float32_ref>\n",
      "\n",
      "get_logits_and_losses: X = Tensor(\"IteratorGetNext:0\", shape=(8, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(8, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(8, 512), dtype=float32).\n",
      "\n",
      "get_train_eval_generator_outputs: Z = Tensor(\"random_normal:0\", shape=(8, 512), dtype=float32)\n",
      "\n",
      "get_train_eval_generator_outputs: NOT GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "create_base_generator_network: Z = Tensor(\"random_normal:0\", shape=(8, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_3/generator_projection_layer/BiasAdd_1:0\", shape=(8, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator_6/generator_projection_reshaped:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_leaky = Tensor(\"generator_6/generator_projection_tensor_reshaped_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "use_generator_projection_layer: pixel_norm_output = Tensor(\"generator_6/generator/pixel_norm/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: projection = Tensor(\"generator_6/generator/pixel_norm/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "\n",
      "fused_conv2d_pixel_norm: conv_output = Tensor(\"generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd_1:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: conv_output_leaky = Tensor(\"generator_6/generator_fused_conv2d_pixel_norm_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: pixel_norm_output = Tensor(\"generator_6/generator/pixel_norm_1/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_0 = Tensor(\"generator_6/generator/pixel_norm_1/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "\n",
      "fused_conv2d_pixel_norm: conv_output = Tensor(\"generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd_1:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: conv_output_leaky = Tensor(\"generator_6/generator_fused_conv2d_pixel_norm_leaky_relu_1:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: pixel_norm_output = Tensor(\"generator_6/generator/pixel_norm_2/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_1 = Tensor(\"generator_6/generator/pixel_norm_2/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: to_rgb_conv = Tensor(\"generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_1:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      "get_train_eval_generator_outputs: generated_outputs = Tensor(\"generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_1:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      "Call discriminator with generator_outputs = Tensor(\"generator_generated_outputs_identity:0\", shape=(8, 4, 4, 3), dtype=float32).\n",
      "\n",
      "get_train_eval_discriminator_logits: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      " get_train_eval_discriminator_logits: NOT GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_1:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv_leaky = Tensor(\"discriminator_7/discriminator_from_rgb_conv_2d_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "\n",
      "minibatch_stddev: static_image_shape = [4, 4, 512]\n",
      "minibatch_stddev: dynamic_image_shape = Tensor(\"discriminator_7/discriminator/minibatch_stddev/dynamic_image_shape:0\", shape=(4,), dtype=int32)\n",
      "\n",
      "grouped_minibatch_stddev: group_size = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/group_size:0\", shape=(), dtype=int32)\n",
      "grouped_minibatch_stddev: grouped_image = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_image:0\", shape=(4, 2, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: grouped_mean = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_mean:0\", shape=(1, 2, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: centered_grouped_image = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/centered_grouped_image:0\", shape=(4, 2, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: grouped_variance = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_variance:0\", shape=(2, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev:0\", shape=(2, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev_average = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_average:0\", shape=(2, 1, 1, 1), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev_feature_map = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_feature_map:0\", shape=(8, 4, 4, 1), dtype=float32)\n",
      "grouped_minibatch_stddev: stddev_feature_map = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_feature_map:0\", shape=(8, 4, 4, 1), dtype=float32)\n",
      "\n",
      "ungrouped_minibatch_stddev: mean = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/mean:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "ungrouped_minibatch_stddev: centered_image = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/centered_image:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "ungrouped_minibatch_stddev: variance = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/variance:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev_average = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_average:0\", shape=(1, 1, 1, 1), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev_feature_map = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_feature_map:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "ungrouped_minibatch_stddev: stddev_feature_map = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_feature_map:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "minibatch_stddev: stddev_feature_map = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/Merge:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "minibatch_stddev: appended_image = Tensor(\"discriminator_7/discriminator/minibatch_stddev/appended_image:0\", shape=(8, 4, 4, 513), dtype=float32)\n",
      "\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_7/discriminator/minibatch_stddev/appended_image:0\", shape=(8, 4, 4, 513), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/BiasAdd_1:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv_leaky = Tensor(\"discriminator_7/discriminator/discriminator_base_layers_conv2d_0_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/BiasAdd_1:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv_leaky = Tensor(\"discriminator_7/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_7/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_7/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_6/discriminator_flatten_layer/Reshape_1:0\", shape=(8, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_1:0\", shape=(8, 1), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_1:0\", shape=(8, 1), dtype=float32)\n",
      "\n",
      "get_train_eval_discriminator_logits: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_1:0\", shape=(8, 1), dtype=float32)\n",
      "\n",
      "resize_real_images: image = Tensor(\"IteratorGetNext:0\", shape=(8, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "\n",
      ": NEVER GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "resize_real_image: block_idx = 0\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(8, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_image: resized_image = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      "Call discriminator with real_images = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(8, 4, 4, 3), dtype=float32).\n",
      "\n",
      "get_train_eval_discriminator_logits: X = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      " get_train_eval_discriminator_logits: NOT GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_2:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv_leaky = Tensor(\"discriminator_8/discriminator_from_rgb_conv_2d_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "\n",
      "minibatch_stddev: static_image_shape = [4, 4, 512]\n",
      "minibatch_stddev: dynamic_image_shape = Tensor(\"discriminator_8/discriminator/minibatch_stddev/dynamic_image_shape:0\", shape=(4,), dtype=int32)\n",
      "\n",
      "grouped_minibatch_stddev: group_size = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/group_size:0\", shape=(), dtype=int32)\n",
      "grouped_minibatch_stddev: grouped_image = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_image:0\", shape=(4, 2, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: grouped_mean = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_mean:0\", shape=(1, 2, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: centered_grouped_image = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/centered_grouped_image:0\", shape=(4, 2, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: grouped_variance = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_variance:0\", shape=(2, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev:0\", shape=(2, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev_average = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_average:0\", shape=(2, 1, 1, 1), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev_feature_map = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_feature_map:0\", shape=(8, 4, 4, 1), dtype=float32)\n",
      "grouped_minibatch_stddev: stddev_feature_map = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_feature_map:0\", shape=(8, 4, 4, 1), dtype=float32)\n",
      "\n",
      "ungrouped_minibatch_stddev: mean = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/mean:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "ungrouped_minibatch_stddev: centered_image = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/centered_image:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "ungrouped_minibatch_stddev: variance = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/variance:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev_average = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_average:0\", shape=(1, 1, 1, 1), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev_feature_map = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_feature_map:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "ungrouped_minibatch_stddev: stddev_feature_map = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_feature_map:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "minibatch_stddev: stddev_feature_map = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/Merge:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "minibatch_stddev: appended_image = Tensor(\"discriminator_8/discriminator/minibatch_stddev/appended_image:0\", shape=(8, 4, 4, 513), dtype=float32)\n",
      "\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_8/discriminator/minibatch_stddev/appended_image:0\", shape=(8, 4, 4, 513), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/BiasAdd_2:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv_leaky = Tensor(\"discriminator_8/discriminator/discriminator_base_layers_conv2d_0_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/BiasAdd_2:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv_leaky = Tensor(\"discriminator_8/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_8/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_8/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_6/discriminator_flatten_layer/Reshape_2:0\", shape=(8, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_2:0\", shape=(8, 1), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_2:0\", shape=(8, 1), dtype=float32)\n",
      "\n",
      "get_train_eval_discriminator_logits: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_2:0\", shape=(8, 1), dtype=float32)\n",
      "\n",
      "Call encoder with generator_outputs = Tensor(\"generator_generated_outputs_identity:0\", shape=(8, 4, 4, 3), dtype=float32).\n",
      "\n",
      "get_train_eval_encoder_logits: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      " get_train_eval_encoder_logits: NOT GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "create_base_img_to_vec_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "create_base_img_to_vec_network: from_rgb_conv = Tensor(\"encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_1:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "\n",
      "create_base_encoder_block_and_logits: block_conv = Tensor(\"encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_1:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv = Tensor(\"encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/BiasAdd_1:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv_leaky = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_0_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv = Tensor(\"encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/BiasAdd_1:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv_leaky = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "\n",
      "use_encoder_logits_layer: block_conv = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "use_encoder_logits_layer: block_conv = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "use_encoder_logits_layer: block_conv_flat = Tensor(\"encoder_6/encoder_flatten_layer/Reshape_1:0\", shape=(8, 512), dtype=float32)\n",
      "use_encoder_logits_layer: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(8, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(8, 512), dtype=float32)\n",
      "\n",
      "get_train_eval_encoder_logits: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(8, 512), dtype=float32)\n",
      "\n",
      "Call generator with encoder_logits = Tensor(\"encoder_logits_identity:0\", shape=(8, 512), dtype=float32).\n",
      "\n",
      "get_train_eval_generator_outputs: Z = Tensor(\"encoder_logits_identity:0\", shape=(8, 512), dtype=float32)\n",
      "\n",
      "get_train_eval_generator_outputs: NOT GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "create_base_generator_network: Z = Tensor(\"encoder_logits_identity:0\", shape=(8, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_3/generator_projection_layer/BiasAdd_2:0\", shape=(8, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator_7/generator_projection_reshaped:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_leaky = Tensor(\"generator_7/generator_projection_tensor_reshaped_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "use_generator_projection_layer: pixel_norm_output = Tensor(\"generator_7/generator/pixel_norm/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: projection = Tensor(\"generator_7/generator/pixel_norm/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "\n",
      "fused_conv2d_pixel_norm: conv_output = Tensor(\"generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd_2:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: conv_output_leaky = Tensor(\"generator_7/generator_fused_conv2d_pixel_norm_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: pixel_norm_output = Tensor(\"generator_7/generator/pixel_norm_1/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_0 = Tensor(\"generator_7/generator/pixel_norm_1/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "\n",
      "fused_conv2d_pixel_norm: conv_output = Tensor(\"generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd_2:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: conv_output_leaky = Tensor(\"generator_7/generator_fused_conv2d_pixel_norm_leaky_relu_1:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: pixel_norm_output = Tensor(\"generator_7/generator/pixel_norm_2/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_1 = Tensor(\"generator_7/generator/pixel_norm_2/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: to_rgb_conv = Tensor(\"generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_2:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      "get_train_eval_generator_outputs: generated_outputs = Tensor(\"generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_2:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = generator\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'generator_3/generator_projection_layer/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_generator: generator_3/generator_projection_layer/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d41287d0>\n",
      "get_regularization_loss_generator: generator_4/generator_base_layers_conv2d_0_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d41287d0>\n",
      "get_regularization_loss_generator: generator_4/generator_base_layers_conv2d_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d41287d0>\n",
      "get_regularization_loss_generator: generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d41287d0>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'generator_3/generator_projection_layer/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"generator_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'generator_3/generator_projection_layer/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'generator_3/generator_projection_layer/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"generator_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"generator_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_generated_loss = Tensor(\"discriminator_generated_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"discriminator/gradient_penalty/random_uniform_num:0\", shape=(8, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"discriminator/gradient_penalty/sub:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      "get_train_eval_discriminator_logits: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      " get_train_eval_discriminator_logits: NOT GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_3:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv_leaky = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator_from_rgb_conv_2d_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "\n",
      "minibatch_stddev: static_image_shape = [4, 4, 512]\n",
      "minibatch_stddev: dynamic_image_shape = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/dynamic_image_shape:0\", shape=(4,), dtype=int32)\n",
      "\n",
      "grouped_minibatch_stddev: group_size = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/group_size:0\", shape=(), dtype=int32)\n",
      "grouped_minibatch_stddev: grouped_image = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_image:0\", shape=(4, 2, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: grouped_mean = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_mean:0\", shape=(1, 2, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: centered_grouped_image = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/centered_grouped_image:0\", shape=(4, 2, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: grouped_variance = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_variance:0\", shape=(2, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev:0\", shape=(2, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev_average = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_average:0\", shape=(2, 1, 1, 1), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev_feature_map = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_feature_map:0\", shape=(8, 4, 4, 1), dtype=float32)\n",
      "grouped_minibatch_stddev: stddev_feature_map = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_feature_map:0\", shape=(8, 4, 4, 1), dtype=float32)\n",
      "\n",
      "ungrouped_minibatch_stddev: mean = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/mean:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "ungrouped_minibatch_stddev: centered_image = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/centered_image:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "ungrouped_minibatch_stddev: variance = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/variance:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev_average = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_average:0\", shape=(1, 1, 1, 1), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev_feature_map = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_feature_map:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "ungrouped_minibatch_stddev: stddev_feature_map = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_feature_map:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "minibatch_stddev: stddev_feature_map = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/Merge:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "minibatch_stddev: appended_image = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/appended_image:0\", shape=(8, 4, 4, 513), dtype=float32)\n",
      "\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/appended_image:0\", shape=(8, 4, 4, 513), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/BiasAdd_3:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv_leaky = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/discriminator_base_layers_conv2d_0_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/BiasAdd_3:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv_leaky = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_6/discriminator_flatten_layer/Reshape_3:0\", shape=(8, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_3:0\", shape=(8, 1), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_3:0\", shape=(8, 1), dtype=float32)\n",
      "\n",
      "get_train_eval_discriminator_logits: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_3:0\", shape=(8, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"discriminator/gradient_penalty/discriminator_logits_identity:0\", shape=(8, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"discriminator/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"discriminator/gradient_penalty/gradients/discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/Conv2D_3_grad/Conv2DBackpropInput:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"discriminator/gradient_penalty/Sqrt:0\", shape=(8,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"discriminator/gradient_penalty/squared_difference:0\", shape=(8,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"discriminator/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_gradient_penalty = Tensor(\"discriminator/gradient_penalty/gradient_penalty_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: epsilon_drift_penalty = Tensor(\"epsilon_drift_penalty:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_wasserstein_gp_loss = Tensor(\"discriminator_wasserstein_gp_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = discriminator\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_6/discriminator_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_discriminator: discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d41287d0>\n",
      "get_regularization_loss_discriminator: discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d41287d0>\n",
      "get_regularization_loss_discriminator: discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d41287d0>\n",
      "get_regularization_loss_discriminator: discriminator_6/discriminator_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d41287d0>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_6/discriminator_layers_dense_logits/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"discriminator_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_6/discriminator_layers_dense_logits/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_6/discriminator_layers_dense_logits/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"discriminator_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"discriminator_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "get_encoder_loss: generator_encoder_image_diff = Tensor(\"generator_encoder_image_diff:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "get_encoder_loss: image_diff_l1_norm = Tensor(\"Sum:0\", shape=(8,), dtype=float32)\n",
      "get_encoder_loss: encoder_loss = Tensor(\"encoder_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = encoder\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'encoder_6/encoder_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_encoder: encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d41287d0>\n",
      "get_regularization_loss_encoder: encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d41287d0>\n",
      "get_regularization_loss_encoder: encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d41287d0>\n",
      "get_regularization_loss_encoder: encoder_6/encoder_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d41287d0>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'encoder_6/encoder_layers_dense_logits/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"encoder_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'encoder_6/encoder_layers_dense_logits/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'encoder_6/encoder_layers_dense_logits/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"encoder_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_encoder_loss: encoder_reg_loss = Tensor(\"encoder_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_encoder_loss: encoder_total_loss = Tensor(\"encoder_total_loss:0\", shape=(), dtype=float32)\n",
      "\\get_eval_metric_ops: discriminator_logits = Tensor(\"discriminator_concat_logits:0\", shape=(16, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_labels = Tensor(\"discriminator_concat_labels:0\", shape=(16, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_probabilities = Tensor(\"discriminator_probabilities:0\", shape=(16, 1), dtype=float32)\n",
      "get_eval_metric_ops: eval_metric_ops = {'accuracy': (<tf.Tensor 'discriminator_accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_accuracy/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'discriminator_precision/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'discriminator_recall/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_recall/update_op:0' shape=() dtype=float32>), 'auc_roc': (<tf.Tensor 'discriminator_auc_roc/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_roc/update_op:0' shape=() dtype=float32>), 'auc_pr': (<tf.Tensor 'discriminator_auc_pr/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_pr/update_op:0' shape=() dtype=float32>)}\n",
      "\n",
      "serving_input_fn: feature_placeholders = {'query_image': <tf.Tensor 'serving_input_placeholder_query_image:0' shape=(?, 32, 32, 3) dtype=uint8>}\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "serving_input_fn: features = {'query_image': <tf.Tensor 'sub:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "\n",
      "pg_anogan_sim_enc_model: features = {'query_image': <tf.Tensor 'sub:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "pg_anogan_sim_enc_model: labels = None\n",
      "pg_anogan_sim_enc_model: mode = infer\n",
      "pg_anogan_sim_enc_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/', 'train_batch_size': 16, 'train_steps': 3000, 'prev_train_steps': 0, 'use_tpu': False, 'eval_batch_size': 8, 'eval_steps': 10, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'eval_on_tpu': False, 'exports_to_keep': 20, 'export_to_tpu': False, 'export_to_cpu': True, 'predict_all_resolutions': True, 'anomaly_threshold': 5.0, 'anom_convex_combo_factor': 0.05, 'height': 32, 'width': 32, 'depth': 3, 'num_steps_until_growth': 1000, 'conv_num_filters': [[512, 512]], 'conv_kernel_sizes': [[4, 3]], 'conv_strides': [[1, 1]], 'latent_size': 512, 'use_pixel_norm': True, 'pixel_norm_epsilon': 1e-08, 'normalize_latent': True, 'generator_projection_dims': [4, 4, 512], 'generator_leaky_relu_alpha': 0.2, 'generator_to_rgb_activation': 'tanh', 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.99, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': 5.0, 'generator_train_steps': 1, 'use_minibatch_stddev': True, 'minibatch_stddev_group_size': 4, 'minibatch_stddev_averaging': 'True', 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.01, 'discriminator_l2_regularization_scale': 0.01, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0001, 'discriminator_adam_beta1': 0.0, 'discriminator_adam_beta2': 0.99, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': 5.0, 'discriminator_gradient_penalty_coefficient': 10.0, 'epsilon_drift': 0.001, 'discriminator_train_steps': 1, 'encoder_leaky_relu_alpha': 0.2, 'encoder_l1_regularization_scale': 0.01, 'encoder_l2_regularization_scale': 0.01, 'encoder_optimizer': 'Adam', 'encoder_learning_rate': 0.0001, 'encoder_adam_beta1': 0.0, 'encoder_adam_beta2': 0.99, 'encoder_adam_epsilon': 1e-08, 'encoder_clip_gradients': 5.0, 'generator_base_conv_blocks': [[[4, 4, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]]], 'generator_growth_conv_blocks': [], 'generator_to_rgb_layers': [[[1, 1, 512, 3, 1, 1]]], 'discriminator_from_rgb_layers': [[[1, 1, 3, 512, 1, 1]]], 'discriminator_base_conv_blocks': [[[3, 3, 512, 512, 1, 1], [4, 4, 512, 512, 1, 1]]], 'discriminator_growth_conv_blocks': [], 'encoder_from_rgb_layers': [[[1, 1, 3, 512, 1, 1]]], 'encoder_base_conv_blocks': [[[3, 3, 512, 512, 1, 1], [4, 4, 512, 512, 1, 1]]], 'encoder_growth_conv_blocks': []}\n",
      "\n",
      "instantiate_generator_projection_layer: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7fa368265fd0>\n",
      "\n",
      "instantiate_generator_layers: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7fa368265fd0>\n",
      "\n",
      "instantiate_generator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa36826a210>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa36826a390>]\n",
      "instantiate_generator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa36826a210>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa36826a390>]]\n",
      "\n",
      "instantiate_generator_to_rgb_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa36826a5d0>]\n",
      "instantiate_generator_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa36826a5d0>]\n",
      "\n",
      "build_generator_projection_layer: projection_tensor = Tensor(\"generator_3/generator_projection_layer/BiasAdd:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_layers: projection_tensor = Tensor(\"generator_3/generator_projection_layer/BiasAdd:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "build_generator_layers: conv_block_tensors = [[<tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>]]\n",
      "build_generator_layers: conv_block_tensors = [<tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_to_rgb_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "build_generator_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "\n",
      "instantiate_discriminator_from_rgb_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3682283d0>]\n",
      "\n",
      "instantiate_discriminator_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3682283d0>]\n",
      "\n",
      "instantiate_discriminator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa368228f90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa368236290>]\n",
      "instantiate_discriminator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa368228f90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa368236290>]]\n",
      "\n",
      "instantiate_discriminator_growth_transition_downsample_layers: downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa3681bcb10>]\n",
      "instantiate_discriminator_layers: transition_downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa3681bcb10>]\n",
      "instantiate_img_to_vec_logits_layer: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa3681bc750>\n",
      "instantiate_img_to_vec_logits_layer: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3681bc490>\n",
      "instantiate_discriminator_layers: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa3681bc750>\n",
      "instantiate_discriminator_layers: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3681bc490>\n",
      "\n",
      "build_discriminator_from_rgb_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "build_discriminator_layers: conv_block_tensors = [<tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_6/discriminator_flatten_layer/Reshape:0\", shape=(1, 512), dtype=float32)\n",
      "build_discriminator_logits_layer: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "build_discriminator_layers: logits_tensor = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "\n",
      "instantiate_encoder_from_rgb_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa36817add0>]\n",
      "\n",
      "instantiate_encoder_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa36817add0>]\n",
      "\n",
      "instantiate_encoder_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa36817ac90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa368185e90>]\n",
      "instantiate_encoder_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa36817ac90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa368185e90>]]\n",
      "\n",
      "instantiate_encoder_growth_transition_downsample_layers: downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa3681803d0>]\n",
      "instantiate_encoder_layers: transition_downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa3681803d0>]\n",
      "instantiate_img_to_vec_logits_layer: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa3681801d0>\n",
      "instantiate_img_to_vec_logits_layer: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa36818db90>\n",
      "instantiate_encoder_layers: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa3681801d0>\n",
      "instantiate_encoder_layers: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa36818db90>\n",
      "\n",
      "build_encoder_from_rgb_layers: from_rgb_conv_tensors = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_encoder_layers: from_rgb_conv_tensors = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_img_to_vec_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "build_encoder_layers: conv_block_tensors = [<tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_encoder_logits_layer: block_conv_flat = Tensor(\"encoder_6/encoder_flatten_layer/Reshape:0\", shape=(1, 512), dtype=float32)\n",
      "build_encoder_logits_layer: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd:0\", shape=(1, 512), dtype=float32)\n",
      "build_encoder_layers: logits_tensor = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd:0\", shape=(1, 512), dtype=float32)\n",
      "pg_anogan_sim_enc_model: alpha_var = <tf.Variable 'alpha_var:0' shape=() dtype=float32_ref>\n",
      "\n",
      "get_predictions_and_export_outputs: query_images = Tensor(\"sub:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_predictions_and_export_outputs: loop_start = 0\n",
      "get_predictions_and_export_outputs: loop_end = 1\n",
      "\n",
      "get_predictions: query_images = Tensor(\"sub:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 0\n",
      "resize_real_image: image = Tensor(\"sub:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "resize_real_image: resized_image = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "get_predictions: resized_query_images = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "\n",
      "Call encoder with resized_query_images = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(?, 4, 4, 3), dtype=float32).\n",
      "\n",
      "get_predict_encoder_logits: X = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "\n",
      "create_base_img_to_vec_network: X = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "create_base_img_to_vec_network: from_rgb_conv = Tensor(\"encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_1:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "create_base_encoder_block_and_logits: block_conv = Tensor(\"encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_1:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv = Tensor(\"encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/BiasAdd_1:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv_leaky = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_0_leaky_relu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv = Tensor(\"encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/BiasAdd_1:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv_leaky = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_1_leaky_relu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "\n",
      "use_encoder_logits_layer: block_conv = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_1_leaky_relu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_encoder_logits_layer: block_conv = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_1_leaky_relu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_encoder_logits_layer: block_conv_flat = Tensor(\"encoder_6/encoder_flatten_layer/Reshape_1:0\", shape=(?, 512), dtype=float32)\n",
      "use_encoder_logits_layer: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(?, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "get_predict_encoder_logits: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_predictions: encoder_logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "Call generator with encoder_logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_predict_generator_outputs: Z = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "create_base_generator_network: Z = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_3/generator_projection_layer/BiasAdd_1:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator_6/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_leaky = Tensor(\"generator_6/generator_projection_tensor_reshaped_leaky_relu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "use_generator_projection_layer: pixel_norm_output = Tensor(\"generator_6/generator/pixel_norm/mul:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: projection = Tensor(\"generator_6/generator/pixel_norm/mul:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "fused_conv2d_pixel_norm: conv_output = Tensor(\"generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd_1:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: conv_output_leaky = Tensor(\"generator_6/generator_fused_conv2d_pixel_norm_leaky_relu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: pixel_norm_output = Tensor(\"generator_6/generator/pixel_norm_1/mul:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_0 = Tensor(\"generator_6/generator/pixel_norm_1/mul:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "fused_conv2d_pixel_norm: conv_output = Tensor(\"generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd_1:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: conv_output_leaky = Tensor(\"generator_6/generator_fused_conv2d_pixel_norm_leaky_relu_1:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: pixel_norm_output = Tensor(\"generator_6/generator/pixel_norm_2/mul:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_1 = Tensor(\"generator_6/generator/pixel_norm_2/mul:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: to_rgb_conv = Tensor(\"generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_1:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "get_predict_generator_outputs: generated_outputs = Tensor(\"generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_1:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "get_predictions: encoded_images = Tensor(\"generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_1:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "\n",
      "query_images_normalized: query_images_normalized = Tensor(\"minmax_normalization_normalized:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "get_residual_loss: image_difference = Tensor(\"image_difference:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "get_residual_loss: image_difference_l2_norm = Tensor(\"image_difference_l2_norm:0\", shape=(?,), dtype=float32)\n",
      "get_residual_loss: residual_loss = Tensor(\"residual_loss:0\", shape=(?,), dtype=float32)\n",
      "\n",
      "get_anomaly_scores: residual_loss = Tensor(\"residual_loss:0\", shape=(?,), dtype=float32)\n",
      "\n",
      "get_origin_distance_loss: z_hat_l2_norm = Tensor(\"z_hat_l2_norm:0\", shape=(?,), dtype=float32)\n",
      "get_origin_distance_loss: origin_distance_loss = Tensor(\"origin_distance_loss:0\", shape=(?,), dtype=float32)\n",
      "get_anomaly_scores: origin_dist_loss = Tensor(\"origin_distance_loss:0\", shape=(?,), dtype=float32)\n",
      "get_anomaly_scores: anomaly_scores = Tensor(\"anomaly_scores:0\", shape=(?,), dtype=float32)\n",
      "\n",
      "anomaly_detection: anomaly_scores = Tensor(\"anomaly_scores:0\", shape=(?,), dtype=float32)\n",
      "anomaly_detection: anomaly_flags = Tensor(\"Cast_3:0\", shape=(?,), dtype=int32)\n",
      "get_predictions: anomaly_scores = Tensor(\"anomaly_scores:0\", shape=(?,), dtype=float32)\n",
      "get_predictions: anomaly_flags = Tensor(\"Cast_3:0\", shape=(?,), dtype=int32)\n",
      "get_predictions_and_export_outputs: predictions_dict = {'encoded_images_4x4': <tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_1:0' shape=(?, 4, 4, 3) dtype=float32>, 'anomaly_scores_4x4': <tf.Tensor 'anomaly_scores:0' shape=(?,) dtype=float32>, 'anomaly_flags_4x4': <tf.Tensor 'Cast_3:0' shape=(?,) dtype=int32>}\n",
      "get_predictions_and_export_outputs: export_outputs = {'predict_export_outputs': <tensorflow.python.saved_model.model_utils.export_output.PredictOutput object at 0x7fa368123650>}\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "\n",
      "pg_anogan_sim_enc_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(8, 32, 32, 3) dtype=float32>}\n",
      "pg_anogan_sim_enc_model: labels = Tensor(\"IteratorGetNext:1\", shape=(8,), dtype=int32, device=/device:CPU:0)\n",
      "pg_anogan_sim_enc_model: mode = eval\n",
      "pg_anogan_sim_enc_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/', 'train_batch_size': 16, 'train_steps': 3000, 'prev_train_steps': 0, 'use_tpu': False, 'eval_batch_size': 8, 'eval_steps': 10, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'eval_on_tpu': False, 'exports_to_keep': 20, 'export_to_tpu': False, 'export_to_cpu': True, 'predict_all_resolutions': True, 'anomaly_threshold': 5.0, 'anom_convex_combo_factor': 0.05, 'height': 32, 'width': 32, 'depth': 3, 'num_steps_until_growth': 1000, 'conv_num_filters': [[512, 512]], 'conv_kernel_sizes': [[4, 3]], 'conv_strides': [[1, 1]], 'latent_size': 512, 'use_pixel_norm': True, 'pixel_norm_epsilon': 1e-08, 'normalize_latent': True, 'generator_projection_dims': [4, 4, 512], 'generator_leaky_relu_alpha': 0.2, 'generator_to_rgb_activation': 'tanh', 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.99, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': 5.0, 'generator_train_steps': 1, 'use_minibatch_stddev': True, 'minibatch_stddev_group_size': 4, 'minibatch_stddev_averaging': 'True', 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.01, 'discriminator_l2_regularization_scale': 0.01, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0001, 'discriminator_adam_beta1': 0.0, 'discriminator_adam_beta2': 0.99, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': 5.0, 'discriminator_gradient_penalty_coefficient': 10.0, 'epsilon_drift': 0.001, 'discriminator_train_steps': 1, 'encoder_leaky_relu_alpha': 0.2, 'encoder_l1_regularization_scale': 0.01, 'encoder_l2_regularization_scale': 0.01, 'encoder_optimizer': 'Adam', 'encoder_learning_rate': 0.0001, 'encoder_adam_beta1': 0.0, 'encoder_adam_beta2': 0.99, 'encoder_adam_epsilon': 1e-08, 'encoder_clip_gradients': 5.0, 'generator_base_conv_blocks': [[[4, 4, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]]], 'generator_growth_conv_blocks': [], 'generator_to_rgb_layers': [[[1, 1, 512, 3, 1, 1]]], 'discriminator_from_rgb_layers': [[[1, 1, 3, 512, 1, 1]]], 'discriminator_base_conv_blocks': [[[3, 3, 512, 512, 1, 1], [4, 4, 512, 512, 1, 1]]], 'discriminator_growth_conv_blocks': [], 'encoder_from_rgb_layers': [[[1, 1, 3, 512, 1, 1]]], 'encoder_base_conv_blocks': [[[3, 3, 512, 512, 1, 1], [4, 4, 512, 512, 1, 1]]], 'encoder_growth_conv_blocks': [], 'batch_size': 8}\n",
      "\n",
      "instantiate_generator_projection_layer: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7fa36803ad90>\n",
      "\n",
      "instantiate_generator_layers: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7fa36803ad90>\n",
      "\n",
      "instantiate_generator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa36803af90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa368040150>]\n",
      "instantiate_generator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa36803af90>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa368040150>]]\n",
      "\n",
      "instantiate_generator_to_rgb_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa368040390>]\n",
      "instantiate_generator_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa368040390>]\n",
      "\n",
      "build_generator_projection_layer: projection_tensor = Tensor(\"generator_3/generator_projection_layer/BiasAdd:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_layers: projection_tensor = Tensor(\"generator_3/generator_projection_layer/BiasAdd:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "build_generator_layers: conv_block_tensors = [[<tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>]]\n",
      "build_generator_layers: conv_block_tensors = [<tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_to_rgb_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "build_generator_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "\n",
      "instantiate_discriminator_from_rgb_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa368077090>]\n",
      "\n",
      "instantiate_discriminator_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa368077090>]\n",
      "\n",
      "instantiate_discriminator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3680779d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3287c35d0>]\n",
      "instantiate_discriminator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3680779d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3287c35d0>]]\n",
      "\n",
      "instantiate_discriminator_growth_transition_downsample_layers: downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa3287cc950>]\n",
      "instantiate_discriminator_layers: transition_downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa3287cc950>]\n",
      "instantiate_img_to_vec_logits_layer: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa3287cc510>\n",
      "instantiate_img_to_vec_logits_layer: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3287cc250>\n",
      "instantiate_discriminator_layers: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa3287cc510>\n",
      "instantiate_discriminator_layers: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3287cc250>\n",
      "\n",
      "build_discriminator_from_rgb_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "build_discriminator_layers: conv_block_tensors = [<tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_6/discriminator_flatten_layer/Reshape:0\", shape=(1, 512), dtype=float32)\n",
      "build_discriminator_logits_layer: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "build_discriminator_layers: logits_tensor = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "\n",
      "instantiate_encoder_from_rgb_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa32878cb90>]\n",
      "\n",
      "instantiate_encoder_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa32878cb90>]\n",
      "\n",
      "instantiate_encoder_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa32878ca50>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa32878cf50>]\n",
      "instantiate_encoder_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa32878ca50>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa32878cf50>]]\n",
      "\n",
      "instantiate_encoder_growth_transition_downsample_layers: downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa328792f90>]\n",
      "instantiate_encoder_layers: transition_downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa328792f90>]\n",
      "instantiate_img_to_vec_logits_layer: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa32879aed0>\n",
      "instantiate_img_to_vec_logits_layer: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3287a1950>\n",
      "instantiate_encoder_layers: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa32879aed0>\n",
      "instantiate_encoder_layers: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3287a1950>\n",
      "\n",
      "build_encoder_from_rgb_layers: from_rgb_conv_tensors = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_encoder_layers: from_rgb_conv_tensors = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_img_to_vec_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "build_encoder_layers: conv_block_tensors = [<tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_encoder_logits_layer: block_conv_flat = Tensor(\"encoder_6/encoder_flatten_layer/Reshape:0\", shape=(1, 512), dtype=float32)\n",
      "build_encoder_logits_layer: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd:0\", shape=(1, 512), dtype=float32)\n",
      "build_encoder_layers: logits_tensor = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd:0\", shape=(1, 512), dtype=float32)\n",
      "pg_anogan_sim_enc_model: alpha_var = <tf.Variable 'alpha_var:0' shape=() dtype=float32_ref>\n",
      "\n",
      "get_logits_and_losses: X = Tensor(\"IteratorGetNext:0\", shape=(8, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(8, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(8, 512), dtype=float32).\n",
      "\n",
      "get_train_eval_generator_outputs: Z = Tensor(\"random_normal:0\", shape=(8, 512), dtype=float32)\n",
      "\n",
      "get_train_eval_generator_outputs: NOT GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "create_base_generator_network: Z = Tensor(\"random_normal:0\", shape=(8, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_3/generator_projection_layer/BiasAdd_1:0\", shape=(8, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator_6/generator_projection_reshaped:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_leaky = Tensor(\"generator_6/generator_projection_tensor_reshaped_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "use_generator_projection_layer: pixel_norm_output = Tensor(\"generator_6/generator/pixel_norm/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: projection = Tensor(\"generator_6/generator/pixel_norm/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "\n",
      "fused_conv2d_pixel_norm: conv_output = Tensor(\"generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd_1:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: conv_output_leaky = Tensor(\"generator_6/generator_fused_conv2d_pixel_norm_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: pixel_norm_output = Tensor(\"generator_6/generator/pixel_norm_1/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_0 = Tensor(\"generator_6/generator/pixel_norm_1/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "\n",
      "fused_conv2d_pixel_norm: conv_output = Tensor(\"generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd_1:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: conv_output_leaky = Tensor(\"generator_6/generator_fused_conv2d_pixel_norm_leaky_relu_1:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: pixel_norm_output = Tensor(\"generator_6/generator/pixel_norm_2/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_1 = Tensor(\"generator_6/generator/pixel_norm_2/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: to_rgb_conv = Tensor(\"generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_1:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      "get_train_eval_generator_outputs: generated_outputs = Tensor(\"generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_1:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      "Call discriminator with generator_outputs = Tensor(\"generator_generated_outputs_identity:0\", shape=(8, 4, 4, 3), dtype=float32).\n",
      "\n",
      "get_train_eval_discriminator_logits: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      " get_train_eval_discriminator_logits: NOT GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_1:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv_leaky = Tensor(\"discriminator_7/discriminator_from_rgb_conv_2d_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "\n",
      "minibatch_stddev: static_image_shape = [4, 4, 512]\n",
      "minibatch_stddev: dynamic_image_shape = Tensor(\"discriminator_7/discriminator/minibatch_stddev/dynamic_image_shape:0\", shape=(4,), dtype=int32)\n",
      "\n",
      "grouped_minibatch_stddev: group_size = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/group_size:0\", shape=(), dtype=int32)\n",
      "grouped_minibatch_stddev: grouped_image = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_image:0\", shape=(4, 2, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: grouped_mean = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_mean:0\", shape=(1, 2, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: centered_grouped_image = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/centered_grouped_image:0\", shape=(4, 2, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: grouped_variance = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_variance:0\", shape=(2, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev:0\", shape=(2, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev_average = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_average:0\", shape=(2, 1, 1, 1), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev_feature_map = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_feature_map:0\", shape=(8, 4, 4, 1), dtype=float32)\n",
      "grouped_minibatch_stddev: stddev_feature_map = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_feature_map:0\", shape=(8, 4, 4, 1), dtype=float32)\n",
      "\n",
      "ungrouped_minibatch_stddev: mean = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/mean:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "ungrouped_minibatch_stddev: centered_image = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/centered_image:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "ungrouped_minibatch_stddev: variance = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/variance:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev_average = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_average:0\", shape=(1, 1, 1, 1), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev_feature_map = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_feature_map:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "ungrouped_minibatch_stddev: stddev_feature_map = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_feature_map:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "minibatch_stddev: stddev_feature_map = Tensor(\"discriminator_7/discriminator/minibatch_stddev/stddev_feature_map_cond/Merge:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "minibatch_stddev: appended_image = Tensor(\"discriminator_7/discriminator/minibatch_stddev/appended_image:0\", shape=(8, 4, 4, 513), dtype=float32)\n",
      "\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_7/discriminator/minibatch_stddev/appended_image:0\", shape=(8, 4, 4, 513), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/BiasAdd_1:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv_leaky = Tensor(\"discriminator_7/discriminator/discriminator_base_layers_conv2d_0_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/BiasAdd_1:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv_leaky = Tensor(\"discriminator_7/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_7/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_7/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_6/discriminator_flatten_layer/Reshape_1:0\", shape=(8, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_1:0\", shape=(8, 1), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_1:0\", shape=(8, 1), dtype=float32)\n",
      "\n",
      "get_train_eval_discriminator_logits: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_1:0\", shape=(8, 1), dtype=float32)\n",
      "\n",
      "resize_real_images: image = Tensor(\"IteratorGetNext:0\", shape=(8, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "\n",
      ": NEVER GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "resize_real_image: block_idx = 0\n",
      "resize_real_image: image = Tensor(\"IteratorGetNext:0\", shape=(8, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "resize_real_image: resized_image = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "resize_real_images: resized_image = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      "Call discriminator with real_images = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(8, 4, 4, 3), dtype=float32).\n",
      "\n",
      "get_train_eval_discriminator_logits: X = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      " get_train_eval_discriminator_logits: NOT GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_2:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv_leaky = Tensor(\"discriminator_8/discriminator_from_rgb_conv_2d_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "\n",
      "minibatch_stddev: static_image_shape = [4, 4, 512]\n",
      "minibatch_stddev: dynamic_image_shape = Tensor(\"discriminator_8/discriminator/minibatch_stddev/dynamic_image_shape:0\", shape=(4,), dtype=int32)\n",
      "\n",
      "grouped_minibatch_stddev: group_size = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/group_size:0\", shape=(), dtype=int32)\n",
      "grouped_minibatch_stddev: grouped_image = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_image:0\", shape=(4, 2, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: grouped_mean = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_mean:0\", shape=(1, 2, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: centered_grouped_image = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/centered_grouped_image:0\", shape=(4, 2, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: grouped_variance = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_variance:0\", shape=(2, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev:0\", shape=(2, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev_average = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_average:0\", shape=(2, 1, 1, 1), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev_feature_map = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_feature_map:0\", shape=(8, 4, 4, 1), dtype=float32)\n",
      "grouped_minibatch_stddev: stddev_feature_map = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_feature_map:0\", shape=(8, 4, 4, 1), dtype=float32)\n",
      "\n",
      "ungrouped_minibatch_stddev: mean = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/mean:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "ungrouped_minibatch_stddev: centered_image = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/centered_image:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "ungrouped_minibatch_stddev: variance = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/variance:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev_average = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_average:0\", shape=(1, 1, 1, 1), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev_feature_map = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_feature_map:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "ungrouped_minibatch_stddev: stddev_feature_map = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_feature_map:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "minibatch_stddev: stddev_feature_map = Tensor(\"discriminator_8/discriminator/minibatch_stddev/stddev_feature_map_cond/Merge:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "minibatch_stddev: appended_image = Tensor(\"discriminator_8/discriminator/minibatch_stddev/appended_image:0\", shape=(8, 4, 4, 513), dtype=float32)\n",
      "\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_8/discriminator/minibatch_stddev/appended_image:0\", shape=(8, 4, 4, 513), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/BiasAdd_2:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv_leaky = Tensor(\"discriminator_8/discriminator/discriminator_base_layers_conv2d_0_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/BiasAdd_2:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv_leaky = Tensor(\"discriminator_8/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_8/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator_8/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_6/discriminator_flatten_layer/Reshape_2:0\", shape=(8, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_2:0\", shape=(8, 1), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_2:0\", shape=(8, 1), dtype=float32)\n",
      "\n",
      "get_train_eval_discriminator_logits: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_2:0\", shape=(8, 1), dtype=float32)\n",
      "\n",
      "Call encoder with generator_outputs = Tensor(\"generator_generated_outputs_identity:0\", shape=(8, 4, 4, 3), dtype=float32).\n",
      "\n",
      "get_train_eval_encoder_logits: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      " get_train_eval_encoder_logits: NOT GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "create_base_img_to_vec_network: X = Tensor(\"generator_generated_outputs_identity:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "create_base_img_to_vec_network: from_rgb_conv = Tensor(\"encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_1:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "\n",
      "create_base_encoder_block_and_logits: block_conv = Tensor(\"encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_1:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv = Tensor(\"encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/BiasAdd_1:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv_leaky = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_0_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv = Tensor(\"encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/BiasAdd_1:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv_leaky = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "\n",
      "use_encoder_logits_layer: block_conv = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "use_encoder_logits_layer: block_conv = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "use_encoder_logits_layer: block_conv_flat = Tensor(\"encoder_6/encoder_flatten_layer/Reshape_1:0\", shape=(8, 512), dtype=float32)\n",
      "use_encoder_logits_layer: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(8, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(8, 512), dtype=float32)\n",
      "\n",
      "get_train_eval_encoder_logits: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(8, 512), dtype=float32)\n",
      "\n",
      "Call generator with encoder_logits = Tensor(\"encoder_logits_identity:0\", shape=(8, 512), dtype=float32).\n",
      "\n",
      "get_train_eval_generator_outputs: Z = Tensor(\"encoder_logits_identity:0\", shape=(8, 512), dtype=float32)\n",
      "\n",
      "get_train_eval_generator_outputs: NOT GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "create_base_generator_network: Z = Tensor(\"encoder_logits_identity:0\", shape=(8, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_3/generator_projection_layer/BiasAdd_2:0\", shape=(8, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator_7/generator_projection_reshaped:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_leaky = Tensor(\"generator_7/generator_projection_tensor_reshaped_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "use_generator_projection_layer: pixel_norm_output = Tensor(\"generator_7/generator/pixel_norm/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: projection = Tensor(\"generator_7/generator/pixel_norm/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "\n",
      "fused_conv2d_pixel_norm: conv_output = Tensor(\"generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd_2:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: conv_output_leaky = Tensor(\"generator_7/generator_fused_conv2d_pixel_norm_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: pixel_norm_output = Tensor(\"generator_7/generator/pixel_norm_1/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_0 = Tensor(\"generator_7/generator/pixel_norm_1/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "\n",
      "fused_conv2d_pixel_norm: conv_output = Tensor(\"generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd_2:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: conv_output_leaky = Tensor(\"generator_7/generator_fused_conv2d_pixel_norm_leaky_relu_1:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: pixel_norm_output = Tensor(\"generator_7/generator/pixel_norm_2/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_1 = Tensor(\"generator_7/generator/pixel_norm_2/mul:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: to_rgb_conv = Tensor(\"generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_2:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      "get_train_eval_generator_outputs: generated_outputs = Tensor(\"generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_2:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = generator\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'generator_3/generator_projection_layer/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_generator: generator_3/generator_projection_layer/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d4128890>\n",
      "get_regularization_loss_generator: generator_4/generator_base_layers_conv2d_0_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d4128890>\n",
      "get_regularization_loss_generator: generator_4/generator_base_layers_conv2d_1_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d4128890>\n",
      "get_regularization_loss_generator: generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d4128890>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'generator_3/generator_projection_layer/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"generator_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'generator_3/generator_projection_layer/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'generator_3/generator_projection_layer/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"generator_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"generator_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_generated_loss = Tensor(\"discriminator_generated_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"discriminator/gradient_penalty/random_uniform_num:0\", shape=(8, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"discriminator/gradient_penalty/sub:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      "get_train_eval_discriminator_logits: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "\n",
      " get_train_eval_discriminator_logits: NOT GOING TO GROW, SKIP SWITCH CASE!\n",
      "\n",
      "create_base_discriminator_network: X = Tensor(\"discriminator/gradient_penalty/add:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv = Tensor(\"discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_3:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_network: from_rgb_conv_leaky = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator_from_rgb_conv_2d_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "\n",
      "minibatch_stddev: static_image_shape = [4, 4, 512]\n",
      "minibatch_stddev: dynamic_image_shape = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/dynamic_image_shape:0\", shape=(4,), dtype=int32)\n",
      "\n",
      "grouped_minibatch_stddev: group_size = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/group_size:0\", shape=(), dtype=int32)\n",
      "grouped_minibatch_stddev: grouped_image = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_image:0\", shape=(4, 2, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: grouped_mean = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_mean:0\", shape=(1, 2, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: centered_grouped_image = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/centered_grouped_image:0\", shape=(4, 2, 4, 4, 512), dtype=float32)\n",
      "grouped_minibatch_stddev: grouped_variance = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/grouped_variance:0\", shape=(2, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev:0\", shape=(2, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev_average = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_average:0\", shape=(2, 1, 1, 1), dtype=float32)\n",
      "minibatch_stddev_common: grouped_stddev_feature_map = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_feature_map:0\", shape=(8, 4, 4, 1), dtype=float32)\n",
      "grouped_minibatch_stddev: stddev_feature_map = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/grouped_minibatch_stddev/discriminator/grouped_minibatch_stddev/grouped_stddev_feature_map:0\", shape=(8, 4, 4, 1), dtype=float32)\n",
      "\n",
      "ungrouped_minibatch_stddev: mean = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/mean:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "ungrouped_minibatch_stddev: centered_image = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/centered_image:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "ungrouped_minibatch_stddev: variance = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/variance:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev:0\", shape=(1, 4, 4, 512), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev_average = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_average:0\", shape=(1, 1, 1, 1), dtype=float32)\n",
      "minibatch_stddev_common: ungrouped_stddev_feature_map = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_feature_map:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "ungrouped_minibatch_stddev: stddev_feature_map = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/discriminator/ungrouped_minibatch_stddev/discriminator/ungrouped_minibatch_stddev/ungrouped_stddev_feature_map:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "minibatch_stddev: stddev_feature_map = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/stddev_feature_map_cond/Merge:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "minibatch_stddev: appended_image = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/appended_image:0\", shape=(8, 4, 4, 513), dtype=float32)\n",
      "\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/minibatch_stddev/appended_image:0\", shape=(8, 4, 4, 513), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/BiasAdd_3:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv_leaky = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/discriminator_base_layers_conv2d_0_leaky_relu:0\", shape=(8, 4, 4, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv = Tensor(\"discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/BiasAdd_3:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: block_conv_leaky = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv = Tensor(\"discriminator/gradient_penalty/discriminator/discriminator/discriminator_base_layers_conv2d_1_leaky_relu:0\", shape=(8, 1, 1, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_6/discriminator_flatten_layer/Reshape_3:0\", shape=(8, 512), dtype=float32)\n",
      "use_discriminator_logits_layer: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_3:0\", shape=(8, 1), dtype=float32)\n",
      "create_base_discriminator_block_and_logits: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_3:0\", shape=(8, 1), dtype=float32)\n",
      "\n",
      "get_train_eval_discriminator_logits: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd_3:0\", shape=(8, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"discriminator/gradient_penalty/discriminator_logits_identity:0\", shape=(8, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"discriminator/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"discriminator/gradient_penalty/gradients/discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/Conv2D_3_grad/Conv2DBackpropInput:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"discriminator/gradient_penalty/Sqrt:0\", shape=(8,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"discriminator/gradient_penalty/squared_difference:0\", shape=(8,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"discriminator/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_gradient_penalty = Tensor(\"discriminator/gradient_penalty/gradient_penalty_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: epsilon_drift_penalty = Tensor(\"epsilon_drift_penalty:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_wasserstein_gp_loss = Tensor(\"discriminator_wasserstein_gp_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = discriminator\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_6/discriminator_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_discriminator: discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d4128890>\n",
      "get_regularization_loss_discriminator: discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d4128890>\n",
      "get_regularization_loss_discriminator: discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d4128890>\n",
      "get_regularization_loss_discriminator: discriminator_6/discriminator_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d4128890>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_6/discriminator_layers_dense_logits/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"discriminator_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_6/discriminator_layers_dense_logits/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_6/discriminator_layers_dense_logits/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"discriminator_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"discriminator_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "get_encoder_loss: generator_encoder_image_diff = Tensor(\"generator_encoder_image_diff:0\", shape=(8, 4, 4, 3), dtype=float32)\n",
      "get_encoder_loss: image_diff_l1_norm = Tensor(\"Sum:0\", shape=(8,), dtype=float32)\n",
      "get_encoder_loss: encoder_loss = Tensor(\"encoder_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_regularization_loss: scope = encoder\n",
      "get_regularization_loss: trainable_reg_vars_list = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'encoder_6/encoder_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0' shape=() dtype=float32>]\n",
      "get_regularization_loss_encoder: encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d4128890>\n",
      "get_regularization_loss_encoder: encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d4128890>\n",
      "get_regularization_loss_encoder: encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d4128890>\n",
      "get_regularization_loss_encoder: encoder_6/encoder_layers_dense_logits/kernel/Regularizer/l1_l2_regularizer:0 = <tensorflow.python.framework.ops.Graph object at 0x7fa3d4128890>\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/kernel_abs_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'encoder_6/encoder_layers_dense_logits/kernel_abs_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"encoder_t_scalar_sum_tensor:0\", shape=(), dtype=float32)\n",
      "get_regularization_loss: trainable_reg_vars_squared_list = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/kernel_squared:0' shape=() dtype=float32>, <tf.Tensor 'encoder_6/encoder_layers_dense_logits/kernel_squared:0' shape=() dtype=float32>]\n",
      "\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_reduce_sum_list = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/kernel_squared_reduce_sum:0' shape=() dtype=float32>, <tf.Tensor 'encoder_6/encoder_layers_dense_logits/kernel_squared_reduce_sum:0' shape=() dtype=float32>]\n",
      "sum_nd_tensor_list_to_scalar_tensor: t_scalar_sum_tensor = Tensor(\"encoder_t_scalar_sum_tensor_1:0\", shape=(), dtype=float32)\n",
      "get_encoder_loss: encoder_reg_loss = Tensor(\"encoder_l1_l2_loss:0\", shape=(), dtype=float32)\n",
      "get_encoder_loss: encoder_total_loss = Tensor(\"encoder_total_loss:0\", shape=(), dtype=float32)\n",
      "\\get_eval_metric_ops: discriminator_logits = Tensor(\"discriminator_concat_logits:0\", shape=(16, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_labels = Tensor(\"discriminator_concat_labels:0\", shape=(16, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_probabilities = Tensor(\"discriminator_probabilities:0\", shape=(16, 1), dtype=float32)\n",
      "get_eval_metric_ops: eval_metric_ops = {'accuracy': (<tf.Tensor 'discriminator_accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_accuracy/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'discriminator_precision/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'discriminator_recall/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_recall/update_op:0' shape=() dtype=float32>), 'auc_roc': (<tf.Tensor 'discriminator_auc_roc/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_roc/update_op:0' shape=() dtype=float32>), 'auc_pr': (<tf.Tensor 'discriminator_auc_pr/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_pr/update_op:0' shape=() dtype=float32>)}\n",
      "\n",
      "serving_input_fn: feature_placeholders = {'query_image': <tf.Tensor 'serving_input_placeholder_query_image:0' shape=(?, 32, 32, 3) dtype=uint8>}\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "serving_input_fn: features = {'query_image': <tf.Tensor 'sub:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "\n",
      "pg_anogan_sim_enc_model: features = {'query_image': <tf.Tensor 'sub:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "pg_anogan_sim_enc_model: labels = None\n",
      "pg_anogan_sim_enc_model: mode = infer\n",
      "pg_anogan_sim_enc_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/', 'train_batch_size': 16, 'train_steps': 3000, 'prev_train_steps': 0, 'use_tpu': False, 'eval_batch_size': 8, 'eval_steps': 10, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'eval_on_tpu': False, 'exports_to_keep': 20, 'export_to_tpu': False, 'export_to_cpu': True, 'predict_all_resolutions': True, 'anomaly_threshold': 5.0, 'anom_convex_combo_factor': 0.05, 'height': 32, 'width': 32, 'depth': 3, 'num_steps_until_growth': 1000, 'conv_num_filters': [[512, 512]], 'conv_kernel_sizes': [[4, 3]], 'conv_strides': [[1, 1]], 'latent_size': 512, 'use_pixel_norm': True, 'pixel_norm_epsilon': 1e-08, 'normalize_latent': True, 'generator_projection_dims': [4, 4, 512], 'generator_leaky_relu_alpha': 0.2, 'generator_to_rgb_activation': 'tanh', 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.99, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': 5.0, 'generator_train_steps': 1, 'use_minibatch_stddev': True, 'minibatch_stddev_group_size': 4, 'minibatch_stddev_averaging': 'True', 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.01, 'discriminator_l2_regularization_scale': 0.01, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0001, 'discriminator_adam_beta1': 0.0, 'discriminator_adam_beta2': 0.99, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': 5.0, 'discriminator_gradient_penalty_coefficient': 10.0, 'epsilon_drift': 0.001, 'discriminator_train_steps': 1, 'encoder_leaky_relu_alpha': 0.2, 'encoder_l1_regularization_scale': 0.01, 'encoder_l2_regularization_scale': 0.01, 'encoder_optimizer': 'Adam', 'encoder_learning_rate': 0.0001, 'encoder_adam_beta1': 0.0, 'encoder_adam_beta2': 0.99, 'encoder_adam_epsilon': 1e-08, 'encoder_clip_gradients': 5.0, 'generator_base_conv_blocks': [[[4, 4, 512, 512, 1, 1], [3, 3, 512, 512, 1, 1]]], 'generator_growth_conv_blocks': [], 'generator_to_rgb_layers': [[[1, 1, 512, 3, 1, 1]]], 'discriminator_from_rgb_layers': [[[1, 1, 3, 512, 1, 1]]], 'discriminator_base_conv_blocks': [[[3, 3, 512, 512, 1, 1], [4, 4, 512, 512, 1, 1]]], 'discriminator_growth_conv_blocks': [], 'encoder_from_rgb_layers': [[[1, 1, 3, 512, 1, 1]]], 'encoder_base_conv_blocks': [[[3, 3, 512, 512, 1, 1], [4, 4, 512, 512, 1, 1]]], 'encoder_growth_conv_blocks': []}\n",
      "\n",
      "instantiate_generator_projection_layer: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3a80c9b10>\n",
      "\n",
      "instantiate_generator_layers: projection_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3a80c9b10>\n",
      "\n",
      "instantiate_generator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a80c9d10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a80c9e90>]\n",
      "instantiate_generator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a80c9d10>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a80c9e90>]]\n",
      "\n",
      "instantiate_generator_to_rgb_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a80ef110>]\n",
      "instantiate_generator_layers: to_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a80ef110>]\n",
      "\n",
      "build_generator_projection_layer: projection_tensor = Tensor(\"generator_3/generator_projection_layer/BiasAdd:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_layers: projection_tensor = Tensor(\"generator_3/generator_projection_layer/BiasAdd:0\", shape=(1, 8192), dtype=float32)\n",
      "\n",
      "build_generator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "build_generator_layers: conv_block_tensors = [[<tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>]]\n",
      "build_generator_layers: conv_block_tensors = [<tf.Tensor 'generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd:0' shape=(1, 4, 4, 512) dtype=float32>, <tf.Tensor 'generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>]\n",
      "\n",
      "build_generator_to_rgb_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "build_generator_layers: to_rgb_conv_tensors = [<tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd:0' shape=(1, 1, 1, 3) dtype=float32>]\n",
      "\n",
      "instantiate_discriminator_from_rgb_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a808ded0>]\n",
      "\n",
      "instantiate_discriminator_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a808ded0>]\n",
      "\n",
      "instantiate_discriminator_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a80929d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a808ee90>]\n",
      "instantiate_discriminator_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a80929d0>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a808ee90>]]\n",
      "\n",
      "instantiate_discriminator_growth_transition_downsample_layers: downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa3a808efd0>]\n",
      "instantiate_discriminator_layers: transition_downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa3a808efd0>]\n",
      "instantiate_img_to_vec_logits_layer: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa3a80ad1d0>\n",
      "instantiate_img_to_vec_logits_layer: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3a80ad290>\n",
      "instantiate_discriminator_layers: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa3a80ad1d0>\n",
      "instantiate_discriminator_layers: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3a80ad290>\n",
      "\n",
      "build_discriminator_from_rgb_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_layers: from_rgb_conv_tensors = [<tf.Tensor 'discriminator_4/discriminator_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "build_discriminator_layers: conv_block_tensors = [<tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'discriminator_5/discriminator_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_discriminator_logits_layer: block_conv_flat = Tensor(\"discriminator_6/discriminator_flatten_layer/Reshape:0\", shape=(1, 512), dtype=float32)\n",
      "build_discriminator_logits_layer: logits = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "build_discriminator_layers: logits_tensor = Tensor(\"discriminator_6/discriminator_layers_dense_logits/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "\n",
      "instantiate_encoder_from_rgb_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a0561050>]\n",
      "\n",
      "instantiate_encoder_layers: from_rgb_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a0561050>]\n",
      "\n",
      "instantiate_encoder_base_conv_layer_block: base_conv_layers = [<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a0575210>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a0575850>]\n",
      "instantiate_encoder_layers: conv_layer_blocks = [[<tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a0575210>, <tensorflow.python.layers.convolutional.Conv2D object at 0x7fa3a0575850>]]\n",
      "\n",
      "instantiate_encoder_growth_transition_downsample_layers: downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa3a0575350>]\n",
      "instantiate_encoder_layers: transition_downsample_layers = [<tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fa3a0575350>]\n",
      "instantiate_img_to_vec_logits_layer: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa3a056ce10>\n",
      "instantiate_img_to_vec_logits_layer: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3a056e710>\n",
      "instantiate_encoder_layers: flatten_layer = <tensorflow.python.layers.core.Flatten object at 0x7fa3a056ce10>\n",
      "instantiate_encoder_layers: logits_layer = <tensorflow.python.layers.core.Dense object at 0x7fa3a056e710>\n",
      "\n",
      "build_encoder_from_rgb_layers: from_rgb_conv_tensors = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_encoder_layers: from_rgb_conv_tensors = [<tf.Tensor 'encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_img_to_vec_base_conv_layer_block: base_conv_tensors = [<tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "build_encoder_layers: conv_block_tensors = [<tf.Tensor 'encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/BiasAdd:0' shape=(1, 3, 3, 512) dtype=float32>, <tf.Tensor 'encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/BiasAdd:0' shape=(1, 1, 1, 512) dtype=float32>]\n",
      "\n",
      "build_encoder_logits_layer: block_conv_flat = Tensor(\"encoder_6/encoder_flatten_layer/Reshape:0\", shape=(1, 512), dtype=float32)\n",
      "build_encoder_logits_layer: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd:0\", shape=(1, 512), dtype=float32)\n",
      "build_encoder_layers: logits_tensor = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd:0\", shape=(1, 512), dtype=float32)\n",
      "pg_anogan_sim_enc_model: alpha_var = <tf.Variable 'alpha_var:0' shape=() dtype=float32_ref>\n",
      "\n",
      "get_predictions_and_export_outputs: query_images = Tensor(\"sub:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_predictions_and_export_outputs: loop_start = 0\n",
      "get_predictions_and_export_outputs: loop_end = 1\n",
      "\n",
      "get_predictions: query_images = Tensor(\"sub:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: block_idx = 0\n",
      "resize_real_image: image = Tensor(\"sub:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "resize_real_image: resized_image = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "get_predictions: resized_query_images = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "\n",
      "Call encoder with resized_query_images = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(?, 4, 4, 3), dtype=float32).\n",
      "\n",
      "get_predict_encoder_logits: X = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "\n",
      "create_base_img_to_vec_network: X = Tensor(\"resize_real_image_resized_image_0/ResizeNearestNeighbor:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "create_base_img_to_vec_network: from_rgb_conv = Tensor(\"encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_1:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "create_base_encoder_block_and_logits: block_conv = Tensor(\"encoder_4/encoder_from_rgb_layers_conv2d_0_1x1_3_512/BiasAdd_1:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv = Tensor(\"encoder_5/encoder_base_layers_conv2d_0_3x3_512_512/BiasAdd_1:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv_leaky = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_0_leaky_relu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv = Tensor(\"encoder_5/encoder_base_layers_conv2d_1_4x4_512_512/BiasAdd_1:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: block_conv_leaky = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_1_leaky_relu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "\n",
      "use_encoder_logits_layer: block_conv = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_1_leaky_relu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_encoder_logits_layer: block_conv = Tensor(\"encoder_7/encoder/encoder_base_layers_conv2d_1_leaky_relu:0\", shape=(?, 1, 1, 512), dtype=float32)\n",
      "use_encoder_logits_layer: block_conv_flat = Tensor(\"encoder_6/encoder_flatten_layer/Reshape_1:0\", shape=(?, 512), dtype=float32)\n",
      "use_encoder_logits_layer: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(?, 512), dtype=float32)\n",
      "create_base_encoder_block_and_logits: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "get_predict_encoder_logits: logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_predictions: encoder_logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "Call generator with encoder_logits = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_predict_generator_outputs: Z = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "create_base_generator_network: Z = Tensor(\"encoder_6/encoder_layers_dense_logits/BiasAdd_1:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "use_generator_projection_layer: projection_tensor = Tensor(\"generator_3/generator_projection_layer/BiasAdd_1:0\", shape=(?, 8192), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_reshaped = Tensor(\"generator_6/generator_projection_reshaped:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "use_generator_projection_layer: projection_tensor_leaky = Tensor(\"generator_6/generator_projection_tensor_reshaped_leaky_relu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "use_generator_projection_layer: pixel_norm_output = Tensor(\"generator_6/generator/pixel_norm/mul:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: projection = Tensor(\"generator_6/generator/pixel_norm/mul:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "fused_conv2d_pixel_norm: conv_output = Tensor(\"generator_4/generator_base_layers_conv2d_0_4x4_512_512/BiasAdd_1:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: conv_output_leaky = Tensor(\"generator_6/generator_fused_conv2d_pixel_norm_leaky_relu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: pixel_norm_output = Tensor(\"generator_6/generator/pixel_norm_1/mul:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_0 = Tensor(\"generator_6/generator/pixel_norm_1/mul:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "\n",
      "fused_conv2d_pixel_norm: conv_output = Tensor(\"generator_4/generator_base_layers_conv2d_1_3x3_512_512/BiasAdd_1:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: conv_output_leaky = Tensor(\"generator_6/generator_fused_conv2d_pixel_norm_leaky_relu_1:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "fused_conv2d_pixel_norm: pixel_norm_output = Tensor(\"generator_6/generator/pixel_norm_2/mul:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: block_conv_1 = Tensor(\"generator_6/generator/pixel_norm_2/mul:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "create_base_generator_network: to_rgb_conv = Tensor(\"generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_1:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "get_predict_generator_outputs: generated_outputs = Tensor(\"generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_1:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "get_predictions: encoded_images = Tensor(\"generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_1:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "\n",
      "query_images_normalized: query_images_normalized = Tensor(\"minmax_normalization_normalized:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "get_residual_loss: image_difference = Tensor(\"image_difference:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "get_residual_loss: image_difference_l2_norm = Tensor(\"image_difference_l2_norm:0\", shape=(?,), dtype=float32)\n",
      "get_residual_loss: residual_loss = Tensor(\"residual_loss:0\", shape=(?,), dtype=float32)\n",
      "\n",
      "get_anomaly_scores: residual_loss = Tensor(\"residual_loss:0\", shape=(?,), dtype=float32)\n",
      "\n",
      "get_origin_distance_loss: z_hat_l2_norm = Tensor(\"z_hat_l2_norm:0\", shape=(?,), dtype=float32)\n",
      "get_origin_distance_loss: origin_distance_loss = Tensor(\"origin_distance_loss:0\", shape=(?,), dtype=float32)\n",
      "get_anomaly_scores: origin_dist_loss = Tensor(\"origin_distance_loss:0\", shape=(?,), dtype=float32)\n",
      "get_anomaly_scores: anomaly_scores = Tensor(\"anomaly_scores:0\", shape=(?,), dtype=float32)\n",
      "\n",
      "anomaly_detection: anomaly_scores = Tensor(\"anomaly_scores:0\", shape=(?,), dtype=float32)\n",
      "anomaly_detection: anomaly_flags = Tensor(\"Cast_3:0\", shape=(?,), dtype=int32)\n",
      "get_predictions: anomaly_scores = Tensor(\"anomaly_scores:0\", shape=(?,), dtype=float32)\n",
      "get_predictions: anomaly_flags = Tensor(\"Cast_3:0\", shape=(?,), dtype=int32)\n",
      "get_predictions_and_export_outputs: predictions_dict = {'encoded_images_4x4': <tf.Tensor 'generator_5/generator_to_rgb_layers_conv2d_0_1x1_512_3/BiasAdd_1:0' shape=(?, 4, 4, 3) dtype=float32>, 'anomaly_scores_4x4': <tf.Tensor 'anomaly_scores:0' shape=(?,) dtype=float32>, 'anomaly_flags_4x4': <tf.Tensor 'Cast_3:0' shape=(?,) dtype=int32>}\n",
      "get_predictions_and_export_outputs: export_outputs = {'predict_export_outputs': <tensorflow.python.saved_model.model_utils.export_output.PredictOutput object at 0x7fa3a06175d0>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/model.py:22: The name tf.summary.FileWriterCache is deprecated. Please use tf.compat.v1.summary.FileWriterCache instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/model.py:25: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/model.py:25: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/model.py:136: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa3d7f56490>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu False\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 100 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/input.py:140: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/input.py:157: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/input.py:172: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running train on CPU\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/vector_to_image.py:73: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/vector_to_image.py:73: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/vector_to_image.py:78: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/vector_to_image.py:126: The name tf.layers.Conv2D is deprecated. Please use tf.compat.v1.layers.Conv2D instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/image_to_vector.py:253: The name tf.layers.AveragePooling2D is deprecated. Please use tf.compat.v1.layers.AveragePooling2D instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/discriminator.py:49: The name tf.layers.Flatten is deprecated. Please use tf.compat.v1.layers.Flatten instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/pg_anogan_sim_enc.py:73: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/vector_to_image.py:476: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/discriminator.py:443: The name tf.mod is deprecated. Please use tf.math.mod instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/regularization.py:53: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/regularization.py:54: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/generator.py:76: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/train.py:377: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/train.py:109: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/train.py:110: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/train.py:111: The name tf.train.AdagradDAOptimizer is deprecated. Please use tf.compat.v1.train.AdagradDAOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/train.py:112: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/train.py:113: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/train.py:114: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/train.py:115: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/train.py:116: The name tf.train.ProximalAdagradOptimizer is deprecated. Please use tf.compat.v1.train.ProximalAdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/train.py:117: The name tf.train.ProximalGradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.ProximalGradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/train.py:118: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/train.py:148: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2020-06-12 11:18:51.888091: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
      "2020-06-12 11:18:51.889050: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a2bd1f9d70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-06-12 11:18:51.889089: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-06-12 11:18:51.889197: I tensorflow/core/common_runtime/process_util.cc:136] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.88714\n",
      "INFO:tensorflow:examples/sec: 30.1943\n",
      "INFO:tensorflow:Saving checkpoints for 100 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/eval_metrics.py:52: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/eval_metrics.py:57: The name tf.metrics.precision is deprecated. Please use tf.compat.v1.metrics.precision instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/eval_metrics.py:62: The name tf.metrics.recall is deprecated. Please use tf.compat.v1.metrics.recall instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/eval_metrics.py:67: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\n",
      "\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-12T11:20:11Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-12-11:20:19\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.0, auc_pr = 0.26132056, auc_roc = 7.813741e-05, global_step = 100, loss = 2134.7368, precision = 0.5, recall = 1.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt-100\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/pg_anogan_sim_enc/tf_pg_anogan_sim_enc/pg_anogan_sim_enc_tpu_module/trainer/serving.py:19: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running infer on CPU\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt-100\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/export/exporter/temp-b'1591960821'/saved_model.pb\n",
      "INFO:tensorflow:global_step/sec: 1.02906\n",
      "INFO:tensorflow:examples/sec: 16.4649\n",
      "INFO:tensorflow:global_step/sec: 3.56951\n",
      "INFO:tensorflow:examples/sec: 57.1122\n",
      "INFO:tensorflow:Saving checkpoints for 200 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.26922\n",
      "INFO:tensorflow:examples/sec: 36.3075\n",
      "INFO:tensorflow:global_step/sec: 3.57378\n",
      "INFO:tensorflow:examples/sec: 57.1806\n",
      "INFO:tensorflow:Saving checkpoints for 300 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.29088\n",
      "INFO:tensorflow:examples/sec: 36.6542\n",
      "INFO:tensorflow:global_step/sec: 3.51504\n",
      "INFO:tensorflow:examples/sec: 56.2406\n",
      "INFO:tensorflow:Saving checkpoints for 400 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.3211\n",
      "INFO:tensorflow:examples/sec: 37.1376\n",
      "INFO:tensorflow:global_step/sec: 3.49475\n",
      "INFO:tensorflow:examples/sec: 55.9161\n",
      "INFO:tensorflow:Saving checkpoints for 500 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.37139\n",
      "INFO:tensorflow:examples/sec: 37.9423\n",
      "INFO:tensorflow:global_step/sec: 3.58454\n",
      "INFO:tensorflow:examples/sec: 57.3527\n",
      "INFO:tensorflow:Saving checkpoints for 600 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 1.69503\n",
      "INFO:tensorflow:examples/sec: 27.1205\n",
      "INFO:tensorflow:global_step/sec: 2.9881\n",
      "INFO:tensorflow:examples/sec: 47.8097\n",
      "INFO:tensorflow:Saving checkpoints for 700 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.29071\n",
      "INFO:tensorflow:examples/sec: 36.6514\n",
      "INFO:tensorflow:global_step/sec: 3.53031\n",
      "INFO:tensorflow:examples/sec: 56.4849\n",
      "INFO:tensorflow:Saving checkpoints for 800 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.10966\n",
      "INFO:tensorflow:examples/sec: 33.7545\n",
      "INFO:tensorflow:global_step/sec: 3.5934\n",
      "INFO:tensorflow:examples/sec: 57.4944\n",
      "INFO:tensorflow:Saving checkpoints for 900 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.16633\n",
      "INFO:tensorflow:examples/sec: 34.6613\n",
      "INFO:tensorflow:global_step/sec: 3.40786\n",
      "INFO:tensorflow:examples/sec: 54.5258\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.26192\n",
      "INFO:tensorflow:examples/sec: 36.1907\n",
      "INFO:tensorflow:global_step/sec: 3.54764\n",
      "INFO:tensorflow:examples/sec: 56.7622\n",
      "INFO:tensorflow:Saving checkpoints for 1100 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.19509\n",
      "INFO:tensorflow:examples/sec: 35.1214\n",
      "INFO:tensorflow:global_step/sec: 3.49749\n",
      "INFO:tensorflow:examples/sec: 55.9599\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.06849\n",
      "INFO:tensorflow:examples/sec: 33.0958\n",
      "INFO:tensorflow:global_step/sec: 3.56439\n",
      "INFO:tensorflow:examples/sec: 57.0303\n",
      "INFO:tensorflow:Saving checkpoints for 1300 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.2146\n",
      "INFO:tensorflow:examples/sec: 35.4336\n",
      "INFO:tensorflow:global_step/sec: 3.53006\n",
      "INFO:tensorflow:examples/sec: 56.481\n",
      "INFO:tensorflow:Saving checkpoints for 1400 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.20417\n",
      "INFO:tensorflow:examples/sec: 35.2667\n",
      "INFO:tensorflow:global_step/sec: 3.52462\n",
      "INFO:tensorflow:examples/sec: 56.3939\n",
      "INFO:tensorflow:Saving checkpoints for 1500 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.30065\n",
      "INFO:tensorflow:examples/sec: 36.8104\n",
      "INFO:tensorflow:global_step/sec: 3.50061\n",
      "INFO:tensorflow:examples/sec: 56.0098\n",
      "INFO:tensorflow:Saving checkpoints for 1600 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.21419\n",
      "INFO:tensorflow:examples/sec: 35.4271\n",
      "INFO:tensorflow:global_step/sec: 3.52381\n",
      "INFO:tensorflow:examples/sec: 56.3809\n",
      "INFO:tensorflow:Saving checkpoints for 1700 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.23669\n",
      "INFO:tensorflow:examples/sec: 35.787\n",
      "INFO:tensorflow:global_step/sec: 3.53226\n",
      "INFO:tensorflow:examples/sec: 56.5162\n",
      "INFO:tensorflow:Saving checkpoints for 1800 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.2401\n",
      "INFO:tensorflow:examples/sec: 35.8416\n",
      "INFO:tensorflow:global_step/sec: 3.57807\n",
      "INFO:tensorflow:examples/sec: 57.2491\n",
      "INFO:tensorflow:Saving checkpoints for 1900 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.30727\n",
      "INFO:tensorflow:examples/sec: 36.9162\n",
      "INFO:tensorflow:global_step/sec: 3.59594\n",
      "INFO:tensorflow:examples/sec: 57.535\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.24573\n",
      "INFO:tensorflow:examples/sec: 35.9317\n",
      "INFO:tensorflow:global_step/sec: 3.55398\n",
      "INFO:tensorflow:examples/sec: 56.8637\n",
      "INFO:tensorflow:Saving checkpoints for 2100 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.29214\n",
      "INFO:tensorflow:examples/sec: 36.6742\n",
      "INFO:tensorflow:global_step/sec: 3.51887\n",
      "INFO:tensorflow:examples/sec: 56.3019\n",
      "INFO:tensorflow:Saving checkpoints for 2200 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.32771\n",
      "INFO:tensorflow:examples/sec: 37.2433\n",
      "INFO:tensorflow:global_step/sec: 3.70758\n",
      "INFO:tensorflow:examples/sec: 59.3213\n",
      "INFO:tensorflow:Saving checkpoints for 2300 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.27521\n",
      "INFO:tensorflow:examples/sec: 36.4034\n",
      "INFO:tensorflow:global_step/sec: 3.62566\n",
      "INFO:tensorflow:examples/sec: 58.0106\n",
      "INFO:tensorflow:Saving checkpoints for 2400 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.27508\n",
      "INFO:tensorflow:examples/sec: 36.4013\n",
      "INFO:tensorflow:global_step/sec: 3.62319\n",
      "INFO:tensorflow:examples/sec: 57.9711\n",
      "INFO:tensorflow:Saving checkpoints for 2500 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.18269\n",
      "INFO:tensorflow:examples/sec: 34.923\n",
      "INFO:tensorflow:global_step/sec: 3.56171\n",
      "INFO:tensorflow:examples/sec: 56.9874\n",
      "INFO:tensorflow:Saving checkpoints for 2600 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.15213\n",
      "INFO:tensorflow:examples/sec: 34.4341\n",
      "INFO:tensorflow:global_step/sec: 3.58791\n",
      "INFO:tensorflow:examples/sec: 57.4066\n",
      "INFO:tensorflow:Saving checkpoints for 2700 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.10359\n",
      "INFO:tensorflow:examples/sec: 33.6575\n",
      "INFO:tensorflow:global_step/sec: 3.56298\n",
      "INFO:tensorflow:examples/sec: 57.0077\n",
      "INFO:tensorflow:Saving checkpoints for 2800 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.2591\n",
      "INFO:tensorflow:examples/sec: 36.1457\n",
      "INFO:tensorflow:global_step/sec: 3.46825\n",
      "INFO:tensorflow:examples/sec: 55.492\n",
      "INFO:tensorflow:Saving checkpoints for 2900 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 2.14542\n",
      "INFO:tensorflow:examples/sec: 34.3268\n",
      "INFO:tensorflow:global_step/sec: 3.62209\n",
      "INFO:tensorflow:examples/sec: 57.9534\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-12T11:38:21Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-12-11:38:28\n",
      "INFO:tensorflow:Saving dict for global step 3000: accuracy = 0.0, auc_pr = 0.30685943, auc_roc = 0.0031250098, global_step = 3000, loss = 0.41771626, precision = 0.5, recall = 1.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt-3000\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running infer on CPU\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/model.ckpt-3000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/export/exporter/temp-b'1591961908'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 32.072945.\n",
      "INFO:tensorflow:training_loop marked as finished\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil rm -rf ${OUTPUT_DIR}\n",
    "export PYTHONPATH=$PYTHONPATH:$PWD/pg_anogan_sim_enc_tpu_module\n",
    "python3 -m trainer.task \\\n",
    "    --train_file_pattern=${TRAIN_FILE_PATTERN} \\\n",
    "    --eval_file_pattern=${EVAL_FILE_PATTERN} \\\n",
    "    --output_dir=${OUTPUT_DIR} \\\n",
    "    --job-dir=./tmp \\\n",
    "    \\\n",
    "    --train_batch_size=${TRAIN_BATCH_SIZE} \\\n",
    "    --train_steps=${TRAIN_STEPS} \\\n",
    "    --use_tpu=${USE_TPU} \\\n",
    "    \\\n",
    "    --eval_batch_size=${EVAL_BATCH_SIZE} \\\n",
    "    --eval_steps=${EVAL_STEPS} \\\n",
    "    --start_delay_secs=${START_DELAY_SECS} \\\n",
    "    --throttle_secs=${THROTTLE_SECS} \\\n",
    "    --eval_on_tpu=${EVAL_ON_TPU} \\\n",
    "    \\\n",
    "    --exports_to_keep=${EXPORTS_TO_KEEP} \\\n",
    "    --export_to_tpu=${EXPORT_TO_TPU} \\\n",
    "    --export_to_cpu=${EXPORT_TO_CPU} \\\n",
    "    --predict_all_resolutions=${PREDICT_ALL_RESOLUTIONS} \\\n",
    "    --anomaly_threshold=${ANOMALY_THRESHOLD} \\\n",
    "    --anom_convex_combo_factor=${ANOM_CONVEX_COMBO_FACTOR} \\\n",
    "    \\\n",
    "    --height=${HEIGHT} \\\n",
    "    --width=${WIDTH} \\\n",
    "    --depth=${DEPTH} \\\n",
    "    \\\n",
    "    --num_steps_until_growth=${NUM_STEPS_UNTIL_GROWTH} \\\n",
    "    --conv_num_filters=${CONV_NUM_FILTERS} \\\n",
    "    --conv_kernel_sizes=${CONV_KERNEL_SIZES} \\\n",
    "    --conv_strides=${CONV_STRIDES} \\\n",
    "    \\\n",
    "    --latent_size=${LATENT_SIZE} \\\n",
    "    --normalize_latent=${NORMALIZE_LATENT} \\\n",
    "    --use_pixel_norm=${USE_PIXEL_NORM} \\\n",
    "    --pixel_norm_epsilon=${PIXEL_NORM_EPSILON} \\\n",
    "    --generator_projection_dims=${GENERATOR_PROJECTION_DIMS} \\\n",
    "    --generator_leaky_relu_alpha=${GENERATOR_LEAKY_RELU_ALPHA} \\\n",
    "    --generator_to_rgb_activation=${GENERATOR_TO_RGB_ACTIVATION} \\\n",
    "    --generator_l1_regularization_scale=${GENERATOR_L1_REGULARIZATION_SCALE} \\\n",
    "    --generator_l2_regularization_scale=${GENERATOR_L2_REGULARIZATION_SCALE} \\\n",
    "    --generator_optimizer=${GENERATOR_OPTIMIZER} \\\n",
    "    --generator_learning_rate=${GENERATOR_LEARNING_RATE} \\\n",
    "    --generator_adam_beta1=${GENERATOR_ADAM_BETA1} \\\n",
    "    --generator_adam_beta2=${GENERATOR_ADAM_BETA2} \\\n",
    "    --generator_adam_epsilon=${GENERATOR_ADAM_EPSILON} \\\n",
    "    --generator_clip_gradients=${GENERATOR_CLIP_GRADIENTS} \\\n",
    "    --generator_train_steps=${GENERATOR_TRAIN_STEPS} \\\n",
    "    \\\n",
    "    --use_minibatch_stddev=${USE_MINIBATCH_STDDEV} \\\n",
    "    --minibatch_stddev_group_size=${MINIBATCH_STDDEV_GROUP_SIZE} \\\n",
    "    --minibatch_stddev_averaging=${MINIBATCH_STDDEV_AVERAGING} \\\n",
    "    --discriminator_leaky_relu_alpha=${DISCRIMINATOR_LEAKY_RELU_ALPHA} \\\n",
    "    --discriminator_l1_regularization_scale=${DISCRIMINATOR_L1_REGULARIZATION_SCALE} \\\n",
    "    --discriminator_l2_regularization_scale=${DISCRIMINATOR_L2_REGULARIZATION_SCALE} \\\n",
    "    --discriminator_optimizer=${DISCRIMINATOR_OPTIMIZER} \\\n",
    "    --discriminator_learning_rate=${DISCRIMINATOR_LEARNING_RATE} \\\n",
    "    --discriminator_adam_beta1=${DISCRIMINATOR_ADAM_BETA1} \\\n",
    "    --discriminator_adam_beta2=${DISCRIMINATOR_ADAM_BETA2} \\\n",
    "    --discriminator_adam_epsilon=${DISCRIMINATOR_ADAM_EPSILON} \\\n",
    "    --discriminator_clip_gradients=${DISCRIMINATOR_CLIP_GRADIENTS} \\\n",
    "    --discriminator_gradient_penalty_coefficient=${DISCRIMINATOR_GRADIENT_PENALTY_COEFFICIENT} \\\n",
    "    --epsilon_drift=${EPSILON_DRIFT} \\\n",
    "    --discriminator_train_steps=${DISCRIMINATOR_TRAIN_STEPS} \\\n",
    "    \\\n",
    "    --encoder_leaky_relu_alpha=${ENCODER_LEAKY_RELU_ALPHA} \\\n",
    "    --encoder_l1_regularization_scale=${ENCODER_L1_REGULARIZATION_SCALE} \\\n",
    "    --encoder_l2_regularization_scale=${ENCODER_L2_REGULARIZATION_SCALE} \\\n",
    "    --encoder_optimizer=${ENCODER_OPTIMIZER} \\\n",
    "    --encoder_learning_rate=${ENCODER_LEARNING_RATE} \\\n",
    "    --encoder_adam_beta1=${ENCODER_ADAM_BETA1} \\\n",
    "    --encoder_adam_beta2=${ENCODER_ADAM_BETA2} \\\n",
    "    --encoder_adam_epsilon=${ENCODER_ADAM_EPSILON} \\\n",
    "    --encoder_clip_gradients=${ENCODER_CLIP_GRADIENTS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (50000, 32, 32, 3)\n",
      "y_train.shape = (50000, 1)\n",
      "x_test.shape = (10000, 32, 32, 3)\n",
      "y_test.shape = (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "print(\"x_train.shape = {}\".format(x_train.shape))\n",
    "print(\"y_train.shape = {}\".format(y_train.shape))\n",
    "print(\"x_test.shape = {}\".format(x_test.shape))\n",
    "print(\"y_test.shape = {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/export/exporter/1591961908/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/export/exporter | tail -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/export/exporter/1591961908/variables/variables\n"
     ]
    }
   ],
   "source": [
    "predict_fn = tf.contrib.predictor.from_saved_model(\n",
    "    \"gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/export/exporter/1591961908/\"\n",
    ")\n",
    "predictions = predict_fn(\n",
    "    {\n",
    "        \"query_image\": x_test[0:10]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encoded_images_4x4', 'anomaly_scores_4x4', 'anomaly_flags_4x4']\n"
     ]
    }
   ],
   "source": [
    "print(list(predictions.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoded_images_4x4']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_images = {k: v for k, v in predictions.items() if k[0:14] == \"encoded_images\"}\n",
    "list(encoded_images.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anomaly_scores_4x4']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_scores = {k: v for k, v in predictions.items() if k[0:14] == \"anomaly_scores\"}\n",
    "list(anomaly_scores.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anomaly_flags_4x4']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_flags = {k: v for k, v in predictions.items() if k[0:13] == \"anomaly_flags\"}\n",
    "list(anomaly_flags.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict_by_image_size(input_dict):\n",
    "    \"\"\"Sort predictions dictionary by image size.\n",
    "    \n",
    "    Args:\n",
    "        input_dict: dict, contains prediction keys and array values.\n",
    "    Return:\n",
    "        Sorted input dictionary on image size in ascending order.\n",
    "    \"\"\"\n",
    "    sorted_input_dict = [\n",
    "        x[0:2]\n",
    "        for x in sorted(\n",
    "            [\n",
    "                (\n",
    "                    k,\n",
    "                    input_dict[k],\n",
    "                    int(k.split(\"x\")[-1])\n",
    "                )\n",
    "                for k in input_dict.keys()\n",
    "            ],\n",
    "            key=lambda tup: tup[2]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    for k, v in sorted_input_dict:\n",
    "        print(k, v.shape)\n",
    "\n",
    "    return sorted_input_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_images_4x4 (10, 4, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "encoded_images = {\n",
    "    k: np.clip(\n",
    "        a=((v + 1.0) * (255. / 2)).astype(np.int32),\n",
    "        a_min=0,\n",
    "        a_max=255\n",
    "    )\n",
    "    for k, v in encoded_images.items()\n",
    "}\n",
    "\n",
    "sorted_encoded_images = sort_dict_by_image_size(encoded_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly_scores_4x4 (10,)\n"
     ]
    }
   ],
   "source": [
    "sorted_anomaly_scores = sort_dict_by_image_size(anomaly_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly_flags_4x4 (10,)\n"
     ]
    }
   ],
   "source": [
    "sorted_anomaly_flags = sort_dict_by_image_size(anomaly_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_images_4x4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPEAAAA4CAYAAAAsLB51AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAEG0lEQVR4nO3dS2hcZRjG8Wdyn0wmEyeZJsZAJ1RQKmrbpAakindduVGQIgalBERxJSouRPC+UERFF1KDSHVj3agoQcEbLmwTRKG0tklNW2uqmZhkYtLcJsedIHjO+w1S9YX/b3se3vNmmGcmMB8zqSiKBMCvmv96AQD/DCUGnKPEgHOUGHCOEgPOUWLAubpqwm3pXNSV3WTmWhqy9rCawNePFjsy+fOkSnOlVNz1jraOqNhVtAdVAvY5uxEQktRof3Q3OX1SpfJM7N755raoJ9dtzmnINNv7hPxtktQUFhs7MlaKoqjwd9ey9S1RoSlvzsi3288lrayFLZSuDYqN/fht7N7pmnSUrc2ZM1rr7Md7Zfls0D7p88Ie8GOzk7F7V1Xiruwm7b3tZTO3q/dqe1gmE3bTATvSP9ifeL3YVdTo8Kg9aD5gn+8XA0KSeu0nX/+j1yZe78l16/09+8w5xb4d9j6/2xFJ0kVhsdRA6kTctUJTXk9uf8Sccefg/faNxn8JW2hbwAuZpNTu1ti9s7U53ZG/y5xxQ3ufmRk/+l3QPpdevzUod/P+wdi9+XcacI4SA85RYsA5Sgw4R4kB5ygx4BwlBpyr6nPitY41TQ2dMXMPj95nZtItbWH3PGAfHDm9eDrxeqVlVeUrT5pznn7zBTOzsjFnZiSp81SvmTmzmvwZ6HJhVceGJs05z33xqpmZmLDnSNLCBytBuSSV7nUtPP6rmXts8QEzMz4zEXTPwkQxKJekeUuddgy3m7kn3nnIzGSviT3D8xdzl98elNP++Eu8EwPOUWLAOUoMOEeJAecoMeAcJQaco8SAc5QYcK6qwx6ZSloDs5eYuTdees3MbN2yOeiedRn7dSZaSD6g8NuJkvYNDZtzMgv2tzEs1SybGUkqF34yM5VV44sDZiuqvFc256Q/KpmZXR0dZkaSei6zD6lI0jfvfh17rXUjp5uWbjFn7H39FTNz3cXbg/ZZalgNyiWpL6fUNdJo5ob7njczp+bDDgUV8vY3oEjSU3ox9hrvxIBzlBhwjhIDzlFiwDlKDDhHiQHnKDHgHCUGnKPEgHNVndiaWi7rmfFPzNzOZ/eYmU8//yzonkuHj5uZciX5xNZM/bLeOv+wOWd6JfaXMv607YqdZkaSjn950MzMryWfEJurX9eH3TPmnAP2ITpd0NlphyR99cORoFyS+cZIH19o/4zN2+1TZqa3Key3imYPHQ3KJeps0/qDt5qx4ZERM9N341VBt7z37nuCckl4Jwaco8SAc5QYcI4SA85RYsA5Sgw4R4kB5ygx4BwlBpxLRVEUHk6lpiXZx5r+fZujKCrEXWTvcyJ2d/Y+J+L3rqbEAP5/+HcacI4SA85RYsA5Sgw4R4kB5ygx4BwlBpyjxIBzlBhw7g8ayfuOSglj/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_images = 5\n",
    "\n",
    "for k, v in sorted_encoded_images:\n",
    "    print(k)\n",
    "    plt.figure(figsize=(int(k.split(\"x\")[-1]), int(k.split(\"x\")[-1])))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(v[i], cmap=plt.cm.binary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly_scores_4x4\n",
      "[-0.36319256 -0.4460332  -0.3430669  -0.22148114 -0.2577624  -0.2967108\n",
      " -0.4022779  -0.32170016 -0.4400419  -0.51137537]\n"
     ]
    }
   ],
   "source": [
    "for k, v in sorted_anomaly_scores:\n",
    "    print(k)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly_flags_4x4\n",
      "[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for k, v in sorted_anomaly_flags:\n",
    "    print(k)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
