{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model module locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "def convert_conv_layer_property_lists_to_string(property_list, prop_list_len):\n",
    "    \"\"\"Convert conv layer property list to string.\n",
    "\n",
    "    Args:\n",
    "        property_list: list, nested list of blocks of a conv layer property.\n",
    "        prop_list_len: int, length of list to process.\n",
    "\n",
    "    Returns:\n",
    "        Doubly delimited string of conv layer property values.\n",
    "    \"\"\"\n",
    "    return (\";\").join(\n",
    "        [\n",
    "            (\",\").join([str(val) for val in block])\n",
    "            for block in property_list[0:prop_list_len]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "\n",
    "# Import os environment variables for file hyperparameters.\n",
    "os.environ[\"TRAIN_FILE_PATTERN\"] = \"gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/data/cifar10_car/train*.tfrecord\"\n",
    "os.environ[\"EVAL_FILE_PATTERN\"] = \"gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/data/cifar10_car/test*.tfrecord\"\n",
    "os.environ[\"OUTPUT_DIR\"] = \"gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model\"\n",
    "\n",
    "# Import os environment variables for train hyperparameters.\n",
    "os.environ[\"TRAIN_BATCH_SIZE\"] = str(16)\n",
    "os.environ[\"TRAIN_STEPS\"] = str(60)\n",
    "os.environ[\"USE_TPU\"] = \"False\"\n",
    "os.environ[\"USE_ESTIMATOR_TRAIN_AND_EVALUATE\"] = \"False\"\n",
    "os.environ[\"SAVE_OPTIMIZER_METRICS_TO_CHECKPOINT\"] = \"True\"\n",
    "os.environ[\"SAVE_SUMMARY_STEPS\"] = str(1)\n",
    "os.environ[\"SAVE_CHECKPOINTS_STEPS\"] = str(100)\n",
    "os.environ[\"KEEP_CHECKPOINT_MAX\"] = str(100)\n",
    "\n",
    "# Import os environment variables for eval hyperparameters.\n",
    "os.environ[\"EVAL_BATCH_SIZE\"] = str(16)\n",
    "os.environ[\"EVAL_STEPS\"] = \"None\"\n",
    "os.environ[\"START_DELAY_SECS\"] = str(600)\n",
    "os.environ[\"THROTTLE_SECS\"] = str(600)\n",
    "os.environ[\"EVAL_ON_TPU\"] = \"False\"\n",
    "\n",
    "# Import os environment variables for serving hyperparameters.\n",
    "os.environ[\"EXPORTS_TO_KEEP\"] = str(50)\n",
    "os.environ[\"EXPORT_TO_TPU\"] = \"False\"\n",
    "os.environ[\"EXPORT_TO_CPU\"] = \"True\"\n",
    "os.environ[\"PREDICT_ALL_RESOLUTIONS\"] = \"True\"\n",
    "os.environ[\"PREDICT_G_Z\"] = \"True\"\n",
    "os.environ[\"ANOMALY_THRESHOLD\"] = str(5.0)\n",
    "os.environ[\"ANOM_CONVEX_COMBO_FACTOR\"] = str(0.05)\n",
    "\n",
    "# Import os environment variables for image hyperparameters.\n",
    "os.environ[\"HEIGHT\"] = str(32)\n",
    "os.environ[\"WIDTH\"] = str(32)\n",
    "os.environ[\"DEPTH\"] = str(3)\n",
    "\n",
    "# Import os environment variables for shared hyperparameters.\n",
    "os.environ[\"NUM_STEPS_UNTIL_GROWTH\"] = str(10)\n",
    "os.environ[\"USE_EQUALIZED_LEARNING_RATE\"] = \"True\"\n",
    "\n",
    "# Full lists for full 1024x1024 network growth.\n",
    "full_conv_num_filters = [[512, 512], [512, 512], [512, 512], [512, 512], [256, 256], [128, 128], [64, 64], [32, 32], [16, 16]]\n",
    "full_conv_kernel_sizes = [[4, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]]\n",
    "full_conv_strides = [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]]\n",
    "\n",
    "# Set final image size as a multiple of 2, starting at 4.\n",
    "image_size = 16\n",
    "os.environ[\"IMAGE_SIZE\"] = str(image_size)\n",
    "prop_list_len = max(\n",
    "    min(int(math.log(image_size, 2) - 1), len(full_conv_num_filters)), 1\n",
    ")\n",
    "\n",
    "# Get slices of lists.\n",
    "conv_num_filters = convert_conv_layer_property_lists_to_string(\n",
    "    full_conv_num_filters, prop_list_len\n",
    ")\n",
    "print(\"conv_num_filters = {}\".format(conv_num_filters))\n",
    "conv_kernel_sizes = convert_conv_layer_property_lists_to_string(\n",
    "    full_conv_kernel_sizes, prop_list_len\n",
    ")\n",
    "print(\"conv_kernel_sizes = {}\".format(conv_kernel_sizes))\n",
    "conv_strides = convert_conv_layer_property_lists_to_string(\n",
    "    full_conv_strides, prop_list_len\n",
    ")\n",
    "print(\"conv_strides = {}\".format(conv_strides))\n",
    "\n",
    "os.environ[\"CONV_NUM_FILTERS\"] = conv_num_filters\n",
    "os.environ[\"CONV_KERNEL_SIZES\"] = conv_kernel_sizes\n",
    "os.environ[\"CONV_STRIDES\"] = conv_strides\n",
    "\n",
    "# Import os environment variables for generator hyperparameters.\n",
    "os.environ[\"LATENT_SIZE\"] = str(512)\n",
    "os.environ[\"NORMALIZE_LATENT\"] = \"True\"\n",
    "os.environ[\"USE_PIXEL_NORM\"] = \"True\"\n",
    "os.environ[\"PIXEL_NORM_EPSILON\"] = str(1e-8)\n",
    "os.environ[\"GENERATOR_PROJECTION_DIMS\"] = \"4,4,512\"\n",
    "os.environ[\"GENERATOR_LEAKY_RELU_ALPHA\"] = str(0.2)\n",
    "os.environ[\"GENERATOR_TO_RGB_ACTIVATION\"] = \"None\"\n",
    "os.environ[\"GENERATOR_L1_REGULARIZATION_SCALE\"] = str(0.)\n",
    "os.environ[\"GENERATOR_L2_REGULARIZATION_SCALE\"] = str(0.)\n",
    "os.environ[\"GENERATOR_OPTIMIZER\"] = \"Adam\"\n",
    "os.environ[\"GENERATOR_LEARNING_RATE\"] = str(0.001)\n",
    "os.environ[\"GENERATOR_ADAM_BETA1\"] = str(0.)\n",
    "os.environ[\"GENERATOR_ADAM_BETA2\"] = str(0.99)\n",
    "os.environ[\"GENERATOR_ADAM_EPSILON\"] = str(1e-8)\n",
    "os.environ[\"GENERATOR_CLIP_GRADIENTS\"] = \"None\"\n",
    "os.environ[\"GENERATOR_TRAIN_STEPS\"] = str(1)\n",
    "\n",
    "# Import os environment variables for discriminator hyperparameters.\n",
    "os.environ[\"USE_MINIBATCH_STDDEV\"] = \"True\"\n",
    "os.environ[\"MINIBATCH_STDDEV_GROUP_SIZE\"] = str(4)\n",
    "os.environ[\"MINIBATCH_STDDEV_AVERAGING\"] = \"True\"\n",
    "os.environ[\"DISCRIMINATOR_LEAKY_RELU_ALPHA\"] = str(0.2)\n",
    "os.environ[\"DISCRIMINATOR_L1_REGULARIZATION_SCALE\"] = str(0.)\n",
    "os.environ[\"DISCRIMINATOR_L2_REGULARIZATION_SCALE\"] = str(0.)\n",
    "os.environ[\"DISCRIMINATOR_OPTIMIZER\"] = \"Adam\"\n",
    "os.environ[\"DISCRIMINATOR_LEARNING_RATE\"] = str(0.001)\n",
    "os.environ[\"DISCRIMINATOR_ADAM_BETA1\"] = str(0.)\n",
    "os.environ[\"DISCRIMINATOR_ADAM_BETA2\"] = str(0.99)\n",
    "os.environ[\"DISCRIMINATOR_ADAM_EPSILON\"] = str(1e-8)\n",
    "os.environ[\"DISCRIMINATOR_CLIP_GRADIENTS\"] = \"None\"\n",
    "os.environ[\"DISCRIMINATOR_GRADIENT_PENALTY_COEFFICIENT\"] = str(10.0)\n",
    "os.environ[\"EPSILON_DRIFT\"] = str(0.001)\n",
    "os.environ[\"DISCRIMINATOR_TRAIN_STEPS\"] = str(1)\n",
    "\n",
    "# Import os environment variables for encoder hyperparameters.\n",
    "os.environ[\"ENCODER_LEAKY_RELU_ALPHA\"] = str(0.2)\n",
    "os.environ[\"ENCODER_L1_REGULARIZATION_SCALE\"] = str(0.)\n",
    "os.environ[\"ENCODER_L2_REGULARIZATION_SCALE\"] = str(0.)\n",
    "os.environ[\"ENCODER_OPTIMIZER\"] = \"Adam\"\n",
    "os.environ[\"ENCODER_LEARNING_RATE\"] = str(0.001)\n",
    "os.environ[\"ENCODER_ADAM_BETA1\"] = str(0.)\n",
    "os.environ[\"ENCODER_ADAM_BETA2\"] = str(0.99)\n",
    "os.environ[\"ENCODER_ADAM_EPSILON\"] = str(1e-8)\n",
    "os.environ[\"ENCODER_CLIP_GRADIENTS\"] = \"None\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train pg_AnoGAN_Sim_Enc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil -m rm -rf ${OUTPUT_DIR}\n",
    "export PYTHONPATH=$PYTHONPATH:$PWD/pg_anogan_sim_enc_tpu_module\n",
    "python3 -m trainer.task \\\n",
    "    --train_file_pattern=${TRAIN_FILE_PATTERN} \\\n",
    "    --eval_file_pattern=${EVAL_FILE_PATTERN} \\\n",
    "    --output_dir=${OUTPUT_DIR} \\\n",
    "    --job-dir=./tmp \\\n",
    "    \\\n",
    "    --train_batch_size=${TRAIN_BATCH_SIZE} \\\n",
    "    --train_steps=${TRAIN_STEPS} \\\n",
    "    --use_tpu=${USE_TPU} \\\n",
    "    --use_estimator_train_and_evaluate=${USE_ESTIMATOR_TRAIN_AND_EVALUATE} \\\n",
    "    --save_optimizer_metrics_to_checkpoint=${SAVE_OPTIMIZER_METRICS_TO_CHECKPOINT} \\\n",
    "    --save_summary_steps=${SAVE_SUMMARY_STEPS} \\\n",
    "    --save_checkpoints_steps=${SAVE_CHECKPOINTS_STEPS} \\\n",
    "    --keep_checkpoint_max=${KEEP_CHECKPOINT_MAX} \\\n",
    "    \\\n",
    "    --eval_batch_size=${EVAL_BATCH_SIZE} \\\n",
    "    --eval_steps=${EVAL_STEPS} \\\n",
    "    --start_delay_secs=${START_DELAY_SECS} \\\n",
    "    --throttle_secs=${THROTTLE_SECS} \\\n",
    "    --eval_on_tpu=${EVAL_ON_TPU} \\\n",
    "    \\\n",
    "    --exports_to_keep=${EXPORTS_TO_KEEP} \\\n",
    "    --export_to_tpu=${EXPORT_TO_TPU} \\\n",
    "    --export_to_cpu=${EXPORT_TO_CPU} \\\n",
    "    --predict_all_resolutions=${PREDICT_ALL_RESOLUTIONS} \\\n",
    "    --predict_g_z=${PREDICT_G_Z} \\\n",
    "    --anomaly_threshold=${ANOMALY_THRESHOLD} \\\n",
    "    --anom_convex_combo_factor=${ANOM_CONVEX_COMBO_FACTOR} \\\n",
    "    \\\n",
    "    --height=${HEIGHT} \\\n",
    "    --width=${WIDTH} \\\n",
    "    --depth=${DEPTH} \\\n",
    "    \\\n",
    "    --num_steps_until_growth=${NUM_STEPS_UNTIL_GROWTH} \\\n",
    "    --use_equalized_learning_rate=${USE_EQUALIZED_LEARNING_RATE} \\\n",
    "    --conv_num_filters=${CONV_NUM_FILTERS} \\\n",
    "    --conv_kernel_sizes=${CONV_KERNEL_SIZES} \\\n",
    "    --conv_strides=${CONV_STRIDES} \\\n",
    "    \\\n",
    "    --latent_size=${LATENT_SIZE} \\\n",
    "    --normalize_latent=${NORMALIZE_LATENT} \\\n",
    "    --use_pixel_norm=${USE_PIXEL_NORM} \\\n",
    "    --pixel_norm_epsilon=${PIXEL_NORM_EPSILON} \\\n",
    "    --generator_projection_dims=${GENERATOR_PROJECTION_DIMS} \\\n",
    "    --generator_leaky_relu_alpha=${GENERATOR_LEAKY_RELU_ALPHA} \\\n",
    "    --generator_to_rgb_activation=${GENERATOR_TO_RGB_ACTIVATION} \\\n",
    "    --generator_l1_regularization_scale=${GENERATOR_L1_REGULARIZATION_SCALE} \\\n",
    "    --generator_l2_regularization_scale=${GENERATOR_L2_REGULARIZATION_SCALE} \\\n",
    "    --generator_optimizer=${GENERATOR_OPTIMIZER} \\\n",
    "    --generator_learning_rate=${GENERATOR_LEARNING_RATE} \\\n",
    "    --generator_adam_beta1=${GENERATOR_ADAM_BETA1} \\\n",
    "    --generator_adam_beta2=${GENERATOR_ADAM_BETA2} \\\n",
    "    --generator_adam_epsilon=${GENERATOR_ADAM_EPSILON} \\\n",
    "    --generator_clip_gradients=${GENERATOR_CLIP_GRADIENTS} \\\n",
    "    --generator_train_steps=${GENERATOR_TRAIN_STEPS} \\\n",
    "    \\\n",
    "    --use_minibatch_stddev=${USE_MINIBATCH_STDDEV} \\\n",
    "    --minibatch_stddev_group_size=${MINIBATCH_STDDEV_GROUP_SIZE} \\\n",
    "    --minibatch_stddev_averaging=${MINIBATCH_STDDEV_AVERAGING} \\\n",
    "    --discriminator_leaky_relu_alpha=${DISCRIMINATOR_LEAKY_RELU_ALPHA} \\\n",
    "    --discriminator_l1_regularization_scale=${DISCRIMINATOR_L1_REGULARIZATION_SCALE} \\\n",
    "    --discriminator_l2_regularization_scale=${DISCRIMINATOR_L2_REGULARIZATION_SCALE} \\\n",
    "    --discriminator_optimizer=${DISCRIMINATOR_OPTIMIZER} \\\n",
    "    --discriminator_learning_rate=${DISCRIMINATOR_LEARNING_RATE} \\\n",
    "    --discriminator_adam_beta1=${DISCRIMINATOR_ADAM_BETA1} \\\n",
    "    --discriminator_adam_beta2=${DISCRIMINATOR_ADAM_BETA2} \\\n",
    "    --discriminator_adam_epsilon=${DISCRIMINATOR_ADAM_EPSILON} \\\n",
    "    --discriminator_clip_gradients=${DISCRIMINATOR_CLIP_GRADIENTS} \\\n",
    "    --discriminator_gradient_penalty_coefficient=${DISCRIMINATOR_GRADIENT_PENALTY_COEFFICIENT} \\\n",
    "    --epsilon_drift=${EPSILON_DRIFT} \\\n",
    "    --discriminator_train_steps=${DISCRIMINATOR_TRAIN_STEPS} \\\n",
    "    \\\n",
    "    --encoder_leaky_relu_alpha=${ENCODER_LEAKY_RELU_ALPHA} \\\n",
    "    --encoder_l1_regularization_scale=${ENCODER_L1_REGULARIZATION_SCALE} \\\n",
    "    --encoder_l2_regularization_scale=${ENCODER_L2_REGULARIZATION_SCALE} \\\n",
    "    --encoder_optimizer=${ENCODER_OPTIMIZER} \\\n",
    "    --encoder_learning_rate=${ENCODER_LEARNING_RATE} \\\n",
    "    --encoder_adam_beta1=${ENCODER_ADAM_BETA1} \\\n",
    "    --encoder_adam_beta2=${ENCODER_ADAM_BETA2} \\\n",
    "    --encoder_adam_epsilon=${ENCODER_ADAM_EPSILON} \\\n",
    "    --encoder_clip_gradients=${ENCODER_CLIP_GRADIENTS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_stages = 5\n",
    "# num_steps_until_growth = 10\n",
    "# with tf.Session() as sess:\n",
    "#     # Create alpha variable to use for weighted sum for smooth fade-in.\n",
    "#     with tf.variable_scope(name_or_scope=\"alpha\", reuse=tf.AUTO_REUSE):\n",
    "#         alpha_var = tf.get_variable(\n",
    "#             name=\"alpha_var\",\n",
    "#             dtype=tf.float32,\n",
    "#             # When the initializer is a function, tensorflow can place it\n",
    "#             # \"outside of the control flow context\" to make sure it always runs.\n",
    "#             initializer=lambda: tf.zeros(shape=[], dtype=tf.float32),\n",
    "#             trainable=False\n",
    "#         )\n",
    "\n",
    "#     for growth_idx in range(num_stages):\n",
    "#         for step in range(num_steps_until_growth):\n",
    "#             global_step = growth_idx * num_steps_until_growth + step\n",
    "\n",
    "#             if growth_idx > 0:\n",
    "#                 if growth_idx % 2 == 1:\n",
    "#                     # Update alpha var to linearly scale from 0 to 1 based on steps.\n",
    "#                     alpha_var = tf.assign(\n",
    "#                         ref=alpha_var,\n",
    "#                         value=tf.divide(\n",
    "#                             x=tf.cast(\n",
    "#                                 # Add 1 since it trains on global step 0, so off by 1.\n",
    "#                                 x=tf.add(\n",
    "#                                     x=tf.mod(\n",
    "#                                         x=global_step, y=num_steps_until_growth\n",
    "#                                     ),\n",
    "#                                     y=1\n",
    "#                                 ),\n",
    "#                                 dtype=tf.float32\n",
    "#                             ),\n",
    "#                             y=num_steps_until_growth\n",
    "#                         ),\n",
    "#                         name=\"alpha_var_update_op_assign_linear\"\n",
    "#                     )\n",
    "#                 else:\n",
    "#                     alpha_var = tf.assign(\n",
    "#                         ref=alpha_var,\n",
    "#                         value=tf.ones(shape=[], dtype=tf.float32),\n",
    "#                         name=\"alpha_var_update_op_assign_ones\"\n",
    "#                     )\n",
    "#             sess.run(tf.global_variables_initializer())\n",
    "#             alpha_arr = sess.run(alpha_var)\n",
    "#             print(global_step, alpha_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "1 0 0\n",
      "2 0 0\n",
      "3 0 0\n",
      "4 0 0\n",
      "5 0 0\n",
      "6 0 0\n",
      "7 0 0\n",
      "8 0 0\n",
      "9 0 0\n",
      "10 1 1\n",
      "11 1 1\n",
      "12 1 1\n",
      "13 1 1\n",
      "14 1 1\n",
      "15 1 1\n",
      "16 1 1\n",
      "17 1 1\n",
      "18 1 1\n",
      "19 1 1\n",
      "20 2 0\n",
      "21 2 0\n",
      "22 2 0\n",
      "23 2 0\n",
      "24 2 0\n",
      "25 2 0\n",
      "26 2 0\n",
      "27 2 0\n",
      "28 2 0\n",
      "29 2 0\n",
      "30 3 1\n",
      "31 3 1\n",
      "32 3 1\n",
      "33 3 1\n",
      "34 3 1\n",
      "35 3 1\n",
      "36 3 1\n",
      "37 3 1\n",
      "38 3 1\n",
      "39 3 1\n",
      "40 4 0\n",
      "41 4 0\n",
      "42 4 0\n",
      "43 4 0\n",
      "44 4 0\n",
      "45 4 0\n",
      "46 4 0\n",
      "47 4 0\n",
      "48 4 0\n",
      "49 4 0\n",
      "50 5 1\n",
      "51 5 1\n",
      "52 5 1\n",
      "53 5 1\n",
      "54 5 1\n",
      "55 5 1\n",
      "56 5 1\n",
      "57 5 1\n",
      "58 5 1\n",
      "59 5 1\n",
      "60 6 0\n",
      "61 6 0\n",
      "62 6 0\n",
      "63 6 0\n",
      "64 6 0\n",
      "65 6 0\n",
      "66 6 0\n",
      "67 6 0\n",
      "68 6 0\n",
      "69 6 0\n",
      "70 7 1\n",
      "71 7 1\n",
      "72 7 1\n",
      "73 7 1\n",
      "74 7 1\n",
      "75 7 1\n",
      "76 7 1\n",
      "77 7 1\n",
      "78 7 1\n",
      "79 7 1\n",
      "80 8 0\n",
      "81 8 0\n",
      "82 8 0\n",
      "83 8 0\n",
      "84 8 0\n",
      "85 8 0\n",
      "86 8 0\n",
      "87 8 0\n",
      "88 8 0\n",
      "89 8 0\n",
      "90 9 1\n",
      "91 9 1\n",
      "92 9 1\n",
      "93 9 1\n",
      "94 9 1\n",
      "95 9 1\n",
      "96 9 1\n",
      "97 9 1\n",
      "98 9 1\n",
      "99 9 1\n",
      "100 10 0\n",
      "101 10 0\n",
      "102 10 0\n",
      "103 10 0\n",
      "104 10 0\n",
      "105 10 0\n",
      "106 10 0\n",
      "107 10 0\n",
      "108 10 0\n",
      "109 10 0\n",
      "110 11 1\n",
      "111 11 1\n",
      "112 11 1\n",
      "113 11 1\n",
      "114 11 1\n",
      "115 11 1\n",
      "116 11 1\n",
      "117 11 1\n",
      "118 11 1\n",
      "119 11 1\n",
      "120 12 0\n",
      "121 12 0\n",
      "122 12 0\n",
      "123 12 0\n",
      "124 12 0\n",
      "125 12 0\n",
      "126 12 0\n",
      "127 12 0\n",
      "128 12 0\n",
      "129 12 0\n",
      "130 13 1\n",
      "131 13 1\n",
      "132 13 1\n",
      "133 13 1\n",
      "134 13 1\n",
      "135 13 1\n",
      "136 13 1\n",
      "137 13 1\n",
      "138 13 1\n",
      "139 13 1\n",
      "140 14 0\n",
      "141 14 0\n",
      "142 14 0\n",
      "143 14 0\n",
      "144 14 0\n",
      "145 14 0\n",
      "146 14 0\n",
      "147 14 0\n",
      "148 14 0\n",
      "149 14 0\n",
      "150 15 1\n",
      "151 15 1\n",
      "152 15 1\n",
      "153 15 1\n",
      "154 15 1\n",
      "155 15 1\n",
      "156 15 1\n",
      "157 15 1\n",
      "158 15 1\n",
      "159 15 1\n",
      "160 16 0\n",
      "161 16 0\n",
      "162 16 0\n",
      "163 16 0\n",
      "164 16 0\n",
      "165 16 0\n",
      "166 16 0\n",
      "167 16 0\n",
      "168 16 0\n",
      "169 16 0\n",
      "170 16 0\n",
      "171 16 0\n",
      "172 16 0\n",
      "173 16 0\n",
      "174 16 0\n",
      "175 16 0\n",
      "176 16 0\n",
      "177 16 0\n",
      "178 16 0\n",
      "179 16 0\n",
      "180 16 0\n",
      "181 16 0\n",
      "182 16 0\n",
      "183 16 0\n",
      "184 16 0\n",
      "185 16 0\n",
      "186 16 0\n",
      "187 16 0\n",
      "188 16 0\n",
      "189 16 0\n",
      "190 16 0\n",
      "191 16 0\n",
      "192 16 0\n",
      "193 16 0\n",
      "194 16 0\n",
      "195 16 0\n",
      "196 16 0\n",
      "197 16 0\n",
      "198 16 0\n",
      "199 16 0\n"
     ]
    }
   ],
   "source": [
    "conv_num_filters = 9\n",
    "num_steps_until_growth = 10\n",
    "train_steps = 200\n",
    "num_stages = 2 * conv_num_filters - 1\n",
    "min_train_steps_for_full_growth = num_stages * num_steps_until_growth\n",
    "train_steps = max(train_steps, min_train_steps_for_full_growth)\n",
    "with tf.Session() as sess:\n",
    "    for global_step in range(train_steps):\n",
    "        growth_index = tf.minimum(\n",
    "            x=tf.cast(\n",
    "                x=tf.floordiv(\n",
    "                    x=global_step,\n",
    "                    y=num_steps_until_growth,\n",
    "                    name=\"global_step_floordiv\"\n",
    "                ),\n",
    "                dtype=tf.int32),\n",
    "            y=(conv_num_filters - 1) * 2,\n",
    "            name=\"growth_index\"\n",
    "        )\n",
    "        growth_index_arr = sess.run(growth_index)\n",
    "        print(global_step, growth_index_arr, growth_index_arr % 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "print(\"x_train.shape = {}\".format(x_train.shape))\n",
    "print(\"y_train.shape = {}\".format(y_train.shape))\n",
    "print(\"x_test.shape = {}\".format(x_test.shape))\n",
    "print(\"y_test.shape = {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/export/exporter | tail -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn = tf.contrib.predictor.from_saved_model(\n",
    "    \"gs://machine-learning-1234-bucket/gan/pg_anogan_sim_enc/trained_model/export/exporter/1591961908/\"\n",
    ")\n",
    "predictions = predict_fn(\n",
    "    {\n",
    "        \"query_image\": x_test[0:10]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(predictions.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_images = {k: v for k, v in predictions.items() if k[0:14] == \"encoded_images\"}\n",
    "list(encoded_images.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_scores = {k: v for k, v in predictions.items() if k[0:14] == \"anomaly_scores\"}\n",
    "list(anomaly_scores.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_flags = {k: v for k, v in predictions.items() if k[0:13] == \"anomaly_flags\"}\n",
    "list(anomaly_flags.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict_by_image_size(input_dict):\n",
    "    \"\"\"Sort predictions dictionary by image size.\n",
    "    \n",
    "    Args:\n",
    "        input_dict: dict, contains prediction keys and array values.\n",
    "    Return:\n",
    "        Sorted input dictionary on image size in ascending order.\n",
    "    \"\"\"\n",
    "    sorted_input_dict = [\n",
    "        x[0:2]\n",
    "        for x in sorted(\n",
    "            [\n",
    "                (\n",
    "                    k,\n",
    "                    input_dict[k],\n",
    "                    int(k.split(\"x\")[-1])\n",
    "                )\n",
    "                for k in input_dict.keys()\n",
    "            ],\n",
    "            key=lambda tup: tup[2]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    for k, v in sorted_input_dict:\n",
    "        print(k, v.shape)\n",
    "\n",
    "    return sorted_input_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_images = {\n",
    "    k: np.clip(\n",
    "        a=((v + 1.0) * (255. / 2)).astype(np.int32),\n",
    "        a_min=0,\n",
    "        a_max=255\n",
    "    )\n",
    "    for k, v in encoded_images.items()\n",
    "}\n",
    "\n",
    "sorted_encoded_images = sort_dict_by_image_size(encoded_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_anomaly_scores = sort_dict_by_image_size(anomaly_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_anomaly_flags = sort_dict_by_image_size(anomaly_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 5\n",
    "\n",
    "for k, v in sorted_encoded_images:\n",
    "    print(k)\n",
    "    plt.figure(figsize=(int(k.split(\"x\")[-1]), int(k.split(\"x\")[-1])))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(v[i], cmap=plt.cm.binary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in sorted_anomaly_scores:\n",
    "    print(k)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in sorted_anomaly_flags:\n",
    "    print(k)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
