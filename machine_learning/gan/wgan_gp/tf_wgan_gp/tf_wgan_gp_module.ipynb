{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print_object.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile wgan_gp_module/trainer/print_object.py\n",
    "def print_obj(function_name, object_name, object_value):\n",
    "    \"\"\"Prints enclosing function, object name, and object value.\n",
    "\n",
    "    Args:\n",
    "        function_name: str, name of function.\n",
    "        object_name: str, name of object.\n",
    "        object_value: object, value of passed object.\n",
    "    \"\"\"\n",
    "#     pass\n",
    "    print(\"{}: {} = {}\".format(function_name, object_name, object_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile wgan_gp_module/trainer/input.py\n",
    "import tensorflow as tf\n",
    "\n",
    "from .print_object import print_obj\n",
    "\n",
    "\n",
    "def decode_example(protos, params):\n",
    "    \"\"\"Decodes TFRecord file into tensors.\n",
    "\n",
    "    Given protobufs, decode into image and label tensors.\n",
    "\n",
    "    Args:\n",
    "        protos: protobufs from TFRecord file.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Image and label tensors.\n",
    "    \"\"\"\n",
    "    # Create feature schema map for protos.\n",
    "    features = {\n",
    "        \"image_raw\": tf.FixedLenFeature(shape=[], dtype=tf.string),\n",
    "        \"label\": tf.FixedLenFeature(shape=[], dtype=tf.int64)\n",
    "    }\n",
    "\n",
    "    # Parse features from tf.Example.\n",
    "    parsed_features = tf.parse_single_example(\n",
    "        serialized=protos, features=features\n",
    "    )\n",
    "    print_obj(\"\\ndecode_example\", \"features\", features)\n",
    "\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length height * width * depth) to a uint8 tensor with shape\n",
    "    # [height * width * depth].\n",
    "    image = tf.decode_raw(\n",
    "        input_bytes=parsed_features[\"image_raw\"], out_type=tf.uint8\n",
    "    )\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Reshape flattened image back into normal dimensions.\n",
    "    image = tf.reshape(\n",
    "        tensor=image,\n",
    "        shape=[params[\"height\"], params[\"width\"], params[\"depth\"]]\n",
    "    )\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Convert from [0, 255] -> [-1.0, 1.0] floats.\n",
    "    image = tf.cast(x=image, dtype=tf.float32) * (2. / 255) - 1.0\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "    label = tf.cast(x=parsed_features[\"label\"], dtype=tf.int32)\n",
    "    print_obj(\"decode_example\", \"label\", label)\n",
    "\n",
    "    return {\"image\": image}, label\n",
    "\n",
    "\n",
    "def read_dataset(filename, mode, batch_size, params):\n",
    "    \"\"\"Reads CSV time series data using tf.data, doing necessary preprocessing.\n",
    "\n",
    "    Given filename, mode, batch size, and other parameters, read CSV dataset\n",
    "    using Dataset API, apply necessary preprocessing, and return an input\n",
    "    function to the Estimator API.\n",
    "\n",
    "    Args:\n",
    "        filename: str, file pattern that to read into our tf.data dataset.\n",
    "        mode: The estimator ModeKeys. Can be TRAIN or EVAL.\n",
    "        batch_size: int, number of examples per batch.\n",
    "        params: dict, dictionary of user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        An input function.\n",
    "    \"\"\"\n",
    "    def _input_fn():\n",
    "        \"\"\"Wrapper input function used by Estimator API to get data tensors.\n",
    "\n",
    "        Returns:\n",
    "            Batched dataset object of dictionary of feature tensors and label\n",
    "                tensor.\n",
    "        \"\"\"\n",
    "        # Create list of files that match pattern.\n",
    "        file_list = tf.gfile.Glob(filename=filename)\n",
    "\n",
    "        # Create dataset from file list.\n",
    "        dataset = tf.data.TFRecordDataset(\n",
    "            filenames=file_list, num_parallel_reads=40\n",
    "        )\n",
    "\n",
    "        # Shuffle and repeat if training with fused op.\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            dataset = dataset.apply(\n",
    "                tf.contrib.data.shuffle_and_repeat(\n",
    "                    buffer_size=50 * batch_size,\n",
    "                    count=None  # indefinitely\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Decode CSV file into a features dictionary of tensors, then batch.\n",
    "        dataset = dataset.apply(\n",
    "            tf.contrib.data.map_and_batch(\n",
    "                map_func=lambda x: decode_example(\n",
    "                    protos=x,\n",
    "                    params=params\n",
    "                ),\n",
    "                batch_size=batch_size,\n",
    "                num_parallel_calls=4\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Prefetch data to improve latency.\n",
    "        dataset = dataset.prefetch(buffer_size=2)\n",
    "\n",
    "        # Create a iterator, then get batch of features from example queue.\n",
    "        batched_dataset = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        return batched_dataset\n",
    "    return _input_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile wgan_gp_module/trainer/generator.py\n",
    "import tensorflow as tf\n",
    "\n",
    "from .print_object import print_obj\n",
    "\n",
    "\n",
    "def generator_network(Z, mode, params, reuse=False):\n",
    "    \"\"\"Creates generator network and returns generated output.\n",
    "\n",
    "    Args:\n",
    "        Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "        mode: tf.estimator.ModeKeys with values of either TRAIN, EVAL, or\n",
    "            PREDICT.\n",
    "        params: dict, user passed parameters.\n",
    "        reuse: bool, whether to reuse variables or not.\n",
    "\n",
    "    Returns:\n",
    "        Generated outputs tensor of shape\n",
    "            [cur_batch_size, height * width * depth].\n",
    "    \"\"\"\n",
    "    # Create regularizer for dense layer kernel weights.\n",
    "    regularizer = tf.contrib.layers.l1_l2_regularizer(\n",
    "        scale_l1=params[\"generator_l1_regularization_scale\"],\n",
    "        scale_l2=params[\"generator_l2_regularization_scale\"]\n",
    "    )\n",
    "\n",
    "    with tf.variable_scope(\"generator\", reuse=reuse):\n",
    "        # Project latent vectors.\n",
    "        projection_height = params[\"generator_projection_dims\"][0]\n",
    "        projection_width = params[\"generator_projection_dims\"][1]\n",
    "        projection_depth = params[\"generator_projection_dims\"][2]\n",
    "\n",
    "        # shape = (\n",
    "        #     cur_batch_size,\n",
    "        #     projection_height * projection_width * projection_depth\n",
    "        # )\n",
    "        projection = tf.layers.dense(\n",
    "            inputs=Z,\n",
    "            units=projection_height * projection_width * projection_depth,\n",
    "            activation=tf.nn.leaky_relu,\n",
    "            name=\"projection_layer\"\n",
    "        )\n",
    "        print_obj(\"generator_network\", \"projection\", projection)\n",
    "\n",
    "        # shape = (\n",
    "        #     cur_batch_size,\n",
    "        #     projection_height * projection_width * projection_depth\n",
    "        # )\n",
    "        projection_batch_norm = tf.layers.batch_normalization(\n",
    "            inputs=projection,\n",
    "            training=(mode == tf.estimator.ModeKeys.TRAIN),\n",
    "            name=\"projection_batch_norm\"\n",
    "        )\n",
    "        print_obj(\n",
    "            \"generator_network\",\n",
    "            \"projection_batch_norm\",\n",
    "            projection_batch_norm\n",
    "        )\n",
    "\n",
    "        # Reshape projection into \"image\".\n",
    "        # shape = (\n",
    "        #     cur_batch_size,\n",
    "        #     projection_height,\n",
    "        #     projection_width,\n",
    "        #     projection_depth\n",
    "        # )\n",
    "        network = tf.reshape(\n",
    "            tensor=projection_batch_norm,\n",
    "            shape=[-1, projection_height, projection_width, projection_depth],\n",
    "            name=\"projection_reshaped\"\n",
    "        )\n",
    "        print_obj(\"generator_network\", \"network\", network)\n",
    "\n",
    "        # Iteratively build upsampling layers.\n",
    "        for i in range(len(params[\"generator_num_filters\"])):\n",
    "            # Add convolutional transpose layers with given params per layer.\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     generator_kernel_sizes[i - 1] * generator_strides[i],\n",
    "            #     generator_kernel_sizes[i - 1] * generator_strides[i],\n",
    "            #     generator_num_filters[i]\n",
    "            # )\n",
    "            network = tf.layers.conv2d_transpose(\n",
    "                inputs=network,\n",
    "                filters=params[\"generator_num_filters\"][i],\n",
    "                kernel_size=params[\"generator_kernel_sizes\"][i],\n",
    "                strides=params[\"generator_strides\"][i],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.leaky_relu,\n",
    "                use_bias=False,\n",
    "                kernel_regularizer=regularizer,\n",
    "                name=\"layers_conv2d_tranpose_{}\".format(i)\n",
    "            )\n",
    "            print_obj(\"generator_network\", \"network\", network)\n",
    "\n",
    "            # Add batch normalization to keep the inputs from blowing up.\n",
    "            network = tf.layers.batch_normalization(\n",
    "                inputs=network,\n",
    "                training=(mode == tf.estimator.ModeKeys.TRAIN),\n",
    "                name=\"layers_batch_norm_{}\".format(i)\n",
    "            )\n",
    "            print_obj(\"generator_network\", \"network\", network)\n",
    "\n",
    "        # Final conv2d transpose layer for image output.\n",
    "        # shape = (cur_batch_size, height * width * depth)\n",
    "        generated_outputs = tf.layers.conv2d_transpose(\n",
    "                inputs=network,\n",
    "                filters=params[\"generator_final_num_filters\"],\n",
    "                kernel_size=params[\"generator_final_kernel_size\"],\n",
    "                strides=params[\"generator_final_stride\"],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.tanh,\n",
    "                use_bias=False,\n",
    "                kernel_regularizer=regularizer,\n",
    "                name=\"layers_conv2d_tranpose_generated_outputs\"\n",
    "        )\n",
    "        print_obj(\"generator_network\", \"generated_outputs\", generated_outputs)\n",
    "\n",
    "    return generated_outputs\n",
    "\n",
    "\n",
    "def get_generator_loss(generated_logits):\n",
    "    \"\"\"Gets generator loss.\n",
    "\n",
    "    Args:\n",
    "        generated_logits: tensor, shape of\n",
    "            [cur_batch_size, height * width * depth].\n",
    "\n",
    "    Returns:\n",
    "        Tensor of generator's total loss of shape [].\n",
    "    \"\"\"\n",
    "    # Calculate base generator loss.\n",
    "    generator_loss = -tf.reduce_mean(\n",
    "        input_tensor=generated_logits,\n",
    "        name=\"generator_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"\\nget_generator_loss\",\n",
    "        \"generator_loss\",\n",
    "        generator_loss\n",
    "    )\n",
    "\n",
    "    # Get regularization losses.\n",
    "    generator_regularization_loss = tf.losses.get_regularization_loss(\n",
    "        scope=\"generator\",\n",
    "        name=\"generator_regularization_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_generator_loss\",\n",
    "        \"generator_regularization_loss\",\n",
    "        generator_regularization_loss\n",
    "    )\n",
    "\n",
    "    # Combine losses for total losses.\n",
    "    generator_total_loss = tf.math.add(\n",
    "        x=generator_loss,\n",
    "        y=generator_regularization_loss,\n",
    "        name=\"generator_total_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_generator_loss\", \"generator_total_loss\", generator_total_loss\n",
    "    )\n",
    "\n",
    "    return generator_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## critic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile wgan_gp_module/trainer/critic.py\n",
    "import tensorflow as tf\n",
    "\n",
    "from .print_object import print_obj\n",
    "\n",
    "\n",
    "def critic_network(X, params, reuse=False):\n",
    "    \"\"\"Creates critic network and returns logits.\n",
    "\n",
    "    Args:\n",
    "        X: tensor, image tensors of shape\n",
    "            [cur_batch_size, height, width, depth].\n",
    "        params: dict, user passed parameters.\n",
    "        reuse: bool, whether to reuse variables or not.\n",
    "\n",
    "    Returns:\n",
    "        Logits tensor of shape [cur_batch_size, 1].\n",
    "    \"\"\"\n",
    "    # Create the input layer to our DNN.\n",
    "    # shape = (cur_batch_size, height * width * depth)\n",
    "    network = X\n",
    "    print_obj(\"\\ncritic_network\", \"network\", network)\n",
    "\n",
    "    # Create regularizer for dense layer kernel weights.\n",
    "    regularizer = tf.contrib.layers.l1_l2_regularizer(\n",
    "        scale_l1=params[\"critic_l1_regularization_scale\"],\n",
    "        scale_l2=params[\"critic_l2_regularization_scale\"]\n",
    "    )\n",
    "\n",
    "    with tf.variable_scope(\"critic\", reuse=reuse):\n",
    "        # Iteratively build downsampling layers.\n",
    "        for i in range(len(params[\"critic_num_filters\"])):\n",
    "            # Add convolutional transpose layers with given params per layer.\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     critic_kernel_sizes[i - 1] / critic_strides[i],\n",
    "            #     critic_kernel_sizes[i - 1] / critic_strides[i],\n",
    "            #     critic_num_filters[i]\n",
    "            # )\n",
    "            network = tf.layers.conv2d(\n",
    "                inputs=network,\n",
    "                filters=params[\"critic_num_filters\"][i],\n",
    "                kernel_size=params[\"critic_kernel_sizes\"][i],\n",
    "                strides=params[\"critic_strides\"][i],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.leaky_relu,\n",
    "                kernel_regularizer=regularizer,\n",
    "                name=\"layers_conv2d_{}\".format(i)\n",
    "            )\n",
    "            print_obj(\"critic_network\", \"network\", network)\n",
    "\n",
    "            # Add some dropout for better regularization and stability.\n",
    "            network = tf.layers.dropout(\n",
    "                inputs=network,\n",
    "                rate=params[\"critic_dropout_rates\"][i],\n",
    "                name=\"layers_dropout_{}\".format(i)\n",
    "            )\n",
    "            print_obj(\"critic_network\", \"network\", network)\n",
    "\n",
    "        # Flatten network output.\n",
    "        # shape = (\n",
    "        #     cur_batch_size,\n",
    "        #     (critic_kernel_sizes[-2] / critic_strides[-1]) ** 2 * critic_num_filters[-1]\n",
    "        # )\n",
    "        network_flat = tf.layers.Flatten()(inputs=network)\n",
    "        print_obj(\"critic_network\", \"network_flat\", network_flat)\n",
    "\n",
    "        # Final linear layer for logits.\n",
    "        # shape = (cur_batch_size, 1)\n",
    "        logits = tf.layers.dense(\n",
    "            inputs=network_flat,\n",
    "            units=1,\n",
    "            activation=None,\n",
    "            kernel_regularizer=regularizer,\n",
    "            name=\"layers_dense_logits\"\n",
    "        )\n",
    "        print_obj(\"critic_network\", \"logits\", logits)\n",
    "\n",
    "    return logits\n",
    "\n",
    "\n",
    "def get_critic_loss(generated_logits, real_logits, params):\n",
    "    \"\"\"Gets critic loss.\n",
    "\n",
    "    Args:\n",
    "        generated_logits: tensor, shape of\n",
    "            [cur_batch_size, height * width * depth].\n",
    "        real_logits: tensor, shape of\n",
    "            [cur_batch_size, height * width * depth].\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Tensor of critic's total loss of shape [].\n",
    "    \"\"\"\n",
    "    # Calculate base critic loss.\n",
    "    critic_real_loss = tf.reduce_mean(\n",
    "        input_tensor=real_logits,\n",
    "        name=\"critic_real_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"\\nget_critic_loss\",\n",
    "        \"critic_real_loss\",\n",
    "        critic_real_loss\n",
    "    )\n",
    "\n",
    "    critic_generated_loss = tf.reduce_mean(\n",
    "        input_tensor=generated_logits,\n",
    "        name=\"critic_generated_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_critic_loss\",\n",
    "        \"critic_generated_loss\",\n",
    "        critic_generated_loss\n",
    "    )\n",
    "\n",
    "    critic_loss = tf.add(\n",
    "        x=critic_real_loss, y=-critic_generated_loss,\n",
    "        name=\"critic_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_critic_loss\",\n",
    "        \"critic_loss\",\n",
    "        critic_loss\n",
    "    )\n",
    "\n",
    "    # Get critic gradient penalty.\n",
    "    critic_gradients = tf.gradients(\n",
    "        ys=critic_loss,\n",
    "        xs=tf.trainable_variables(scope=\"critic\"),\n",
    "        name=\"critic_gradients_for_penalty\"\n",
    "    )\n",
    "\n",
    "    critic_gradient_penalty = tf.square(\n",
    "        x=tf.multiply(\n",
    "            x=params[\"critic_gradient_penalty_coefficient\"],\n",
    "            y=tf.linalg.global_norm(\n",
    "                t_list=critic_gradients, name=\"critic_gradients_global_norm\"\n",
    "            ) - 1.0\n",
    "        ),\n",
    "        name=\"critic_gradient_penalty\"\n",
    "    )\n",
    "\n",
    "    critic_wasserstein_gp_loss = tf.add(\n",
    "        x=critic_loss,\n",
    "        y=critic_gradient_penalty,\n",
    "        name=\"critic_wasserstein_gp_loss\"\n",
    "    )\n",
    "\n",
    "    # Get regularization losses.\n",
    "    critic_regularization_loss = tf.losses.get_regularization_loss(\n",
    "        scope=\"critic\",\n",
    "        name=\"critic_regularization_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_critic_loss\",\n",
    "        \"critic_regularization_loss\",\n",
    "        critic_regularization_loss\n",
    "    )\n",
    "\n",
    "    # Combine losses for total losses.\n",
    "    critic_total_loss = tf.math.add(\n",
    "        x=critic_wasserstein_gp_loss,\n",
    "        y=critic_regularization_loss,\n",
    "        name=\"critic_total_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_critic_loss\",\n",
    "        \"critic_total_loss\",\n",
    "        critic_total_loss\n",
    "    )\n",
    "\n",
    "    return critic_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wgan_gp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile wgan_gp_module/trainer/wgan_gp.py\n",
    "import tensorflow as tf\n",
    "\n",
    "from . import critic\n",
    "from . import generator\n",
    "from .print_object import print_obj\n",
    "\n",
    "\n",
    "def train_network(loss, global_step, params, scope):\n",
    "    \"\"\"Trains network and returns loss and train op.\n",
    "\n",
    "    Args:\n",
    "        loss: tensor, shape of [].\n",
    "        global_step: tensor, the current training step or batch in the\n",
    "            training loop.\n",
    "        params: dict, user passed parameters.\n",
    "        scope: str, the variables that to train.\n",
    "\n",
    "    Returns:\n",
    "        Loss tensor and training op.\n",
    "    \"\"\"\n",
    "    # Create optimizer map.\n",
    "    optimizers = {\n",
    "        \"Adam\": tf.train.AdamOptimizer,\n",
    "        \"Adadelta\": tf.train.AdadeltaOptimizer,\n",
    "        \"AdagradDA\": tf.train.AdagradDAOptimizer,\n",
    "        \"Adagrad\": tf.train.AdagradOptimizer,\n",
    "        \"Ftrl\": tf.train.FtrlOptimizer,\n",
    "        \"GradientDescent\": tf.train.GradientDescentOptimizer,\n",
    "        \"Momentum\": tf.train.MomentumOptimizer,\n",
    "        \"ProximalAdagrad\": tf.train.ProximalAdagradOptimizer,\n",
    "        \"ProximalGradientDescent\": tf.train.ProximalGradientDescentOptimizer,\n",
    "        \"RMSProp\": tf.train.RMSPropOptimizer\n",
    "    }\n",
    "\n",
    "    # Get gradients.\n",
    "    gradients = tf.gradients(\n",
    "        ys=loss,\n",
    "        xs=tf.trainable_variables(scope=scope),\n",
    "        name=\"{}_gradients\".format(scope)\n",
    "    )\n",
    "\n",
    "    # Clip gradients.\n",
    "    if params[\"{}_clip_gradients\".format(scope)]:\n",
    "        gradients, _ = tf.clip_by_global_norm(\n",
    "            t_list=gradients,\n",
    "            clip_norm=params[\"{}_clip_gradients\".format(scope)],\n",
    "            name=\"{}_clip_by_global_norm_gradients\".format(scope)\n",
    "        )\n",
    "\n",
    "    # Zip back together gradients and variables.\n",
    "    grads_and_vars = zip(gradients, tf.trainable_variables(scope=scope))\n",
    "\n",
    "    # Get optimizer and instantiate it.\n",
    "    optimizer = optimizers[params[\"{}_optimizer\".format(scope)]](\n",
    "        learning_rate=params[\"{}_learning_rate\".format(scope)]\n",
    "    )\n",
    "\n",
    "    # Create train op by applying gradients to variables and incrementing\n",
    "    # global step.\n",
    "    train_op = optimizer.apply_gradients(\n",
    "        grads_and_vars=grads_and_vars,\n",
    "        global_step=global_step,\n",
    "        name=\"{}_apply_gradients\".format(scope)\n",
    "    )\n",
    "\n",
    "    return loss, train_op\n",
    "\n",
    "\n",
    "def wgan_gp_model(features, labels, mode, params):\n",
    "    \"\"\"Wasserstein GAN with gradient penalty custom Estimator model function.\n",
    "\n",
    "    Args:\n",
    "        features: dict, keys are feature names and values are feature tensors.\n",
    "        labels: tensor, label data.\n",
    "        mode: tf.estimator.ModeKeys with values of either TRAIN, EVAL, or\n",
    "            PREDICT.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Instance of `tf.estimator.EstimatorSpec` class.\n",
    "    \"\"\"\n",
    "    print_obj(\"\\nwgan_model\", \"features\", features)\n",
    "    print_obj(\"wgan_model\", \"labels\", labels)\n",
    "    print_obj(\"wgan_model\", \"mode\", mode)\n",
    "    print_obj(\"wgan_model\", \"params\", params)\n",
    "\n",
    "    # Loss function, training/eval ops, etc.\n",
    "    predictions_dict = None\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = None\n",
    "    export_outputs = None\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # Extract given latent vectors from features dictionary.\n",
    "        Z = tf.cast(x=features[\"Z\"], dtype=tf.float32)\n",
    "\n",
    "        # Get predictions from generator.\n",
    "        generated_images = generator.generator_network(\n",
    "            Z, mode, params, reuse=False\n",
    "        )\n",
    "\n",
    "        # Create predictions dictionary.\n",
    "        predictions_dict = {\n",
    "            \"generated_images\": generated_images\n",
    "        }\n",
    "\n",
    "        # Create export outputs.\n",
    "        export_outputs = {\n",
    "            \"predict_export_outputs\": tf.estimator.export.PredictOutput(\n",
    "                outputs=predictions_dict)\n",
    "        }\n",
    "    else:\n",
    "        # Extract image from features dictionary.\n",
    "        X = features[\"image\"]\n",
    "\n",
    "        # Get dynamic batch size in case of partial batch.\n",
    "        cur_batch_size = tf.shape(\n",
    "            input=X,\n",
    "            out_type=tf.int32,\n",
    "            name=\"wgan_model_cur_batch_size\"\n",
    "        )[0]\n",
    "\n",
    "        # Create random noise latent vector for each batch example.\n",
    "        Z = tf.random.normal(\n",
    "            shape=[cur_batch_size, params[\"latent_size\"]],\n",
    "            mean=0.0,\n",
    "            stddev=1.0,\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        # Establish generator network subgraph.\n",
    "        generator_outputs = generator.generator_network(\n",
    "            Z, mode, params, reuse=False\n",
    "        )\n",
    "\n",
    "        # Establish critic network subgraph.\n",
    "        real_logits = critic.critic_network(X, params, reuse=False)\n",
    "\n",
    "        # Get generated logits too.\n",
    "        generated_logits = critic.critic_network(\n",
    "            generator_outputs, params, reuse=True\n",
    "        )\n",
    "\n",
    "        # Get generator total loss.\n",
    "        generator_total_loss = generator.get_generator_loss(generated_logits)\n",
    "\n",
    "        # Get critic total loss.\n",
    "        critic_total_loss = critic.get_critic_loss(\n",
    "            generated_logits, real_logits, params\n",
    "        )\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            # Get global step.\n",
    "            global_step = tf.train.get_global_step()\n",
    "\n",
    "            # Determine if it is time to train generator or critic.\n",
    "            cycle_step = tf.mod(\n",
    "                x=global_step,\n",
    "                y=tf.cast(\n",
    "                    x=tf.add(\n",
    "                        x=params[\"generator_train_steps\"],\n",
    "                        y=params[\"critic_train_steps\"]\n",
    "                    ),\n",
    "                    dtype=tf.int64\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Create choose generator condition.\n",
    "            condition = tf.less(\n",
    "                x=cycle_step, y=params[\"generator_train_steps\"]\n",
    "            )\n",
    "\n",
    "            # Needed for batch normalization, but has no effect otherwise.\n",
    "            update_ops = tf.get_collection(key=tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "            with tf.control_dependencies(control_inputs=update_ops):\n",
    "                # Conditionally choose to train generator or critic.\n",
    "                loss, train_op = tf.cond(\n",
    "                    pred=condition,\n",
    "                    true_fn=lambda: train_network(\n",
    "                        loss=generator_total_loss,\n",
    "                        global_step=global_step,\n",
    "                        params=params,\n",
    "                        scope=\"generator\"\n",
    "                    ),\n",
    "                    false_fn=lambda: train_network(\n",
    "                        loss=critic_total_loss,\n",
    "                        global_step=global_step,\n",
    "                        params=params,\n",
    "                        scope=\"critic\"\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            loss = critic_total_loss\n",
    "\n",
    "            # Concatenate critic logits and labels.\n",
    "            critic_logits = tf.concat(\n",
    "                values=[real_logits, generated_logits],\n",
    "                axis=0,\n",
    "                name=\"critic_concat_logits\"\n",
    "            )\n",
    "\n",
    "            critic_labels = tf.concat(\n",
    "                values=[\n",
    "                    tf.ones_like(tensor=real_logits),\n",
    "                    tf.zeros_like(tensor=generated_logits)\n",
    "                ],\n",
    "                axis=0,\n",
    "                name=\"critic_concat_labels\"\n",
    "            )\n",
    "\n",
    "            # Calculate critic probabilities.\n",
    "            critic_probabilities = tf.nn.sigmoid(\n",
    "                x=critic_logits, name=\"critic_probabilities\"\n",
    "            )\n",
    "\n",
    "            # Create eval metric ops dictionary.\n",
    "            eval_metric_ops = {\n",
    "                \"accuracy\": tf.metrics.accuracy(\n",
    "                    labels=critic_labels,\n",
    "                    predictions=critic_probabilities,\n",
    "                    name=\"wgan_model_accuracy\"\n",
    "                ),\n",
    "                \"precision\": tf.metrics.precision(\n",
    "                    labels=critic_labels,\n",
    "                    predictions=critic_probabilities,\n",
    "                    name=\"wgan_model_precision\"\n",
    "                ),\n",
    "                \"recall\": tf.metrics.recall(\n",
    "                    labels=critic_labels,\n",
    "                    predictions=critic_probabilities,\n",
    "                    name=\"wgan_model_recall\"\n",
    "                ),\n",
    "                \"auc_roc\": tf.metrics.auc(\n",
    "                    labels=critic_labels,\n",
    "                    predictions=critic_probabilities,\n",
    "                    num_thresholds=200,\n",
    "                    curve=\"ROC\",\n",
    "                    name=\"wgan_model_auc_roc\"\n",
    "                ),\n",
    "                \"auc_pr\": tf.metrics.auc(\n",
    "                    labels=critic_labels,\n",
    "                    predictions=critic_probabilities,\n",
    "                    num_thresholds=200,\n",
    "                    curve=\"PR\",\n",
    "                    name=\"wgan_model_auc_pr\"\n",
    "                )\n",
    "            }\n",
    "\n",
    "    # Return EstimatorSpec\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions_dict,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops,\n",
    "        export_outputs=export_outputs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## serving.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile wgan_gp_module/trainer/serving.py\n",
    "import tensorflow as tf\n",
    "\n",
    "from .print_object import print_obj\n",
    "\n",
    "\n",
    "def serving_input_fn(params):\n",
    "    \"\"\"Serving input function.\n",
    "\n",
    "    Args:\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        ServingInputReceiver object containing features and receiver tensors.\n",
    "    \"\"\"\n",
    "    # Create placeholders to accept data sent to the model at serving time.\n",
    "    # shape = (batch_size,)\n",
    "    feature_placeholders = {\n",
    "        \"Z\": tf.placeholder(\n",
    "            dtype=tf.float32,\n",
    "            shape=[None, params[\"latent_size\"]],\n",
    "            name=\"serving_input_placeholder_Z\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    print_obj(\n",
    "        \"serving_input_fn\",\n",
    "        \"feature_placeholders\",\n",
    "        feature_placeholders\n",
    "    )\n",
    "\n",
    "    # Create clones of the feature placeholder tensors so that the SavedModel\n",
    "    # SignatureDef will point to the placeholder.\n",
    "    features = {\n",
    "        key: tf.identity(\n",
    "            input=value,\n",
    "            name=\"serving_input_fn_identity_placeholder_{}\".format(key)\n",
    "        )\n",
    "        for key, value in feature_placeholders.items()\n",
    "    }\n",
    "\n",
    "    print_obj(\n",
    "        \"serving_input_fn\",\n",
    "        \"features\",\n",
    "        features\n",
    "    )\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features=features, receiver_tensors=feature_placeholders\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile wgan_gp_module/trainer/model.py\n",
    "import tensorflow as tf\n",
    "\n",
    "from . import input\n",
    "from . import serving\n",
    "from . import wgan_gp\n",
    "\n",
    "\n",
    "def train_and_evaluate(args):\n",
    "    \"\"\"Trains and evaluates custom Estimator model.\n",
    "\n",
    "    Args:\n",
    "        args: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        `Estimator` object.\n",
    "    \"\"\"\n",
    "    # Set logging to be level of INFO.\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    # Create our custom estimator using our model function.\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn=wgan_gp.wgan_gp_model,\n",
    "        model_dir=args[\"output_dir\"],\n",
    "        params=args\n",
    "    )\n",
    "\n",
    "    # Create train spec to read in our training data.\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=input.read_dataset(\n",
    "            filename=args[\"train_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.TRAIN,\n",
    "            batch_size=args[\"train_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        max_steps=args[\"train_steps\"]\n",
    "    )\n",
    "\n",
    "    # Create exporter to save out the complete model to disk.\n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        name=\"exporter\",\n",
    "        serving_input_receiver_fn=lambda: serving.serving_input_fn(args)\n",
    "    )\n",
    "\n",
    "    # Create eval spec to read in our validation data and export our model.\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=input.read_dataset(\n",
    "            filename=args[\"eval_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.EVAL,\n",
    "            batch_size=args[\"eval_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        steps=args[\"eval_steps\"],\n",
    "        start_delay_secs=args[\"start_delay_secs\"],\n",
    "        throttle_secs=args[\"throttle_secs\"],\n",
    "        exporters=exporter\n",
    "    )\n",
    "\n",
    "    # Create train and evaluate loop to train and evaluate our estimator.\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile wgan_gp_module/trainer/task.py\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from . import model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # File arguments.\n",
    "    parser.add_argument(\n",
    "        \"--train_file_pattern\",\n",
    "        help=\"GCS location to read training data.\",\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--eval_file_pattern\",\n",
    "        help=\"GCS location to read evaluation data.\",\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        help=\"GCS location to write checkpoints and export models.\",\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--job-dir\",\n",
    "        help=\"This model ignores this field, but it is required by gcloud.\",\n",
    "        default=\"junk\"\n",
    "    )\n",
    "\n",
    "    # Training parameters.\n",
    "    parser.add_argument(\n",
    "        \"--train_batch_size\",\n",
    "        help=\"Number of examples in training batch.\",\n",
    "        type=int,\n",
    "        default=32\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--train_steps\",\n",
    "        help=\"Number of steps to train for.\",\n",
    "        type=int,\n",
    "        default=100\n",
    "    )\n",
    "\n",
    "    # Eval parameters.\n",
    "    parser.add_argument(\n",
    "        \"--eval_batch_size\",\n",
    "        help=\"Number of examples in evaluation batch.\",\n",
    "        type=int,\n",
    "        default=32\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--eval_steps\",\n",
    "        help=\"Number of steps to evaluate for.\",\n",
    "        type=str,\n",
    "        default=\"None\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--start_delay_secs\",\n",
    "        help=\"Number of seconds to wait before first evaluation.\",\n",
    "        type=int,\n",
    "        default=60\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--throttle_secs\",\n",
    "        help=\"Number of seconds to wait between evaluations.\",\n",
    "        type=int,\n",
    "        default=120\n",
    "    )\n",
    "\n",
    "    # Image parameters.\n",
    "    parser.add_argument(\n",
    "        \"--height\",\n",
    "        help=\"Height of image.\",\n",
    "        type=int,\n",
    "        default=32\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--width\",\n",
    "        help=\"Width of image.\",\n",
    "        type=int,\n",
    "        default=32\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--depth\",\n",
    "        help=\"Depth of image.\",\n",
    "        type=int,\n",
    "        default=3\n",
    "    )\n",
    "\n",
    "    # Generator parameters.\n",
    "    parser.add_argument(\n",
    "        \"--latent_size\",\n",
    "        help=\"The latent size of the noise vector.\",\n",
    "        type=int,\n",
    "        default=3\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--generator_projection_dims\",\n",
    "        help=\"The 3D dimensions to project latent noise vector into.\",\n",
    "        type=str,\n",
    "        default=\"8,8,256\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--generator_num_filters\",\n",
    "        help=\"Number of filters for generator conv layers.\",\n",
    "        type=str,\n",
    "        default=\"128, 64\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--generator_kernel_sizes\",\n",
    "        help=\"Kernel sizes for generator conv layers.\",\n",
    "        type=str,\n",
    "        default=\"5,5\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--generator_strides\",\n",
    "        help=\"Strides for generator conv layers.\",\n",
    "        type=str,\n",
    "        default=\"1,2\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--generator_final_num_filters\",\n",
    "        help=\"Number of filters for final generator conv layer.\",\n",
    "        type=int,\n",
    "        default=3\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--generator_final_kernel_size\",\n",
    "        help=\"Kernel sizes for final generator conv layer.\",\n",
    "        type=int,\n",
    "        default=5\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--generator_final_stride\",\n",
    "        help=\"Strides for final generator conv layer.\",\n",
    "        type=int,\n",
    "        default=2\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--generator_l1_regularization_scale\",\n",
    "        help=\"Scale factor for L1 regularization for generator.\",\n",
    "        type=float,\n",
    "        default=0.0\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--generator_l2_regularization_scale\",\n",
    "        help=\"Scale factor for L2 regularization for generator.\",\n",
    "        type=float,\n",
    "        default=0.0\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--generator_optimizer\",\n",
    "        help=\"Name of optimizer to use for generator.\",\n",
    "        type=str,\n",
    "        default=\"Adam\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--generator_learning_rate\",\n",
    "        help=\"How quickly we train our model by scaling the gradient for generator.\",\n",
    "        type=float,\n",
    "        default=0.1\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--generator_clip_gradients\",\n",
    "        help=\"Global clipping to prevent gradient norm to exceed this value for generator.\",\n",
    "        type=str,\n",
    "        default=\"None\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--generator_train_steps\",\n",
    "        help=\"Number of steps to train generator for per cycle.\",\n",
    "        type=int,\n",
    "        default=100\n",
    "    )\n",
    "\n",
    "    # Critic parameters.\n",
    "    parser.add_argument(\n",
    "        \"--critic_num_filters\",\n",
    "        help=\"Number of filters for critic conv layers.\",\n",
    "        type=str,\n",
    "        default=\"64, 128\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--critic_kernel_sizes\",\n",
    "        help=\"Kernel sizes for critic conv layers.\",\n",
    "        type=str,\n",
    "        default=\"5,5\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--critic_strides\",\n",
    "        help=\"Strides for critic conv layers.\",\n",
    "        type=str,\n",
    "        default=\"1,2\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--critic_dropout_rates\",\n",
    "        help=\"Dropout rates for critic dropout layers.\",\n",
    "        type=str,\n",
    "        default=\"0.3,0.3\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--critic_l1_regularization_scale\",\n",
    "        help=\"Scale factor for L1 regularization for critic.\",\n",
    "        type=float,\n",
    "        default=0.0\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--critic_l2_regularization_scale\",\n",
    "        help=\"Scale factor for L2 regularization for critic.\",\n",
    "        type=float,\n",
    "        default=0.0\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--critic_optimizer\",\n",
    "        help=\"Name of optimizer to use for critic.\",\n",
    "        type=str,\n",
    "        default=\"Adam\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--critic_learning_rate\",\n",
    "        help=\"How quickly we train our model by scaling the gradient for critic.\",\n",
    "        type=float,\n",
    "        default=0.1\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--critic_clip_gradients\",\n",
    "        help=\"Global clipping to prevent gradient norm to exceed this value for critic.\",\n",
    "        type=str,\n",
    "        default=\"None\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--critic_gradient_penalty_coefficient\",\n",
    "        help=\"Coefficient of gradient penalty for critic.\",\n",
    "        type=float,\n",
    "        default=10.0\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--critic_train_steps\",\n",
    "        help=\"Number of steps to train critic for per cycle.\",\n",
    "        type=int,\n",
    "        default=100\n",
    "    )\n",
    "\n",
    "    # Parse all arguments.\n",
    "    args = parser.parse_args()\n",
    "    arguments = args.__dict__\n",
    "\n",
    "    # Unused args provided by service.\n",
    "    arguments.pop(\"job_dir\", None)\n",
    "    arguments.pop(\"job-dir\", None)\n",
    "\n",
    "    # Fix eval steps.\n",
    "    if arguments[\"eval_steps\"] == \"None\":\n",
    "        arguments[\"eval_steps\"] = None\n",
    "    else:\n",
    "        arguments[\"eval_steps\"] = int(arguments[\"eval_steps\"])\n",
    "\n",
    "    # Fix generator_projection_dims.\n",
    "    arguments[\"generator_projection_dims\"] = [\n",
    "        int(x)\n",
    "        for x in arguments[\"generator_projection_dims\"].split(\",\")\n",
    "    ]\n",
    "\n",
    "    # Fix num_filters.\n",
    "    arguments[\"generator_num_filters\"] = [\n",
    "        int(x)\n",
    "        for x in arguments[\"generator_num_filters\"].split(\",\")\n",
    "    ]\n",
    "\n",
    "    arguments[\"critic_num_filters\"] = [\n",
    "        int(x)\n",
    "        for x in arguments[\"critic_num_filters\"].split(\",\")\n",
    "    ]\n",
    "\n",
    "    # Fix kernel_sizes.\n",
    "    arguments[\"generator_kernel_sizes\"] = [\n",
    "        int(x)\n",
    "        for x in arguments[\"generator_kernel_sizes\"].split(\",\")\n",
    "    ]\n",
    "\n",
    "    arguments[\"critic_kernel_sizes\"] = [\n",
    "        int(x)\n",
    "        for x in arguments[\"critic_kernel_sizes\"].split(\",\")\n",
    "    ]\n",
    "\n",
    "    # Fix strides.\n",
    "    arguments[\"generator_strides\"] = [\n",
    "        int(x)\n",
    "        for x in arguments[\"generator_strides\"].split(\",\")\n",
    "    ]\n",
    "\n",
    "    arguments[\"critic_strides\"] = [\n",
    "        int(x)\n",
    "        for x in arguments[\"critic_strides\"].split(\",\")\n",
    "    ]\n",
    "\n",
    "    # Fix critic_dropout_rates.\n",
    "    arguments[\"critic_dropout_rates\"] = [\n",
    "        float(x)\n",
    "        for x in arguments[\"critic_dropout_rates\"].split(\",\")\n",
    "    ]\n",
    "\n",
    "    # Fix clip_gradients.\n",
    "    if arguments[\"generator_clip_gradients\"] == \"None\":\n",
    "        arguments[\"generator_clip_gradients\"] = None\n",
    "    else:\n",
    "        arguments[\"generator_clip_gradients\"] = float(\n",
    "            arguments[\"generator_clip_gradients\"]\n",
    "        )\n",
    "\n",
    "    if arguments[\"critic_clip_gradients\"] == \"None\":\n",
    "        arguments[\"critic_clip_gradients\"] = None\n",
    "    else:\n",
    "        arguments[\"critic_clip_gradients\"] = float(\n",
    "            arguments[\"critic_clip_gradients\"]\n",
    "        )\n",
    "\n",
    "    # Append trial_id to path if we are doing hptuning.\n",
    "    # This code can be removed if you are not using hyperparameter tuning.\n",
    "    arguments[\"output_dir\"] = os.path.join(\n",
    "        arguments[\"output_dir\"],\n",
    "        json.loads(\n",
    "            os.environ.get(\n",
    "                \"TF_CONFIG\", \"{}\"\n",
    "            )\n",
    "        ).get(\"task\", {}).get(\"trial\", \"\"))\n",
    "\n",
    "    # Start fresh output directory.\n",
    "    shutil.rmtree(path=arguments[\"output_dir\"], ignore_errors=True)\n",
    "\n",
    "    # Run the training job.\n",
    "    model.train_and_evaluate(arguments)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
