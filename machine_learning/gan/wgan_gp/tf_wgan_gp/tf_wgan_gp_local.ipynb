{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2-dlenv_tfe\n",
      "1.18.1\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and modules\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {}\n",
    "# File arguments\n",
    "arguments[\"output_dir\"] = \"trained_model\"\n",
    "\n",
    "# Training parameters\n",
    "arguments[\"train_batch_size\"] = 32\n",
    "arguments[\"eval_batch_size\"] = 32\n",
    "arguments[\"train_steps\"] = 200\n",
    "arguments[\"eval_steps\"] = 100\n",
    "\n",
    "# Eval parameters\n",
    "arguments[\"start_delay_secs\"] = 60\n",
    "arguments[\"throttle_secs\"] = 120\n",
    "\n",
    "# Image parameters\n",
    "arguments[\"height\"] = 32\n",
    "arguments[\"width\"] = 32\n",
    "arguments[\"depth\"] = 3\n",
    "\n",
    "# Generator parameters\n",
    "arguments[\"latent_size\"] = 512\n",
    "arguments[\"generator_projection_dims\"] = [8, 8, 256]\n",
    "arguments[\"generator_num_filters\"] = [128, 64]\n",
    "arguments[\"generator_kernel_sizes\"] = [5, 5]\n",
    "arguments[\"generator_strides\"] = [1, 2]\n",
    "arguments[\"generator_final_num_filters\"] = 3\n",
    "arguments[\"generator_final_kernel_size\"] = 5\n",
    "arguments[\"generator_final_stride\"] = 2\n",
    "arguments[\"generator_l1_regularization_scale\"] = 0.01\n",
    "arguments[\"generator_l2_regularization_scale\"] = 0.01\n",
    "arguments[\"generator_learning_rate\"] = 0.0001\n",
    "arguments[\"generator_optimizer\"] = \"Adam\"\n",
    "arguments[\"generator_clip_gradients\"] = 5.0\n",
    "arguments[\"generator_train_steps\"] = 1\n",
    "\n",
    "# Critic hyperparameters\n",
    "arguments[\"critic_num_filters\"] = [64, 128]\n",
    "arguments[\"critic_kernel_sizes\"] = [5, 5]\n",
    "arguments[\"critic_strides\"] = [2, 2]\n",
    "arguments[\"critic_dropout_rates\"] = [0.3, 0.3]\n",
    "arguments[\"critic_l1_regularization_scale\"] = 0.01\n",
    "arguments[\"critic_l2_regularization_scale\"] = 0.01\n",
    "arguments[\"critic_learning_rate\"] = 0.0001\n",
    "arguments[\"critic_optimizer\"] = \"Adam\"\n",
    "arguments[\"critic_clip_gradients\"] = 5.0\n",
    "arguments[\"critic_gradient_penalty_coefficient\"] = 10.0\n",
    "arguments[\"critic_train_steps\"] = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print_object.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_obj(function_name, object_name, object_value):\n",
    "    \"\"\"Prints enclosing function, object name, and object value.\n",
    "\n",
    "    Args:\n",
    "        function_name: str, name of function.\n",
    "        object_name: str, name of object.\n",
    "        object_value: object, value of passed object.\n",
    "    \"\"\"\n",
    "#     pass\n",
    "    print(\"{}: {} = {}\".format(function_name, object_name, object_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_example(protos, params):\n",
    "    \"\"\"Decodes TFRecord file into tensors.\n",
    "\n",
    "    Given protobufs, decode into image and label tensors.\n",
    "\n",
    "    Args:\n",
    "        protos: protobufs from TFRecord file.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Image and label tensors.\n",
    "    \"\"\"\n",
    "    # Create feature schema map for protos.\n",
    "    features = {\n",
    "        \"image_raw\": tf.FixedLenFeature(shape=[], dtype=tf.string),\n",
    "        \"label\": tf.FixedLenFeature(shape=[], dtype=tf.int64)\n",
    "    }\n",
    "\n",
    "    # Parse features from tf.Example.\n",
    "    parsed_features = tf.parse_single_example(\n",
    "        serialized=protos, features=features\n",
    "    )\n",
    "    print_obj(\"\\ndecode_example\", \"features\", features)\n",
    "\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length height * width * depth) to a uint8 tensor with shape\n",
    "    # [height * width * depth].\n",
    "    image = tf.decode_raw(\n",
    "        input_bytes=parsed_features[\"image_raw\"], out_type=tf.uint8\n",
    "    )\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Reshape flattened image back into normal dimensions.\n",
    "    image = tf.reshape(\n",
    "        tensor=image,\n",
    "        shape=[params[\"height\"], params[\"width\"], params[\"depth\"]]\n",
    "    )\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Convert from [0, 255] -> [-1.0, 1.0] floats.\n",
    "    image = tf.cast(x=image, dtype=tf.float32) * (2. / 255) - 1.0\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "    label = tf.cast(x=parsed_features[\"label\"], dtype=tf.int32)\n",
    "    print_obj(\"decode_example\", \"label\", label)\n",
    "\n",
    "    return {\"image\": image}, label\n",
    "\n",
    "\n",
    "def read_dataset(filename, mode, batch_size, params):\n",
    "    \"\"\"Reads CSV time series data using tf.data, doing necessary preprocessing.\n",
    "\n",
    "    Given filename, mode, batch size, and other parameters, read CSV dataset\n",
    "    using Dataset API, apply necessary preprocessing, and return an input\n",
    "    function to the Estimator API.\n",
    "\n",
    "    Args:\n",
    "        filename: str, file pattern that to read into our tf.data dataset.\n",
    "        mode: The estimator ModeKeys. Can be TRAIN or EVAL.\n",
    "        batch_size: int, number of examples per batch.\n",
    "        params: dict, dictionary of user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        An input function.\n",
    "    \"\"\"\n",
    "    def _input_fn():\n",
    "        \"\"\"Wrapper input function used by Estimator API to get data tensors.\n",
    "\n",
    "        Returns:\n",
    "            Batched dataset object of dictionary of feature tensors and label\n",
    "                tensor.\n",
    "        \"\"\"\n",
    "        # Create list of files that match pattern.\n",
    "        file_list = tf.gfile.Glob(filename=filename)\n",
    "\n",
    "        # Create dataset from file list.\n",
    "        dataset = tf.data.TFRecordDataset(\n",
    "            filenames=file_list, num_parallel_reads=40\n",
    "        )\n",
    "\n",
    "        # Shuffle and repeat if training with fused op.\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            dataset = dataset.apply(\n",
    "                tf.contrib.data.shuffle_and_repeat(\n",
    "                    buffer_size=50 * batch_size,\n",
    "                    count=None  # indefinitely\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Decode CSV file into a features dictionary of tensors, then batch.\n",
    "        dataset = dataset.apply(\n",
    "            tf.contrib.data.map_and_batch(\n",
    "                map_func=lambda x: decode_example(\n",
    "                    protos=x,\n",
    "                    params=params\n",
    "                ),\n",
    "                batch_size=batch_size,\n",
    "                num_parallel_calls=4\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Prefetch data to improve latency.\n",
    "        dataset = dataset.prefetch(buffer_size=2)\n",
    "\n",
    "        # Create a iterator, then get batch of features from example queue.\n",
    "        batched_dataset = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        return batched_dataset\n",
    "    return _input_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_network(Z, mode, params, reuse=False):\n",
    "    \"\"\"Creates generator network and returns generated output.\n",
    "\n",
    "    Args:\n",
    "        Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "        mode: tf.estimator.ModeKeys with values of either TRAIN, EVAL, or\n",
    "            PREDICT.\n",
    "        params: dict, user passed parameters.\n",
    "        reuse: bool, whether to reuse variables or not.\n",
    "\n",
    "    Returns:\n",
    "        Generated outputs tensor of shape\n",
    "            [cur_batch_size, height * width * depth].\n",
    "    \"\"\"\n",
    "    # Create regularizer for dense layer kernel weights.\n",
    "    regularizer = tf.contrib.layers.l1_l2_regularizer(\n",
    "        scale_l1=params[\"generator_l1_regularization_scale\"],\n",
    "        scale_l2=params[\"generator_l2_regularization_scale\"]\n",
    "    )\n",
    "\n",
    "    with tf.variable_scope(\"generator\", reuse=reuse):\n",
    "        # Project latent vectors.\n",
    "        projection_height = params[\"generator_projection_dims\"][0]\n",
    "        projection_width = params[\"generator_projection_dims\"][1]\n",
    "        projection_depth = params[\"generator_projection_dims\"][2]\n",
    "\n",
    "        # shape = (\n",
    "        #     cur_batch_size,\n",
    "        #     projection_height * projection_width * projection_depth\n",
    "        # )\n",
    "        projection = tf.layers.dense(\n",
    "            inputs=Z,\n",
    "            units=projection_height * projection_width * projection_depth,\n",
    "            activation=tf.nn.leaky_relu,\n",
    "            name=\"projection_layer\"\n",
    "        )\n",
    "        print_obj(\"generator_network\", \"projection\", projection)\n",
    "\n",
    "        # shape = (\n",
    "        #     cur_batch_size,\n",
    "        #     projection_height * projection_width * projection_depth\n",
    "        # )\n",
    "        projection_batch_norm = tf.layers.batch_normalization(\n",
    "            inputs=projection,\n",
    "            training=(mode == tf.estimator.ModeKeys.TRAIN),\n",
    "            name=\"projection_batch_norm\"\n",
    "        )\n",
    "        print_obj(\n",
    "            \"generator_network\",\n",
    "            \"projection_batch_norm\",\n",
    "            projection_batch_norm\n",
    "        )\n",
    "\n",
    "        # Reshape projection into \"image\".\n",
    "        # shape = (\n",
    "        #     cur_batch_size,\n",
    "        #     projection_height,\n",
    "        #     projection_width,\n",
    "        #     projection_depth\n",
    "        # )\n",
    "        network = tf.reshape(\n",
    "            tensor=projection_batch_norm,\n",
    "            shape=[-1, projection_height, projection_width, projection_depth],\n",
    "            name=\"projection_reshaped\"\n",
    "        )\n",
    "        print_obj(\"generator_network\", \"network\", network)\n",
    "\n",
    "        # Iteratively build upsampling layers.\n",
    "        for i in range(len(params[\"generator_num_filters\"])):\n",
    "            # Add convolutional transpose layers with given params per layer.\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     generator_kernel_sizes[i - 1] * generator_strides[i],\n",
    "            #     generator_kernel_sizes[i - 1] * generator_strides[i],\n",
    "            #     generator_num_filters[i]\n",
    "            # )\n",
    "            network = tf.layers.conv2d_transpose(\n",
    "                inputs=network,\n",
    "                filters=params[\"generator_num_filters\"][i],\n",
    "                kernel_size=params[\"generator_kernel_sizes\"][i],\n",
    "                strides=params[\"generator_strides\"][i],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.leaky_relu,\n",
    "                use_bias=False,\n",
    "                kernel_regularizer=regularizer,\n",
    "                name=\"layers_conv2d_tranpose_{}\".format(i)\n",
    "            )\n",
    "            print_obj(\"generator_network\", \"network\", network)\n",
    "\n",
    "            # Add batch normalization to keep the inputs from blowing up.\n",
    "            network = tf.layers.batch_normalization(\n",
    "                inputs=network,\n",
    "                training=(mode == tf.estimator.ModeKeys.TRAIN),\n",
    "                name=\"layers_batch_norm_{}\".format(i)\n",
    "            )\n",
    "            print_obj(\"generator_network\", \"network\", network)\n",
    "\n",
    "        # Final conv2d transpose layer for image output.\n",
    "        # shape = (cur_batch_size, height * width * depth)\n",
    "        generated_outputs = tf.layers.conv2d_transpose(\n",
    "                inputs=network,\n",
    "                filters=params[\"generator_final_num_filters\"],\n",
    "                kernel_size=params[\"generator_final_kernel_size\"],\n",
    "                strides=params[\"generator_final_stride\"],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.tanh,\n",
    "                use_bias=False,\n",
    "                kernel_regularizer=regularizer,\n",
    "                name=\"layers_conv2d_tranpose_generated_outputs\"\n",
    "        )\n",
    "        print_obj(\"generator_network\", \"generated_outputs\", generated_outputs)\n",
    "\n",
    "    return generated_outputs\n",
    "\n",
    "\n",
    "def get_generator_loss(generated_logits):\n",
    "    \"\"\"Gets generator loss.\n",
    "\n",
    "    Args:\n",
    "        generated_logits: tensor, shape of\n",
    "            [cur_batch_size, height * width * depth].\n",
    "\n",
    "    Returns:\n",
    "        Tensor of generator's total loss of shape [].\n",
    "    \"\"\"\n",
    "    # Calculate base generator loss.\n",
    "    generator_loss = -tf.reduce_mean(\n",
    "        input_tensor=generated_logits,\n",
    "        name=\"generator_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"\\nget_generator_loss\",\n",
    "        \"generator_loss\",\n",
    "        generator_loss\n",
    "    )\n",
    "\n",
    "    # Get regularization losses.\n",
    "    generator_regularization_loss = tf.losses.get_regularization_loss(\n",
    "        scope=\"generator\",\n",
    "        name=\"generator_regularization_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_generator_loss\",\n",
    "        \"generator_regularization_loss\",\n",
    "        generator_regularization_loss\n",
    "    )\n",
    "\n",
    "    # Combine losses for total losses.\n",
    "    generator_total_loss = tf.math.add(\n",
    "        x=generator_loss,\n",
    "        y=generator_regularization_loss,\n",
    "        name=\"generator_total_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_generator_loss\", \"generator_total_loss\", generator_total_loss\n",
    "    )\n",
    "\n",
    "    return generator_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## critic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic_network(X, params, reuse=False):\n",
    "    \"\"\"Creates critic network and returns logits.\n",
    "\n",
    "    Args:\n",
    "        X: tensor, image tensors of shape\n",
    "            [cur_batch_size, height, width, depth].\n",
    "        params: dict, user passed parameters.\n",
    "        reuse: bool, whether to reuse variables or not.\n",
    "\n",
    "    Returns:\n",
    "        Logits tensor of shape [cur_batch_size, 1].\n",
    "    \"\"\"\n",
    "    # Create the input layer to our DNN.\n",
    "    # shape = (cur_batch_size, height * width * depth)\n",
    "    network = X\n",
    "    print_obj(\"\\ncritic_network\", \"network\", network)\n",
    "\n",
    "    # Create regularizer for dense layer kernel weights.\n",
    "    regularizer = tf.contrib.layers.l1_l2_regularizer(\n",
    "        scale_l1=params[\"critic_l1_regularization_scale\"],\n",
    "        scale_l2=params[\"critic_l2_regularization_scale\"]\n",
    "    )\n",
    "\n",
    "    with tf.variable_scope(\"critic\", reuse=reuse):\n",
    "        # Iteratively build downsampling layers.\n",
    "        for i in range(len(params[\"critic_num_filters\"])):\n",
    "            # Add convolutional transpose layers with given params per layer.\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     critic_kernel_sizes[i - 1] / critic_strides[i],\n",
    "            #     critic_kernel_sizes[i - 1] / critic_strides[i],\n",
    "            #     critic_num_filters[i]\n",
    "            # )\n",
    "            network = tf.layers.conv2d(\n",
    "                inputs=network,\n",
    "                filters=params[\"critic_num_filters\"][i],\n",
    "                kernel_size=params[\"critic_kernel_sizes\"][i],\n",
    "                strides=params[\"critic_strides\"][i],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.leaky_relu,\n",
    "                kernel_regularizer=regularizer,\n",
    "                name=\"layers_conv2d_{}\".format(i)\n",
    "            )\n",
    "            print_obj(\"critic_network\", \"network\", network)\n",
    "\n",
    "            # Add some dropout for better regularization and stability.\n",
    "            network = tf.layers.dropout(\n",
    "                inputs=network,\n",
    "                rate=params[\"critic_dropout_rates\"][i],\n",
    "                name=\"layers_dropout_{}\".format(i)\n",
    "            )\n",
    "            print_obj(\"critic_network\", \"network\", network)\n",
    "\n",
    "        # Flatten network output.\n",
    "        # shape = (\n",
    "        #     cur_batch_size,\n",
    "        #     (critic_kernel_sizes[-2] / critic_strides[-1]) ** 2 * critic_num_filters[-1]\n",
    "        # )\n",
    "        network_flat = tf.layers.Flatten()(inputs=network)\n",
    "        print_obj(\"critic_network\", \"network_flat\", network_flat)\n",
    "\n",
    "        # Final linear layer for logits.\n",
    "        # shape = (cur_batch_size, 1)\n",
    "        logits = tf.layers.dense(\n",
    "            inputs=network_flat,\n",
    "            units=1,\n",
    "            activation=None,\n",
    "            kernel_regularizer=regularizer,\n",
    "            name=\"layers_dense_logits\"\n",
    "        )\n",
    "        print_obj(\"critic_network\", \"logits\", logits)\n",
    "\n",
    "    return logits\n",
    "\n",
    "\n",
    "def get_critic_loss(generated_logits, real_logits, params):\n",
    "    \"\"\"Gets critic loss.\n",
    "\n",
    "    Args:\n",
    "        generated_logits: tensor, shape of\n",
    "            [cur_batch_size, height * width * depth].\n",
    "        real_logits: tensor, shape of\n",
    "            [cur_batch_size, height * width * depth].\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Tensor of critic's total loss of shape [].\n",
    "    \"\"\"\n",
    "    # Calculate base critic loss.\n",
    "    critic_real_loss = tf.reduce_mean(\n",
    "        input_tensor=real_logits,\n",
    "        name=\"critic_real_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"\\nget_critic_loss\",\n",
    "        \"critic_real_loss\",\n",
    "        critic_real_loss\n",
    "    )\n",
    "\n",
    "    critic_generated_loss = tf.reduce_mean(\n",
    "        input_tensor=generated_logits,\n",
    "        name=\"critic_generated_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_critic_loss\",\n",
    "        \"critic_generated_loss\",\n",
    "        critic_generated_loss\n",
    "    )\n",
    "\n",
    "    critic_loss = tf.add(\n",
    "        x=critic_real_loss, y=-critic_generated_loss,\n",
    "        name=\"critic_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_critic_loss\",\n",
    "        \"critic_loss\",\n",
    "        critic_loss\n",
    "    )\n",
    "\n",
    "    # Get critic gradient penalty.\n",
    "    critic_gradients = tf.gradients(\n",
    "        ys=critic_loss,\n",
    "        xs=tf.trainable_variables(scope=\"critic\"),\n",
    "        name=\"critic_gradients_for_penalty\"\n",
    "    )\n",
    "\n",
    "    critic_gradient_penalty = tf.square(\n",
    "        x=tf.multiply(\n",
    "            x=params[\"critic_gradient_penalty_coefficient\"],\n",
    "            y=tf.linalg.global_norm(\n",
    "                t_list=critic_gradients, name=\"critic_gradients_global_norm\"\n",
    "            ) - 1.0\n",
    "        ),\n",
    "        name=\"critic_gradient_penalty\"\n",
    "    )\n",
    "\n",
    "    critic_wasserstein_gp_loss = tf.add(\n",
    "        x=critic_loss,\n",
    "        y=critic_gradient_penalty,\n",
    "        name=\"critic_wasserstein_gp_loss\"\n",
    "    )\n",
    "\n",
    "    # Get regularization losses.\n",
    "    critic_regularization_loss = tf.losses.get_regularization_loss(\n",
    "        scope=\"critic\",\n",
    "        name=\"critic_regularization_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_critic_loss\",\n",
    "        \"critic_regularization_loss\",\n",
    "        critic_regularization_loss\n",
    "    )\n",
    "\n",
    "    # Combine losses for total losses.\n",
    "    critic_total_loss = tf.math.add(\n",
    "        x=critic_wasserstein_gp_loss,\n",
    "        y=critic_regularization_loss,\n",
    "        name=\"critic_total_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_critic_loss\",\n",
    "        \"critic_total_loss\",\n",
    "        critic_total_loss\n",
    "    )\n",
    "\n",
    "    return critic_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wgan_gp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(loss, global_step, params, scope):\n",
    "    \"\"\"Trains network and returns loss and train op.\n",
    "\n",
    "    Args:\n",
    "        loss: tensor, shape of [].\n",
    "        global_step: tensor, the current training step or batch in the\n",
    "            training loop.\n",
    "        params: dict, user passed parameters.\n",
    "        scope: str, the variables that to train.\n",
    "\n",
    "    Returns:\n",
    "        Loss tensor and training op.\n",
    "    \"\"\"\n",
    "    # Create optimizer map.\n",
    "    optimizers = {\n",
    "        \"Adam\": tf.train.AdamOptimizer,\n",
    "        \"Adadelta\": tf.train.AdadeltaOptimizer,\n",
    "        \"AdagradDA\": tf.train.AdagradDAOptimizer,\n",
    "        \"Adagrad\": tf.train.AdagradOptimizer,\n",
    "        \"Ftrl\": tf.train.FtrlOptimizer,\n",
    "        \"GradientDescent\": tf.train.GradientDescentOptimizer,\n",
    "        \"Momentum\": tf.train.MomentumOptimizer,\n",
    "        \"ProximalAdagrad\": tf.train.ProximalAdagradOptimizer,\n",
    "        \"ProximalGradientDescent\": tf.train.ProximalGradientDescentOptimizer,\n",
    "        \"RMSProp\": tf.train.RMSPropOptimizer\n",
    "    }\n",
    "\n",
    "    # Get gradients.\n",
    "    gradients = tf.gradients(\n",
    "        ys=loss,\n",
    "        xs=tf.trainable_variables(scope=scope),\n",
    "        name=\"{}_gradients\".format(scope)\n",
    "    )\n",
    "\n",
    "    # Clip gradients.\n",
    "    if params[\"{}_clip_gradients\".format(scope)]:\n",
    "        gradients, _ = tf.clip_by_global_norm(\n",
    "            t_list=gradients,\n",
    "            clip_norm=params[\"{}_clip_gradients\".format(scope)],\n",
    "            name=\"{}_clip_by_global_norm_gradients\".format(scope)\n",
    "        )\n",
    "\n",
    "    # Zip back together gradients and variables.\n",
    "    grads_and_vars = zip(gradients, tf.trainable_variables(scope=scope))\n",
    "\n",
    "    # Get optimizer and instantiate it.\n",
    "    optimizer = optimizers[params[\"{}_optimizer\".format(scope)]](\n",
    "        learning_rate=params[\"{}_learning_rate\".format(scope)]\n",
    "    )\n",
    "\n",
    "    # Create train op by applying gradients to variables and incrementing\n",
    "    # global step.\n",
    "    train_op = optimizer.apply_gradients(\n",
    "        grads_and_vars=grads_and_vars,\n",
    "        global_step=global_step,\n",
    "        name=\"{}_apply_gradients\".format(scope)\n",
    "    )\n",
    "\n",
    "    return loss, train_op\n",
    "\n",
    "\n",
    "def wgan_gp_model(features, labels, mode, params):\n",
    "    \"\"\"Wasserstein GAN with gradient penalty custom Estimator model function.\n",
    "\n",
    "    Args:\n",
    "        features: dict, keys are feature names and values are feature tensors.\n",
    "        labels: tensor, label data.\n",
    "        mode: tf.estimator.ModeKeys with values of either TRAIN, EVAL, or\n",
    "            PREDICT.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Instance of `tf.estimator.EstimatorSpec` class.\n",
    "    \"\"\"\n",
    "    print_obj(\"\\nwgan_model\", \"features\", features)\n",
    "    print_obj(\"wgan_model\", \"labels\", labels)\n",
    "    print_obj(\"wgan_model\", \"mode\", mode)\n",
    "    print_obj(\"wgan_model\", \"params\", params)\n",
    "\n",
    "    # Loss function, training/eval ops, etc.\n",
    "    predictions_dict = None\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = None\n",
    "    export_outputs = None\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # Extract given latent vectors from features dictionary.\n",
    "        Z = tf.cast(x=features[\"Z\"], dtype=tf.float32)\n",
    "\n",
    "        # Get predictions from generator.\n",
    "        generated_images = generator_network(Z, mode, params, reuse=False)\n",
    "\n",
    "        # Create predictions dictionary.\n",
    "        predictions_dict = {\n",
    "            \"generated_images\": generated_images\n",
    "        }\n",
    "\n",
    "        # Create export outputs.\n",
    "        export_outputs = {\n",
    "            \"predict_export_outputs\": tf.estimator.export.PredictOutput(\n",
    "                outputs=predictions_dict)\n",
    "        }\n",
    "    else:\n",
    "        # Extract image from features dictionary.\n",
    "        X = features[\"image\"]\n",
    "\n",
    "        # Get dynamic batch size in case of partial batch.\n",
    "        cur_batch_size = tf.shape(\n",
    "            input=X,\n",
    "            out_type=tf.int32,\n",
    "            name=\"wgan_model_cur_batch_size\"\n",
    "        )[0]\n",
    "\n",
    "        # Create random noise latent vector for each batch example.\n",
    "        Z = tf.random.normal(\n",
    "            shape=[cur_batch_size, params[\"latent_size\"]],\n",
    "            mean=0.0,\n",
    "            stddev=1.0,\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        # Establish generator network subgraph.\n",
    "        generator_outputs = generator_network(Z, mode, params, reuse=False)\n",
    "\n",
    "        # Establish critic network subgraph.\n",
    "        real_logits = critic_network(X, params, reuse=False)\n",
    "\n",
    "        # Get generated logits too.\n",
    "        generated_logits = critic_network(\n",
    "            generator_outputs, params, reuse=True\n",
    "        )\n",
    "\n",
    "        # Get generator total loss.\n",
    "        generator_total_loss = get_generator_loss(generated_logits)\n",
    "\n",
    "        # Get critic total loss.\n",
    "        critic_total_loss = get_critic_loss(\n",
    "            generated_logits, real_logits, params\n",
    "        )\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            # Get global step.\n",
    "            global_step = tf.train.get_global_step()\n",
    "\n",
    "            # Determine if it is time to train generator or critic.\n",
    "            cycle_step = tf.mod(\n",
    "                x=global_step,\n",
    "                y=tf.cast(\n",
    "                    x=tf.add(\n",
    "                        x=params[\"generator_train_steps\"],\n",
    "                        y=params[\"critic_train_steps\"]\n",
    "                    ),\n",
    "                    dtype=tf.int64\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Create choose generator condition.\n",
    "            condition = tf.less(\n",
    "                x=cycle_step, y=params[\"generator_train_steps\"]\n",
    "            )\n",
    "\n",
    "            # Needed for batch normalization, but has no effect otherwise.\n",
    "            update_ops = tf.get_collection(key=tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "            with tf.control_dependencies(control_inputs=update_ops):\n",
    "                # Conditionally choose to train generator or critic.\n",
    "                loss, train_op = tf.cond(\n",
    "                    pred=condition,\n",
    "                    true_fn=lambda: train_network(\n",
    "                        loss=generator_total_loss,\n",
    "                        global_step=global_step,\n",
    "                        params=params,\n",
    "                        scope=\"generator\"\n",
    "                    ),\n",
    "                    false_fn=lambda: train_network(\n",
    "                        loss=critic_total_loss,\n",
    "                        global_step=global_step,\n",
    "                        params=params,\n",
    "                        scope=\"critic\"\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            loss = critic_total_loss\n",
    "\n",
    "            # Concatenate critic logits and labels.\n",
    "            critic_logits = tf.concat(\n",
    "                values=[real_logits, generated_logits],\n",
    "                axis=0,\n",
    "                name=\"critic_concat_logits\"\n",
    "            )\n",
    "\n",
    "            critic_labels = tf.concat(\n",
    "                values=[\n",
    "                    tf.ones_like(tensor=real_logits),\n",
    "                    tf.zeros_like(tensor=generated_logits)\n",
    "                ],\n",
    "                axis=0,\n",
    "                name=\"critic_concat_labels\"\n",
    "            )\n",
    "\n",
    "            # Calculate critic probabilities.\n",
    "            critic_probabilities = tf.nn.sigmoid(\n",
    "                x=critic_logits, name=\"critic_probabilities\"\n",
    "            )\n",
    "\n",
    "            # Create eval metric ops dictionary.\n",
    "            eval_metric_ops = {\n",
    "                \"accuracy\": tf.metrics.accuracy(\n",
    "                    labels=critic_labels,\n",
    "                    predictions=critic_probabilities,\n",
    "                    name=\"wgan_model_accuracy\"\n",
    "                ),\n",
    "                \"precision\": tf.metrics.precision(\n",
    "                    labels=critic_labels,\n",
    "                    predictions=critic_probabilities,\n",
    "                    name=\"wgan_model_precision\"\n",
    "                ),\n",
    "                \"recall\": tf.metrics.recall(\n",
    "                    labels=critic_labels,\n",
    "                    predictions=critic_probabilities,\n",
    "                    name=\"wgan_model_recall\"\n",
    "                ),\n",
    "                \"auc_roc\": tf.metrics.auc(\n",
    "                    labels=critic_labels,\n",
    "                    predictions=critic_probabilities,\n",
    "                    num_thresholds=200,\n",
    "                    curve=\"ROC\",\n",
    "                    name=\"wgan_model_auc_roc\"\n",
    "                ),\n",
    "                \"auc_pr\": tf.metrics.auc(\n",
    "                    labels=critic_labels,\n",
    "                    predictions=critic_probabilities,\n",
    "                    num_thresholds=200,\n",
    "                    curve=\"PR\",\n",
    "                    name=\"wgan_model_auc_pr\"\n",
    "                )\n",
    "            }\n",
    "\n",
    "    # Return EstimatorSpec\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions_dict,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops,\n",
    "        export_outputs=export_outputs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## serving.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn(params):\n",
    "    \"\"\"Serving input function.\n",
    "\n",
    "    Args:\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        ServingInputReceiver object containing features and receiver tensors.\n",
    "    \"\"\"\n",
    "    # Create placeholders to accept data sent to the model at serving time.\n",
    "    # shape = (batch_size,)\n",
    "    feature_placeholders = {\n",
    "        \"Z\": tf.placeholder(\n",
    "            dtype=tf.float32,\n",
    "            shape=[None, params[\"latent_size\"]],\n",
    "            name=\"serving_input_placeholder_Z\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    print_obj(\n",
    "        \"serving_input_fn\",\n",
    "        \"feature_placeholders\",\n",
    "        feature_placeholders\n",
    "    )\n",
    "\n",
    "    # Create clones of the feature placeholder tensors so that the SavedModel\n",
    "    # SignatureDef will point to the placeholder.\n",
    "    features = {\n",
    "        key: tf.identity(\n",
    "            input=value,\n",
    "            name=\"serving_input_fn_identity_placeholder_{}\".format(key)\n",
    "        )\n",
    "        for key, value in feature_placeholders.items()\n",
    "    }\n",
    "\n",
    "    print_obj(\n",
    "        \"serving_input_fn\",\n",
    "        \"features\",\n",
    "        features\n",
    "    )\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features=features, receiver_tensors=feature_placeholders\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(args):\n",
    "    \"\"\"Trains and evaluates custom Estimator model.\n",
    "\n",
    "    Args:\n",
    "        args: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        `Estimator` object.\n",
    "    \"\"\"\n",
    "    # Set logging to be level of INFO.\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    # Create our custom estimator using our model function.\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn=wgan_gp_model,\n",
    "        model_dir=args[\"output_dir\"],\n",
    "        params=args\n",
    "    )\n",
    "\n",
    "    # Create train spec to read in our training data.\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=\"data/train.tfrecord\",\n",
    "            mode=tf.estimator.ModeKeys.TRAIN,\n",
    "            batch_size=args[\"train_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        max_steps=args[\"train_steps\"]\n",
    "    )\n",
    "\n",
    "    # Create exporter to save out the complete model to disk.\n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        name=\"exporter\",\n",
    "        serving_input_receiver_fn=lambda: serving_input_fn(args)\n",
    "    )\n",
    "\n",
    "    # Create eval spec to read in our validation data and export our model.\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=\"data/test.tfrecord\",\n",
    "            mode=tf.estimator.ModeKeys.EVAL,\n",
    "            batch_size=args[\"eval_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        steps=args[\"eval_steps\"],\n",
    "        start_delay_secs=args[\"start_delay_secs\"],\n",
    "        throttle_secs=args[\"throttle_secs\"],\n",
    "        exporters=exporter\n",
    "    )\n",
    "\n",
    "    # Create train and evaluate loop to train and evaluate our estimator.\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n",
    "\n",
    "    return estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'trained_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f98a66d5890>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-4-90b050af9c1b>:87: shuffle_and_repeat (from tensorflow.contrib.data.python.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.shuffle_and_repeat(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/shuffle_ops.py:54: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From <ipython-input-4-90b050af9c1b>:99: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "WARNING:tensorflow:From <ipython-input-4-90b050af9c1b>:107: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "wgan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "wgan_model: mode = train\n",
      "wgan_model: params = {'output_dir': 'trained_model', 'train_batch_size': 32, 'eval_batch_size': 32, 'train_steps': 200, 'eval_steps': 100, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [8, 8, 256], 'generator_num_filters': [128, 64], 'generator_kernel_sizes': [5, 5], 'generator_strides': [1, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 5, 'generator_final_stride': 2, 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_learning_rate': 0.0001, 'generator_optimizer': 'Adam', 'generator_clip_gradients': 5.0, 'generator_train_steps': 1, 'critic_num_filters': [64, 128], 'critic_kernel_sizes': [5, 5], 'critic_strides': [2, 2], 'critic_dropout_rates': [0.3, 0.3], 'critic_l1_regularization_scale': 0.01, 'critic_l2_regularization_scale': 0.01, 'critic_learning_rate': 0.0001, 'critic_optimizer': 'Adam', 'critic_clip_gradients': 5.0, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "WARNING:tensorflow:From <ipython-input-5-49614946eb1d>:35: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "generator_network: projection = Tensor(\"generator/projection_layer/LeakyRelu:0\", shape=(?, 16384), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-5-49614946eb1d>:46: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "generator_network: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 16384), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 8, 8, 256), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-5-49614946eb1d>:86: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "generator_network: network = Tensor(\"generator/layers_conv2d_tranpose_0/LeakyRelu:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_conv2d_tranpose_1/LeakyRelu:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "generator_network: generated_outputs = Tensor(\"generator/layers_conv2d_tranpose_generated_outputs/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "critic_network: network = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "WARNING:tensorflow:From <ipython-input-6-469a9859cb36>:42: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "critic_network: network = Tensor(\"critic/layers_conv2d_0/LeakyRelu:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-6-469a9859cb36>:50: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "critic_network: network = Tensor(\"critic/layers_dropout_0/Identity:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic/layers_conv2d_1/LeakyRelu:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic/layers_dropout_1/Identity:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network_flat = Tensor(\"critic/flatten/Reshape:0\", shape=(?, 8192), dtype=float32)\n",
      "critic_network: logits = Tensor(\"critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "critic_network: network = Tensor(\"generator/layers_conv2d_tranpose_generated_outputs/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic_1/layers_conv2d_0/LeakyRelu:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic_1/layers_dropout_0/Identity:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic_1/layers_conv2d_1/LeakyRelu:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic_1/layers_dropout_1/Identity:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network_flat = Tensor(\"critic_1/flatten/Reshape:0\", shape=(?, 8192), dtype=float32)\n",
      "critic_network: logits = Tensor(\"critic_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_regularization_loss = Tensor(\"generator_regularization_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_critic_loss: critic_real_loss = Tensor(\"critic_real_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_generated_loss = Tensor(\"critic_generated_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_loss = Tensor(\"critic_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_regularization_loss = Tensor(\"critic_regularization_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_total_loss = Tensor(\"critic_total_loss:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 141.34615, step = 1\n",
      "INFO:tensorflow:global_step/sec: 5.45603\n",
      "INFO:tensorflow:loss = 30.588902, step = 101 (18.330 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into trained_model/model.ckpt.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "wgan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "wgan_model: mode = eval\n",
      "wgan_model: params = {'output_dir': 'trained_model', 'train_batch_size': 32, 'eval_batch_size': 32, 'train_steps': 200, 'eval_steps': 100, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [8, 8, 256], 'generator_num_filters': [128, 64], 'generator_kernel_sizes': [5, 5], 'generator_strides': [1, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 5, 'generator_final_stride': 2, 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_learning_rate': 0.0001, 'generator_optimizer': 'Adam', 'generator_clip_gradients': 5.0, 'generator_train_steps': 1, 'critic_num_filters': [64, 128], 'critic_kernel_sizes': [5, 5], 'critic_strides': [2, 2], 'critic_dropout_rates': [0.3, 0.3], 'critic_l1_regularization_scale': 0.01, 'critic_l2_regularization_scale': 0.01, 'critic_learning_rate': 0.0001, 'critic_optimizer': 'Adam', 'critic_clip_gradients': 5.0, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "generator_network: projection = Tensor(\"generator/projection_layer/LeakyRelu:0\", shape=(?, 16384), dtype=float32)\n",
      "generator_network: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 16384), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 8, 8, 256), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_conv2d_tranpose_0/LeakyRelu:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_conv2d_tranpose_1/LeakyRelu:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "generator_network: generated_outputs = Tensor(\"generator/layers_conv2d_tranpose_generated_outputs/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "critic_network: network = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "critic_network: network = Tensor(\"critic/layers_conv2d_0/LeakyRelu:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic/layers_dropout_0/Identity:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic/layers_conv2d_1/LeakyRelu:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic/layers_dropout_1/Identity:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network_flat = Tensor(\"critic/flatten/Reshape:0\", shape=(?, 8192), dtype=float32)\n",
      "critic_network: logits = Tensor(\"critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "critic_network: network = Tensor(\"generator/layers_conv2d_tranpose_generated_outputs/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic_1/layers_conv2d_0/LeakyRelu:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic_1/layers_dropout_0/Identity:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic_1/layers_conv2d_1/LeakyRelu:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic_1/layers_dropout_1/Identity:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network_flat = Tensor(\"critic_1/flatten/Reshape:0\", shape=(?, 8192), dtype=float32)\n",
      "critic_network: logits = Tensor(\"critic_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_regularization_loss = Tensor(\"generator_regularization_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_critic_loss: critic_real_loss = Tensor(\"critic_real_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_generated_loss = Tensor(\"critic_generated_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_loss = Tensor(\"critic_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_regularization_loss = Tensor(\"critic_regularization_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_total_loss = Tensor(\"critic_total_loss:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-01T05:41:43Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-01-05:41:52\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.0, auc_pr = 0.37273067, auc_roc = 0.14633505, global_step = 200, loss = 20.828794, precision = 0.5, recall = 1.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: trained_model/model.ckpt-200\n",
      "serving_input_fn: feature_placeholders = {'Z': <tf.Tensor 'serving_input_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "serving_input_fn: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_model: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "wgan_model: labels = None\n",
      "wgan_model: mode = infer\n",
      "wgan_model: params = {'output_dir': 'trained_model', 'train_batch_size': 32, 'eval_batch_size': 32, 'train_steps': 200, 'eval_steps': 100, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [8, 8, 256], 'generator_num_filters': [128, 64], 'generator_kernel_sizes': [5, 5], 'generator_strides': [1, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 5, 'generator_final_stride': 2, 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_learning_rate': 0.0001, 'generator_optimizer': 'Adam', 'generator_clip_gradients': 5.0, 'generator_train_steps': 1, 'critic_num_filters': [64, 128], 'critic_kernel_sizes': [5, 5], 'critic_strides': [2, 2], 'critic_dropout_rates': [0.3, 0.3], 'critic_l1_regularization_scale': 0.01, 'critic_l2_regularization_scale': 0.01, 'critic_learning_rate': 0.0001, 'critic_optimizer': 'Adam', 'critic_clip_gradients': 5.0, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "generator_network: projection = Tensor(\"generator/projection_layer/LeakyRelu:0\", shape=(?, 16384), dtype=float32)\n",
      "generator_network: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 16384), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 8, 8, 256), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_conv2d_tranpose_0/LeakyRelu:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_conv2d_tranpose_1/LeakyRelu:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "generator_network: generated_outputs = Tensor(\"generator/layers_conv2d_tranpose_generated_outputs/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-200\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: trained_model/export/exporter/temp-b'1590990112'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 20.15767.\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree(path=arguments[\"output_dir\"], ignore_errors=True)\n",
    "estimator = train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1590990112\n"
     ]
    }
   ],
   "source": [
    "!ls trained_model/export/exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/predictor/saved_model_predictor.py:153: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from trained_model/export/exporter/1590990112/variables/variables\n"
     ]
    }
   ],
   "source": [
    "predict_fn = tf.contrib.predictor.from_saved_model(\n",
    "    \"trained_model/export/exporter/1590990112\"\n",
    ")\n",
    "predictions = predict_fn(\n",
    "    {\n",
    "        \"Z\": np.random.normal(size=(500, 512))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = np.clip(\n",
    "    a=((predictions[\"generated_images\"] + 1.0) * (255. / 2)).astype(np.int32),\n",
    "    a_min=0,\n",
    "    a_max=255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(generated_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(generated_images[i], cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
