{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18.1\n",
      "1.15.2-dlenv_tfe\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(np.__version__)\n",
    "print(tf.__version__)\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {}\n",
    "# File arguments.\n",
    "arguments[\"train_file_pattern\"] = \"gs://machine-learning-1234-bucket/gan/data/cifar10_car/train*.tfrecord\"\n",
    "arguments[\"eval_file_pattern\"] = \"gs://machine-learning-1234-bucket/gan/data/cifar10_car/test*.tfrecord\"\n",
    "arguments[\"output_dir\"] = \"gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model\"\n",
    "\n",
    "# Training parameters.\n",
    "arguments[\"train_batch_size\"] = 64\n",
    "arguments[\"train_steps\"] = 40000\n",
    "arguments[\"save_summary_steps\"] = 100\n",
    "arguments[\"save_checkpoints_steps\"] = 5000\n",
    "arguments[\"keep_checkpoint_max\"] = 10\n",
    "arguments[\"input_fn_autotune\"] = False\n",
    "\n",
    "# Eval parameters.\n",
    "arguments[\"eval_batch_size\"] = 5\n",
    "arguments[\"eval_steps\"] = 10\n",
    "arguments[\"start_delay_secs\"] = 60\n",
    "arguments[\"throttle_secs\"] = 120\n",
    "\n",
    "# Image parameters.\n",
    "arguments[\"height\"] = 32\n",
    "arguments[\"width\"] = 32\n",
    "arguments[\"depth\"] = 3\n",
    "\n",
    "# Generator parameters.\n",
    "arguments[\"latent_size\"] = 512\n",
    "arguments[\"generator_projection_dims\"] = [4, 4, 256]\n",
    "arguments[\"generator_num_filters\"] = [128, 128, 128]\n",
    "arguments[\"generator_kernel_sizes\"] = [4, 4, 4]\n",
    "arguments[\"generator_strides\"] = [2, 2, 2]\n",
    "arguments[\"generator_final_num_filters\"] = arguments[\"depth\"]\n",
    "arguments[\"generator_final_kernel_size\"] = 3\n",
    "arguments[\"generator_final_stride\"] = 1\n",
    "arguments[\"generator_leaky_relu_alpha\"] = 0.2\n",
    "arguments[\"generator_use_batch_normalization\"] = True\n",
    "arguments[\"generator_final_activation\"] = \"tanh\"\n",
    "arguments[\"generator_l1_regularization_scale\"] = 0.\n",
    "arguments[\"generator_l2_regularization_scale\"] = 0.\n",
    "arguments[\"generator_optimizer\"] = \"Adam\"\n",
    "arguments[\"generator_learning_rate\"] = 0.0001\n",
    "arguments[\"generator_adam_beta1\"] = 0.0\n",
    "arguments[\"generator_adam_beta2\"] = 0.9\n",
    "arguments[\"generator_adam_epsilon\"] = 1e-8\n",
    "arguments[\"generator_clip_gradients\"] = None\n",
    "arguments[\"generator_train_steps\"] = 1\n",
    "\n",
    "# Critic hyperparameters.\n",
    "arguments[\"critic_num_filters\"] = [64, 128, 128, 256]\n",
    "arguments[\"critic_kernel_sizes\"] = [3, 3, 3, 3]\n",
    "arguments[\"critic_strides\"] = [1, 2, 2, 2]\n",
    "arguments[\"critic_leaky_relu_alpha\"] = 0.2\n",
    "arguments[\"critic_use_layer_normalization\"] = True\n",
    "arguments[\"critic_l1_regularization_scale\"] = 0.\n",
    "arguments[\"critic_l2_regularization_scale\"] = 0.\n",
    "arguments[\"critic_optimizer\"] = \"Adam\"\n",
    "arguments[\"critic_learning_rate\"] = 0.0001\n",
    "arguments[\"critic_adam_beta1\"] = 0.0\n",
    "arguments[\"critic_adam_beta2\"] = 0.9\n",
    "arguments[\"critic_adam_epsilon\"] = 1e-8\n",
    "arguments[\"critic_clip_gradients\"] = None\n",
    "arguments[\"critic_gradient_penalty_coefficient\"] = 10.0\n",
    "arguments[\"critic_train_steps\"] = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print_object.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_obj(function_name, object_name, object_value):\n",
    "    \"\"\"Prints enclosing function, object name, and object value.\n",
    "\n",
    "    Args:\n",
    "        function_name: str, name of function.\n",
    "        object_name: str, name of object.\n",
    "        object_value: object, value of passed object.\n",
    "    \"\"\"\n",
    "#     pass\n",
    "    print(\"{}: {} = {}\".format(function_name, object_name, object_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, params):\n",
    "    \"\"\"Preprocess image tensor.\n",
    "\n",
    "    Args:\n",
    "        image: tensor, input image with shape\n",
    "            [cur_batch_size, height, width, depth].\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Preprocessed image tensor with shape\n",
    "            [cur_batch_size, height, width, depth].\n",
    "    \"\"\"\n",
    "    func_name = \"preprocess_image\"\n",
    "    # Convert from [0, 255] -> [-1.0, 1.0] floats.\n",
    "    image = tf.cast(x=image, dtype=tf.float32) * (2. / 255) - 1.0\n",
    "    print_obj(func_name, \"image\", image)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def resize_fake_images(fake_images, params):\n",
    "    \"\"\"Resizes fake images to match real image sizes.\n",
    "\n",
    "    Args:\n",
    "        fake_images: tensor, fake images from generator.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Resized image tensor.\n",
    "    \"\"\"\n",
    "    func_name = \"resize_real_image\"\n",
    "    print_obj(\"\\n\" + func_name, \"fake_images\", fake_images)\n",
    "\n",
    "    # Resize fake images to match real image sizes.\n",
    "    resized_fake_images = tf.image.resize(\n",
    "        images=fake_images,\n",
    "        size=[params[\"height\"], params[\"width\"]],\n",
    "        method=\"nearest\",\n",
    "        name=\"resized_fake_images\"\n",
    "    )\n",
    "    print_obj(func_name, \"resized_fake_images\", resized_fake_images)\n",
    "\n",
    "    return resized_fake_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_example(protos, params):\n",
    "    \"\"\"Decodes TFRecord file into tensors.\n",
    "\n",
    "    Given protobufs, decode into image and label tensors.\n",
    "\n",
    "    Args:\n",
    "        protos: protobufs from TFRecord file.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Image and label tensors.\n",
    "    \"\"\"\n",
    "    func_name = \"decode_example\"\n",
    "    # Create feature schema map for protos.\n",
    "    features = {\n",
    "        \"image_raw\": tf.FixedLenFeature(shape=[], dtype=tf.string),\n",
    "        \"label\": tf.FixedLenFeature(shape=[], dtype=tf.int64)\n",
    "    }\n",
    "\n",
    "    # Parse features from tf.Example.\n",
    "    parsed_features = tf.parse_single_example(\n",
    "        serialized=protos, features=features\n",
    "    )\n",
    "    print_obj(\"\\n\" + func_name, \"features\", features)\n",
    "\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length height * width * depth) to a uint8 tensor with shape\n",
    "    # [height * width * depth].\n",
    "    image = tf.decode_raw(\n",
    "        input_bytes=parsed_features[\"image_raw\"], out_type=tf.uint8\n",
    "    )\n",
    "    print_obj(func_name, \"image\", image)\n",
    "\n",
    "    # Reshape flattened image back into normal dimensions.\n",
    "    image = tf.reshape(\n",
    "        tensor=image,\n",
    "        shape=[params[\"height\"], params[\"width\"], params[\"depth\"]]\n",
    "    )\n",
    "    print_obj(func_name, \"image\", image)\n",
    "\n",
    "    # Preprocess image.\n",
    "    image = preprocess_image(image=image, params=params)\n",
    "    print_obj(func_name, \"image\", image)\n",
    "\n",
    "    # Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "    label = tf.cast(x=parsed_features[\"label\"], dtype=tf.int32)\n",
    "    print_obj(func_name, \"label\", label)\n",
    "\n",
    "    return {\"image\": image}, label\n",
    "\n",
    "\n",
    "def read_dataset(filename, mode, batch_size, params):\n",
    "    \"\"\"Reads TF Record data using tf.data, doing necessary preprocessing.\n",
    "\n",
    "    Given filename, mode, batch size, and other parameters, read TF Record\n",
    "    dataset using Dataset API, apply necessary preprocessing, and return an\n",
    "    input function to the Estimator API.\n",
    "\n",
    "    Args:\n",
    "        filename: str, file pattern that to read into our tf.data dataset.\n",
    "        mode: The estimator ModeKeys. Can be TRAIN or EVAL.\n",
    "        batch_size: int, number of examples per batch.\n",
    "        params: dict, dictionary of user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        An input function.\n",
    "    \"\"\"\n",
    "    def _input_fn():\n",
    "        \"\"\"Wrapper input function used by Estimator API to get data tensors.\n",
    "\n",
    "        Returns:\n",
    "            Batched dataset object of dictionary of feature tensors and label\n",
    "                tensor.\n",
    "        \"\"\"\n",
    "        # Create list of files that match pattern.\n",
    "        file_list = tf.gfile.Glob(filename=filename)\n",
    "\n",
    "        # Create dataset from file list.\n",
    "        if params[\"input_fn_autotune\"]:\n",
    "            dataset = tf.data.TFRecordDataset(\n",
    "                filenames=file_list,\n",
    "                num_parallel_reads=tf.contrib.data.AUTOTUNE\n",
    "            )\n",
    "        else:\n",
    "            dataset = tf.data.TFRecordDataset(filenames=file_list)\n",
    "\n",
    "        # Shuffle and repeat if training with fused op.\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            dataset = dataset.apply(\n",
    "                tf.contrib.data.shuffle_and_repeat(\n",
    "                    buffer_size=50 * batch_size,\n",
    "                    count=None  # indefinitely\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Decode CSV file into a features dictionary of tensors, then batch.\n",
    "        if params[\"input_fn_autotune\"]:\n",
    "            dataset = dataset.apply(\n",
    "                tf.contrib.data.map_and_batch(\n",
    "                    map_func=lambda x: decode_example(\n",
    "                        protos=x,\n",
    "                        params=params\n",
    "                    ),\n",
    "                    batch_size=batch_size,\n",
    "                    num_parallel_calls=tf.contrib.data.AUTOTUNE\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            dataset = dataset.apply(\n",
    "                tf.contrib.data.map_and_batch(\n",
    "                    map_func=lambda x: decode_example(\n",
    "                        protos=x,\n",
    "                        params=params\n",
    "                    ),\n",
    "                    batch_size=batch_size\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Prefetch data to improve latency.\n",
    "        if params[\"input_fn_autotune\"]:\n",
    "            dataset = dataset.prefetch(buffer_size=tf.contrib.data.AUTOTUNE)\n",
    "        else:\n",
    "            dataset = dataset.prefetch(buffer_size=1)\n",
    "\n",
    "        # Create a iterator, then get batch of features from example queue.\n",
    "        batched_dataset = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        return batched_dataset\n",
    "    return _input_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(object):\n",
    "    \"\"\"Generator that takes latent vector input and outputs image.\n",
    "    Fields:\n",
    "        name: str, name of `Generator`.\n",
    "        kernel_regularizer: `l1_l2_regularizer` object, regularizar for kernel\n",
    "            variables.\n",
    "        bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "            variables.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_regularizer, bias_regularizer, name):\n",
    "        \"\"\"Instantiates and builds generator network.\n",
    "        Args:\n",
    "            kernel_regularizer: `l1_l2_regularizer` object, regularizar for\n",
    "                kernel variables.\n",
    "            bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "                variables.\n",
    "            name: str, name of generator.\n",
    "        \"\"\"\n",
    "        # Set name of generator.\n",
    "        self.name = name\n",
    "\n",
    "        # Regularizer for kernel weights.\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "\n",
    "        # Regularizer for bias weights.\n",
    "        self.bias_regularizer = bias_regularizer\n",
    "\n",
    "    def get_fake_images(self, Z, mode, params):\n",
    "        \"\"\"Creates generator network and returns generated images.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            mode: tf.estimator.ModeKeys with values of either TRAIN, EVAL, or\n",
    "                PREDICT.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Generated image tensor of shape\n",
    "                [cur_batch_size, height, width, depth].\n",
    "        \"\"\"\n",
    "        func_name = \"get_fake_images\"\n",
    "        print_obj(\"\\n\" + func_name, \"Z\", Z)\n",
    "\n",
    "        # Dictionary containing possible final activations.\n",
    "        final_activation_dict = {\n",
    "            \"sigmoid\": tf.nn.sigmoid, \"relu\": tf.nn.relu, \"tanh\": tf.nn.tanh\n",
    "        }\n",
    "\n",
    "        with tf.variable_scope(\"generator\", reuse=tf.AUTO_REUSE):\n",
    "            # Project latent vectors.\n",
    "            projection_height = params[\"generator_projection_dims\"][0]\n",
    "            projection_width = params[\"generator_projection_dims\"][1]\n",
    "            projection_depth = params[\"generator_projection_dims\"][2]\n",
    "\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     projection_height * projection_width * projection_depth\n",
    "            # )\n",
    "            projection = tf.layers.dense(\n",
    "                inputs=Z,\n",
    "                units=projection_height * projection_width * projection_depth,\n",
    "                activation=None,\n",
    "                kernel_regularizer=self.kernel_regularizer,\n",
    "                bias_regularizer=self.bias_regularizer,\n",
    "                name=\"projection_dense_layer\"\n",
    "            )\n",
    "            print_obj(func_name, \"projection\", projection)\n",
    "\n",
    "            projection_leaky_relu = tf.nn.leaky_relu(\n",
    "                features=projection,\n",
    "                alpha=params[\"generator_leaky_relu_alpha\"],\n",
    "                name=\"projection_leaky_relu\"\n",
    "            )\n",
    "            print_obj(\n",
    "                func_name, \"projection_leaky_relu\", projection_leaky_relu\n",
    "            )\n",
    "\n",
    "            if params[\"generator_use_batch_normalization\"]:\n",
    "                # Add batch normalization to stop inputs from blowing up.\n",
    "                # shape = (\n",
    "                #     cur_batch_size,\n",
    "                #     projection_height * projection_width * projection_depth\n",
    "                # )\n",
    "                projection_leaky_relu = tf.layers.batch_normalization(\n",
    "                    inputs=projection_leaky_relu,\n",
    "                    training=(mode == tf.estimator.ModeKeys.TRAIN),\n",
    "                    name=\"projection_batch_norm\"\n",
    "                )\n",
    "                print_obj(\n",
    "                    func_name, \"projection_batch_norm\", projection_leaky_relu\n",
    "                )\n",
    "\n",
    "            # Reshape projection into \"image\".\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     projection_height,\n",
    "            #     projection_width,\n",
    "            #     projection_depth\n",
    "            # )\n",
    "            network = tf.reshape(\n",
    "                tensor=projection_leaky_relu,\n",
    "                shape=[\n",
    "                    -1, projection_height, projection_width, projection_depth\n",
    "                ],\n",
    "                name=\"projection_reshaped\"\n",
    "            )\n",
    "            print_obj(func_name, \"network\", network)\n",
    "\n",
    "            # Iteratively build upsampling layers.\n",
    "            for i in range(len(params[\"generator_num_filters\"])):\n",
    "                # Add conv transpose layers with given params per layer.\n",
    "                # shape = (\n",
    "                #     cur_batch_size,\n",
    "                #     generator_kernel_sizes[i - 1] * generator_strides[i],\n",
    "                #     generator_kernel_sizes[i - 1] * generator_strides[i],\n",
    "                #     generator_num_filters[i]\n",
    "                # )\n",
    "                network = tf.layers.conv2d_transpose(\n",
    "                    inputs=network,\n",
    "                    filters=params[\"generator_num_filters\"][i],\n",
    "                    kernel_size=params[\"generator_kernel_sizes\"][i],\n",
    "                    strides=params[\"generator_strides\"][i],\n",
    "                    padding=\"same\",\n",
    "                    activation=None,\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"layers_conv2d_tranpose_{}\".format(i)\n",
    "                )\n",
    "                print_obj(func_name, \"network\", network)\n",
    "\n",
    "                network = tf.nn.leaky_relu(\n",
    "                    features=network,\n",
    "                    alpha=params[\"generator_leaky_relu_alpha\"],\n",
    "                    name=\"leaky_relu_{}\".format(i)\n",
    "                )\n",
    "                print_obj(func_name, \"network\", network)\n",
    "\n",
    "                if params[\"generator_use_batch_normalization\"]:\n",
    "                    # Add batch normalization to stop inputs from blowing up.\n",
    "                    network = tf.layers.batch_normalization(\n",
    "                        inputs=network,\n",
    "                        training=(mode == tf.estimator.ModeKeys.TRAIN),\n",
    "                        name=\"layers_batch_norm_{}\".format(i)\n",
    "                    )\n",
    "                    print_obj(func_name, \"network\", network)\n",
    "\n",
    "            # Final conv2d transpose layer for image output.\n",
    "            # shape = (cur_batch_size, height, width, depth)\n",
    "            fake_images = tf.layers.conv2d_transpose(\n",
    "                inputs=network,\n",
    "                filters=params[\"generator_final_num_filters\"],\n",
    "                kernel_size=params[\"generator_final_kernel_size\"],\n",
    "                strides=params[\"generator_final_stride\"],\n",
    "                padding=\"same\",\n",
    "                activation=final_activation_dict.get(\n",
    "                    params[\"generator_final_activation\"].lower(), None\n",
    "                ),\n",
    "                kernel_regularizer=self.kernel_regularizer,\n",
    "                bias_regularizer=self.bias_regularizer,\n",
    "                name=\"layers_conv2d_tranpose_fake_images\"\n",
    "            )\n",
    "            print_obj(func_name, \"fake_images\", fake_images)\n",
    "\n",
    "        return fake_images\n",
    "\n",
    "    def get_generator_loss(self, fake_logits):\n",
    "        \"\"\"Gets generator loss.\n",
    "\n",
    "        Args:\n",
    "            fake_logits: tensor, shape of\n",
    "                [cur_batch_size, 1].\n",
    "\n",
    "        Returns:\n",
    "            Tensor of generator's total loss of shape [].\n",
    "        \"\"\"\n",
    "        func_name = \"get_generator_loss\"\n",
    "        # Calculate base generator loss.\n",
    "        generator_loss = -tf.reduce_mean(\n",
    "            input_tensor=fake_logits,\n",
    "            name=\"generator_loss\"\n",
    "        )\n",
    "        print_obj(\"\\n\" + func_name, \"generator_loss\", generator_loss)\n",
    "\n",
    "        # Get regularization losses.\n",
    "        generator_reg_loss = tf.losses.get_regularization_loss(\n",
    "            scope=\"generator\",\n",
    "            name=\"generator_reg_loss\"\n",
    "        )\n",
    "        print_obj(func_name, \"generator_reg_loss\", generator_reg_loss)\n",
    "\n",
    "        # Combine losses for total losses.\n",
    "        generator_total_loss = tf.math.add(\n",
    "            x=generator_loss,\n",
    "            y=generator_reg_loss,\n",
    "            name=\"generator_total_loss\"\n",
    "        )\n",
    "        print_obj(func_name, \"generator_total_loss\", generator_total_loss)\n",
    "\n",
    "        # Add summaries for TensorBoard.\n",
    "        tf.summary.scalar(\n",
    "            name=\"generator_loss\", tensor=generator_loss, family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"generator_reg_loss\",\n",
    "            tensor=generator_reg_loss,\n",
    "            family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"generator_total_loss\",\n",
    "            tensor=generator_total_loss,\n",
    "            family=\"total_losses\"\n",
    "        )\n",
    "\n",
    "        return generator_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## critic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(object):\n",
    "    \"\"\"Critic that takes image input and outputs logits.\n",
    "    Fields:\n",
    "        name: str, name of `Critic`.\n",
    "        kernel_regularizer: `l1_l2_regularizer` object, regularizar for kernel\n",
    "            variables.\n",
    "        bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "            variables.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_regularizer, bias_regularizer, name):\n",
    "        \"\"\"Instantiates and builds critic network.\n",
    "        Args:\n",
    "            kernel_regularizer: `l1_l2_regularizer` object, regularizar for\n",
    "                kernel variables.\n",
    "            bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "                variables.\n",
    "            name: str, name of critic.\n",
    "        \"\"\"\n",
    "        # Set name of critic.\n",
    "        self.name = name\n",
    "\n",
    "        # Regularizer for kernel weights.\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "\n",
    "        # Regularizer for bias weights.\n",
    "        self.bias_regularizer = bias_regularizer\n",
    "\n",
    "    def get_critic_logits(self, X, params):\n",
    "        \"\"\"Creates critic network and returns logits.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, image tensors of shape\n",
    "                [cur_batch_size, height, width, depth].\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Logits tensor of shape [cur_batch_size, 1].\n",
    "        \"\"\"\n",
    "        func_name = \"get_critic_logits\"\n",
    "        # Create the input layer to our CNN.\n",
    "        # shape = (cur_batch_size, height * width * depth)\n",
    "        network = X\n",
    "        print_obj(\"\\n\" + func_name, \"network\", network)\n",
    "\n",
    "        with tf.variable_scope(\"critic\", reuse=tf.AUTO_REUSE):\n",
    "            # Iteratively build downsampling layers.\n",
    "            for i in range(len(params[\"critic_num_filters\"])):\n",
    "                # Add convolutional layers with given params per layer.\n",
    "                # shape = (\n",
    "                #     cur_batch_size,\n",
    "                #     critic_kernel_sizes[i - 1] / critic_strides[i],\n",
    "                #     critic_kernel_sizes[i - 1] / critic_strides[i],\n",
    "                #     critic_num_filters[i]\n",
    "                # )\n",
    "                network = tf.layers.conv2d(\n",
    "                    inputs=network,\n",
    "                    filters=params[\"critic_num_filters\"][i],\n",
    "                    kernel_size=params[\"critic_kernel_sizes\"][i],\n",
    "                    strides=params[\"critic_strides\"][i],\n",
    "                    padding=\"same\",\n",
    "                    activation=None,\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"layers_conv2d_{}\".format(i)\n",
    "                )\n",
    "                print_obj(func_name, \"network\", network)\n",
    "\n",
    "                network = tf.nn.leaky_relu(\n",
    "                    features=network,\n",
    "                    alpha=params[\"critic_leaky_relu_alpha\"],\n",
    "                    name=\"leaky_relu_{}\".format(i)\n",
    "                )\n",
    "                print_obj(func_name, \"network\", network)\n",
    "\n",
    "                if params[\"critic_use_layer_normalization\"]:\n",
    "                    # Normalize layer.\n",
    "                    network = tf.contrib.layers.layer_norm(inputs=network)\n",
    "\n",
    "            # Flatten network output.\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     (critic_kernel_sizes[-2] / critic_strides[-1]) ** 2 * critic_num_filters[-1]\n",
    "            # )\n",
    "            network_flat = tf.layers.Flatten()(inputs=network)\n",
    "            print_obj(func_name, \"network_flat\", network_flat)\n",
    "\n",
    "            # Final linear layer for logits.\n",
    "            # shape = (cur_batch_size, 1)\n",
    "            logits = tf.layers.dense(\n",
    "                inputs=network_flat,\n",
    "                units=1,\n",
    "                activation=None,\n",
    "                kernel_regularizer=self.kernel_regularizer,\n",
    "                bias_regularizer=self.bias_regularizer,\n",
    "                name=\"layers_dense_logits\"\n",
    "            )\n",
    "            print_obj(func_name, \"logits\", logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def get_gradient_penalty_loss(\n",
    "            self, cur_batch_size, fake_images, real_images, params):\n",
    "        \"\"\"Gets critic gradient penalty loss.\n",
    "\n",
    "        Args:\n",
    "            cur_batch_size: tensor, in case of a partial batch instead of\n",
    "                using the user passed int.\n",
    "            fake_images: tensor, images generated by the generator from random\n",
    "                noise of shape [cur_batch_size, image_size, image_size, 3].\n",
    "            real_images: tensor, real images from input of shape\n",
    "                [cur_batch_size, image_size, image_size, 3].\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Critic's gradient penalty loss of shape [].\n",
    "        \"\"\"\n",
    "        func_name = \"get_gradient_penalty_loss\"\n",
    "        with tf.name_scope(name=\"critic/gradient_penalty\"):\n",
    "            # Get a random uniform number rank 4 tensor.\n",
    "            random_uniform_num = tf.random.uniform(\n",
    "                shape=[cur_batch_size, 1, 1, 1],\n",
    "                minval=0., maxval=1.,\n",
    "                dtype=tf.float32,\n",
    "                name=\"random_uniform_num\"\n",
    "            )\n",
    "            print_obj(\n",
    "                \"\\n\" + func_name, \"random_uniform_num\", random_uniform_num\n",
    "            )\n",
    "\n",
    "            # Find the element-wise difference between images.\n",
    "            image_difference = fake_images - real_images\n",
    "            print_obj(func_name, \"image_difference\", image_difference)\n",
    "\n",
    "            # Get random samples from this mixed image distribution.\n",
    "            mixed_images = random_uniform_num * image_difference\n",
    "            mixed_images += real_images\n",
    "            print_obj(func_name, \"mixed_images\", mixed_images)\n",
    "\n",
    "            # Send to the critic to get logits.\n",
    "            mixed_logits = self.get_critic_logits(\n",
    "                X=mixed_images, params=params\n",
    "            )\n",
    "            print_obj(func_name, \"mixed_logits\", mixed_logits)\n",
    "\n",
    "            # Get the mixed loss.\n",
    "            mixed_loss = tf.reduce_sum(\n",
    "                input_tensor=mixed_logits, name=\"mixed_loss\"\n",
    "            )\n",
    "            print_obj(func_name, \"mixed_loss\", mixed_loss)\n",
    "\n",
    "            # Get gradient from returned list of length 1.\n",
    "            mixed_gradients = tf.gradients(\n",
    "                ys=mixed_loss, xs=[mixed_images], name=\"gradients\"\n",
    "            )[0]\n",
    "            print_obj(func_name, \"mixed_gradients\", mixed_gradients)\n",
    "\n",
    "            # Get gradient's L2 norm.\n",
    "            mixed_norms = tf.sqrt(\n",
    "                x=tf.reduce_sum(\n",
    "                    input_tensor=tf.square(\n",
    "                        x=mixed_gradients,\n",
    "                        name=\"squared_grads\"\n",
    "                    ),\n",
    "                    axis=[1, 2, 3]\n",
    "                ) + 1e-8\n",
    "            )\n",
    "            print_obj(func_name, \"mixed_norms\", mixed_norms)\n",
    "\n",
    "            # Get squared difference from target of 1.0.\n",
    "            squared_difference = tf.square(\n",
    "                x=mixed_norms - 1.0, name=\"squared_difference\"\n",
    "            )\n",
    "            print_obj(func_name, \"squared_difference\", squared_difference)\n",
    "\n",
    "            # Get gradient penalty scalar.\n",
    "            gradient_penalty = tf.reduce_mean(\n",
    "                input_tensor=squared_difference, name=\"gradient_penalty\"\n",
    "            )\n",
    "            print_obj(func_name, \"gradient_penalty\", gradient_penalty)\n",
    "\n",
    "            # Multiply with lambda to get gradient penalty loss.\n",
    "            gradient_penalty_loss = tf.multiply(\n",
    "                x=params[\"critic_gradient_penalty_coefficient\"],\n",
    "                y=gradient_penalty,\n",
    "                name=\"gradient_penalty_loss\"\n",
    "            )\n",
    "\n",
    "            return gradient_penalty_loss\n",
    "\n",
    "    def get_critic_loss(\n",
    "            self,\n",
    "            cur_batch_size,\n",
    "            fake_images,\n",
    "            real_images,\n",
    "            fake_logits,\n",
    "            real_logits,\n",
    "            params):\n",
    "        \"\"\"Gets critic's total loss.\n",
    "\n",
    "        Args:\n",
    "            cur_batch_size: tensor, in case of a partial batch instead of\n",
    "                using the user passed int.\n",
    "            fake_images: tensor, images generated by the generator from random\n",
    "                noise of shape [cur_batch_size, image_size, image_size, 3].\n",
    "            real_images: tensor, real images from input of shape\n",
    "                [cur_batch_size, image_size, image_size, 3].\n",
    "            fake_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "                critic having processed generator's output image.\n",
    "            fake_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "                critic having processed real image.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Critic's total loss tensor of shape [].\n",
    "        \"\"\"\n",
    "        func_name = \"get_critic_loss\"\n",
    "        # Calculate base critic loss.\n",
    "        critic_real_loss = tf.reduce_mean(\n",
    "            input_tensor=real_logits, name=\"critic_real_loss\"\n",
    "        )\n",
    "        print_obj(\"\\n\" + func_name, \"critic_real_loss\", critic_real_loss)\n",
    "\n",
    "        critic_fake_loss = tf.reduce_mean(\n",
    "            input_tensor=fake_logits, name=\"critic_fake_loss\"\n",
    "        )\n",
    "        print_obj(\n",
    "            func_name, \"critic_fake_loss\", critic_fake_loss\n",
    "        )\n",
    "\n",
    "        critic_loss = tf.subtract(\n",
    "            x=critic_fake_loss, y=critic_real_loss, name=\"critic_loss\"\n",
    "        )\n",
    "        print_obj(func_name, \"critic_loss\", critic_loss)\n",
    "\n",
    "        # Get critic gradient penalty loss.\n",
    "        gradient_penalty_loss = self.get_gradient_penalty_loss(\n",
    "            cur_batch_size=cur_batch_size,\n",
    "            fake_images=fake_images,\n",
    "            real_images=real_images,\n",
    "            params=params\n",
    "        )\n",
    "        print_obj(func_name, \"gradient_penalty_loss\", gradient_penalty_loss)\n",
    "\n",
    "        # Get critic Wasserstein GP loss.\n",
    "        critic_wasserstein_gp_loss = tf.add(\n",
    "            x=critic_loss,\n",
    "            y=gradient_penalty_loss,\n",
    "            name=\"critic_wasserstein_gp_loss\"\n",
    "        )\n",
    "        print_obj(\n",
    "            func_name,\n",
    "            \"critic_wasserstein_gp_loss\",\n",
    "            critic_wasserstein_gp_loss\n",
    "        )\n",
    "\n",
    "        # Get regularization losses.\n",
    "        critic_reg_loss = tf.losses.get_regularization_loss(\n",
    "            scope=\"critic\", name=\"critic_reg_loss\"\n",
    "        )\n",
    "        print_obj(func_name, \"critic_reg_loss\", critic_reg_loss)\n",
    "\n",
    "        # Combine losses for total losses.\n",
    "        critic_total_loss = tf.math.add(\n",
    "            x=critic_wasserstein_gp_loss,\n",
    "            y=critic_reg_loss,\n",
    "            name=\"critic_total_loss\"\n",
    "        )\n",
    "        print_obj(func_name, \"critic_total_loss\", critic_total_loss)\n",
    "\n",
    "        # Add summaries for TensorBoard.\n",
    "        tf.summary.scalar(\n",
    "            name=\"critic_real_loss\", tensor=critic_real_loss, family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"critic_fake_loss\", tensor=critic_fake_loss, family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"critic_loss\", tensor=critic_loss, family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"gradient_penalty_loss\",\n",
    "            tensor=gradient_penalty_loss,\n",
    "            family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"critic_wasserstein_gp_loss\",\n",
    "            tensor=critic_wasserstein_gp_loss,\n",
    "            family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"critic_reg_loss\", tensor=critic_reg_loss, family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"critic_total_loss\",\n",
    "            tensor=critic_total_loss,\n",
    "            family=\"total_losses\"\n",
    "        )\n",
    "\n",
    "        return critic_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_and_eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits_and_losses(features, generator, critic, mode, params):\n",
    "    \"\"\"Gets logits and losses for both train and eval modes.\n",
    "\n",
    "    Args:\n",
    "        features: dict, feature tensors from input function.\n",
    "        generator: instance of generator.`Generator`.\n",
    "        critic: instance of critic.`Critic`.\n",
    "        mode: tf.estimator.ModeKeys with values of either TRAIN or EVAL.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Real and fake logits and generator and critic losses.\n",
    "    \"\"\"\n",
    "    func_name = \"get_logits_and_losses\"\n",
    "    # Extract real images from features dictionary.\n",
    "    real_images = features[\"image\"]\n",
    "    print_obj(\"\\n\" + func_name, \"real_images\", real_images)\n",
    "\n",
    "    # Get dynamic batch size in case of partial batch.\n",
    "    cur_batch_size = tf.shape(\n",
    "        input=real_images,\n",
    "        out_type=tf.int32,\n",
    "        name=\"{}_cur_batch_size\".format(func_name)\n",
    "    )[0]\n",
    "\n",
    "    # Create random noise latent vector for each batch example.\n",
    "    Z = tf.random.normal(\n",
    "        shape=[cur_batch_size, params[\"latent_size\"]],\n",
    "        mean=0.0,\n",
    "        stddev=1.0,\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "    print_obj(func_name, \"Z\", Z)\n",
    "\n",
    "    # Get generated image from generator network from gaussian noise.\n",
    "    print(\"\\nCall generator with Z = {}.\".format(Z))\n",
    "    fake_images = generator.get_fake_images(Z=Z, mode=mode, params=params)\n",
    "\n",
    "    # Resize fake images to match real image sizes.\n",
    "    fake_images = resize_fake_images(fake_images, params)\n",
    "    print_obj(func_name, \"fake_images\", fake_images)\n",
    "\n",
    "    # Add summaries for TensorBoard.\n",
    "    tf.summary.image(\n",
    "        name=\"fake_images\",\n",
    "        tensor=tf.reshape(\n",
    "            tensor=fake_images,\n",
    "            shape=[-1, params[\"height\"], params[\"width\"], params[\"depth\"]]\n",
    "        ),\n",
    "        max_outputs=5,\n",
    "    )\n",
    "\n",
    "    # Get fake logits from critic using generator's output image.\n",
    "    print(\"\\nCall critic with fake_images = {}.\".format(fake_images))\n",
    "    fake_logits = critic.get_critic_logits(\n",
    "        X=fake_images, params=params\n",
    "    )\n",
    "\n",
    "    # Get real logits from critic using real image.\n",
    "    print(\n",
    "        \"\\nCall critic with real_images = {}.\".format(real_images)\n",
    "    )\n",
    "    real_logits = critic.get_critic_logits(\n",
    "        X=real_images, params=params\n",
    "    )\n",
    "\n",
    "    # Get generator total loss.\n",
    "    generator_total_loss = generator.get_generator_loss(\n",
    "        fake_logits=fake_logits\n",
    "    )\n",
    "\n",
    "    # Get critic total loss.\n",
    "    critic_total_loss = critic.get_critic_loss(\n",
    "        cur_batch_size=cur_batch_size,\n",
    "        fake_images=fake_images,\n",
    "        real_images=real_images,\n",
    "        fake_logits=fake_logits,\n",
    "        real_logits=real_logits,\n",
    "        params=params\n",
    "    )\n",
    "\n",
    "    return (real_logits,\n",
    "            fake_logits,\n",
    "            generator_total_loss,\n",
    "            critic_total_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variables_and_gradients(loss, scope):\n",
    "    \"\"\"Gets variables and their gradients wrt. loss.\n",
    "    Args:\n",
    "        loss: tensor, shape of [].\n",
    "        scope: str, the network's name to find its variables to train.\n",
    "    Returns:\n",
    "        Lists of variables and their gradients.\n",
    "    \"\"\"\n",
    "    func_name = \"get_variables_and_gradients\"\n",
    "    # Get trainable variables.\n",
    "    variables = tf.trainable_variables(scope=scope)\n",
    "    print_obj(\"\\n{}_{}\".format(func_name, scope), \"variables\", variables)\n",
    "\n",
    "    # Get gradients.\n",
    "    gradients = tf.gradients(\n",
    "        ys=loss,\n",
    "        xs=variables,\n",
    "        name=\"{}_gradients\".format(scope)\n",
    "    )\n",
    "    print_obj(\"\\n{}_{}\".format(func_name, scope), \"gradients\", gradients)\n",
    "\n",
    "    # Add variable names back in for identification.\n",
    "    gradients = [\n",
    "        tf.identity(\n",
    "            input=g,\n",
    "            name=\"{}_{}_gradients\".format(func_name, v.name[:-2])\n",
    "        )\n",
    "        if tf.is_tensor(x=g) else g\n",
    "        for g, v in zip(gradients, variables)\n",
    "    ]\n",
    "    print_obj(\"\\n{}_{}\".format(func_name, scope), \"gradients\", gradients)\n",
    "\n",
    "    return variables, gradients\n",
    "\n",
    "\n",
    "def create_variable_and_gradient_histogram_summaries(loss_dict, params):\n",
    "    \"\"\"Creates variable and gradient histogram summaries.\n",
    "    Args:\n",
    "        loss_dict: dict, keys are scopes and values are scalar loss tensors\n",
    "            for each network kind.\n",
    "        params: dict, user passed parameters.\n",
    "    \"\"\"\n",
    "    for scope, loss in loss_dict.items():\n",
    "        # Get variables and their gradients wrt. loss.\n",
    "        variables, gradients = get_variables_and_gradients(loss, scope)\n",
    "\n",
    "        # Add summaries for TensorBoard.\n",
    "        for g, v in zip(gradients, variables):\n",
    "            tf.summary.histogram(\n",
    "                name=\"{}\".format(v.name[:-2]),\n",
    "                values=v,\n",
    "                family=\"{}_variables\".format(scope)\n",
    "            )\n",
    "            if tf.is_tensor(x=g):\n",
    "                tf.summary.histogram(\n",
    "                    name=\"{}\".format(v.name[:-2]),\n",
    "                    values=g,\n",
    "                    family=\"{}_gradients\".format(scope)\n",
    "                )\n",
    "\n",
    "\n",
    "def train_network(loss, global_step, params, scope):\n",
    "    \"\"\"Trains network and returns loss and train op.\n",
    "\n",
    "    Args:\n",
    "        loss: tensor, shape of [].\n",
    "        global_step: tensor, the current training step or batch in the\n",
    "            training loop.\n",
    "        params: dict, user passed parameters.\n",
    "        scope: str, the variables that to train.\n",
    "\n",
    "    Returns:\n",
    "        Loss tensor and training op.\n",
    "    \"\"\"\n",
    "    func_name = \"train_network\"\n",
    "    print_obj(\"\\n\" + func_name, \"scope\", scope)\n",
    "    # Create optimizer map.\n",
    "    optimizers = {\n",
    "        \"Adam\": tf.train.AdamOptimizer,\n",
    "        \"Adadelta\": tf.train.AdadeltaOptimizer,\n",
    "        \"AdagradDA\": tf.train.AdagradDAOptimizer,\n",
    "        \"Adagrad\": tf.train.AdagradOptimizer,\n",
    "        \"Ftrl\": tf.train.FtrlOptimizer,\n",
    "        \"GradientDescent\": tf.train.GradientDescentOptimizer,\n",
    "        \"Momentum\": tf.train.MomentumOptimizer,\n",
    "        \"ProximalAdagrad\": tf.train.ProximalAdagradOptimizer,\n",
    "        \"ProximalGradientDescent\": tf.train.ProximalGradientDescentOptimizer,\n",
    "        \"RMSProp\": tf.train.RMSPropOptimizer\n",
    "    }\n",
    "\n",
    "    # Get optimizer and instantiate it.\n",
    "    if params[\"{}_optimizer\".format(scope)] == \"Adam\":\n",
    "        optimizer = optimizers[params[\"{}_optimizer\".format(scope)]](\n",
    "            learning_rate=params[\"{}_learning_rate\".format(scope)],\n",
    "            beta1=params[\"{}_adam_beta1\".format(scope)],\n",
    "            beta2=params[\"{}_adam_beta2\".format(scope)],\n",
    "            epsilon=params[\"{}_adam_epsilon\".format(scope)],\n",
    "            name=\"{}_{}_optimizer\".format(\n",
    "                scope, params[\"{}_optimizer\".format(scope)].lower()\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        optimizer = optimizers[params[\"{}_optimizer\".format(scope)]](\n",
    "            learning_rate=params[\"{}_learning_rate\".format(scope)],\n",
    "            name=\"{}_{}_optimizer\".format(\n",
    "                scope, params[\"{}_optimizer\".format(scope)].lower()\n",
    "            )\n",
    "        )\n",
    "    print_obj(\"{}_{}\".format(func_name, scope), \"optimizer\", optimizer)\n",
    "\n",
    "    # Get gradients.\n",
    "    gradients = tf.gradients(\n",
    "        ys=loss,\n",
    "        xs=tf.trainable_variables(scope=scope),\n",
    "        name=\"{}_gradients\".format(scope)\n",
    "    )\n",
    "    print_obj(\"\\n{}_{}\".format(func_name, scope), \"gradients\", gradients)\n",
    "\n",
    "    # Clip gradients.\n",
    "    if params[\"{}_clip_gradients\".format(scope)]:\n",
    "        gradients, _ = tf.clip_by_global_norm(\n",
    "            t_list=gradients,\n",
    "            clip_norm=params[\"{}_clip_gradients\".format(scope)],\n",
    "            name=\"{}_clip_by_global_norm_gradients\".format(scope)\n",
    "        )\n",
    "        print_obj(\"\\n{}_{}\".format(func_name, scope), \"gradients\", gradients)\n",
    "\n",
    "    # Zip back together gradients and variables.\n",
    "    grads_and_vars = zip(gradients, tf.trainable_variables(scope=scope))\n",
    "    print_obj(\n",
    "        \"{}_{}\".format(func_name, scope), \"grads_and_vars\", grads_and_vars\n",
    "    )\n",
    "\n",
    "    # Create train op by applying gradients to variables and incrementing\n",
    "    # global step.\n",
    "    train_op = optimizer.apply_gradients(\n",
    "        grads_and_vars=grads_and_vars,\n",
    "        global_step=global_step,\n",
    "        name=\"{}_apply_gradients\".format(scope)\n",
    "    )\n",
    "\n",
    "    return loss, train_op\n",
    "\n",
    "\n",
    "def get_loss_and_train_op(\n",
    "        generator_total_loss, critic_total_loss, params):\n",
    "    \"\"\"Gets loss and train op for train mode.\n",
    "    Args:\n",
    "        generator_total_loss: tensor, scalar total loss of generator.\n",
    "        critic_total_loss: tensor, scalar total loss of critic.\n",
    "        params: dict, user passed parameters.\n",
    "    Returns:\n",
    "        Loss scalar tensor and train_op to be used by the EstimatorSpec.\n",
    "    \"\"\"\n",
    "    func_name = \"get_loss_and_train_op\"\n",
    "    # Get global step.\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    # Determine if it is time to train generator or critic.\n",
    "    cycle_step = tf.mod(\n",
    "        x=global_step,\n",
    "        y=tf.cast(\n",
    "            x=tf.add(\n",
    "                x=params[\"critic_train_steps\"],\n",
    "                y=params[\"generator_train_steps\"]\n",
    "            ),\n",
    "            dtype=tf.int64\n",
    "        ),\n",
    "        name=\"{}_cycle_step\".format(func_name)\n",
    "    )\n",
    "\n",
    "    # Create choose critic condition.\n",
    "    condition = tf.less(\n",
    "        x=cycle_step, y=params[\"critic_train_steps\"]\n",
    "    )\n",
    "\n",
    "    # Needed for batch normalization, but has no effect otherwise.\n",
    "    update_ops = tf.get_collection(key=tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "    # Ensure update ops get updated.\n",
    "    with tf.control_dependencies(control_inputs=update_ops):\n",
    "        # Conditionally choose to train generator or critic subgraph.\n",
    "        loss, train_op = tf.cond(\n",
    "            pred=condition,\n",
    "            true_fn=lambda: train_network(\n",
    "                loss=critic_total_loss,\n",
    "                global_step=global_step,\n",
    "                params=params,\n",
    "                scope=\"critic\"\n",
    "            ),\n",
    "            false_fn=lambda: train_network(\n",
    "                loss=generator_total_loss,\n",
    "                global_step=global_step,\n",
    "                params=params,\n",
    "                scope=\"generator\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return loss, train_op\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval_metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metric_ops(fake_logits, real_logits, params):\n",
    "    \"\"\"Gets eval metric ops.\n",
    "\n",
    "    Args:\n",
    "        fake_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "            critic having processed generator's output image.\n",
    "        real_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "            critic having processed real image.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of eval metric ops.\n",
    "    \"\"\"\n",
    "    func_name = \"get_eval_metric_ops\"\n",
    "    # Concatenate critic logits and labels.\n",
    "    critic_logits = tf.concat(\n",
    "        values=[real_logits, fake_logits],\n",
    "        axis=0,\n",
    "        name=\"critic_concat_logits\"\n",
    "    )\n",
    "    print_obj(\"\\n\" + func_name, \"critic_logits\", critic_logits)\n",
    "\n",
    "    critic_labels = tf.concat(\n",
    "        values=[\n",
    "            tf.ones_like(tensor=real_logits),\n",
    "            tf.zeros_like(tensor=fake_logits)\n",
    "        ],\n",
    "        axis=0,\n",
    "        name=\"critic_concat_labels\"\n",
    "    )\n",
    "    print_obj(func_name, \"critic_labels\", critic_labels)\n",
    "\n",
    "    # Calculate critic probabilities.\n",
    "    critic_probabilities = tf.nn.sigmoid(\n",
    "        x=critic_logits, name=\"critic_probabilities\"\n",
    "    )\n",
    "    print_obj(\n",
    "        func_name, \"critic_probabilities\", critic_probabilities\n",
    "    )\n",
    "\n",
    "    # Create eval metric ops dictionary.\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=critic_labels,\n",
    "            predictions=critic_probabilities,\n",
    "            name=\"critic_accuracy\"\n",
    "        ),\n",
    "        \"precision\": tf.metrics.precision(\n",
    "            labels=critic_labels,\n",
    "            predictions=critic_probabilities,\n",
    "            name=\"critic_precision\"\n",
    "        ),\n",
    "        \"recall\": tf.metrics.recall(\n",
    "            labels=critic_labels,\n",
    "            predictions=critic_probabilities,\n",
    "            name=\"critic_recall\"\n",
    "        ),\n",
    "        \"auc_roc\": tf.metrics.auc(\n",
    "            labels=critic_labels,\n",
    "            predictions=critic_probabilities,\n",
    "            num_thresholds=200,\n",
    "            curve=\"ROC\",\n",
    "            name=\"critic_auc_roc\"\n",
    "        ),\n",
    "        \"auc_pr\": tf.metrics.auc(\n",
    "            labels=critic_labels,\n",
    "            predictions=critic_probabilities,\n",
    "            num_thresholds=200,\n",
    "            curve=\"PR\",\n",
    "            name=\"critic_auc_pr\"\n",
    "        )\n",
    "    }\n",
    "    print_obj(func_name, \"eval_metric_ops\", eval_metric_ops)\n",
    "\n",
    "    return eval_metric_ops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_and_export_outputs(features, generator, params):\n",
    "    \"\"\"Gets predictions and serving export outputs.\n",
    "\n",
    "    Args:\n",
    "        features: dict, feature tensors from serving input function.\n",
    "        generator: instance of `Generator`.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Predictions dictionary and export outputs dictionary.\n",
    "    \"\"\"\n",
    "    func_name = \"get_predictions_and_export_outputs\"\n",
    "\n",
    "    # Extract given latent vectors from features dictionary.\n",
    "    Z = features[\"Z\"]\n",
    "    print_obj(\"\\n\" + func_name, \"Z\", Z)\n",
    "\n",
    "    # Get generated images from generator using latent vector.\n",
    "    generated_images = generator.get_fake_images(\n",
    "        Z=Z, mode=tf.estimator.ModeKeys.PREDICT, params=params\n",
    "    )\n",
    "    print_obj(func_name, \"generated_images\", generated_images)\n",
    "\n",
    "    # Resize generated images to match real image sizes.\n",
    "    generated_images = resize_fake_images(\n",
    "        fake_images=generated_images, params=params\n",
    "    )\n",
    "    print_obj(func_name, \"generated_images\", generated_images)\n",
    "\n",
    "    # Create predictions dictionary.\n",
    "    predictions_dict = {\n",
    "        \"generated_images\": generated_images\n",
    "    }\n",
    "    print_obj(func_name, \"predictions_dict\", predictions_dict)\n",
    "\n",
    "    # Create export outputs.\n",
    "    export_outputs = {\n",
    "        \"predict_export_outputs\": tf.estimator.export.PredictOutput(\n",
    "            outputs=predictions_dict)\n",
    "    }\n",
    "    print_obj(func_name, \"export_outputs\", export_outputs)\n",
    "\n",
    "    return predictions_dict, export_outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wgan_gp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wgan_gp_model(features, labels, mode, params):\n",
    "    \"\"\"Wasserstein GAN with gradient penalty custom Estimator model function.\n",
    "\n",
    "    Args:\n",
    "        features: dict, keys are feature names and values are feature tensors.\n",
    "        labels: tensor, label data.\n",
    "        mode: tf.estimator.ModeKeys with values of either TRAIN, EVAL, or\n",
    "            PREDICT.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Instance of `tf.estimator.EstimatorSpec` class.\n",
    "    \"\"\"\n",
    "    func_name = \"wgan_gp_model\"\n",
    "    print_obj(\"\\n\" + func_name, \"features\", features)\n",
    "    print_obj(func_name, \"labels\", labels)\n",
    "    print_obj(func_name, \"mode\", mode)\n",
    "    print_obj(func_name, \"params\", params)\n",
    "\n",
    "    # Loss function, training/eval ops, etc.\n",
    "    predictions_dict = None\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = None\n",
    "    export_outputs = None\n",
    "\n",
    "    # Instantiate generator.\n",
    "    wgan_generator = Generator(\n",
    "        kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(\n",
    "            scale_l1=params[\"generator_l1_regularization_scale\"],\n",
    "            scale_l2=params[\"generator_l2_regularization_scale\"]\n",
    "        ),\n",
    "        bias_regularizer=None,\n",
    "        name=\"generator\"\n",
    "    )\n",
    "\n",
    "    # Instantiate critic.\n",
    "    wgan_critic = Critic(\n",
    "        kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(\n",
    "            scale_l1=params[\"critic_l1_regularization_scale\"],\n",
    "            scale_l2=params[\"critic_l2_regularization_scale\"]\n",
    "        ),\n",
    "        bias_regularizer=None,\n",
    "        name=\"critic\"\n",
    "    )\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # Get predictions and export outputs.\n",
    "        (predictions_dict,\n",
    "         export_outputs) = get_predictions_and_export_outputs(\n",
    "            features=features, generator=wgan_generator, params=params\n",
    "        )\n",
    "    else:\n",
    "        # Get logits and losses from networks for train and eval modes.\n",
    "        (real_logits,\n",
    "         fake_logits,\n",
    "         generator_total_loss,\n",
    "         critic_total_loss) = get_logits_and_losses(\n",
    "            features=features,\n",
    "            generator=wgan_generator,\n",
    "            critic=wgan_critic,\n",
    "            mode=mode,\n",
    "            params=params\n",
    "        )\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            # Create variable and gradient histogram summaries.\n",
    "            create_variable_and_gradient_histogram_summaries(\n",
    "                loss_dict={\n",
    "                    \"generator\": generator_total_loss,\n",
    "                    \"critic\": critic_total_loss\n",
    "                },\n",
    "                params=params\n",
    "            )\n",
    "\n",
    "            # Get loss and train op for EstimatorSpec.\n",
    "            loss, train_op = get_loss_and_train_op(\n",
    "                generator_total_loss=generator_total_loss,\n",
    "                critic_total_loss=critic_total_loss,\n",
    "                params=params\n",
    "            )\n",
    "        else:\n",
    "            # Set eval loss.\n",
    "            loss = critic_total_loss\n",
    "\n",
    "            # Get eval metrics.\n",
    "            eval_metric_ops = get_eval_metric_ops(\n",
    "                real_logits=real_logits,\n",
    "                fake_logits=fake_logits,\n",
    "                params=params\n",
    "            )\n",
    "\n",
    "    # Return EstimatorSpec\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions_dict,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops,\n",
    "        export_outputs=export_outputs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## serving.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn(params):\n",
    "    \"\"\"Serving input function.\n",
    "\n",
    "    Args:\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        ServingInputReceiver object containing features and receiver tensors.\n",
    "    \"\"\"\n",
    "    func_name = \"serving_input_fn\"\n",
    "    # Create placeholders to accept data sent to the model at serving time.\n",
    "    # shape = (batch_size,)\n",
    "    feature_placeholders = {\n",
    "        \"Z\": tf.placeholder(\n",
    "            dtype=tf.float32,\n",
    "            shape=[None, params[\"latent_size\"]],\n",
    "            name=\"serving_input_placeholder_Z\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    print_obj(\"\\n\" + func_name, \"feature_placeholders\", feature_placeholders)\n",
    "\n",
    "    # Create clones of the feature placeholder tensors so that the SavedModel\n",
    "    # SignatureDef will point to the placeholder.\n",
    "    features = {\n",
    "        key: tf.identity(\n",
    "            input=value,\n",
    "            name=\"{}_identity_placeholder_{}\".format(func_name, key)\n",
    "        )\n",
    "        for key, value in feature_placeholders.items()\n",
    "    }\n",
    "    print_obj(func_name, \"features\", features)\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features=features, receiver_tensors=feature_placeholders\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(args):\n",
    "    \"\"\"Trains and evaluates custom Estimator model.\n",
    "\n",
    "    Args:\n",
    "        args: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        `Estimator` object.\n",
    "    \"\"\"\n",
    "    func_name = \"train_and_evaluate\"\n",
    "    print_obj(\"\\n\" + func_name, \"args\", args)\n",
    "    # Ensure filewriter cache is clear for TensorBoard events file.\n",
    "    tf.summary.FileWriterCache.clear()\n",
    "\n",
    "    # Set logging to be level of INFO.\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    # Create a RunConfig for Estimator.\n",
    "    config = tf.estimator.RunConfig(\n",
    "        model_dir=args[\"output_dir\"],\n",
    "        save_summary_steps=args[\"save_summary_steps\"],\n",
    "        save_checkpoints_steps=args[\"save_checkpoints_steps\"],\n",
    "        keep_checkpoint_max=args[\"keep_checkpoint_max\"]\n",
    "    )\n",
    "\n",
    "    # Create our custom estimator using our model function.\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn=wgan_gp_model,\n",
    "        model_dir=args[\"output_dir\"],\n",
    "        config=config,\n",
    "        params=args\n",
    "    )\n",
    "\n",
    "    # Create train spec to read in our training data.\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"train_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.TRAIN,\n",
    "            batch_size=args[\"train_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        max_steps=args[\"train_steps\"]\n",
    "    )\n",
    "\n",
    "    # Create exporter to save out the complete model to disk.\n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        name=\"exporter\",\n",
    "        serving_input_receiver_fn=lambda: serving_input_fn(args)\n",
    "    )\n",
    "\n",
    "    # Create eval spec to read in our validation data and export our model.\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"eval_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.EVAL,\n",
    "            batch_size=args[\"eval_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        steps=args[\"eval_steps\"],\n",
    "        start_delay_secs=args[\"start_delay_secs\"],\n",
    "        throttle_secs=args[\"throttle_secs\"],\n",
    "        exporters=exporter\n",
    "    )\n",
    "\n",
    "    # Create train and evaluate loop to train and evaluate our estimator.\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n",
    "\n",
    "    return estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OUTPUT_DIR\"] = arguments[\"output_dir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil -m rm -rf ${OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_and_evaluate: args = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model', 'train_batch_size': 64, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [4, 4, 256], 'generator_num_filters': [128, 128, 128], 'generator_kernel_sizes': [4, 4, 4], 'generator_strides': [2, 2, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 3, 'generator_final_stride': 1, 'generator_leaky_relu_alpha': 0.2, 'generator_use_batch_normalization': True, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.9, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'critic_num_filters': [64, 128, 128, 256], 'critic_kernel_sizes': [3, 3, 3, 3], 'critic_strides': [1, 2, 2, 2], 'critic_leaky_relu_alpha': 0.2, 'critic_use_layer_normalization': True, 'critic_l1_regularization_scale': 0.0, 'critic_l2_regularization_scale': 0.0, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_adam_beta1': 0.0, 'critic_adam_beta2': 0.9, 'critic_adam_epsilon': 1e-08, 'critic_clip_gradients': None, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8c241f1110>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 5000 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-5-c725903d59ef>:88: shuffle_and_repeat (from tensorflow.contrib.data.python.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.shuffle_and_repeat(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/shuffle_ops.py:54: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From <ipython-input-5-c725903d59ef>:100: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "WARNING:tensorflow:From <ipython-input-5-c725903d59ef>:108: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_gp_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "wgan_gp_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "wgan_gp_model: mode = train\n",
      "wgan_gp_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model', 'train_batch_size': 64, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [4, 4, 256], 'generator_num_filters': [128, 128, 128], 'generator_kernel_sizes': [4, 4, 4], 'generator_strides': [2, 2, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 3, 'generator_final_stride': 1, 'generator_leaky_relu_alpha': 0.2, 'generator_use_batch_normalization': True, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.9, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'critic_num_filters': [64, 128, 128, 256], 'critic_kernel_sizes': [3, 3, 3, 3], 'critic_strides': [1, 2, 2, 2], 'critic_leaky_relu_alpha': 0.2, 'critic_use_layer_normalization': True, 'critic_l1_regularization_scale': 0.0, 'critic_l2_regularization_scale': 0.0, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_adam_beta1': 0.0, 'critic_adam_beta2': 0.9, 'critic_adam_epsilon': 1e-08, 'critic_clip_gradients': None, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_fake_images: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-6-28e27c65a947>:65: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_leaky_relu = Tensor(\"generator/projection_leaky_relu:0\", shape=(?, 4096), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-6-28e27c65a947>:87: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-6-28e27c65a947>:127: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_2/BiasAdd:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_2/FusedBatchNormV3:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_logits_and_losses: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "Call critic with fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32).\n",
      "\n",
      "get_critic_logits: network = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-7-309653a3f840>:64: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call critic with real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0).\n",
      "\n",
      "get_critic_logits: network = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic_1/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_critic_loss: critic_real_loss = Tensor(\"critic_real_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_fake_loss = Tensor(\"critic_fake_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_loss = Tensor(\"critic_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"critic/gradient_penalty/random_uniform_num:0\", shape=(?, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"critic/gradient_penalty/sub:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic/gradient_penalty/critic/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"critic/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"critic/gradient_penalty/gradients/critic/gradient_penalty/critic/layers_conv2d_0/Conv2D_grad/Conv2DBackpropInput:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"critic/gradient_penalty/Sqrt:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"critic/gradient_penalty/squared_difference:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"critic/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: gradient_penalty_loss = Tensor(\"critic/gradient_penalty/gradient_penalty_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_wasserstein_gp_loss = Tensor(\"critic_wasserstein_gp_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_reg_loss = Tensor(\"Const_5:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_total_loss = Tensor(\"critic_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_variables_and_gradients_generator: variables = [<tf.Variable 'generator/projection_dense_layer/kernel:0' shape=(512, 4096) dtype=float32_ref>, <tf.Variable 'generator/projection_dense_layer/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'generator/projection_batch_norm/gamma:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'generator/projection_batch_norm/beta:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_0/kernel:0' shape=(4, 4, 128, 256) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_0/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'generator/layers_batch_norm_0/gamma:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'generator/layers_batch_norm_0/beta:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_1/kernel:0' shape=(4, 4, 128, 128) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_1/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'generator/layers_batch_norm_1/gamma:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'generator/layers_batch_norm_1/beta:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_2/kernel:0' shape=(4, 4, 128, 128) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_2/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'generator/layers_batch_norm_2/gamma:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'generator/layers_batch_norm_2/beta:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_fake_images/kernel:0' shape=(3, 3, 3, 128) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_fake_images/bias:0' shape=(3,) dtype=float32_ref>]\n",
      "\n",
      "get_variables_and_gradients_generator: gradients = [<tf.Tensor 'generator_gradients/generator/projection_dense_layer/MatMul_grad/MatMul_1:0' shape=(512, 4096) dtype=float32>, <tf.Tensor 'generator_gradients/generator/projection_dense_layer/BiasAdd_grad/BiasAddGrad:0' shape=(4096,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/projection_batch_norm/batchnorm/mul_grad/Mul_1:0' shape=(4096,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/projection_batch_norm/batchnorm/add_1_grad/Reshape_1:0' shape=(4096,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_0/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(4, 4, 128, 256) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_0/BiasAdd_grad/BiasAddGrad:0' shape=(128,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_batch_norm_0/FusedBatchNormV3_grad/FusedBatchNormGradV3:1' shape=(128,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_batch_norm_0/FusedBatchNormV3_grad/FusedBatchNormGradV3:2' shape=(128,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_1/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(4, 4, 128, 128) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_1/BiasAdd_grad/BiasAddGrad:0' shape=(128,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_batch_norm_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:1' shape=(128,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_batch_norm_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:2' shape=(128,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_2/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(4, 4, 128, 128) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_2/BiasAdd_grad/BiasAddGrad:0' shape=(128,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_batch_norm_2/FusedBatchNormV3_grad/FusedBatchNormGradV3:1' shape=(128,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_batch_norm_2/FusedBatchNormV3_grad/FusedBatchNormGradV3:2' shape=(128,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_fake_images/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(3, 3, 3, 128) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_fake_images/BiasAdd_grad/BiasAddGrad:0' shape=(3,) dtype=float32>]\n",
      "\n",
      "get_variables_and_gradients_generator: gradients = [<tf.Tensor 'get_variables_and_gradients_generator/projection_dense_layer/kernel_gradients:0' shape=(512, 4096) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/projection_dense_layer/bias_gradients:0' shape=(4096,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/projection_batch_norm/gamma_gradients:0' shape=(4096,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/projection_batch_norm/beta_gradients:0' shape=(4096,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_0/kernel_gradients:0' shape=(4, 4, 128, 256) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_0/bias_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_batch_norm_0/gamma_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_batch_norm_0/beta_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_1/kernel_gradients:0' shape=(4, 4, 128, 128) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_1/bias_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_batch_norm_1/gamma_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_batch_norm_1/beta_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_2/kernel_gradients:0' shape=(4, 4, 128, 128) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_2/bias_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_batch_norm_2/gamma_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_batch_norm_2/beta_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_fake_images/kernel_gradients:0' shape=(3, 3, 3, 128) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_fake_images/bias_gradients:0' shape=(3,) dtype=float32>]\n",
      "\n",
      "get_variables_and_gradients_critic: variables = [<tf.Variable 'critic/layers_conv2d_0/kernel:0' shape=(3, 3, 3, 64) dtype=float32_ref>, <tf.Variable 'critic/layers_conv2d_0/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'critic/LayerNorm/beta:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'critic/LayerNorm/gamma:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'critic/layers_conv2d_1/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'critic/layers_conv2d_1/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'critic/LayerNorm_1/beta:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'critic/LayerNorm_1/gamma:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'critic/layers_conv2d_2/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'critic/layers_conv2d_2/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'critic/LayerNorm_2/beta:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'critic/LayerNorm_2/gamma:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'critic/layers_conv2d_3/kernel:0' shape=(3, 3, 128, 256) dtype=float32_ref>, <tf.Variable 'critic/layers_conv2d_3/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'critic/LayerNorm_3/beta:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'critic/LayerNorm_3/gamma:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'critic/layers_dense_logits/kernel:0' shape=(4096, 1) dtype=float32_ref>, <tf.Variable 'critic/layers_dense_logits/bias:0' shape=(1,) dtype=float32_ref>]\n",
      "\n",
      "get_variables_and_gradients_critic: gradients = [<tf.Tensor 'critic_gradients/AddN_68:0' shape=(3, 3, 3, 64) dtype=float32>, <tf.Tensor 'critic_gradients/AddN_67:0' shape=(64,) dtype=float32>, <tf.Tensor 'critic_gradients/AddN_59:0' shape=(64,) dtype=float32>, <tf.Tensor 'critic_gradients/AddN_62:0' shape=(64,) dtype=float32>, <tf.Tensor 'critic_gradients/AddN_58:0' shape=(3, 3, 64, 128) dtype=float32>, <tf.Tensor 'critic_gradients/AddN_57:0' shape=(128,) dtype=float32>, <tf.Tensor 'critic_gradients/AddN_49:0' shape=(128,) dtype=float32>, <tf.Tensor 'critic_gradients/AddN_52:0' shape=(128,) dtype=float32>, <tf.Tensor 'critic_gradients/AddN_48:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Tensor 'critic_gradients/AddN_47:0' shape=(128,) dtype=float32>, <tf.Tensor 'critic_gradients/AddN_39:0' shape=(128,) dtype=float32>, <tf.Tensor 'critic_gradients/AddN_42:0' shape=(128,) dtype=float32>, <tf.Tensor 'critic_gradients/AddN_38:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Tensor 'critic_gradients/AddN_37:0' shape=(256,) dtype=float32>, <tf.Tensor 'critic_gradients/AddN_30:0' shape=(256,) dtype=float32>, <tf.Tensor 'critic_gradients/AddN_33:0' shape=(256,) dtype=float32>, <tf.Tensor 'critic_gradients/AddN_29:0' shape=(4096, 1) dtype=float32>, <tf.Tensor 'critic_gradients/AddN:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "get_variables_and_gradients_critic: gradients = [<tf.Tensor 'get_variables_and_gradients_critic/layers_conv2d_0/kernel_gradients:0' shape=(3, 3, 3, 64) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_critic/layers_conv2d_0/bias_gradients:0' shape=(64,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_critic/LayerNorm/beta_gradients:0' shape=(64,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_critic/LayerNorm/gamma_gradients:0' shape=(64,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_critic/layers_conv2d_1/kernel_gradients:0' shape=(3, 3, 64, 128) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_critic/layers_conv2d_1/bias_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_critic/LayerNorm_1/beta_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_critic/LayerNorm_1/gamma_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_critic/layers_conv2d_2/kernel_gradients:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_critic/layers_conv2d_2/bias_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_critic/LayerNorm_2/beta_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_critic/LayerNorm_2/gamma_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_critic/layers_conv2d_3/kernel_gradients:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_critic/layers_conv2d_3/bias_gradients:0' shape=(256,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_critic/LayerNorm_3/beta_gradients:0' shape=(256,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_critic/LayerNorm_3/gamma_gradients:0' shape=(256,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_critic/layers_dense_logits/kernel_gradients:0' shape=(4096, 1) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_critic/layers_dense_logits/bias_gradients:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "train_network: scope = critic\n",
      "train_network_critic: optimizer = <tensorflow.python.training.adam.AdamOptimizer object at 0x7f8c16637ed0>\n",
      "\n",
      "train_network_critic: gradients = [<tf.Tensor 'cond/critic_gradients/AddN_68:0' shape=(3, 3, 3, 64) dtype=float32>, <tf.Tensor 'cond/critic_gradients/AddN_67:0' shape=(64,) dtype=float32>, <tf.Tensor 'cond/critic_gradients/AddN_59:0' shape=(64,) dtype=float32>, <tf.Tensor 'cond/critic_gradients/AddN_62:0' shape=(64,) dtype=float32>, <tf.Tensor 'cond/critic_gradients/AddN_58:0' shape=(3, 3, 64, 128) dtype=float32>, <tf.Tensor 'cond/critic_gradients/AddN_57:0' shape=(128,) dtype=float32>, <tf.Tensor 'cond/critic_gradients/AddN_49:0' shape=(128,) dtype=float32>, <tf.Tensor 'cond/critic_gradients/AddN_52:0' shape=(128,) dtype=float32>, <tf.Tensor 'cond/critic_gradients/AddN_48:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Tensor 'cond/critic_gradients/AddN_47:0' shape=(128,) dtype=float32>, <tf.Tensor 'cond/critic_gradients/AddN_39:0' shape=(128,) dtype=float32>, <tf.Tensor 'cond/critic_gradients/AddN_42:0' shape=(128,) dtype=float32>, <tf.Tensor 'cond/critic_gradients/AddN_38:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Tensor 'cond/critic_gradients/AddN_37:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/critic_gradients/AddN_30:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/critic_gradients/AddN_33:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/critic_gradients/AddN_29:0' shape=(4096, 1) dtype=float32>, <tf.Tensor 'cond/critic_gradients/AddN:0' shape=(1,) dtype=float32>]\n",
      "train_network_critic: grads_and_vars = <zip object at 0x7f8c166330f0>\n",
      "\n",
      "train_network: scope = generator\n",
      "train_network_generator: optimizer = <tensorflow.python.training.adam.AdamOptimizer object at 0x7f8c15c14d50>\n",
      "\n",
      "train_network_generator: gradients = [<tf.Tensor 'cond/generator_gradients/generator/projection_dense_layer/MatMul_grad/MatMul_1:0' shape=(512, 4096) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/projection_dense_layer/BiasAdd_grad/BiasAddGrad:0' shape=(4096,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/projection_batch_norm/batchnorm/mul_grad/Mul_1:0' shape=(4096,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/projection_batch_norm/batchnorm/add_1_grad/Reshape_1:0' shape=(4096,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_0/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(4, 4, 128, 256) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_0/BiasAdd_grad/BiasAddGrad:0' shape=(128,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_batch_norm_0/FusedBatchNormV3_grad/FusedBatchNormGradV3:1' shape=(128,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_batch_norm_0/FusedBatchNormV3_grad/FusedBatchNormGradV3:2' shape=(128,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_1/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(4, 4, 128, 128) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_1/BiasAdd_grad/BiasAddGrad:0' shape=(128,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_batch_norm_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:1' shape=(128,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_batch_norm_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:2' shape=(128,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_2/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(4, 4, 128, 128) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_2/BiasAdd_grad/BiasAddGrad:0' shape=(128,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_batch_norm_2/FusedBatchNormV3_grad/FusedBatchNormGradV3:1' shape=(128,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_batch_norm_2/FusedBatchNormV3_grad/FusedBatchNormGradV3:2' shape=(128,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_fake_images/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(3, 3, 3, 128) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_fake_images/BiasAdd_grad/BiasAddGrad:0' shape=(3,) dtype=float32>]\n",
      "train_network_generator: grads_and_vars = <zip object at 0x7f8c165ef7d0>\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 113.23909, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.89458\n",
      "INFO:tensorflow:loss = -21.619034, step = 101 (112.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01648\n",
      "INFO:tensorflow:loss = -12.40735, step = 201 (97.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0317\n",
      "INFO:tensorflow:loss = -15.721256, step = 301 (97.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.06055\n",
      "INFO:tensorflow:loss = -19.921356, step = 401 (93.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.08503\n",
      "INFO:tensorflow:loss = -21.629183, step = 501 (92.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03432\n",
      "INFO:tensorflow:loss = -20.48111, step = 601 (96.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.07381\n",
      "INFO:tensorflow:loss = -18.696138, step = 701 (93.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00599\n",
      "INFO:tensorflow:loss = -16.329256, step = 801 (98.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.04963\n",
      "INFO:tensorflow:loss = -13.78224, step = 901 (96.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02727\n",
      "INFO:tensorflow:loss = -14.8794155, step = 1001 (96.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.04766\n",
      "INFO:tensorflow:loss = -14.467042, step = 1101 (95.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.04061\n",
      "INFO:tensorflow:loss = -11.289609, step = 1201 (95.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.05464\n",
      "INFO:tensorflow:loss = -12.628509, step = 1301 (95.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00487\n",
      "INFO:tensorflow:loss = -7.622251, step = 1401 (99.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.07561\n",
      "INFO:tensorflow:loss = -7.3574266, step = 1501 (93.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02171\n",
      "INFO:tensorflow:loss = -7.9477906, step = 1601 (97.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02845\n",
      "INFO:tensorflow:loss = -7.113091, step = 1701 (97.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02204\n",
      "INFO:tensorflow:loss = -7.2699537, step = 1801 (97.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.04988\n",
      "INFO:tensorflow:loss = -7.6998386, step = 1901 (95.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.986467\n",
      "INFO:tensorflow:loss = -8.5293, step = 2001 (100.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01334\n",
      "INFO:tensorflow:loss = -5.412497, step = 2101 (99.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01578\n",
      "INFO:tensorflow:loss = -7.0557327, step = 2201 (97.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02935\n",
      "INFO:tensorflow:loss = -6.383376, step = 2301 (97.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00045\n",
      "INFO:tensorflow:loss = -6.099048, step = 2401 (99.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02478\n",
      "INFO:tensorflow:loss = -5.693823, step = 2501 (98.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.998832\n",
      "INFO:tensorflow:loss = -6.7047906, step = 2601 (99.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03684\n",
      "INFO:tensorflow:loss = -5.245904, step = 2701 (96.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.993803\n",
      "INFO:tensorflow:loss = -4.958916, step = 2801 (100.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.992789\n",
      "INFO:tensorflow:loss = -6.285487, step = 2901 (101.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02217\n",
      "INFO:tensorflow:loss = -6.312634, step = 3001 (97.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00802\n",
      "INFO:tensorflow:loss = -6.5394263, step = 3101 (99.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.995303\n",
      "INFO:tensorflow:loss = -5.2114787, step = 3201 (100.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02016\n",
      "INFO:tensorflow:loss = -4.3047285, step = 3301 (98.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.991701\n",
      "INFO:tensorflow:loss = -4.9197474, step = 3401 (100.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01611\n",
      "INFO:tensorflow:loss = -4.717926, step = 3501 (98.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.99667\n",
      "INFO:tensorflow:loss = -5.253345, step = 3601 (99.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0143\n",
      "INFO:tensorflow:loss = -5.09656, step = 3701 (99.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0026\n",
      "INFO:tensorflow:loss = -5.025315, step = 3801 (99.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02768\n",
      "INFO:tensorflow:loss = -4.8573284, step = 3901 (97.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00114\n",
      "INFO:tensorflow:loss = -5.6297226, step = 4001 (99.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01583\n",
      "INFO:tensorflow:loss = -5.4728017, step = 4101 (99.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02884\n",
      "INFO:tensorflow:loss = -5.035735, step = 4201 (96.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02141\n",
      "INFO:tensorflow:loss = -5.3307014, step = 4301 (98.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.989696\n",
      "INFO:tensorflow:loss = -4.1725903, step = 4401 (100.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01633\n",
      "INFO:tensorflow:loss = -4.266609, step = 4501 (98.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03079\n",
      "INFO:tensorflow:loss = -4.1552873, step = 4601 (96.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03181\n",
      "INFO:tensorflow:loss = -3.855589, step = 4701 (97.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01454\n",
      "INFO:tensorflow:loss = -4.42179, step = 4801 (98.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.998056\n",
      "INFO:tensorflow:loss = -4.3588514, step = 4901 (100.679 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_gp_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "wgan_gp_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "wgan_gp_model: mode = eval\n",
      "wgan_gp_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model', 'train_batch_size': 64, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [4, 4, 256], 'generator_num_filters': [128, 128, 128], 'generator_kernel_sizes': [4, 4, 4], 'generator_strides': [2, 2, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 3, 'generator_final_stride': 1, 'generator_leaky_relu_alpha': 0.2, 'generator_use_batch_normalization': True, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.9, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'critic_num_filters': [64, 128, 128, 256], 'critic_kernel_sizes': [3, 3, 3, 3], 'critic_strides': [1, 2, 2, 2], 'critic_leaky_relu_alpha': 0.2, 'critic_use_layer_normalization': True, 'critic_l1_regularization_scale': 0.0, 'critic_l2_regularization_scale': 0.0, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_adam_beta1': 0.0, 'critic_adam_beta2': 0.9, 'critic_adam_epsilon': 1e-08, 'critic_clip_gradients': None, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_fake_images: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_leaky_relu = Tensor(\"generator/projection_leaky_relu:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_2/BiasAdd:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_2/FusedBatchNormV3:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_logits_and_losses: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "Call critic with fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32).\n",
      "\n",
      "get_critic_logits: network = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call critic with real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0).\n",
      "\n",
      "get_critic_logits: network = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic_1/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_critic_loss: critic_real_loss = Tensor(\"critic_real_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_fake_loss = Tensor(\"critic_fake_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_loss = Tensor(\"critic_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"critic/gradient_penalty/random_uniform_num:0\", shape=(?, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"critic/gradient_penalty/sub:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic/gradient_penalty/critic/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"critic/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"critic/gradient_penalty/gradients/critic/gradient_penalty/critic/layers_conv2d_0/Conv2D_grad/Conv2DBackpropInput:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"critic/gradient_penalty/Sqrt:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"critic/gradient_penalty/squared_difference:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"critic/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: gradient_penalty_loss = Tensor(\"critic/gradient_penalty/gradient_penalty_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_wasserstein_gp_loss = Tensor(\"critic_wasserstein_gp_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_reg_loss = Tensor(\"Const_5:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_total_loss = Tensor(\"critic_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_eval_metric_ops: critic_logits = Tensor(\"critic_concat_logits:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: critic_labels = Tensor(\"critic_concat_labels:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: critic_probabilities = Tensor(\"critic_probabilities:0\", shape=(?, 1), dtype=float32)\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "get_eval_metric_ops: eval_metric_ops = {'accuracy': (<tf.Tensor 'critic_accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_accuracy/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'critic_precision/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'critic_recall/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_recall/update_op:0' shape=() dtype=float32>), 'auc_roc': (<tf.Tensor 'critic_auc_roc/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_auc_roc/update_op:0' shape=() dtype=float32>), 'auc_pr': (<tf.Tensor 'critic_auc_pr/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_auc_pr/update_op:0' shape=() dtype=float32>)}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-19T08:48:59Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-19-08:49:05\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.5, auc_pr = 0.75, auc_roc = 0.5, global_step = 5000, loss = -5.083307, precision = 1.0, recall = 0.08\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-5000\n",
      "\n",
      "serving_input_fn: feature_placeholders = {'Z': <tf.Tensor 'serving_input_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "serving_input_fn: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_gp_model: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "wgan_gp_model: labels = None\n",
      "wgan_gp_model: mode = infer\n",
      "wgan_gp_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model', 'train_batch_size': 64, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [4, 4, 256], 'generator_num_filters': [128, 128, 128], 'generator_kernel_sizes': [4, 4, 4], 'generator_strides': [2, 2, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 3, 'generator_final_stride': 1, 'generator_leaky_relu_alpha': 0.2, 'generator_use_batch_normalization': True, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.9, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'critic_num_filters': [64, 128, 128, 256], 'critic_kernel_sizes': [3, 3, 3, 3], 'critic_strides': [1, 2, 2, 2], 'critic_leaky_relu_alpha': 0.2, 'critic_use_layer_normalization': True, 'critic_l1_regularization_scale': 0.0, 'critic_l2_regularization_scale': 0.0, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_adam_beta1': 0.0, 'critic_adam_beta2': 0.9, 'critic_adam_epsilon': 1e-08, 'critic_clip_gradients': None, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_predictions_and_export_outputs: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "get_fake_images: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_leaky_relu = Tensor(\"generator/projection_leaky_relu:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_2/BiasAdd:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_2/FusedBatchNormV3:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_predictions_and_export_outputs: generated_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_predictions_and_export_outputs: predictions_dict = {'generated_images': <tf.Tensor 'generator/layers_conv2d_tranpose_fake_images/Tanh:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "get_predictions_and_export_outputs: export_outputs = {'predict_export_outputs': <tensorflow.python.saved_model.model_utils.export_output.PredictOutput object at 0x7f8b2c48dc50>}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-5000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/export/exporter/temp-b'1592556548'/saved_model.pb\n",
      "INFO:tensorflow:global_step/sec: 0.809891\n",
      "INFO:tensorflow:loss = -4.6005516, step = 5001 (123.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01086\n",
      "INFO:tensorflow:loss = -4.9544396, step = 5101 (98.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01768\n",
      "INFO:tensorflow:loss = -4.2025495, step = 5201 (98.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00998\n",
      "INFO:tensorflow:loss = -4.7747784, step = 5301 (98.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00888\n",
      "INFO:tensorflow:loss = -4.7184987, step = 5401 (99.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.986411\n",
      "INFO:tensorflow:loss = -5.1236486, step = 5501 (100.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01021\n",
      "INFO:tensorflow:loss = -4.90395, step = 5601 (99.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00826\n",
      "INFO:tensorflow:loss = -4.4907722, step = 5701 (98.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.994718\n",
      "INFO:tensorflow:loss = -4.0202513, step = 5801 (101.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.995666\n",
      "INFO:tensorflow:loss = -4.052856, step = 5901 (99.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.990413\n",
      "INFO:tensorflow:loss = -4.5657544, step = 6001 (101.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00524\n",
      "INFO:tensorflow:loss = -4.1539364, step = 6101 (99.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02208\n",
      "INFO:tensorflow:loss = -4.731369, step = 6201 (98.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.993322\n",
      "INFO:tensorflow:loss = -3.6970499, step = 6301 (99.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01327\n",
      "INFO:tensorflow:loss = -3.9703252, step = 6401 (99.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01223\n",
      "INFO:tensorflow:loss = -4.6312485, step = 6501 (98.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03138\n",
      "INFO:tensorflow:loss = -3.9364371, step = 6601 (97.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02417\n",
      "INFO:tensorflow:loss = -3.7968268, step = 6701 (97.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02678\n",
      "INFO:tensorflow:loss = -3.8840144, step = 6801 (97.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02983\n",
      "INFO:tensorflow:loss = -4.39443, step = 6901 (96.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03087\n",
      "INFO:tensorflow:loss = -4.6723576, step = 7001 (97.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0327\n",
      "INFO:tensorflow:loss = -4.674545, step = 7101 (96.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02242\n",
      "INFO:tensorflow:loss = -4.302695, step = 7201 (98.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00616\n",
      "INFO:tensorflow:loss = -3.9500635, step = 7301 (98.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01735\n",
      "INFO:tensorflow:loss = -4.63398, step = 7401 (98.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02468\n",
      "INFO:tensorflow:loss = -4.906143, step = 7501 (97.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00282\n",
      "INFO:tensorflow:loss = -4.534739, step = 7601 (100.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02391\n",
      "INFO:tensorflow:loss = -5.018461, step = 7701 (97.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02145\n",
      "INFO:tensorflow:loss = -4.7024283, step = 7801 (98.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02366\n",
      "INFO:tensorflow:loss = -5.412925, step = 7901 (97.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0326\n",
      "INFO:tensorflow:loss = -4.003051, step = 8001 (97.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03414\n",
      "INFO:tensorflow:loss = -4.2199516, step = 8101 (96.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02289\n",
      "INFO:tensorflow:loss = -4.5114884, step = 8201 (98.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01988\n",
      "INFO:tensorflow:loss = -4.8109007, step = 8301 (97.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02822\n",
      "INFO:tensorflow:loss = -3.5699022, step = 8401 (97.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00965\n",
      "INFO:tensorflow:loss = -4.901324, step = 8501 (98.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03175\n",
      "INFO:tensorflow:loss = -4.3513904, step = 8601 (97.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01188\n",
      "INFO:tensorflow:loss = -4.4989457, step = 8701 (98.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02004\n",
      "INFO:tensorflow:loss = -5.3032293, step = 8801 (98.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.04866\n",
      "INFO:tensorflow:loss = -4.989081, step = 8901 (94.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02034\n",
      "INFO:tensorflow:loss = -3.9975476, step = 9001 (98.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00201\n",
      "INFO:tensorflow:loss = -4.306044, step = 9101 (99.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01769\n",
      "INFO:tensorflow:loss = -5.0487337, step = 9201 (98.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00332\n",
      "INFO:tensorflow:loss = -4.681791, step = 9301 (99.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02301\n",
      "INFO:tensorflow:loss = -4.6030936, step = 9401 (98.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03004\n",
      "INFO:tensorflow:loss = -4.954856, step = 9501 (96.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02232\n",
      "INFO:tensorflow:loss = -4.280402, step = 9601 (98.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00328\n",
      "INFO:tensorflow:loss = -4.733299, step = 9701 (99.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03821\n",
      "INFO:tensorflow:loss = -4.3811626, step = 9801 (96.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02698\n",
      "INFO:tensorflow:loss = -4.40748, step = 9901 (96.858 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_gp_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "wgan_gp_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "wgan_gp_model: mode = eval\n",
      "wgan_gp_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model', 'train_batch_size': 64, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [4, 4, 256], 'generator_num_filters': [128, 128, 128], 'generator_kernel_sizes': [4, 4, 4], 'generator_strides': [2, 2, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 3, 'generator_final_stride': 1, 'generator_leaky_relu_alpha': 0.2, 'generator_use_batch_normalization': True, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.9, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'critic_num_filters': [64, 128, 128, 256], 'critic_kernel_sizes': [3, 3, 3, 3], 'critic_strides': [1, 2, 2, 2], 'critic_leaky_relu_alpha': 0.2, 'critic_use_layer_normalization': True, 'critic_l1_regularization_scale': 0.0, 'critic_l2_regularization_scale': 0.0, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_adam_beta1': 0.0, 'critic_adam_beta2': 0.9, 'critic_adam_epsilon': 1e-08, 'critic_clip_gradients': None, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_fake_images: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_leaky_relu = Tensor(\"generator/projection_leaky_relu:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_2/BiasAdd:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_2/FusedBatchNormV3:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_logits_and_losses: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "Call critic with fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32).\n",
      "\n",
      "get_critic_logits: network = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call critic with real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0).\n",
      "\n",
      "get_critic_logits: network = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic_1/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_critic_loss: critic_real_loss = Tensor(\"critic_real_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_fake_loss = Tensor(\"critic_fake_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_loss = Tensor(\"critic_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"critic/gradient_penalty/random_uniform_num:0\", shape=(?, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"critic/gradient_penalty/sub:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic/gradient_penalty/critic/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"critic/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"critic/gradient_penalty/gradients/critic/gradient_penalty/critic/layers_conv2d_0/Conv2D_grad/Conv2DBackpropInput:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"critic/gradient_penalty/Sqrt:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"critic/gradient_penalty/squared_difference:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"critic/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: gradient_penalty_loss = Tensor(\"critic/gradient_penalty/gradient_penalty_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_wasserstein_gp_loss = Tensor(\"critic_wasserstein_gp_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_reg_loss = Tensor(\"Const_5:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_total_loss = Tensor(\"critic_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_eval_metric_ops: critic_logits = Tensor(\"critic_concat_logits:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: critic_labels = Tensor(\"critic_concat_labels:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: critic_probabilities = Tensor(\"critic_probabilities:0\", shape=(?, 1), dtype=float32)\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "get_eval_metric_ops: eval_metric_ops = {'accuracy': (<tf.Tensor 'critic_accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_accuracy/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'critic_precision/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'critic_recall/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_recall/update_op:0' shape=() dtype=float32>), 'auc_roc': (<tf.Tensor 'critic_auc_roc/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_auc_roc/update_op:0' shape=() dtype=float32>), 'auc_pr': (<tf.Tensor 'critic_auc_pr/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_auc_pr/update_op:0' shape=() dtype=float32>)}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-19T10:11:22Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-19-10:11:27\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.5, auc_pr = 0.75, auc_roc = 0.5, global_step = 10000, loss = -4.058065, precision = 1.0, recall = 0.34\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-10000\n",
      "\n",
      "serving_input_fn: feature_placeholders = {'Z': <tf.Tensor 'serving_input_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "serving_input_fn: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_gp_model: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "wgan_gp_model: labels = None\n",
      "wgan_gp_model: mode = infer\n",
      "wgan_gp_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model', 'train_batch_size': 64, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [4, 4, 256], 'generator_num_filters': [128, 128, 128], 'generator_kernel_sizes': [4, 4, 4], 'generator_strides': [2, 2, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 3, 'generator_final_stride': 1, 'generator_leaky_relu_alpha': 0.2, 'generator_use_batch_normalization': True, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.9, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'critic_num_filters': [64, 128, 128, 256], 'critic_kernel_sizes': [3, 3, 3, 3], 'critic_strides': [1, 2, 2, 2], 'critic_leaky_relu_alpha': 0.2, 'critic_use_layer_normalization': True, 'critic_l1_regularization_scale': 0.0, 'critic_l2_regularization_scale': 0.0, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_adam_beta1': 0.0, 'critic_adam_beta2': 0.9, 'critic_adam_epsilon': 1e-08, 'critic_clip_gradients': None, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_predictions_and_export_outputs: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "get_fake_images: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_leaky_relu = Tensor(\"generator/projection_leaky_relu:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_2/BiasAdd:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_2/FusedBatchNormV3:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_predictions_and_export_outputs: generated_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_predictions_and_export_outputs: predictions_dict = {'generated_images': <tf.Tensor 'generator/layers_conv2d_tranpose_fake_images/Tanh:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "get_predictions_and_export_outputs: export_outputs = {'predict_export_outputs': <tensorflow.python.saved_model.model_utils.export_output.PredictOutput object at 0x7f8b086531d0>}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-10000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/export/exporter/temp-b'1592561488'/saved_model.pb\n",
      "INFO:tensorflow:global_step/sec: 0.820954\n",
      "INFO:tensorflow:loss = -4.3948474, step = 10001 (121.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02283\n",
      "INFO:tensorflow:loss = -3.63044, step = 10101 (97.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01865\n",
      "INFO:tensorflow:loss = -4.399651, step = 10201 (98.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00185\n",
      "INFO:tensorflow:loss = -3.9765959, step = 10301 (99.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01245\n",
      "INFO:tensorflow:loss = -4.726942, step = 10401 (99.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0249\n",
      "INFO:tensorflow:loss = -3.956969, step = 10501 (97.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03225\n",
      "INFO:tensorflow:loss = -3.4672837, step = 10601 (97.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02524\n",
      "INFO:tensorflow:loss = -4.0039043, step = 10701 (97.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02991\n",
      "INFO:tensorflow:loss = -4.719679, step = 10801 (97.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.04575\n",
      "INFO:tensorflow:loss = -3.7612283, step = 10901 (95.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.04026\n",
      "INFO:tensorflow:loss = -4.6141768, step = 11001 (96.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03407\n",
      "INFO:tensorflow:loss = -5.0084195, step = 11101 (96.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03532\n",
      "INFO:tensorflow:loss = -4.3240433, step = 11201 (97.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01473\n",
      "INFO:tensorflow:loss = -4.5114217, step = 11301 (97.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0374\n",
      "INFO:tensorflow:loss = -4.455162, step = 11401 (96.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0223\n",
      "INFO:tensorflow:loss = -4.078611, step = 11501 (97.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03495\n",
      "INFO:tensorflow:loss = -4.0094, step = 11601 (97.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0344\n",
      "INFO:tensorflow:loss = -4.050162, step = 11701 (96.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.04218\n",
      "INFO:tensorflow:loss = -4.0669265, step = 11801 (96.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03215\n",
      "INFO:tensorflow:loss = -4.6573567, step = 11901 (96.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02259\n",
      "INFO:tensorflow:loss = -3.9304667, step = 12001 (98.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02264\n",
      "INFO:tensorflow:loss = -4.7920766, step = 12101 (97.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03127\n",
      "INFO:tensorflow:loss = -4.055488, step = 12201 (97.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03227\n",
      "INFO:tensorflow:loss = -3.5621724, step = 12301 (96.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03392\n",
      "INFO:tensorflow:loss = -4.678362, step = 12401 (97.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0253\n",
      "INFO:tensorflow:loss = -5.009736, step = 12501 (96.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03006\n",
      "INFO:tensorflow:loss = -3.6741045, step = 12601 (97.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01234\n",
      "INFO:tensorflow:loss = -4.3281274, step = 12701 (98.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03376\n",
      "INFO:tensorflow:loss = -4.1909113, step = 12801 (97.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02753\n",
      "INFO:tensorflow:loss = -4.3829484, step = 12901 (96.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02032\n",
      "INFO:tensorflow:loss = -4.689377, step = 13001 (98.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03052\n",
      "INFO:tensorflow:loss = -4.273547, step = 13101 (96.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03485\n",
      "INFO:tensorflow:loss = -2.8320029, step = 13201 (97.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02335\n",
      "INFO:tensorflow:loss = -3.4927363, step = 13301 (97.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02504\n",
      "INFO:tensorflow:loss = -3.7822146, step = 13401 (98.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00568\n",
      "INFO:tensorflow:loss = -3.9043536, step = 13501 (98.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01016\n",
      "INFO:tensorflow:loss = -2.7964609, step = 13601 (99.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03322\n",
      "INFO:tensorflow:loss = -4.1910996, step = 13701 (96.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03149\n",
      "INFO:tensorflow:loss = -3.4956207, step = 13801 (97.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02373\n",
      "INFO:tensorflow:loss = -5.2261314, step = 13901 (97.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01927\n",
      "INFO:tensorflow:loss = -4.565507, step = 14001 (98.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03018\n",
      "INFO:tensorflow:loss = -3.7477198, step = 14101 (96.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03846\n",
      "INFO:tensorflow:loss = -4.1838026, step = 14201 (96.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02629\n",
      "INFO:tensorflow:loss = -5.008847, step = 14301 (96.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01499\n",
      "INFO:tensorflow:loss = -4.1790137, step = 14401 (99.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01592\n",
      "INFO:tensorflow:loss = -4.6309814, step = 14501 (97.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02454\n",
      "INFO:tensorflow:loss = -4.192724, step = 14601 (98.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00395\n",
      "INFO:tensorflow:loss = -4.3826423, step = 14701 (98.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02059\n",
      "INFO:tensorflow:loss = -4.0856695, step = 14801 (98.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02618\n",
      "INFO:tensorflow:loss = -4.206904, step = 14901 (96.674 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_gp_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "wgan_gp_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "wgan_gp_model: mode = eval\n",
      "wgan_gp_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model', 'train_batch_size': 64, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [4, 4, 256], 'generator_num_filters': [128, 128, 128], 'generator_kernel_sizes': [4, 4, 4], 'generator_strides': [2, 2, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 3, 'generator_final_stride': 1, 'generator_leaky_relu_alpha': 0.2, 'generator_use_batch_normalization': True, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.9, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'critic_num_filters': [64, 128, 128, 256], 'critic_kernel_sizes': [3, 3, 3, 3], 'critic_strides': [1, 2, 2, 2], 'critic_leaky_relu_alpha': 0.2, 'critic_use_layer_normalization': True, 'critic_l1_regularization_scale': 0.0, 'critic_l2_regularization_scale': 0.0, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_adam_beta1': 0.0, 'critic_adam_beta2': 0.9, 'critic_adam_epsilon': 1e-08, 'critic_clip_gradients': None, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_fake_images: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_leaky_relu = Tensor(\"generator/projection_leaky_relu:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_2/BiasAdd:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_2/FusedBatchNormV3:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_logits_and_losses: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "Call critic with fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32).\n",
      "\n",
      "get_critic_logits: network = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call critic with real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0).\n",
      "\n",
      "get_critic_logits: network = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic_1/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_critic_loss: critic_real_loss = Tensor(\"critic_real_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_fake_loss = Tensor(\"critic_fake_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_loss = Tensor(\"critic_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"critic/gradient_penalty/random_uniform_num:0\", shape=(?, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"critic/gradient_penalty/sub:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic/gradient_penalty/critic/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"critic/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"critic/gradient_penalty/gradients/critic/gradient_penalty/critic/layers_conv2d_0/Conv2D_grad/Conv2DBackpropInput:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"critic/gradient_penalty/Sqrt:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"critic/gradient_penalty/squared_difference:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"critic/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: gradient_penalty_loss = Tensor(\"critic/gradient_penalty/gradient_penalty_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_wasserstein_gp_loss = Tensor(\"critic_wasserstein_gp_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_reg_loss = Tensor(\"Const_5:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_total_loss = Tensor(\"critic_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_eval_metric_ops: critic_logits = Tensor(\"critic_concat_logits:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: critic_labels = Tensor(\"critic_concat_labels:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: critic_probabilities = Tensor(\"critic_probabilities:0\", shape=(?, 1), dtype=float32)\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "get_eval_metric_ops: eval_metric_ops = {'accuracy': (<tf.Tensor 'critic_accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_accuracy/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'critic_precision/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'critic_recall/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_recall/update_op:0' shape=() dtype=float32>), 'auc_roc': (<tf.Tensor 'critic_auc_roc/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_auc_roc/update_op:0' shape=() dtype=float32>), 'auc_pr': (<tf.Tensor 'critic_auc_pr/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_auc_pr/update_op:0' shape=() dtype=float32>)}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-19T11:33:00Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-15000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-19-11:33:07\n",
      "INFO:tensorflow:Saving dict for global step 15000: accuracy = 0.5, auc_pr = 0.75, auc_roc = 0.5, global_step = 15000, loss = -3.6173234, precision = 1.0, recall = 0.02\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15000: gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-15000\n",
      "\n",
      "serving_input_fn: feature_placeholders = {'Z': <tf.Tensor 'serving_input_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "serving_input_fn: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_gp_model: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "wgan_gp_model: labels = None\n",
      "wgan_gp_model: mode = infer\n",
      "wgan_gp_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model', 'train_batch_size': 64, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [4, 4, 256], 'generator_num_filters': [128, 128, 128], 'generator_kernel_sizes': [4, 4, 4], 'generator_strides': [2, 2, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 3, 'generator_final_stride': 1, 'generator_leaky_relu_alpha': 0.2, 'generator_use_batch_normalization': True, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.9, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'critic_num_filters': [64, 128, 128, 256], 'critic_kernel_sizes': [3, 3, 3, 3], 'critic_strides': [1, 2, 2, 2], 'critic_leaky_relu_alpha': 0.2, 'critic_use_layer_normalization': True, 'critic_l1_regularization_scale': 0.0, 'critic_l2_regularization_scale': 0.0, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_adam_beta1': 0.0, 'critic_adam_beta2': 0.9, 'critic_adam_epsilon': 1e-08, 'critic_clip_gradients': None, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_predictions_and_export_outputs: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "get_fake_images: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_leaky_relu = Tensor(\"generator/projection_leaky_relu:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_2/BiasAdd:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_2/FusedBatchNormV3:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_predictions_and_export_outputs: generated_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_predictions_and_export_outputs: predictions_dict = {'generated_images': <tf.Tensor 'generator/layers_conv2d_tranpose_fake_images/Tanh:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "get_predictions_and_export_outputs: export_outputs = {'predict_export_outputs': <tensorflow.python.saved_model.model_utils.export_output.PredictOutput object at 0x7f8c14a552d0>}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-15000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/export/exporter/temp-b'1592566388'/saved_model.pb\n",
      "INFO:tensorflow:global_step/sec: 0.812308\n",
      "INFO:tensorflow:loss = -4.6472545, step = 15001 (123.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0244\n",
      "INFO:tensorflow:loss = -4.232027, step = 15101 (97.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03674\n",
      "INFO:tensorflow:loss = -4.5061064, step = 15201 (97.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03491\n",
      "INFO:tensorflow:loss = -3.802308, step = 15301 (95.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03776\n",
      "INFO:tensorflow:loss = -5.0677576, step = 15401 (96.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02479\n",
      "INFO:tensorflow:loss = -3.9079785, step = 15501 (97.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02953\n",
      "INFO:tensorflow:loss = -4.3461127, step = 15601 (97.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02836\n",
      "INFO:tensorflow:loss = -3.5437877, step = 15701 (96.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02742\n",
      "INFO:tensorflow:loss = -4.574231, step = 15801 (97.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02495\n",
      "INFO:tensorflow:loss = -3.798986, step = 15901 (97.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.021\n",
      "INFO:tensorflow:loss = -3.5646794, step = 16001 (99.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01164\n",
      "INFO:tensorflow:loss = -3.7114568, step = 16101 (96.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.05344\n",
      "INFO:tensorflow:loss = -3.7895088, step = 16201 (95.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00342\n",
      "INFO:tensorflow:loss = -4.4780946, step = 16301 (98.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03596\n",
      "INFO:tensorflow:loss = -4.144438, step = 16401 (97.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03079\n",
      "INFO:tensorflow:loss = -3.3173585, step = 16501 (96.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01764\n",
      "INFO:tensorflow:loss = -4.349378, step = 16601 (98.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02828\n",
      "INFO:tensorflow:loss = -4.054436, step = 16701 (96.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03975\n",
      "INFO:tensorflow:loss = -4.2303, step = 16801 (97.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01416\n",
      "INFO:tensorflow:loss = -3.807258, step = 16901 (97.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02447\n",
      "INFO:tensorflow:loss = -4.8934546, step = 17001 (98.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03858\n",
      "INFO:tensorflow:loss = -3.4941516, step = 17101 (95.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01444\n",
      "INFO:tensorflow:loss = -3.4816527, step = 17201 (99.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01989\n",
      "INFO:tensorflow:loss = -4.0706453, step = 17301 (97.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02359\n",
      "INFO:tensorflow:loss = -4.6279964, step = 17401 (98.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02988\n",
      "INFO:tensorflow:loss = -4.100119, step = 17501 (96.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0213\n",
      "INFO:tensorflow:loss = -4.320032, step = 17601 (98.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01109\n",
      "INFO:tensorflow:loss = -4.246309, step = 17701 (98.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00832\n",
      "INFO:tensorflow:loss = -4.0954957, step = 17801 (99.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00616\n",
      "INFO:tensorflow:loss = -3.7149334, step = 17901 (98.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02554\n",
      "INFO:tensorflow:loss = -4.824817, step = 18001 (98.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02388\n",
      "INFO:tensorflow:loss = -3.200035, step = 18101 (97.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03199\n",
      "INFO:tensorflow:loss = -2.9748333, step = 18201 (97.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02354\n",
      "INFO:tensorflow:loss = -4.546733, step = 18301 (97.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00276\n",
      "INFO:tensorflow:loss = -3.4430757, step = 18401 (100.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.998885\n",
      "INFO:tensorflow:loss = -3.4709384, step = 18501 (99.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02502\n",
      "INFO:tensorflow:loss = -3.8102245, step = 18601 (98.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03875\n",
      "INFO:tensorflow:loss = -3.912449, step = 18701 (95.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.999828\n",
      "INFO:tensorflow:loss = -3.8761375, step = 18801 (100.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02397\n",
      "INFO:tensorflow:loss = -4.578566, step = 18901 (96.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03512\n",
      "INFO:tensorflow:loss = -4.1816773, step = 19001 (97.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01074\n",
      "INFO:tensorflow:loss = -4.7587624, step = 19101 (98.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01895\n",
      "INFO:tensorflow:loss = -2.3103032, step = 19201 (98.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00235\n",
      "INFO:tensorflow:loss = -3.786399, step = 19301 (99.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00772\n",
      "INFO:tensorflow:loss = -4.682216, step = 19401 (99.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01759\n",
      "INFO:tensorflow:loss = -4.379941, step = 19501 (97.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00592\n",
      "INFO:tensorflow:loss = -4.485208, step = 19601 (99.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.986199\n",
      "INFO:tensorflow:loss = -4.4000754, step = 19701 (100.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01231\n",
      "INFO:tensorflow:loss = -3.2930758, step = 19801 (99.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01407\n",
      "INFO:tensorflow:loss = -3.92546, step = 19901 (98.047 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_gp_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "wgan_gp_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "wgan_gp_model: mode = eval\n",
      "wgan_gp_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model', 'train_batch_size': 64, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [4, 4, 256], 'generator_num_filters': [128, 128, 128], 'generator_kernel_sizes': [4, 4, 4], 'generator_strides': [2, 2, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 3, 'generator_final_stride': 1, 'generator_leaky_relu_alpha': 0.2, 'generator_use_batch_normalization': True, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.9, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'critic_num_filters': [64, 128, 128, 256], 'critic_kernel_sizes': [3, 3, 3, 3], 'critic_strides': [1, 2, 2, 2], 'critic_leaky_relu_alpha': 0.2, 'critic_use_layer_normalization': True, 'critic_l1_regularization_scale': 0.0, 'critic_l2_regularization_scale': 0.0, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_adam_beta1': 0.0, 'critic_adam_beta2': 0.9, 'critic_adam_epsilon': 1e-08, 'critic_clip_gradients': None, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_fake_images: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_leaky_relu = Tensor(\"generator/projection_leaky_relu:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_2/BiasAdd:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_2/FusedBatchNormV3:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_logits_and_losses: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "Call critic with fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32).\n",
      "\n",
      "get_critic_logits: network = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call critic with real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0).\n",
      "\n",
      "get_critic_logits: network = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic_1/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_critic_loss: critic_real_loss = Tensor(\"critic_real_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_fake_loss = Tensor(\"critic_fake_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_loss = Tensor(\"critic_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"critic/gradient_penalty/random_uniform_num:0\", shape=(?, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"critic/gradient_penalty/sub:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic/gradient_penalty/critic/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"critic/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"critic/gradient_penalty/gradients/critic/gradient_penalty/critic/layers_conv2d_0/Conv2D_grad/Conv2DBackpropInput:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"critic/gradient_penalty/Sqrt:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"critic/gradient_penalty/squared_difference:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"critic/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: gradient_penalty_loss = Tensor(\"critic/gradient_penalty/gradient_penalty_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_wasserstein_gp_loss = Tensor(\"critic_wasserstein_gp_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_reg_loss = Tensor(\"Const_5:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_total_loss = Tensor(\"critic_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_eval_metric_ops: critic_logits = Tensor(\"critic_concat_logits:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: critic_labels = Tensor(\"critic_concat_labels:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: critic_probabilities = Tensor(\"critic_probabilities:0\", shape=(?, 1), dtype=float32)\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "get_eval_metric_ops: eval_metric_ops = {'accuracy': (<tf.Tensor 'critic_accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_accuracy/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'critic_precision/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'critic_recall/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_recall/update_op:0' shape=() dtype=float32>), 'auc_roc': (<tf.Tensor 'critic_auc_roc/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_auc_roc/update_op:0' shape=() dtype=float32>), 'auc_pr': (<tf.Tensor 'critic_auc_pr/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_auc_pr/update_op:0' shape=() dtype=float32>)}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-19T12:55:04Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-19-12:55:10\n",
      "INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.5, auc_pr = 0.75, auc_roc = 0.5, global_step = 20000, loss = -3.8660233, precision = 0.0, recall = 0.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-20000\n",
      "\n",
      "serving_input_fn: feature_placeholders = {'Z': <tf.Tensor 'serving_input_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "serving_input_fn: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_gp_model: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "wgan_gp_model: labels = None\n",
      "wgan_gp_model: mode = infer\n",
      "wgan_gp_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model', 'train_batch_size': 64, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [4, 4, 256], 'generator_num_filters': [128, 128, 128], 'generator_kernel_sizes': [4, 4, 4], 'generator_strides': [2, 2, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 3, 'generator_final_stride': 1, 'generator_leaky_relu_alpha': 0.2, 'generator_use_batch_normalization': True, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.9, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'critic_num_filters': [64, 128, 128, 256], 'critic_kernel_sizes': [3, 3, 3, 3], 'critic_strides': [1, 2, 2, 2], 'critic_leaky_relu_alpha': 0.2, 'critic_use_layer_normalization': True, 'critic_l1_regularization_scale': 0.0, 'critic_l2_regularization_scale': 0.0, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_adam_beta1': 0.0, 'critic_adam_beta2': 0.9, 'critic_adam_epsilon': 1e-08, 'critic_clip_gradients': None, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_predictions_and_export_outputs: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "get_fake_images: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_leaky_relu = Tensor(\"generator/projection_leaky_relu:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_2/BiasAdd:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_2/FusedBatchNormV3:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_predictions_and_export_outputs: generated_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_predictions_and_export_outputs: predictions_dict = {'generated_images': <tf.Tensor 'generator/layers_conv2d_tranpose_fake_images/Tanh:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "get_predictions_and_export_outputs: export_outputs = {'predict_export_outputs': <tensorflow.python.saved_model.model_utils.export_output.PredictOutput object at 0x7f8b2c1316d0>}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-20000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/export/exporter/temp-b'1592571310'/saved_model.pb\n",
      "INFO:tensorflow:global_step/sec: 0.82004\n",
      "INFO:tensorflow:loss = -4.158679, step = 20001 (121.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01133\n",
      "INFO:tensorflow:loss = -3.2633533, step = 20101 (98.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.976986\n",
      "INFO:tensorflow:loss = -4.2769504, step = 20201 (102.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01178\n",
      "INFO:tensorflow:loss = -2.902928, step = 20301 (98.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.99633\n",
      "INFO:tensorflow:loss = -4.088786, step = 20401 (100.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01164\n",
      "INFO:tensorflow:loss = -3.5686774, step = 20501 (98.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01176\n",
      "INFO:tensorflow:loss = -3.8714128, step = 20601 (99.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01169\n",
      "INFO:tensorflow:loss = -2.985532, step = 20701 (98.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01936\n",
      "INFO:tensorflow:loss = -3.6789927, step = 20801 (98.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00656\n",
      "INFO:tensorflow:loss = -4.098234, step = 20901 (98.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01606\n",
      "INFO:tensorflow:loss = -2.9374607, step = 21001 (99.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01701\n",
      "INFO:tensorflow:loss = -2.3718657, step = 21101 (97.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03637\n",
      "INFO:tensorflow:loss = -4.0032096, step = 21201 (97.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.01555\n",
      "INFO:tensorflow:loss = -3.5512471, step = 21301 (97.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00745\n",
      "INFO:tensorflow:loss = -3.2671032, step = 21401 (99.905 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.00868\n",
      "INFO:tensorflow:loss = -4.4589314, step = 21501 (98.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.04721\n",
      "INFO:tensorflow:loss = -3.5259914, step = 21601 (96.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.04288\n",
      "INFO:tensorflow:loss = -3.5902328, step = 21701 (95.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.04397\n",
      "INFO:tensorflow:loss = -3.9155135, step = 21801 (96.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02119\n",
      "INFO:tensorflow:loss = -3.3853354, step = 21901 (97.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0673\n",
      "INFO:tensorflow:loss = -4.1686873, step = 22001 (94.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.07506\n",
      "INFO:tensorflow:loss = -3.7279525, step = 22101 (92.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10586\n",
      "INFO:tensorflow:loss = -4.4958763, step = 22201 (91.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0726\n",
      "INFO:tensorflow:loss = -4.0903707, step = 22301 (92.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09143\n",
      "INFO:tensorflow:loss = -4.1437073, step = 22401 (92.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0701\n",
      "INFO:tensorflow:loss = -3.6894581, step = 22501 (92.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09244\n",
      "INFO:tensorflow:loss = -3.284283, step = 22601 (92.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09385\n",
      "INFO:tensorflow:loss = -4.531209, step = 22701 (90.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.07788\n",
      "INFO:tensorflow:loss = -3.2854722, step = 22801 (93.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.07271\n",
      "INFO:tensorflow:loss = -4.310596, step = 22901 (92.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.08653\n",
      "INFO:tensorflow:loss = -3.7720416, step = 23001 (92.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.08312\n",
      "INFO:tensorflow:loss = -4.3820124, step = 23101 (91.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0568\n",
      "INFO:tensorflow:loss = -3.7625492, step = 23201 (95.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.872166\n",
      "INFO:tensorflow:loss = -3.6367168, step = 23301 (114.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.643599\n",
      "INFO:tensorflow:loss = -3.0504673, step = 23401 (155.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.964578\n",
      "INFO:tensorflow:loss = -4.2071323, step = 23501 (103.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.795363\n",
      "INFO:tensorflow:loss = -3.6507719, step = 23601 (126.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.662693\n",
      "INFO:tensorflow:loss = -3.5172977, step = 23701 (150.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.07167\n",
      "INFO:tensorflow:loss = -4.206507, step = 23801 (92.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10091\n",
      "INFO:tensorflow:loss = -3.7345428, step = 23901 (91.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.07741\n",
      "INFO:tensorflow:loss = -4.011574, step = 24001 (92.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.08378\n",
      "INFO:tensorflow:loss = -4.0830846, step = 24101 (93.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.07597\n",
      "INFO:tensorflow:loss = -3.879644, step = 24201 (92.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.07553\n",
      "INFO:tensorflow:loss = -3.804568, step = 24301 (93.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.08017\n",
      "INFO:tensorflow:loss = -4.593243, step = 24401 (91.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10616\n",
      "INFO:tensorflow:loss = -3.597167, step = 24501 (91.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09123\n",
      "INFO:tensorflow:loss = -3.917244, step = 24601 (90.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0966\n",
      "INFO:tensorflow:loss = -4.1654034, step = 24701 (91.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10704\n",
      "INFO:tensorflow:loss = -4.431157, step = 24801 (89.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09693\n",
      "INFO:tensorflow:loss = -3.1545873, step = 24901 (91.859 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_gp_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "wgan_gp_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "wgan_gp_model: mode = eval\n",
      "wgan_gp_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model', 'train_batch_size': 64, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [4, 4, 256], 'generator_num_filters': [128, 128, 128], 'generator_kernel_sizes': [4, 4, 4], 'generator_strides': [2, 2, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 3, 'generator_final_stride': 1, 'generator_leaky_relu_alpha': 0.2, 'generator_use_batch_normalization': True, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.9, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'critic_num_filters': [64, 128, 128, 256], 'critic_kernel_sizes': [3, 3, 3, 3], 'critic_strides': [1, 2, 2, 2], 'critic_leaky_relu_alpha': 0.2, 'critic_use_layer_normalization': True, 'critic_l1_regularization_scale': 0.0, 'critic_l2_regularization_scale': 0.0, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_adam_beta1': 0.0, 'critic_adam_beta2': 0.9, 'critic_adam_epsilon': 1e-08, 'critic_clip_gradients': None, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_fake_images: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_leaky_relu = Tensor(\"generator/projection_leaky_relu:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_2/BiasAdd:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_2/FusedBatchNormV3:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_logits_and_losses: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "Call critic with fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32).\n",
      "\n",
      "get_critic_logits: network = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call critic with real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0).\n",
      "\n",
      "get_critic_logits: network = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic_1/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_critic_loss: critic_real_loss = Tensor(\"critic_real_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_fake_loss = Tensor(\"critic_fake_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_loss = Tensor(\"critic_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"critic/gradient_penalty/random_uniform_num:0\", shape=(?, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"critic/gradient_penalty/sub:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic/gradient_penalty/critic/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"critic/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"critic/gradient_penalty/gradients/critic/gradient_penalty/critic/layers_conv2d_0/Conv2D_grad/Conv2DBackpropInput:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"critic/gradient_penalty/Sqrt:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"critic/gradient_penalty/squared_difference:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"critic/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: gradient_penalty_loss = Tensor(\"critic/gradient_penalty/gradient_penalty_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_wasserstein_gp_loss = Tensor(\"critic_wasserstein_gp_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_reg_loss = Tensor(\"Const_5:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_total_loss = Tensor(\"critic_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_eval_metric_ops: critic_logits = Tensor(\"critic_concat_logits:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: critic_labels = Tensor(\"critic_concat_labels:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: critic_probabilities = Tensor(\"critic_probabilities:0\", shape=(?, 1), dtype=float32)\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "get_eval_metric_ops: eval_metric_ops = {'accuracy': (<tf.Tensor 'critic_accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_accuracy/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'critic_precision/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'critic_recall/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_recall/update_op:0' shape=() dtype=float32>), 'auc_roc': (<tf.Tensor 'critic_auc_roc/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_auc_roc/update_op:0' shape=() dtype=float32>), 'auc_pr': (<tf.Tensor 'critic_auc_pr/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_auc_pr/update_op:0' shape=() dtype=float32>)}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-19T14:17:26Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-25000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-19-14:17:31\n",
      "INFO:tensorflow:Saving dict for global step 25000: accuracy = 0.5, auc_pr = 0.75, auc_roc = 0.5, global_step = 25000, loss = -3.1955352, precision = 0.0, recall = 0.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 25000: gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-25000\n",
      "\n",
      "serving_input_fn: feature_placeholders = {'Z': <tf.Tensor 'serving_input_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "serving_input_fn: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_gp_model: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "wgan_gp_model: labels = None\n",
      "wgan_gp_model: mode = infer\n",
      "wgan_gp_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model', 'train_batch_size': 64, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [4, 4, 256], 'generator_num_filters': [128, 128, 128], 'generator_kernel_sizes': [4, 4, 4], 'generator_strides': [2, 2, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 3, 'generator_final_stride': 1, 'generator_leaky_relu_alpha': 0.2, 'generator_use_batch_normalization': True, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.9, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'critic_num_filters': [64, 128, 128, 256], 'critic_kernel_sizes': [3, 3, 3, 3], 'critic_strides': [1, 2, 2, 2], 'critic_leaky_relu_alpha': 0.2, 'critic_use_layer_normalization': True, 'critic_l1_regularization_scale': 0.0, 'critic_l2_regularization_scale': 0.0, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_adam_beta1': 0.0, 'critic_adam_beta2': 0.9, 'critic_adam_epsilon': 1e-08, 'critic_clip_gradients': None, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_predictions_and_export_outputs: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "get_fake_images: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_leaky_relu = Tensor(\"generator/projection_leaky_relu:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_2/BiasAdd:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_2/FusedBatchNormV3:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_predictions_and_export_outputs: generated_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_predictions_and_export_outputs: predictions_dict = {'generated_images': <tf.Tensor 'generator/layers_conv2d_tranpose_fake_images/Tanh:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "get_predictions_and_export_outputs: export_outputs = {'predict_export_outputs': <tensorflow.python.saved_model.model_utils.export_output.PredictOutput object at 0x7f8b2c2164d0>}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-25000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/export/exporter/temp-b'1592576252'/saved_model.pb\n",
      "INFO:tensorflow:global_step/sec: 0.86681\n",
      "INFO:tensorflow:loss = -3.5614097, step = 25001 (114.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.08173\n",
      "INFO:tensorflow:loss = -4.1286287, step = 25101 (93.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10615\n",
      "INFO:tensorflow:loss = -3.9604442, step = 25201 (89.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09515\n",
      "INFO:tensorflow:loss = -3.4902613, step = 25301 (91.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10332\n",
      "INFO:tensorflow:loss = -3.9565933, step = 25401 (90.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.08847\n",
      "INFO:tensorflow:loss = -4.275318, step = 25501 (92.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09042\n",
      "INFO:tensorflow:loss = -3.7202313, step = 25601 (90.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09289\n",
      "INFO:tensorflow:loss = -3.7692974, step = 25701 (92.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11087\n",
      "INFO:tensorflow:loss = -3.2056336, step = 25801 (89.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12052\n",
      "INFO:tensorflow:loss = -3.7763877, step = 25901 (89.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09084\n",
      "INFO:tensorflow:loss = -3.761444, step = 26001 (90.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10434\n",
      "INFO:tensorflow:loss = -3.695585, step = 26101 (91.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.08244\n",
      "INFO:tensorflow:loss = -3.889295, step = 26201 (91.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10374\n",
      "INFO:tensorflow:loss = -3.9092736, step = 26301 (91.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10728\n",
      "INFO:tensorflow:loss = -3.5065324, step = 26401 (89.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12166\n",
      "INFO:tensorflow:loss = -4.201218, step = 26501 (89.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10444\n",
      "INFO:tensorflow:loss = -3.8539245, step = 26601 (89.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11871\n",
      "INFO:tensorflow:loss = -4.2222567, step = 26701 (90.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.07774\n",
      "INFO:tensorflow:loss = -4.0694118, step = 26801 (92.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.07816\n",
      "INFO:tensorflow:loss = -3.9875789, step = 26901 (93.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09695\n",
      "INFO:tensorflow:loss = -4.3210726, step = 27001 (90.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09911\n",
      "INFO:tensorflow:loss = -4.418665, step = 27101 (91.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0626\n",
      "INFO:tensorflow:loss = -4.0216417, step = 27201 (93.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12594\n",
      "INFO:tensorflow:loss = -3.3770618, step = 27301 (89.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10402\n",
      "INFO:tensorflow:loss = -3.9362636, step = 27401 (89.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11501\n",
      "INFO:tensorflow:loss = -4.2009797, step = 27501 (90.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1167\n",
      "INFO:tensorflow:loss = -3.5603464, step = 27601 (88.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10905\n",
      "INFO:tensorflow:loss = -3.6137505, step = 27701 (90.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10377\n",
      "INFO:tensorflow:loss = -3.342294, step = 27801 (89.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1088\n",
      "INFO:tensorflow:loss = -3.8173137, step = 27901 (90.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09683\n",
      "INFO:tensorflow:loss = -4.2775793, step = 28001 (90.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1048\n",
      "INFO:tensorflow:loss = -3.6343238, step = 28101 (91.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0923\n",
      "INFO:tensorflow:loss = -3.2679126, step = 28201 (90.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.07425\n",
      "INFO:tensorflow:loss = -3.4454036, step = 28301 (94.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.08325\n",
      "INFO:tensorflow:loss = -3.5575614, step = 28401 (91.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09442\n",
      "INFO:tensorflow:loss = -3.9203043, step = 28501 (92.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10021\n",
      "INFO:tensorflow:loss = -3.8755155, step = 28601 (90.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12277\n",
      "INFO:tensorflow:loss = -3.7896779, step = 28701 (89.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10292\n",
      "INFO:tensorflow:loss = -3.8886485, step = 28801 (90.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10021\n",
      "INFO:tensorflow:loss = -4.4598994, step = 28901 (91.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09357\n",
      "INFO:tensorflow:loss = -1.721036, step = 29001 (90.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09672\n",
      "INFO:tensorflow:loss = -3.7952356, step = 29101 (91.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11601\n",
      "INFO:tensorflow:loss = -3.384427, step = 29201 (88.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11857\n",
      "INFO:tensorflow:loss = -3.736968, step = 29301 (90.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.108\n",
      "INFO:tensorflow:loss = -3.9537368, step = 29401 (89.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10496\n",
      "INFO:tensorflow:loss = -4.708865, step = 29501 (91.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12786\n",
      "INFO:tensorflow:loss = -3.5139887, step = 29601 (87.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1042\n",
      "INFO:tensorflow:loss = -3.7752929, step = 29701 (91.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1156\n",
      "INFO:tensorflow:loss = -3.7426214, step = 29801 (88.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1206\n",
      "INFO:tensorflow:loss = -3.916171, step = 29901 (89.890 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_gp_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "wgan_gp_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "wgan_gp_model: mode = eval\n",
      "wgan_gp_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model', 'train_batch_size': 64, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [4, 4, 256], 'generator_num_filters': [128, 128, 128], 'generator_kernel_sizes': [4, 4, 4], 'generator_strides': [2, 2, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 3, 'generator_final_stride': 1, 'generator_leaky_relu_alpha': 0.2, 'generator_use_batch_normalization': True, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.9, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'critic_num_filters': [64, 128, 128, 256], 'critic_kernel_sizes': [3, 3, 3, 3], 'critic_strides': [1, 2, 2, 2], 'critic_leaky_relu_alpha': 0.2, 'critic_use_layer_normalization': True, 'critic_l1_regularization_scale': 0.0, 'critic_l2_regularization_scale': 0.0, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_adam_beta1': 0.0, 'critic_adam_beta2': 0.9, 'critic_adam_epsilon': 1e-08, 'critic_clip_gradients': None, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_fake_images: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_leaky_relu = Tensor(\"generator/projection_leaky_relu:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_2/BiasAdd:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_2/FusedBatchNormV3:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_logits_and_losses: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "Call critic with fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32).\n",
      "\n",
      "get_critic_logits: network = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call critic with real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0).\n",
      "\n",
      "get_critic_logits: network = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic_1/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_critic_loss: critic_real_loss = Tensor(\"critic_real_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_fake_loss = Tensor(\"critic_fake_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_loss = Tensor(\"critic_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"critic/gradient_penalty/random_uniform_num:0\", shape=(?, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"critic/gradient_penalty/sub:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic/gradient_penalty/critic/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"critic/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"critic/gradient_penalty/gradients/critic/gradient_penalty/critic/layers_conv2d_0/Conv2D_grad/Conv2DBackpropInput:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"critic/gradient_penalty/Sqrt:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"critic/gradient_penalty/squared_difference:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"critic/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: gradient_penalty_loss = Tensor(\"critic/gradient_penalty/gradient_penalty_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_wasserstein_gp_loss = Tensor(\"critic_wasserstein_gp_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_reg_loss = Tensor(\"Const_5:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_total_loss = Tensor(\"critic_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_eval_metric_ops: critic_logits = Tensor(\"critic_concat_logits:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: critic_labels = Tensor(\"critic_concat_labels:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: critic_probabilities = Tensor(\"critic_probabilities:0\", shape=(?, 1), dtype=float32)\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "get_eval_metric_ops: eval_metric_ops = {'accuracy': (<tf.Tensor 'critic_accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_accuracy/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'critic_precision/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'critic_recall/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_recall/update_op:0' shape=() dtype=float32>), 'auc_roc': (<tf.Tensor 'critic_auc_roc/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_auc_roc/update_op:0' shape=() dtype=float32>), 'auc_pr': (<tf.Tensor 'critic_auc_pr/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_auc_pr/update_op:0' shape=() dtype=float32>)}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-19T15:33:26Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-19-15:33:31\n",
      "INFO:tensorflow:Saving dict for global step 30000: accuracy = 0.5, auc_pr = 0.75, auc_roc = 0.5, global_step = 30000, loss = -2.39846, precision = 0.0, recall = 0.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-30000\n",
      "\n",
      "serving_input_fn: feature_placeholders = {'Z': <tf.Tensor 'serving_input_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "serving_input_fn: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_gp_model: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "wgan_gp_model: labels = None\n",
      "wgan_gp_model: mode = infer\n",
      "wgan_gp_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model', 'train_batch_size': 64, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [4, 4, 256], 'generator_num_filters': [128, 128, 128], 'generator_kernel_sizes': [4, 4, 4], 'generator_strides': [2, 2, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 3, 'generator_final_stride': 1, 'generator_leaky_relu_alpha': 0.2, 'generator_use_batch_normalization': True, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.9, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'critic_num_filters': [64, 128, 128, 256], 'critic_kernel_sizes': [3, 3, 3, 3], 'critic_strides': [1, 2, 2, 2], 'critic_leaky_relu_alpha': 0.2, 'critic_use_layer_normalization': True, 'critic_l1_regularization_scale': 0.0, 'critic_l2_regularization_scale': 0.0, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_adam_beta1': 0.0, 'critic_adam_beta2': 0.9, 'critic_adam_epsilon': 1e-08, 'critic_clip_gradients': None, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_predictions_and_export_outputs: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "get_fake_images: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_leaky_relu = Tensor(\"generator/projection_leaky_relu:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_2/BiasAdd:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_2/FusedBatchNormV3:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_predictions_and_export_outputs: generated_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_predictions_and_export_outputs: predictions_dict = {'generated_images': <tf.Tensor 'generator/layers_conv2d_tranpose_fake_images/Tanh:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "get_predictions_and_export_outputs: export_outputs = {'predict_export_outputs': <tensorflow.python.saved_model.model_utils.export_output.PredictOutput object at 0x7f8ae8392c50>}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-30000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/export/exporter/temp-b'1592580812'/saved_model.pb\n",
      "INFO:tensorflow:global_step/sec: 0.878294\n",
      "INFO:tensorflow:loss = -4.1585956, step = 30001 (113.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10737\n",
      "INFO:tensorflow:loss = -4.459417, step = 30101 (90.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11407\n",
      "INFO:tensorflow:loss = -3.612597, step = 30201 (89.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12526\n",
      "INFO:tensorflow:loss = -3.254506, step = 30301 (89.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10512\n",
      "INFO:tensorflow:loss = -3.289565, step = 30401 (89.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11466\n",
      "INFO:tensorflow:loss = -3.3944654, step = 30501 (90.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10283\n",
      "INFO:tensorflow:loss = -4.0395703, step = 30601 (90.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10848\n",
      "INFO:tensorflow:loss = -2.9963372, step = 30701 (90.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1144\n",
      "INFO:tensorflow:loss = -4.031046, step = 30801 (89.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12513\n",
      "INFO:tensorflow:loss = -3.1383457, step = 30901 (89.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11575\n",
      "INFO:tensorflow:loss = -3.411954, step = 31001 (89.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13528\n",
      "INFO:tensorflow:loss = -3.0571918, step = 31101 (89.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.07397\n",
      "INFO:tensorflow:loss = -3.2911632, step = 31201 (91.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.07755\n",
      "INFO:tensorflow:loss = -3.9161265, step = 31301 (93.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12005\n",
      "INFO:tensorflow:loss = -3.6405864, step = 31401 (88.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12681\n",
      "INFO:tensorflow:loss = -3.0353477, step = 31501 (89.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10677\n",
      "INFO:tensorflow:loss = -3.760273, step = 31601 (89.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11849\n",
      "INFO:tensorflow:loss = -4.381094, step = 31701 (90.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12133\n",
      "INFO:tensorflow:loss = -3.759526, step = 31801 (88.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11939\n",
      "INFO:tensorflow:loss = -4.019368, step = 31901 (89.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11052\n",
      "INFO:tensorflow:loss = -3.227525, step = 32001 (89.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12446\n",
      "INFO:tensorflow:loss = -2.7726831, step = 32101 (89.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10406\n",
      "INFO:tensorflow:loss = -3.7455325, step = 32201 (89.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09023\n",
      "INFO:tensorflow:loss = -2.9646301, step = 32301 (92.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12389\n",
      "INFO:tensorflow:loss = -2.9288244, step = 32401 (88.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09426\n",
      "INFO:tensorflow:loss = -4.1283092, step = 32501 (92.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.07152\n",
      "INFO:tensorflow:loss = -3.805852, step = 32601 (92.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12871\n",
      "INFO:tensorflow:loss = -3.1031666, step = 32701 (89.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10218\n",
      "INFO:tensorflow:loss = -3.3004751, step = 32801 (89.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12317\n",
      "INFO:tensorflow:loss = -3.5216641, step = 32901 (89.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0968\n",
      "INFO:tensorflow:loss = -3.732339, step = 33001 (90.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09819\n",
      "INFO:tensorflow:loss = -3.891622, step = 33101 (91.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12114\n",
      "INFO:tensorflow:loss = -4.17977, step = 33201 (88.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1146\n",
      "INFO:tensorflow:loss = -2.3648477, step = 33301 (90.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1168\n",
      "INFO:tensorflow:loss = -2.767967, step = 33401 (88.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11138\n",
      "INFO:tensorflow:loss = -4.4479265, step = 33501 (90.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09369\n",
      "INFO:tensorflow:loss = -2.9935622, step = 33601 (90.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10578\n",
      "INFO:tensorflow:loss = -3.8250775, step = 33701 (91.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11969\n",
      "INFO:tensorflow:loss = -4.039982, step = 33801 (88.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11735\n",
      "INFO:tensorflow:loss = -3.1742442, step = 33901 (90.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11514\n",
      "INFO:tensorflow:loss = -3.5295897, step = 34001 (88.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14308\n",
      "INFO:tensorflow:loss = -3.731925, step = 34101 (88.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11158\n",
      "INFO:tensorflow:loss = -3.4098492, step = 34201 (89.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10583\n",
      "INFO:tensorflow:loss = -3.3208127, step = 34301 (91.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11515\n",
      "INFO:tensorflow:loss = -3.4744878, step = 34401 (88.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11801\n",
      "INFO:tensorflow:loss = -3.9079614, step = 34501 (90.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09771\n",
      "INFO:tensorflow:loss = -4.5465875, step = 34601 (90.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13186\n",
      "INFO:tensorflow:loss = -3.532052, step = 34701 (89.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.08688\n",
      "INFO:tensorflow:loss = -3.666365, step = 34801 (90.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11632\n",
      "INFO:tensorflow:loss = -2.9193354, step = 34901 (90.286 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 35000 into gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_gp_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "wgan_gp_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "wgan_gp_model: mode = eval\n",
      "wgan_gp_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model', 'train_batch_size': 64, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [4, 4, 256], 'generator_num_filters': [128, 128, 128], 'generator_kernel_sizes': [4, 4, 4], 'generator_strides': [2, 2, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 3, 'generator_final_stride': 1, 'generator_leaky_relu_alpha': 0.2, 'generator_use_batch_normalization': True, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.9, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'critic_num_filters': [64, 128, 128, 256], 'critic_kernel_sizes': [3, 3, 3, 3], 'critic_strides': [1, 2, 2, 2], 'critic_leaky_relu_alpha': 0.2, 'critic_use_layer_normalization': True, 'critic_l1_regularization_scale': 0.0, 'critic_l2_regularization_scale': 0.0, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_adam_beta1': 0.0, 'critic_adam_beta2': 0.9, 'critic_adam_epsilon': 1e-08, 'critic_clip_gradients': None, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_fake_images: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_leaky_relu = Tensor(\"generator/projection_leaky_relu:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_2/BiasAdd:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_2/FusedBatchNormV3:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_logits_and_losses: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "Call critic with fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32).\n",
      "\n",
      "get_critic_logits: network = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call critic with real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0).\n",
      "\n",
      "get_critic_logits: network = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic_1/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_critic_loss: critic_real_loss = Tensor(\"critic_real_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_fake_loss = Tensor(\"critic_fake_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_loss = Tensor(\"critic_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"critic/gradient_penalty/random_uniform_num:0\", shape=(?, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"critic/gradient_penalty/sub:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic/gradient_penalty/critic/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"critic/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"critic/gradient_penalty/gradients/critic/gradient_penalty/critic/layers_conv2d_0/Conv2D_grad/Conv2DBackpropInput:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"critic/gradient_penalty/Sqrt:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"critic/gradient_penalty/squared_difference:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"critic/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: gradient_penalty_loss = Tensor(\"critic/gradient_penalty/gradient_penalty_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_wasserstein_gp_loss = Tensor(\"critic_wasserstein_gp_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_reg_loss = Tensor(\"Const_5:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_total_loss = Tensor(\"critic_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_eval_metric_ops: critic_logits = Tensor(\"critic_concat_logits:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: critic_labels = Tensor(\"critic_concat_labels:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: critic_probabilities = Tensor(\"critic_probabilities:0\", shape=(?, 1), dtype=float32)\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "get_eval_metric_ops: eval_metric_ops = {'accuracy': (<tf.Tensor 'critic_accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_accuracy/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'critic_precision/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'critic_recall/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_recall/update_op:0' shape=() dtype=float32>), 'auc_roc': (<tf.Tensor 'critic_auc_roc/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_auc_roc/update_op:0' shape=() dtype=float32>), 'auc_pr': (<tf.Tensor 'critic_auc_pr/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_auc_pr/update_op:0' shape=() dtype=float32>)}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-19T16:48:50Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-35000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-19-16:48:55\n",
      "INFO:tensorflow:Saving dict for global step 35000: accuracy = 0.5, auc_pr = 0.75, auc_roc = 0.5, global_step = 35000, loss = -1.9399769, precision = 0.0, recall = 0.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 35000: gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-35000\n",
      "\n",
      "serving_input_fn: feature_placeholders = {'Z': <tf.Tensor 'serving_input_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "serving_input_fn: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_gp_model: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "wgan_gp_model: labels = None\n",
      "wgan_gp_model: mode = infer\n",
      "wgan_gp_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model', 'train_batch_size': 64, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [4, 4, 256], 'generator_num_filters': [128, 128, 128], 'generator_kernel_sizes': [4, 4, 4], 'generator_strides': [2, 2, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 3, 'generator_final_stride': 1, 'generator_leaky_relu_alpha': 0.2, 'generator_use_batch_normalization': True, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.9, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'critic_num_filters': [64, 128, 128, 256], 'critic_kernel_sizes': [3, 3, 3, 3], 'critic_strides': [1, 2, 2, 2], 'critic_leaky_relu_alpha': 0.2, 'critic_use_layer_normalization': True, 'critic_l1_regularization_scale': 0.0, 'critic_l2_regularization_scale': 0.0, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_adam_beta1': 0.0, 'critic_adam_beta2': 0.9, 'critic_adam_epsilon': 1e-08, 'critic_clip_gradients': None, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_predictions_and_export_outputs: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "get_fake_images: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_leaky_relu = Tensor(\"generator/projection_leaky_relu:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_2/BiasAdd:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_2/FusedBatchNormV3:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_predictions_and_export_outputs: generated_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_predictions_and_export_outputs: predictions_dict = {'generated_images': <tf.Tensor 'generator/layers_conv2d_tranpose_fake_images/Tanh:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "get_predictions_and_export_outputs: export_outputs = {'predict_export_outputs': <tensorflow.python.saved_model.model_utils.export_output.PredictOutput object at 0x7f8ac8523f10>}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-35000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/export/exporter/temp-b'1592585336'/saved_model.pb\n",
      "INFO:tensorflow:global_step/sec: 0.88009\n",
      "INFO:tensorflow:loss = -3.2533298, step = 35001 (112.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13885\n",
      "INFO:tensorflow:loss = -4.2731805, step = 35101 (88.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12434\n",
      "INFO:tensorflow:loss = -4.3172245, step = 35201 (87.983 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09966\n",
      "INFO:tensorflow:loss = -3.7787595, step = 35301 (91.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11954\n",
      "INFO:tensorflow:loss = -3.1929717, step = 35401 (88.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1059\n",
      "INFO:tensorflow:loss = -3.0394502, step = 35501 (91.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11876\n",
      "INFO:tensorflow:loss = -3.4948187, step = 35601 (88.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11604\n",
      "INFO:tensorflow:loss = -3.7555902, step = 35701 (90.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.06874\n",
      "INFO:tensorflow:loss = -3.6691911, step = 35801 (92.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10204\n",
      "INFO:tensorflow:loss = -3.3480682, step = 35901 (91.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10122\n",
      "INFO:tensorflow:loss = -3.381973, step = 36001 (90.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12656\n",
      "INFO:tensorflow:loss = -3.4380286, step = 36101 (89.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0912\n",
      "INFO:tensorflow:loss = -3.1791773, step = 36201 (90.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09166\n",
      "INFO:tensorflow:loss = -2.8289688, step = 36301 (92.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10248\n",
      "INFO:tensorflow:loss = -3.5361683, step = 36401 (89.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11475\n",
      "INFO:tensorflow:loss = -2.8508756, step = 36501 (90.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1002\n",
      "INFO:tensorflow:loss = -3.830967, step = 36601 (90.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13802\n",
      "INFO:tensorflow:loss = -3.688033, step = 36701 (88.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10802\n",
      "INFO:tensorflow:loss = -3.3441834, step = 36801 (89.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13335\n",
      "INFO:tensorflow:loss = -3.1381273, step = 36901 (89.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10525\n",
      "INFO:tensorflow:loss = -3.9710631, step = 37001 (89.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09263\n",
      "INFO:tensorflow:loss = -3.1816127, step = 37101 (92.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10194\n",
      "INFO:tensorflow:loss = -3.044356, step = 37201 (89.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11508\n",
      "INFO:tensorflow:loss = -3.2088137, step = 37301 (90.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12425\n",
      "INFO:tensorflow:loss = -4.1583905, step = 37401 (88.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1371\n",
      "INFO:tensorflow:loss = -3.7691808, step = 37501 (88.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12942\n",
      "INFO:tensorflow:loss = -3.212152, step = 37601 (87.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12819\n",
      "INFO:tensorflow:loss = -3.70378, step = 37701 (89.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12843\n",
      "INFO:tensorflow:loss = -2.8549912, step = 37801 (87.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12617\n",
      "INFO:tensorflow:loss = -3.9651442, step = 37901 (89.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11394\n",
      "INFO:tensorflow:loss = -3.738101, step = 38001 (89.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10428\n",
      "INFO:tensorflow:loss = -3.408379, step = 38101 (91.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10276\n",
      "INFO:tensorflow:loss = -4.2208815, step = 38201 (89.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13718\n",
      "INFO:tensorflow:loss = -4.2110972, step = 38301 (88.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11995\n",
      "INFO:tensorflow:loss = -3.802192, step = 38401 (88.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10026\n",
      "INFO:tensorflow:loss = -1.6543195, step = 38501 (91.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09096\n",
      "INFO:tensorflow:loss = -3.1611006, step = 38601 (90.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12381\n",
      "INFO:tensorflow:loss = -3.5749893, step = 38701 (89.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11525\n",
      "INFO:tensorflow:loss = -3.4852247, step = 38801 (88.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11601\n",
      "INFO:tensorflow:loss = -3.1793077, step = 38901 (90.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09525\n",
      "INFO:tensorflow:loss = -2.4910197, step = 39001 (90.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12336\n",
      "INFO:tensorflow:loss = -3.9429965, step = 39101 (89.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1156\n",
      "INFO:tensorflow:loss = -3.0791261, step = 39201 (88.916 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13967\n",
      "INFO:tensorflow:loss = -3.9460251, step = 39301 (88.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11798\n",
      "INFO:tensorflow:loss = -3.692799, step = 39401 (88.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12281\n",
      "INFO:tensorflow:loss = -3.4444203, step = 39501 (89.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13107\n",
      "INFO:tensorflow:loss = -3.869913, step = 39601 (87.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11023\n",
      "INFO:tensorflow:loss = -3.5317225, step = 39701 (90.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11464\n",
      "INFO:tensorflow:loss = -4.245496, step = 39801 (89.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13685\n",
      "INFO:tensorflow:loss = -3.709684, step = 39901 (88.701 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_gp_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "wgan_gp_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "wgan_gp_model: mode = eval\n",
      "wgan_gp_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model', 'train_batch_size': 64, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [4, 4, 256], 'generator_num_filters': [128, 128, 128], 'generator_kernel_sizes': [4, 4, 4], 'generator_strides': [2, 2, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 3, 'generator_final_stride': 1, 'generator_leaky_relu_alpha': 0.2, 'generator_use_batch_normalization': True, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.9, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'critic_num_filters': [64, 128, 128, 256], 'critic_kernel_sizes': [3, 3, 3, 3], 'critic_strides': [1, 2, 2, 2], 'critic_leaky_relu_alpha': 0.2, 'critic_use_layer_normalization': True, 'critic_l1_regularization_scale': 0.0, 'critic_l2_regularization_scale': 0.0, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_adam_beta1': 0.0, 'critic_adam_beta2': 0.9, 'critic_adam_epsilon': 1e-08, 'critic_clip_gradients': None, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_fake_images: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_leaky_relu = Tensor(\"generator/projection_leaky_relu:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_2/BiasAdd:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_2/FusedBatchNormV3:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_logits_and_losses: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "Call critic with fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32).\n",
      "\n",
      "get_critic_logits: network = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call critic with real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0).\n",
      "\n",
      "get_critic_logits: network = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic_1/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic_1/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_critic_loss: critic_real_loss = Tensor(\"critic_real_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_fake_loss = Tensor(\"critic_fake_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_loss = Tensor(\"critic_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"critic/gradient_penalty/random_uniform_num:0\", shape=(?, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"critic/gradient_penalty/sub:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_0/BiasAdd:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_0:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_2/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_2:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_3/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network = Tensor(\"critic/gradient_penalty/critic/leaky_relu_3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_critic_logits: network_flat = Tensor(\"critic/gradient_penalty/critic/flatten/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "get_critic_logits: logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"critic/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"critic/gradient_penalty/gradients/critic/gradient_penalty/critic/layers_conv2d_0/Conv2D_grad/Conv2DBackpropInput:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"critic/gradient_penalty/Sqrt:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"critic/gradient_penalty/squared_difference:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"critic/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: gradient_penalty_loss = Tensor(\"critic/gradient_penalty/gradient_penalty_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_wasserstein_gp_loss = Tensor(\"critic_wasserstein_gp_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_reg_loss = Tensor(\"Const_5:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_total_loss = Tensor(\"critic_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_eval_metric_ops: critic_logits = Tensor(\"critic_concat_logits:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: critic_labels = Tensor(\"critic_concat_labels:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: critic_probabilities = Tensor(\"critic_probabilities:0\", shape=(?, 1), dtype=float32)\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "get_eval_metric_ops: eval_metric_ops = {'accuracy': (<tf.Tensor 'critic_accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_accuracy/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'critic_precision/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'critic_recall/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_recall/update_op:0' shape=() dtype=float32>), 'auc_roc': (<tf.Tensor 'critic_auc_roc/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_auc_roc/update_op:0' shape=() dtype=float32>), 'auc_pr': (<tf.Tensor 'critic_auc_pr/value:0' shape=() dtype=float32>, <tf.Tensor 'critic_auc_pr/update_op:0' shape=() dtype=float32>)}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-19T18:04:02Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-19-18:04:07\n",
      "INFO:tensorflow:Saving dict for global step 40000: accuracy = 0.5, auc_pr = 0.75, auc_roc = 0.5, global_step = 40000, loss = -2.3980062, precision = 0.0, recall = 0.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40000: gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-40000\n",
      "\n",
      "serving_input_fn: feature_placeholders = {'Z': <tf.Tensor 'serving_input_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "serving_input_fn: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_gp_model: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "wgan_gp_model: labels = None\n",
      "wgan_gp_model: mode = infer\n",
      "wgan_gp_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/cifar10_car/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model', 'train_batch_size': 64, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [4, 4, 256], 'generator_num_filters': [128, 128, 128], 'generator_kernel_sizes': [4, 4, 4], 'generator_strides': [2, 2, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 3, 'generator_final_stride': 1, 'generator_leaky_relu_alpha': 0.2, 'generator_use_batch_normalization': True, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_adam_beta1': 0.0, 'generator_adam_beta2': 0.9, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'critic_num_filters': [64, 128, 128, 256], 'critic_kernel_sizes': [3, 3, 3, 3], 'critic_strides': [1, 2, 2, 2], 'critic_leaky_relu_alpha': 0.2, 'critic_use_layer_normalization': True, 'critic_l1_regularization_scale': 0.0, 'critic_l2_regularization_scale': 0.0, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_adam_beta1': 0.0, 'critic_adam_beta2': 0.9, 'critic_adam_epsilon': 1e-08, 'critic_clip_gradients': None, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_predictions_and_export_outputs: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "get_fake_images: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_leaky_relu = Tensor(\"generator/projection_leaky_relu:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 4096), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_2/BiasAdd:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_2/FusedBatchNormV3:0\", shape=(?, 32, 32, 128), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_predictions_and_export_outputs: generated_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_predictions_and_export_outputs: predictions_dict = {'generated_images': <tf.Tensor 'generator/layers_conv2d_tranpose_fake_images/Tanh:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "get_predictions_and_export_outputs: export_outputs = {'predict_export_outputs': <tensorflow.python.saved_model.model_utils.export_output.PredictOutput object at 0x7f8b080edbd0>}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/model.ckpt-40000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/export/exporter/temp-b'1592589848'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: -3.778285.\n"
     ]
    }
   ],
   "source": [
    "estimator = train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/export/exporter/\n",
      "gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/export/exporter/1592571310/\n",
      "gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/export/exporter/1592576252/\n",
      "gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/export/exporter/1592580812/\n",
      "gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/export/exporter/1592585336/\n",
      "gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/export/exporter/1592589848/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/export/exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/predictor/saved_model_predictor.py:153: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/export/exporter/1592589848/variables/variables\n"
     ]
    }
   ],
   "source": [
    "predict_fn = tf.contrib.predictor.from_saved_model(\n",
    "    \"gs://machine-learning-1234-bucket/gan/wgan_gp/trained_model/export/exporter/1592589848\"\n",
    ")\n",
    "predictions = predict_fn(\n",
    "    {\n",
    "        \"Z\": np.random.normal(size=(10, 512))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = np.clip(\n",
    "    a=((predictions[\"generated_images\"] + 1.0) * (255. / 2)).astype(np.int32),\n",
    "    a_min=0,\n",
    "    a_max=255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(generated_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "    \"\"\"Plots images.\n",
    "\n",
    "    Args:\n",
    "        images: np.array, array of images of\n",
    "            [num_images, image_size, image_size, num_channels].\n",
    "    \"\"\"\n",
    "    num_images = len(images)\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(num_images):\n",
    "        image = images[i]\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(\n",
    "            image,\n",
    "            cmap=plt.cm.binary\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
