{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2-dlenv_tfe\n",
      "1.18.1\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and modules\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {}\n",
    "# File arguments.\n",
    "arguments[\"train_file_pattern\"] = \"data/train.tfrecord\"\n",
    "arguments[\"eval_file_pattern\"] = \"data/eval.tfrecord\"\n",
    "arguments[\"output_dir\"] = \"trained_model\"\n",
    "\n",
    "# Training parameters.\n",
    "arguments[\"train_batch_size\"] = 5\n",
    "arguments[\"train_steps\"] = 200\n",
    "\n",
    "# Eval parameters.\n",
    "arguments[\"eval_batch_size\"] = 5\n",
    "arguments[\"eval_steps\"] = 10\n",
    "arguments[\"start_delay_secs\"] = 60\n",
    "arguments[\"throttle_secs\"] = 120\n",
    "\n",
    "# Image parameters.\n",
    "arguments[\"height\"] = 32\n",
    "arguments[\"width\"] = 32\n",
    "arguments[\"depth\"] = 3\n",
    "\n",
    "# Generator parameters.\n",
    "arguments[\"latent_size\"] = 512\n",
    "arguments[\"generator_projection_dims\"] = [8, 8, 256]\n",
    "arguments[\"generator_num_filters\"] = [128, 64]\n",
    "arguments[\"generator_kernel_sizes\"] = [5, 5]\n",
    "arguments[\"generator_strides\"] = [1, 2]\n",
    "arguments[\"generator_final_num_filters\"] = 3\n",
    "arguments[\"generator_final_kernel_size\"] = 5\n",
    "arguments[\"generator_final_stride\"] = 2\n",
    "arguments[\"generator_l1_regularization_scale\"] = 0.01\n",
    "arguments[\"generator_l2_regularization_scale\"] = 0.01\n",
    "arguments[\"generator_optimizer\"] = \"Adam\"\n",
    "arguments[\"generator_learning_rate\"] = 0.0001\n",
    "arguments[\"generator_clip_gradients\"] = 5.0\n",
    "arguments[\"generator_train_steps\"] = 1\n",
    "\n",
    "# Critic hyperparameters.\n",
    "arguments[\"critic_num_filters\"] = [64, 128]\n",
    "arguments[\"critic_kernel_sizes\"] = [5, 5]\n",
    "arguments[\"critic_strides\"] = [2, 2]\n",
    "arguments[\"critic_dropout_rates\"] = [0.3, 0.3]\n",
    "arguments[\"critic_l1_regularization_scale\"] = 0.01\n",
    "arguments[\"critic_l2_regularization_scale\"] = 0.01\n",
    "arguments[\"critic_optimizer\"] = \"Adam\"\n",
    "arguments[\"critic_learning_rate\"] = 0.0001\n",
    "arguments[\"critic_clip_gradients\"] = 5.0\n",
    "arguments[\"critic_gradient_penalty_coefficient\"] = 10.0\n",
    "arguments[\"critic_train_steps\"] = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print_object.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_obj(function_name, object_name, object_value):\n",
    "    \"\"\"Prints enclosing function, object name, and object value.\n",
    "\n",
    "    Args:\n",
    "        function_name: str, name of function.\n",
    "        object_name: str, name of object.\n",
    "        object_value: object, value of passed object.\n",
    "    \"\"\"\n",
    "#     pass\n",
    "    print(\"{}: {} = {}\".format(function_name, object_name, object_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_example(protos, params):\n",
    "    \"\"\"Decodes TFRecord file into tensors.\n",
    "\n",
    "    Given protobufs, decode into image and label tensors.\n",
    "\n",
    "    Args:\n",
    "        protos: protobufs from TFRecord file.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Image and label tensors.\n",
    "    \"\"\"\n",
    "    # Create feature schema map for protos.\n",
    "    features = {\n",
    "        \"image_raw\": tf.FixedLenFeature(shape=[], dtype=tf.string),\n",
    "        \"label\": tf.FixedLenFeature(shape=[], dtype=tf.int64)\n",
    "    }\n",
    "\n",
    "    # Parse features from tf.Example.\n",
    "    parsed_features = tf.parse_single_example(\n",
    "        serialized=protos, features=features\n",
    "    )\n",
    "    print_obj(\"\\ndecode_example\", \"features\", features)\n",
    "\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length height * width * depth) to a uint8 tensor with shape\n",
    "    # [height * width * depth].\n",
    "    image = tf.decode_raw(\n",
    "        input_bytes=parsed_features[\"image_raw\"], out_type=tf.uint8\n",
    "    )\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Reshape flattened image back into normal dimensions.\n",
    "    image = tf.reshape(\n",
    "        tensor=image,\n",
    "        shape=[params[\"height\"], params[\"width\"], params[\"depth\"]]\n",
    "    )\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Convert from [0, 255] -> [-1.0, 1.0] floats.\n",
    "    image = tf.cast(x=image, dtype=tf.float32) * (2. / 255) - 1.0\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "    label = tf.cast(x=parsed_features[\"label\"], dtype=tf.int32)\n",
    "    print_obj(\"decode_example\", \"label\", label)\n",
    "\n",
    "    return {\"image\": image}, label\n",
    "\n",
    "\n",
    "def read_dataset(filename, mode, batch_size, params):\n",
    "    \"\"\"Reads CSV time series data using tf.data, doing necessary preprocessing.\n",
    "\n",
    "    Given filename, mode, batch size, and other parameters, read CSV dataset\n",
    "    using Dataset API, apply necessary preprocessing, and return an input\n",
    "    function to the Estimator API.\n",
    "\n",
    "    Args:\n",
    "        filename: str, file pattern that to read into our tf.data dataset.\n",
    "        mode: The estimator ModeKeys. Can be TRAIN or EVAL.\n",
    "        batch_size: int, number of examples per batch.\n",
    "        params: dict, dictionary of user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        An input function.\n",
    "    \"\"\"\n",
    "    def _input_fn():\n",
    "        \"\"\"Wrapper input function used by Estimator API to get data tensors.\n",
    "\n",
    "        Returns:\n",
    "            Batched dataset object of dictionary of feature tensors and label\n",
    "                tensor.\n",
    "        \"\"\"\n",
    "        # Create list of files that match pattern.\n",
    "        file_list = tf.gfile.Glob(filename=filename)\n",
    "\n",
    "        # Create dataset from file list.\n",
    "        dataset = tf.data.TFRecordDataset(\n",
    "            filenames=file_list, num_parallel_reads=40\n",
    "        )\n",
    "\n",
    "        # Shuffle and repeat if training with fused op.\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            dataset = dataset.apply(\n",
    "                tf.contrib.data.shuffle_and_repeat(\n",
    "                    buffer_size=50 * batch_size,\n",
    "                    count=None  # indefinitely\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Decode CSV file into a features dictionary of tensors, then batch.\n",
    "        dataset = dataset.apply(\n",
    "            tf.contrib.data.map_and_batch(\n",
    "                map_func=lambda x: decode_example(\n",
    "                    protos=x,\n",
    "                    params=params\n",
    "                ),\n",
    "                batch_size=batch_size,\n",
    "                num_parallel_calls=4\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Prefetch data to improve latency.\n",
    "        dataset = dataset.prefetch(buffer_size=2)\n",
    "\n",
    "        # Create a iterator, then get batch of features from example queue.\n",
    "        batched_dataset = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        return batched_dataset\n",
    "    return _input_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_network(Z, mode, params, reuse=False):\n",
    "    \"\"\"Creates generator network and returns generated output.\n",
    "\n",
    "    Args:\n",
    "        Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "        mode: tf.estimator.ModeKeys with values of either TRAIN, EVAL, or\n",
    "            PREDICT.\n",
    "        params: dict, user passed parameters.\n",
    "        reuse: bool, whether to reuse variables or not.\n",
    "\n",
    "    Returns:\n",
    "        Generated outputs tensor of shape\n",
    "            [cur_batch_size, height * width * depth].\n",
    "    \"\"\"\n",
    "    # Create regularizer for layer kernel weights.\n",
    "    regularizer = tf.contrib.layers.l1_l2_regularizer(\n",
    "        scale_l1=params[\"generator_l1_regularization_scale\"],\n",
    "        scale_l2=params[\"generator_l2_regularization_scale\"]\n",
    "    )\n",
    "\n",
    "    with tf.variable_scope(\"generator\", reuse=reuse):\n",
    "        # Project latent vectors.\n",
    "        projection_height = params[\"generator_projection_dims\"][0]\n",
    "        projection_width = params[\"generator_projection_dims\"][1]\n",
    "        projection_depth = params[\"generator_projection_dims\"][2]\n",
    "\n",
    "        # shape = (\n",
    "        #     cur_batch_size,\n",
    "        #     projection_height * projection_width * projection_depth\n",
    "        # )\n",
    "        projection = tf.layers.dense(\n",
    "            inputs=Z,\n",
    "            units=projection_height * projection_width * projection_depth,\n",
    "            activation=tf.nn.leaky_relu,\n",
    "            name=\"projection_layer\"\n",
    "        )\n",
    "        print_obj(\"generator_network\", \"projection\", projection)\n",
    "\n",
    "        # shape = (\n",
    "        #     cur_batch_size,\n",
    "        #     projection_height * projection_width * projection_depth\n",
    "        # )\n",
    "        projection_batch_norm = tf.layers.batch_normalization(\n",
    "            inputs=projection,\n",
    "            training=(mode == tf.estimator.ModeKeys.TRAIN),\n",
    "            name=\"projection_batch_norm\"\n",
    "        )\n",
    "        print_obj(\n",
    "            \"generator_network\",\n",
    "            \"projection_batch_norm\",\n",
    "            projection_batch_norm\n",
    "        )\n",
    "\n",
    "        # Reshape projection into \"image\".\n",
    "        # shape = (\n",
    "        #     cur_batch_size,\n",
    "        #     projection_height,\n",
    "        #     projection_width,\n",
    "        #     projection_depth\n",
    "        # )\n",
    "        network = tf.reshape(\n",
    "            tensor=projection_batch_norm,\n",
    "            shape=[-1, projection_height, projection_width, projection_depth],\n",
    "            name=\"projection_reshaped\"\n",
    "        )\n",
    "        print_obj(\"generator_network\", \"network\", network)\n",
    "\n",
    "        # Iteratively build upsampling layers.\n",
    "        for i in range(len(params[\"generator_num_filters\"])):\n",
    "            # Add convolutional transpose layers with given params per layer.\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     generator_kernel_sizes[i - 1] * generator_strides[i],\n",
    "            #     generator_kernel_sizes[i - 1] * generator_strides[i],\n",
    "            #     generator_num_filters[i]\n",
    "            # )\n",
    "            network = tf.layers.conv2d_transpose(\n",
    "                inputs=network,\n",
    "                filters=params[\"generator_num_filters\"][i],\n",
    "                kernel_size=params[\"generator_kernel_sizes\"][i],\n",
    "                strides=params[\"generator_strides\"][i],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.leaky_relu,\n",
    "                use_bias=False,\n",
    "                kernel_regularizer=regularizer,\n",
    "                name=\"layers_conv2d_tranpose_{}\".format(i)\n",
    "            )\n",
    "            print_obj(\"generator_network\", \"network\", network)\n",
    "\n",
    "            # Add batch normalization to keep the inputs from blowing up.\n",
    "            network = tf.layers.batch_normalization(\n",
    "                inputs=network,\n",
    "                training=(mode == tf.estimator.ModeKeys.TRAIN),\n",
    "                name=\"layers_batch_norm_{}\".format(i)\n",
    "            )\n",
    "            print_obj(\"generator_network\", \"network\", network)\n",
    "\n",
    "        # Final conv2d transpose layer for image output.\n",
    "        # shape = (cur_batch_size, height * width * depth)\n",
    "        generated_outputs = tf.layers.conv2d_transpose(\n",
    "                inputs=network,\n",
    "                filters=params[\"generator_final_num_filters\"],\n",
    "                kernel_size=params[\"generator_final_kernel_size\"],\n",
    "                strides=params[\"generator_final_stride\"],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.tanh,\n",
    "                use_bias=False,\n",
    "                kernel_regularizer=regularizer,\n",
    "                name=\"layers_conv2d_tranpose_generated_outputs\"\n",
    "        )\n",
    "        print_obj(\"generator_network\", \"generated_outputs\", generated_outputs)\n",
    "\n",
    "    return generated_outputs\n",
    "\n",
    "\n",
    "def get_generator_loss(fake_logits):\n",
    "    \"\"\"Gets generator loss.\n",
    "\n",
    "    Args:\n",
    "        fake_logits: tensor, shape of\n",
    "            [cur_batch_size, height * width * depth].\n",
    "\n",
    "    Returns:\n",
    "        Tensor of generator's total loss of shape [].\n",
    "    \"\"\"\n",
    "    # Calculate base generator loss.\n",
    "    generator_loss = -tf.reduce_mean(\n",
    "        input_tensor=fake_logits,\n",
    "        name=\"generator_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"\\nget_generator_loss\",\n",
    "        \"generator_loss\",\n",
    "        generator_loss\n",
    "    )\n",
    "\n",
    "    # Get regularization losses.\n",
    "    generator_regularization_loss = tf.losses.get_regularization_loss(\n",
    "        scope=\"generator\",\n",
    "        name=\"generator_regularization_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_generator_loss\",\n",
    "        \"generator_regularization_loss\",\n",
    "        generator_regularization_loss\n",
    "    )\n",
    "\n",
    "    # Combine losses for total losses.\n",
    "    generator_total_loss = tf.math.add(\n",
    "        x=generator_loss,\n",
    "        y=generator_regularization_loss,\n",
    "        name=\"generator_total_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_generator_loss\", \"generator_total_loss\", generator_total_loss\n",
    "    )\n",
    "\n",
    "    return generator_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## critic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic_network(X, params, reuse=False):\n",
    "    \"\"\"Creates critic network and returns logits.\n",
    "\n",
    "    Args:\n",
    "        X: tensor, image tensors of shape\n",
    "            [cur_batch_size, height, width, depth].\n",
    "        params: dict, user passed parameters.\n",
    "        reuse: bool, whether to reuse variables or not.\n",
    "\n",
    "    Returns:\n",
    "        Logits tensor of shape [cur_batch_size, 1].\n",
    "    \"\"\"\n",
    "    # Create the input layer to our DNN.\n",
    "    # shape = (cur_batch_size, height * width * depth)\n",
    "    network = X\n",
    "    print_obj(\"\\ncritic_network\", \"network\", network)\n",
    "\n",
    "    # Create regularizer for layer kernel weights.\n",
    "    regularizer = tf.contrib.layers.l1_l2_regularizer(\n",
    "        scale_l1=params[\"critic_l1_regularization_scale\"],\n",
    "        scale_l2=params[\"critic_l2_regularization_scale\"]\n",
    "    )\n",
    "\n",
    "    with tf.variable_scope(\"critic\", reuse=reuse):\n",
    "        # Iteratively build downsampling layers.\n",
    "        for i in range(len(params[\"critic_num_filters\"])):\n",
    "            # Add convolutional transpose layers with given params per layer.\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     critic_kernel_sizes[i - 1] / critic_strides[i],\n",
    "            #     critic_kernel_sizes[i - 1] / critic_strides[i],\n",
    "            #     critic_num_filters[i]\n",
    "            # )\n",
    "            network = tf.layers.conv2d(\n",
    "                inputs=network,\n",
    "                filters=params[\"critic_num_filters\"][i],\n",
    "                kernel_size=params[\"critic_kernel_sizes\"][i],\n",
    "                strides=params[\"critic_strides\"][i],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.leaky_relu,\n",
    "                kernel_regularizer=regularizer,\n",
    "                name=\"layers_conv2d_{}\".format(i)\n",
    "            )\n",
    "            print_obj(\"critic_network\", \"network\", network)\n",
    "\n",
    "            # Add some dropout for better regularization and stability.\n",
    "            network = tf.layers.dropout(\n",
    "                inputs=network,\n",
    "                rate=params[\"critic_dropout_rates\"][i],\n",
    "                name=\"layers_dropout_{}\".format(i)\n",
    "            )\n",
    "            print_obj(\"critic_network\", \"network\", network)\n",
    "\n",
    "        # Flatten network output.\n",
    "        # shape = (\n",
    "        #     cur_batch_size,\n",
    "        #     (critic_kernel_sizes[-2] / critic_strides[-1]) ** 2 * critic_num_filters[-1]\n",
    "        # )\n",
    "        network_flat = tf.layers.Flatten()(inputs=network)\n",
    "        print_obj(\"critic_network\", \"network_flat\", network_flat)\n",
    "\n",
    "        # Final linear layer for logits.\n",
    "        # shape = (cur_batch_size, 1)\n",
    "        logits = tf.layers.dense(\n",
    "            inputs=network_flat,\n",
    "            units=1,\n",
    "            activation=None,\n",
    "            kernel_regularizer=regularizer,\n",
    "            name=\"layers_dense_logits\"\n",
    "        )\n",
    "        print_obj(\"critic_network\", \"logits\", logits)\n",
    "\n",
    "    return logits\n",
    "\n",
    "\n",
    "def get_gradient_penalty_loss(\n",
    "        cur_batch_size,\n",
    "        fake_images,\n",
    "        real_images,\n",
    "        params):\n",
    "    \"\"\"Gets critic gradient penalty loss.\n",
    "\n",
    "    Args:\n",
    "        cur_batch_size: tensor, in case of a partial batch instead of\n",
    "            using the user passed int.\n",
    "        fake_images: tensor, images generated by the generator from random\n",
    "            noise of shape [cur_batch_size, image_size, image_size, 3].\n",
    "        real_images: tensor, real images from input of shape\n",
    "            [cur_batch_size, image_size, image_size, 3].\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Critic's gradient penalty loss of shape [].\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name=\"critic/gradient_penalty\"):\n",
    "        # Get a random uniform number rank 4 tensor.\n",
    "        random_uniform_num = tf.random.uniform(\n",
    "            shape=[cur_batch_size, 1, 1, 1],\n",
    "            minval=0., maxval=1.,\n",
    "            dtype=tf.float32,\n",
    "            name=\"random_uniform_num\"\n",
    "        )\n",
    "        print_obj(\n",
    "            \"\\nget_gradient_penalty_loss\",\n",
    "            \"random_uniform_num\",\n",
    "            random_uniform_num\n",
    "        )\n",
    "\n",
    "        # Find the element-wise difference between images.\n",
    "        image_difference = real_images - fake_images\n",
    "        print_obj(\n",
    "            \"get_gradient_penalty_loss\",\n",
    "            \"image_difference\",\n",
    "            image_difference\n",
    "        )\n",
    "\n",
    "        # Get random samples from this mixed image distribution.\n",
    "        mixed_images = random_uniform_num * image_difference\n",
    "        mixed_images += fake_images\n",
    "        print_obj(\n",
    "            \"get_gradient_penalty_loss\",\n",
    "            \"mixed_images\",\n",
    "            mixed_images\n",
    "        )\n",
    "\n",
    "        # Send to the critic to get logits.\n",
    "        mixed_logits = critic_network(\n",
    "            X=mixed_images, params=params, reuse=True\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_gradient_penalty_loss\",\n",
    "            \"mixed_logits\",\n",
    "            mixed_logits\n",
    "        )\n",
    "\n",
    "        # Get the mixed loss.\n",
    "        mixed_loss = tf.reduce_sum(\n",
    "            input_tensor=mixed_images,\n",
    "            name=\"mixed_loss\"\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_gradient_penalty_loss\",\n",
    "            \"mixed_loss\",\n",
    "            mixed_loss\n",
    "        )\n",
    "\n",
    "        # Get gradient from returned list of length 1.\n",
    "        mixed_gradients = tf.gradients(\n",
    "            ys=mixed_loss,\n",
    "            xs=[mixed_images],\n",
    "            name=\"gradients\"\n",
    "        )[0]\n",
    "        print_obj(\n",
    "            \"get_gradient_penalty_loss\",\n",
    "            \"mixed_gradients\",\n",
    "            mixed_gradients\n",
    "        )\n",
    "\n",
    "        # Get gradient's L2 norm.\n",
    "        mixed_norms = tf.sqrt(\n",
    "            x=tf.reduce_sum(\n",
    "                input_tensor=tf.square(\n",
    "                    x=mixed_gradients,\n",
    "                    name=\"squared_grads\"\n",
    "                ),\n",
    "                axis=[1, 2, 3]\n",
    "            )\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_gradient_penalty_loss\",\n",
    "            \"mixed_norms\",\n",
    "            mixed_norms\n",
    "        )\n",
    "\n",
    "        # Get squared difference from target of 1.0.\n",
    "        squared_difference = tf.square(\n",
    "            x=mixed_norms - 1.0,\n",
    "            name=\"squared_difference\"\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_gradient_penalty_loss\",\n",
    "            \"squared_difference\",\n",
    "            squared_difference\n",
    "        )\n",
    "\n",
    "        # Get gradient penalty scalar.\n",
    "        gradient_penalty = tf.reduce_mean(\n",
    "            input_tensor=squared_difference, name=\"gradient_penalty\"\n",
    "        )\n",
    "        print_obj(\n",
    "            \"get_gradient_penalty_loss\",\n",
    "            \"gradient_penalty\",\n",
    "            gradient_penalty\n",
    "        )\n",
    "\n",
    "        # Multiply with lambda to get gradient penalty loss.\n",
    "        gradient_penalty_loss = tf.multiply(\n",
    "            x=params[\"critic_gradient_penalty_coefficient\"],\n",
    "            y=gradient_penalty,\n",
    "            name=\"gradient_penalty_loss\"\n",
    "        )\n",
    "\n",
    "        return gradient_penalty_loss\n",
    "\n",
    "\n",
    "def get_critic_loss(\n",
    "        cur_batch_size,\n",
    "        fake_images,\n",
    "        real_images,\n",
    "        fake_logits,\n",
    "        real_logits,\n",
    "        params):\n",
    "    \"\"\"Gets critic's total loss.\n",
    "\n",
    "    Args:\n",
    "        cur_batch_size: tensor, in case of a partial batch instead of\n",
    "            using the user passed int.\n",
    "        fake_images: tensor, images generated by the generator from random\n",
    "            noise of shape [cur_batch_size, image_size, image_size, 3].\n",
    "        real_images: tensor, real images from input of shape\n",
    "            [cur_batch_size, image_size, image_size, 3].\n",
    "        fake_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "            critic having processed generator's output image.\n",
    "        fake_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "            critic having processed real image.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Critic's total loss tensor of shape [].\n",
    "    \"\"\"\n",
    "    # Calculate base critic loss.\n",
    "    critic_real_loss = tf.reduce_mean(\n",
    "        input_tensor=real_logits,\n",
    "        name=\"critic_real_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"\\nget_critic_loss\",\n",
    "        \"critic_real_loss\",\n",
    "        critic_real_loss\n",
    "    )\n",
    "\n",
    "    critic_generated_loss = tf.reduce_mean(\n",
    "        input_tensor=fake_logits,\n",
    "        name=\"critic_generated_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_critic_loss\",\n",
    "        \"critic_generated_loss\",\n",
    "        critic_generated_loss\n",
    "    )\n",
    "\n",
    "    critic_loss = tf.add(\n",
    "        x=critic_real_loss, y=-critic_generated_loss,\n",
    "        name=\"critic_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_critic_loss\",\n",
    "        \"critic_loss\",\n",
    "        critic_loss\n",
    "    )\n",
    "\n",
    "    # Get critic gradient penalty loss.\n",
    "    critic_gradient_penalty = get_gradient_penalty_loss(\n",
    "        cur_batch_size=cur_batch_size,\n",
    "        fake_images=fake_images,\n",
    "        real_images=real_images,\n",
    "        params=params\n",
    "    )\n",
    "\n",
    "    # Get critic Wasserstein GP loss.\n",
    "    critic_wasserstein_gp_loss = tf.add(\n",
    "        x=critic_loss,\n",
    "        y=critic_gradient_penalty,\n",
    "        name=\"critic_wasserstein_gp_loss\"\n",
    "    )\n",
    "\n",
    "    # Get regularization losses.\n",
    "    critic_regularization_loss = tf.losses.get_regularization_loss(\n",
    "        scope=\"critic\",\n",
    "        name=\"critic_regularization_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_critic_loss\",\n",
    "        \"critic_regularization_loss\",\n",
    "        critic_regularization_loss\n",
    "    )\n",
    "\n",
    "    # Combine losses for total losses.\n",
    "    critic_total_loss = tf.math.add(\n",
    "        x=critic_wasserstein_gp_loss,\n",
    "        y=critic_regularization_loss,\n",
    "        name=\"critic_total_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_critic_loss\",\n",
    "        \"critic_total_loss\",\n",
    "        critic_total_loss\n",
    "    )\n",
    "\n",
    "    return critic_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wgan_gp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(loss, global_step, params, scope):\n",
    "    \"\"\"Trains network and returns loss and train op.\n",
    "\n",
    "    Args:\n",
    "        loss: tensor, shape of [].\n",
    "        global_step: tensor, the current training step or batch in the\n",
    "            training loop.\n",
    "        params: dict, user passed parameters.\n",
    "        scope: str, the variables that to train.\n",
    "\n",
    "    Returns:\n",
    "        Loss tensor and training op.\n",
    "    \"\"\"\n",
    "    # Create optimizer map.\n",
    "    optimizers = {\n",
    "        \"Adam\": tf.train.AdamOptimizer,\n",
    "        \"Adadelta\": tf.train.AdadeltaOptimizer,\n",
    "        \"AdagradDA\": tf.train.AdagradDAOptimizer,\n",
    "        \"Adagrad\": tf.train.AdagradOptimizer,\n",
    "        \"Ftrl\": tf.train.FtrlOptimizer,\n",
    "        \"GradientDescent\": tf.train.GradientDescentOptimizer,\n",
    "        \"Momentum\": tf.train.MomentumOptimizer,\n",
    "        \"ProximalAdagrad\": tf.train.ProximalAdagradOptimizer,\n",
    "        \"ProximalGradientDescent\": tf.train.ProximalGradientDescentOptimizer,\n",
    "        \"RMSProp\": tf.train.RMSPropOptimizer\n",
    "    }\n",
    "\n",
    "    # Get gradients.\n",
    "    gradients = tf.gradients(\n",
    "        ys=loss,\n",
    "        xs=tf.trainable_variables(scope=scope),\n",
    "        name=\"{}_gradients\".format(scope)\n",
    "    )\n",
    "\n",
    "    # Clip gradients.\n",
    "    if params[\"{}_clip_gradients\".format(scope)]:\n",
    "        gradients, _ = tf.clip_by_global_norm(\n",
    "            t_list=gradients,\n",
    "            clip_norm=params[\"{}_clip_gradients\".format(scope)],\n",
    "            name=\"{}_clip_by_global_norm_gradients\".format(scope)\n",
    "        )\n",
    "\n",
    "    # Zip back together gradients and variables.\n",
    "    grads_and_vars = zip(gradients, tf.trainable_variables(scope=scope))\n",
    "\n",
    "    # Get optimizer and instantiate it.\n",
    "    optimizer = optimizers[params[\"{}_optimizer\".format(scope)]](\n",
    "        learning_rate=params[\"{}_learning_rate\".format(scope)]\n",
    "    )\n",
    "\n",
    "    # Create train op by applying gradients to variables and incrementing\n",
    "    # global step.\n",
    "    train_op = optimizer.apply_gradients(\n",
    "        grads_and_vars=grads_and_vars,\n",
    "        global_step=global_step,\n",
    "        name=\"{}_apply_gradients\".format(scope)\n",
    "    )\n",
    "\n",
    "    return loss, train_op\n",
    "\n",
    "\n",
    "def wgan_gp_model(features, labels, mode, params):\n",
    "    \"\"\"Wasserstein GAN with gradient penalty custom Estimator model function.\n",
    "\n",
    "    Args:\n",
    "        features: dict, keys are feature names and values are feature tensors.\n",
    "        labels: tensor, label data.\n",
    "        mode: tf.estimator.ModeKeys with values of either TRAIN, EVAL, or\n",
    "            PREDICT.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Instance of `tf.estimator.EstimatorSpec` class.\n",
    "    \"\"\"\n",
    "    print_obj(\"\\nwgan_model\", \"features\", features)\n",
    "    print_obj(\"wgan_model\", \"labels\", labels)\n",
    "    print_obj(\"wgan_model\", \"mode\", mode)\n",
    "    print_obj(\"wgan_model\", \"params\", params)\n",
    "\n",
    "    # Loss function, training/eval ops, etc.\n",
    "    predictions_dict = None\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = None\n",
    "    export_outputs = None\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # Extract given latent vectors from features dictionary.\n",
    "        Z = tf.cast(x=features[\"Z\"], dtype=tf.float32)\n",
    "\n",
    "        # Get predictions from generator.\n",
    "        generated_images = generator_network(Z, mode, params, reuse=False)\n",
    "\n",
    "        # Create predictions dictionary.\n",
    "        predictions_dict = {\n",
    "            \"generated_images\": generated_images\n",
    "        }\n",
    "\n",
    "        # Create export outputs.\n",
    "        export_outputs = {\n",
    "            \"predict_export_outputs\": tf.estimator.export.PredictOutput(\n",
    "                outputs=predictions_dict)\n",
    "        }\n",
    "    else:\n",
    "        # Extract image from features dictionary.\n",
    "        X = features[\"image\"]\n",
    "\n",
    "        # Get dynamic batch size in case of partial batch.\n",
    "        cur_batch_size = tf.shape(\n",
    "            input=X,\n",
    "            out_type=tf.int32,\n",
    "            name=\"wgan_model_cur_batch_size\"\n",
    "        )[0]\n",
    "\n",
    "        # Create random noise latent vector for each batch example.\n",
    "        Z = tf.random.normal(\n",
    "            shape=[cur_batch_size, params[\"latent_size\"]],\n",
    "            mean=0.0,\n",
    "            stddev=1.0,\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        # Establish generator network subgraph.\n",
    "        generator_outputs = generator_network(Z, mode, params, reuse=False)\n",
    "\n",
    "        # Establish critic network subgraph.\n",
    "        real_logits = critic_network(X, params, reuse=False)\n",
    "\n",
    "        # Get generated logits too.\n",
    "        fake_logits = critic_network(\n",
    "            generator_outputs, params, reuse=True\n",
    "        )\n",
    "\n",
    "        # Get generator total loss.\n",
    "        generator_total_loss = get_generator_loss(fake_logits)\n",
    "\n",
    "        # Get critic total loss.\n",
    "        critic_total_loss = get_critic_loss(\n",
    "            cur_batch_size=cur_batch_size,\n",
    "            fake_images=generator_outputs,\n",
    "            real_images=X,\n",
    "            fake_logits=fake_logits,\n",
    "            real_logits=real_logits,\n",
    "            params=params\n",
    "        )\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            # Get global step.\n",
    "            global_step = tf.train.get_global_step()\n",
    "\n",
    "            # Determine if it is time to train generator or critic.\n",
    "            cycle_step = tf.mod(\n",
    "                x=global_step,\n",
    "                y=tf.cast(\n",
    "                    x=tf.add(\n",
    "                        x=params[\"generator_train_steps\"],\n",
    "                        y=params[\"critic_train_steps\"]\n",
    "                    ),\n",
    "                    dtype=tf.int64\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Create choose generator condition.\n",
    "            condition = tf.less(\n",
    "                x=cycle_step, y=params[\"generator_train_steps\"]\n",
    "            )\n",
    "\n",
    "            # Needed for batch normalization, but has no effect otherwise.\n",
    "            update_ops = tf.get_collection(key=tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "            with tf.control_dependencies(control_inputs=update_ops):\n",
    "                # Conditionally choose to train generator or critic.\n",
    "                loss, train_op = tf.cond(\n",
    "                    pred=condition,\n",
    "                    true_fn=lambda: train_network(\n",
    "                        loss=generator_total_loss,\n",
    "                        global_step=global_step,\n",
    "                        params=params,\n",
    "                        scope=\"generator\"\n",
    "                    ),\n",
    "                    false_fn=lambda: train_network(\n",
    "                        loss=critic_total_loss,\n",
    "                        global_step=global_step,\n",
    "                        params=params,\n",
    "                        scope=\"critic\"\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            loss = critic_total_loss\n",
    "\n",
    "            # Concatenate critic logits and labels.\n",
    "            critic_logits = tf.concat(\n",
    "                values=[real_logits, fake_logits],\n",
    "                axis=0,\n",
    "                name=\"critic_concat_logits\"\n",
    "            )\n",
    "\n",
    "            critic_labels = tf.concat(\n",
    "                values=[\n",
    "                    tf.ones_like(tensor=real_logits),\n",
    "                    tf.zeros_like(tensor=fake_logits)\n",
    "                ],\n",
    "                axis=0,\n",
    "                name=\"critic_concat_labels\"\n",
    "            )\n",
    "\n",
    "            # Calculate critic probabilities.\n",
    "            critic_probabilities = tf.nn.sigmoid(\n",
    "                x=critic_logits, name=\"critic_probabilities\"\n",
    "            )\n",
    "\n",
    "            # Create eval metric ops dictionary.\n",
    "            eval_metric_ops = {\n",
    "                \"accuracy\": tf.metrics.accuracy(\n",
    "                    labels=critic_labels,\n",
    "                    predictions=critic_probabilities,\n",
    "                    name=\"wgan_model_accuracy\"\n",
    "                ),\n",
    "                \"precision\": tf.metrics.precision(\n",
    "                    labels=critic_labels,\n",
    "                    predictions=critic_probabilities,\n",
    "                    name=\"wgan_model_precision\"\n",
    "                ),\n",
    "                \"recall\": tf.metrics.recall(\n",
    "                    labels=critic_labels,\n",
    "                    predictions=critic_probabilities,\n",
    "                    name=\"wgan_model_recall\"\n",
    "                ),\n",
    "                \"auc_roc\": tf.metrics.auc(\n",
    "                    labels=critic_labels,\n",
    "                    predictions=critic_probabilities,\n",
    "                    num_thresholds=200,\n",
    "                    curve=\"ROC\",\n",
    "                    name=\"wgan_model_auc_roc\"\n",
    "                ),\n",
    "                \"auc_pr\": tf.metrics.auc(\n",
    "                    labels=critic_labels,\n",
    "                    predictions=critic_probabilities,\n",
    "                    num_thresholds=200,\n",
    "                    curve=\"PR\",\n",
    "                    name=\"wgan_model_auc_pr\"\n",
    "                )\n",
    "            }\n",
    "\n",
    "    # Return EstimatorSpec\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions_dict,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops,\n",
    "        export_outputs=export_outputs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## serving.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn(params):\n",
    "    \"\"\"Serving input function.\n",
    "\n",
    "    Args:\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        ServingInputReceiver object containing features and receiver tensors.\n",
    "    \"\"\"\n",
    "    # Create placeholders to accept data sent to the model at serving time.\n",
    "    # shape = (batch_size,)\n",
    "    feature_placeholders = {\n",
    "        \"Z\": tf.placeholder(\n",
    "            dtype=tf.float32,\n",
    "            shape=[None, params[\"latent_size\"]],\n",
    "            name=\"serving_input_placeholder_Z\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    print_obj(\n",
    "        \"serving_input_fn\",\n",
    "        \"feature_placeholders\",\n",
    "        feature_placeholders\n",
    "    )\n",
    "\n",
    "    # Create clones of the feature placeholder tensors so that the SavedModel\n",
    "    # SignatureDef will point to the placeholder.\n",
    "    features = {\n",
    "        key: tf.identity(\n",
    "            input=value,\n",
    "            name=\"serving_input_fn_identity_placeholder_{}\".format(key)\n",
    "        )\n",
    "        for key, value in feature_placeholders.items()\n",
    "    }\n",
    "\n",
    "    print_obj(\n",
    "        \"serving_input_fn\",\n",
    "        \"features\",\n",
    "        features\n",
    "    )\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features=features, receiver_tensors=feature_placeholders\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(args):\n",
    "    \"\"\"Trains and evaluates custom Estimator model.\n",
    "\n",
    "    Args:\n",
    "        args: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        `Estimator` object.\n",
    "    \"\"\"\n",
    "    # Set logging to be level of INFO.\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    # Create our custom estimator using our model function.\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn=wgan_gp_model,\n",
    "        model_dir=args[\"output_dir\"],\n",
    "        params=args\n",
    "    )\n",
    "\n",
    "    # Create train spec to read in our training data.\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"train_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.TRAIN,\n",
    "            batch_size=args[\"train_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        max_steps=args[\"train_steps\"]\n",
    "    )\n",
    "\n",
    "    # Create exporter to save out the complete model to disk.\n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        name=\"exporter\",\n",
    "        serving_input_receiver_fn=lambda: serving_input_fn(args)\n",
    "    )\n",
    "\n",
    "    # Create eval spec to read in our validation data and export our model.\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"eval_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.EVAL,\n",
    "            batch_size=args[\"eval_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        steps=args[\"eval_steps\"],\n",
    "        start_delay_secs=args[\"start_delay_secs\"],\n",
    "        throttle_secs=args[\"throttle_secs\"],\n",
    "        exporters=exporter\n",
    "    )\n",
    "\n",
    "    # Create train and evaluate loop to train and evaluate our estimator.\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n",
    "\n",
    "    return estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'trained_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f55c305d850>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-4-90b050af9c1b>:87: shuffle_and_repeat (from tensorflow.contrib.data.python.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.shuffle_and_repeat(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/shuffle_ops.py:54: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From <ipython-input-4-90b050af9c1b>:99: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "WARNING:tensorflow:From <ipython-input-4-90b050af9c1b>:107: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "wgan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "wgan_model: mode = train\n",
      "wgan_model: params = {'train_file_pattern': 'data/train.tfrecord', 'eval_file_pattern': 'data/eval.tfrecord', 'output_dir': 'trained_model', 'train_batch_size': 5, 'train_steps': 200, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [8, 8, 256], 'generator_num_filters': [128, 64], 'generator_kernel_sizes': [5, 5], 'generator_strides': [1, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 5, 'generator_final_stride': 2, 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_clip_gradients': 5.0, 'generator_train_steps': 1, 'critic_num_filters': [64, 128], 'critic_kernel_sizes': [5, 5], 'critic_strides': [2, 2], 'critic_dropout_rates': [0.3, 0.3], 'critic_l1_regularization_scale': 0.01, 'critic_l2_regularization_scale': 0.01, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_clip_gradients': 5.0, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "WARNING:tensorflow:From <ipython-input-5-387edcef79f1>:35: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "generator_network: projection = Tensor(\"generator/projection_layer/LeakyRelu:0\", shape=(?, 16384), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-5-387edcef79f1>:46: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "generator_network: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 16384), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 8, 8, 256), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-5-387edcef79f1>:86: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "generator_network: network = Tensor(\"generator/layers_conv2d_tranpose_0/LeakyRelu:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_conv2d_tranpose_1/LeakyRelu:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "generator_network: generated_outputs = Tensor(\"generator/layers_conv2d_tranpose_generated_outputs/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "critic_network: network = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "WARNING:tensorflow:From <ipython-input-6-7c27fe9eeb7b>:42: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "critic_network: network = Tensor(\"critic/layers_conv2d_0/LeakyRelu:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-6-7c27fe9eeb7b>:50: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "critic_network: network = Tensor(\"critic/layers_dropout_0/Identity:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic/layers_conv2d_1/LeakyRelu:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic/layers_dropout_1/Identity:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network_flat = Tensor(\"critic/flatten/Reshape:0\", shape=(?, 8192), dtype=float32)\n",
      "critic_network: logits = Tensor(\"critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "critic_network: network = Tensor(\"generator/layers_conv2d_tranpose_generated_outputs/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic_1/layers_conv2d_0/LeakyRelu:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic_1/layers_dropout_0/Identity:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic_1/layers_conv2d_1/LeakyRelu:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic_1/layers_dropout_1/Identity:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network_flat = Tensor(\"critic_1/flatten/Reshape:0\", shape=(?, 8192), dtype=float32)\n",
      "critic_network: logits = Tensor(\"critic_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_regularization_loss = Tensor(\"generator_regularization_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_critic_loss: critic_real_loss = Tensor(\"critic_real_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_generated_loss = Tensor(\"critic_generated_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_loss = Tensor(\"critic_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"critic/gradient_penalty/random_uniform_num:0\", shape=(?, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"critic/gradient_penalty/sub:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "critic_network: network = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_0/LeakyRelu:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic/gradient_penalty/critic/layers_dropout_0/Identity:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_1/LeakyRelu:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic/gradient_penalty/critic/layers_dropout_1/Identity:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network_flat = Tensor(\"critic/gradient_penalty/critic/flatten/Reshape:0\", shape=(?, 8192), dtype=float32)\n",
      "critic_network: logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"critic/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"critic/gradient_penalty/gradients/critic/gradient_penalty/mixed_loss_grad/Tile:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"critic/gradient_penalty/Sqrt:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"critic/gradient_penalty/squared_difference:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"critic/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_regularization_loss = Tensor(\"critic_regularization_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_total_loss = Tensor(\"critic_total_loss:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 141.33223, step = 1\n",
      "INFO:tensorflow:global_step/sec: 13.7918\n",
      "INFO:tensorflow:loss = 29642.139, step = 101 (7.253 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into trained_model/model.ckpt.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "wgan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "wgan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "wgan_model: mode = eval\n",
      "wgan_model: params = {'train_file_pattern': 'data/train.tfrecord', 'eval_file_pattern': 'data/eval.tfrecord', 'output_dir': 'trained_model', 'train_batch_size': 5, 'train_steps': 200, 'eval_batch_size': 5, 'eval_steps': 10, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_projection_dims': [8, 8, 256], 'generator_num_filters': [128, 64], 'generator_kernel_sizes': [5, 5], 'generator_strides': [1, 2], 'generator_final_num_filters': 3, 'generator_final_kernel_size': 5, 'generator_final_stride': 2, 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_clip_gradients': 5.0, 'generator_train_steps': 1, 'critic_num_filters': [64, 128], 'critic_kernel_sizes': [5, 5], 'critic_strides': [2, 2], 'critic_dropout_rates': [0.3, 0.3], 'critic_l1_regularization_scale': 0.01, 'critic_l2_regularization_scale': 0.01, 'critic_optimizer': 'Adam', 'critic_learning_rate': 0.0001, 'critic_clip_gradients': 5.0, 'critic_gradient_penalty_coefficient': 10.0, 'critic_train_steps': 5}\n",
      "generator_network: projection = Tensor(\"generator/projection_layer/LeakyRelu:0\", shape=(?, 16384), dtype=float32)\n",
      "generator_network: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 16384), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 8, 8, 256), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_conv2d_tranpose_0/LeakyRelu:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_conv2d_tranpose_1/LeakyRelu:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "generator_network: generated_outputs = Tensor(\"generator/layers_conv2d_tranpose_generated_outputs/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "critic_network: network = Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "critic_network: network = Tensor(\"critic/layers_conv2d_0/LeakyRelu:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic/layers_dropout_0/Identity:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic/layers_conv2d_1/LeakyRelu:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic/layers_dropout_1/Identity:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network_flat = Tensor(\"critic/flatten/Reshape:0\", shape=(?, 8192), dtype=float32)\n",
      "critic_network: logits = Tensor(\"critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "critic_network: network = Tensor(\"generator/layers_conv2d_tranpose_generated_outputs/Tanh:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic_1/layers_conv2d_0/LeakyRelu:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic_1/layers_dropout_0/Identity:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic_1/layers_conv2d_1/LeakyRelu:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic_1/layers_dropout_1/Identity:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network_flat = Tensor(\"critic_1/flatten/Reshape:0\", shape=(?, 8192), dtype=float32)\n",
      "critic_network: logits = Tensor(\"critic_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"Neg:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_regularization_loss = Tensor(\"generator_regularization_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_critic_loss: critic_real_loss = Tensor(\"critic_real_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_generated_loss = Tensor(\"critic_generated_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_loss = Tensor(\"critic_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_gradient_penalty_loss: random_uniform_num = Tensor(\"critic/gradient_penalty/random_uniform_num:0\", shape=(?, 1, 1, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: image_difference = Tensor(\"critic/gradient_penalty/sub:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_images = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "critic_network: network = Tensor(\"critic/gradient_penalty/add:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_0/LeakyRelu:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic/gradient_penalty/critic/layers_dropout_0/Identity:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic/gradient_penalty/critic/layers_conv2d_1/LeakyRelu:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network = Tensor(\"critic/gradient_penalty/critic/layers_dropout_1/Identity:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "critic_network: network_flat = Tensor(\"critic/gradient_penalty/critic/flatten/Reshape:0\", shape=(?, 8192), dtype=float32)\n",
      "critic_network: logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_logits = Tensor(\"critic/gradient_penalty/critic/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_loss = Tensor(\"critic/gradient_penalty/mixed_loss:0\", shape=(), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_gradients = Tensor(\"critic/gradient_penalty/gradients/critic/gradient_penalty/mixed_loss_grad/Tile:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "get_gradient_penalty_loss: mixed_norms = Tensor(\"critic/gradient_penalty/Sqrt:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: squared_difference = Tensor(\"critic/gradient_penalty/squared_difference:0\", shape=(?,), dtype=float32)\n",
      "get_gradient_penalty_loss: gradient_penalty = Tensor(\"critic/gradient_penalty/gradient_penalty:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_regularization_loss = Tensor(\"critic_regularization_loss:0\", shape=(), dtype=float32)\n",
      "get_critic_loss: critic_total_loss = Tensor(\"critic_total_loss:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-05T10:06:40Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree(path=arguments[\"output_dir\"], ignore_errors=True)\n",
    "estimator = train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1591351754\n"
     ]
    }
   ],
   "source": [
    "!ls trained_model/export/exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/predictor/saved_model_predictor.py:153: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from trained_model/export/exporter/1591351754/variables/variables\n"
     ]
    }
   ],
   "source": [
    "predict_fn = tf.contrib.predictor.from_saved_model(\n",
    "    \"trained_model/export/exporter/1591351754\"\n",
    ")\n",
    "predictions = predict_fn(\n",
    "    {\n",
    "        \"Z\": np.random.normal(size=(500, 512))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = np.clip(\n",
    "    a=((predictions[\"generated_images\"] + 1.0) * (255. / 2)).astype(np.int32),\n",
    "    a_min=0,\n",
    "    a_max=255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(generated_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(generated_images[i], cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
