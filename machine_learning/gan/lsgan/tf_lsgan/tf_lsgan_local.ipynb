{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18.1\n",
      "1.15.2-dlenv_tfe\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(np.__version__)\n",
    "print(tf.__version__)\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {}\n",
    "# File arguments.\n",
    "arguments[\"train_file_pattern\"] = \"gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord\"\n",
    "arguments[\"eval_file_pattern\"] = \"gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord\"\n",
    "arguments[\"output_dir\"] = \"gs://machine-learning-1234-bucket/gan/lsgan/trained_model\"\n",
    "\n",
    "# Training parameters.\n",
    "arguments[\"train_batch_size\"] = 32\n",
    "arguments[\"train_steps\"] = 40000\n",
    "arguments[\"save_summary_steps\"] = 100\n",
    "arguments[\"save_checkpoints_steps\"] = 5000\n",
    "arguments[\"keep_checkpoint_max\"] = 10\n",
    "arguments[\"input_fn_autotune\"] = False\n",
    "\n",
    "# Eval parameters.\n",
    "arguments[\"eval_batch_size\"] = 16\n",
    "arguments[\"eval_steps\"] = 10\n",
    "arguments[\"start_delay_secs\"] = 6000\n",
    "arguments[\"throttle_secs\"] = 6000\n",
    "\n",
    "# Image parameters.\n",
    "arguments[\"height\"] = 28\n",
    "arguments[\"width\"] = 28\n",
    "arguments[\"depth\"] = 1\n",
    "\n",
    "# Generator parameters.\n",
    "arguments[\"latent_size\"] = 100\n",
    "arguments[\"generator_projection_dims\"] = [7, 7, 256]\n",
    "arguments[\"generator_num_filters\"] = [128, 64, arguments[\"depth\"]]\n",
    "arguments[\"generator_kernel_sizes\"] = [4, 4, 7]\n",
    "arguments[\"generator_strides\"] = [2, 2, 1]\n",
    "arguments[\"generator_use_batch_norm\"] = [True, True]\n",
    "arguments[\"generator_batch_norm_before_act\"] = False\n",
    "arguments[\"generator_use_leaky_relu\"] = False\n",
    "arguments[\"generator_leaky_relu_alpha\"] = 0.2\n",
    "arguments[\"generator_final_activation\"] = \"tanh\"\n",
    "arguments[\"generator_l1_regularization_scale\"] = 0.\n",
    "arguments[\"generator_l2_regularization_scale\"] = 0.\n",
    "arguments[\"generator_optimizer\"] = \"Adam\"\n",
    "arguments[\"generator_learning_rate\"] = 0.0002\n",
    "arguments[\"generator_adam_beta1\"] = 0.5\n",
    "arguments[\"generator_adam_beta2\"] = 0.999\n",
    "arguments[\"generator_adam_epsilon\"] = 1e-8\n",
    "arguments[\"generator_clip_gradients\"] = None\n",
    "arguments[\"generator_train_steps\"] = 1\n",
    "\n",
    "# Discriminator hyperparameters.\n",
    "arguments[\"discriminator_num_filters\"] = [64, 128]\n",
    "arguments[\"discriminator_kernel_sizes\"] = [4, 4]\n",
    "arguments[\"discriminator_strides\"] = [2, 2]\n",
    "arguments[\"discriminator_use_batch_norm\"] = [True, True]\n",
    "arguments[\"discriminator_batch_norm_before_act\"] = False\n",
    "arguments[\"discriminator_use_leaky_relu\"] = True\n",
    "arguments[\"discriminator_leaky_relu_alpha\"] = 0.2\n",
    "arguments[\"discriminator_l1_regularization_scale\"] = 0.\n",
    "arguments[\"discriminator_l2_regularization_scale\"] = 0.\n",
    "arguments[\"discriminator_optimizer\"] = \"Adam\"\n",
    "arguments[\"discriminator_learning_rate\"] = 0.0002\n",
    "arguments[\"discriminator_adam_beta1\"] = 0.5\n",
    "arguments[\"discriminator_adam_beta2\"] = 0.999\n",
    "arguments[\"discriminator_adam_epsilon\"] = 1e-8\n",
    "arguments[\"discriminator_clip_gradients\"] = None\n",
    "arguments[\"discriminator_train_steps\"] = 1\n",
    "\n",
    "# Loss parameters.\n",
    "arguments[\"loss_a\"] = 0.0\n",
    "arguments[\"loss_b\"] = 1.0\n",
    "arguments[\"loss_c\"] = 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print_object.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_obj(function_name, object_name, object_value):\n",
    "    \"\"\"Prints enclosing function, object name, and object value.\n",
    "\n",
    "    Args:\n",
    "        function_name: str, name of function.\n",
    "        object_name: str, name of object.\n",
    "        object_value: object, value of passed object.\n",
    "    \"\"\"\n",
    "#     pass\n",
    "    print(\"{}: {} = {}\".format(function_name, object_name, object_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, params):\n",
    "    \"\"\"Preprocess image tensor.\n",
    "\n",
    "    Args:\n",
    "        image: tensor, input image with shape\n",
    "            [cur_batch_size, height, width, depth].\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Preprocessed image tensor with shape\n",
    "            [cur_batch_size, height, width, depth].\n",
    "    \"\"\"\n",
    "    func_name = \"preprocess_image\"\n",
    "    # Convert from [0, 255] -> [-1.0, 1.0] floats.\n",
    "    image = tf.cast(x=image, dtype=tf.float32) * (2. / 255) - 1.0\n",
    "    print_obj(func_name, \"image\", image)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def resize_fake_images(fake_images, params):\n",
    "    \"\"\"Resizes fake images to match real image sizes.\n",
    "\n",
    "    Args:\n",
    "        fake_images: tensor, fake images from generator.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Resized image tensor.\n",
    "    \"\"\"\n",
    "    func_name = \"resize_real_image\"\n",
    "    print_obj(\"\\n\" + func_name, \"fake_images\", fake_images)\n",
    "\n",
    "    # Resize fake images to match real image sizes.\n",
    "    resized_fake_images = tf.image.resize(\n",
    "        images=fake_images,\n",
    "        size=[params[\"height\"], params[\"width\"]],\n",
    "        method=\"nearest\",\n",
    "        name=\"resized_fake_images\"\n",
    "    )\n",
    "    print_obj(func_name, \"resized_fake_images\", resized_fake_images)\n",
    "\n",
    "    return resized_fake_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_example(protos, params):\n",
    "    \"\"\"Decodes TFRecord file into tensors.\n",
    "\n",
    "    Given protobufs, decode into image and label tensors.\n",
    "\n",
    "    Args:\n",
    "        protos: protobufs from TFRecord file.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Image and label tensors.\n",
    "    \"\"\"\n",
    "    func_name = \"decode_example\"\n",
    "    # Create feature schema map for protos.\n",
    "    features = {\n",
    "        \"image_raw\": tf.FixedLenFeature(shape=[], dtype=tf.string),\n",
    "        \"label\": tf.FixedLenFeature(shape=[], dtype=tf.int64)\n",
    "    }\n",
    "\n",
    "    # Parse features from tf.Example.\n",
    "    parsed_features = tf.parse_single_example(\n",
    "        serialized=protos, features=features\n",
    "    )\n",
    "    print_obj(\"\\n\" + func_name, \"features\", features)\n",
    "\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length height * width * depth) to a uint8 tensor with shape\n",
    "    # [height * width * depth].\n",
    "    image = tf.decode_raw(\n",
    "        input_bytes=parsed_features[\"image_raw\"], out_type=tf.uint8\n",
    "    )\n",
    "    print_obj(func_name, \"image\", image)\n",
    "\n",
    "    # Reshape flattened image back into normal dimensions.\n",
    "    image = tf.reshape(\n",
    "        tensor=image,\n",
    "        shape=[params[\"height\"], params[\"width\"], params[\"depth\"]]\n",
    "    )\n",
    "    print_obj(func_name, \"image\", image)\n",
    "\n",
    "    # Preprocess image.\n",
    "    image = preprocess_image(image=image, params=params)\n",
    "    print_obj(func_name, \"image\", image)\n",
    "\n",
    "    # Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "    label = tf.cast(x=parsed_features[\"label\"], dtype=tf.int32)\n",
    "    print_obj(func_name, \"label\", label)\n",
    "\n",
    "    return {\"image\": image}, label\n",
    "\n",
    "\n",
    "def read_dataset(filename, mode, batch_size, params):\n",
    "    \"\"\"Reads TF Record data using tf.data, doing necessary preprocessing.\n",
    "\n",
    "    Given filename, mode, batch size, and other parameters, read TF Record\n",
    "    dataset using Dataset API, apply necessary preprocessing, and return an\n",
    "    input function to the Estimator API.\n",
    "\n",
    "    Args:\n",
    "        filename: str, file pattern that to read into our tf.data dataset.\n",
    "        mode: The estimator ModeKeys. Can be TRAIN or EVAL.\n",
    "        batch_size: int, number of examples per batch.\n",
    "        params: dict, dictionary of user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        An input function.\n",
    "    \"\"\"\n",
    "    def _input_fn():\n",
    "        \"\"\"Wrapper input function used by Estimator API to get data tensors.\n",
    "\n",
    "        Returns:\n",
    "            Batched dataset object of dictionary of feature tensors and label\n",
    "                tensor.\n",
    "        \"\"\"\n",
    "        # Create list of files that match pattern.\n",
    "        file_list = tf.gfile.Glob(filename=filename)\n",
    "\n",
    "        # Create dataset from file list.\n",
    "        if params[\"input_fn_autotune\"]:\n",
    "            dataset = tf.data.TFRecordDataset(\n",
    "                filenames=file_list,\n",
    "                num_parallel_reads=tf.contrib.data.AUTOTUNE\n",
    "            )\n",
    "        else:\n",
    "            dataset = tf.data.TFRecordDataset(filenames=file_list)\n",
    "\n",
    "        # Shuffle and repeat if training with fused op.\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            dataset = dataset.apply(\n",
    "                tf.contrib.data.shuffle_and_repeat(\n",
    "                    buffer_size=50 * batch_size,\n",
    "                    count=None  # indefinitely\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Decode CSV file into a features dictionary of tensors, then batch.\n",
    "        if params[\"input_fn_autotune\"]:\n",
    "            dataset = dataset.apply(\n",
    "                tf.contrib.data.map_and_batch(\n",
    "                    map_func=lambda x: decode_example(\n",
    "                        protos=x,\n",
    "                        params=params\n",
    "                    ),\n",
    "                    batch_size=batch_size,\n",
    "                    num_parallel_calls=tf.contrib.data.AUTOTUNE\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            dataset = dataset.apply(\n",
    "                tf.contrib.data.map_and_batch(\n",
    "                    map_func=lambda x: decode_example(\n",
    "                        protos=x,\n",
    "                        params=params\n",
    "                    ),\n",
    "                    batch_size=batch_size\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Prefetch data to improve latency.\n",
    "        if params[\"input_fn_autotune\"]:\n",
    "            dataset = dataset.prefetch(buffer_size=tf.contrib.data.AUTOTUNE)\n",
    "        else:\n",
    "            dataset = dataset.prefetch(buffer_size=1)\n",
    "\n",
    "        # Create a iterator, then get batch of features from example queue.\n",
    "        batched_dataset = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        return batched_dataset\n",
    "    return _input_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(object):\n",
    "    \"\"\"Generator that takes latent vector input and outputs image.\n",
    "    Fields:\n",
    "        name: str, name of `Generator`.\n",
    "        kernel_regularizer: `l1_l2_regularizer` object, regularizar for kernel\n",
    "            variables.\n",
    "        bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "            variables.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_regularizer, bias_regularizer, name):\n",
    "        \"\"\"Instantiates and builds generator network.\n",
    "        Args:\n",
    "            kernel_regularizer: `l1_l2_regularizer` object, regularizar for\n",
    "                kernel variables.\n",
    "            bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "                variables.\n",
    "            name: str, name of generator.\n",
    "        \"\"\"\n",
    "        # Set name of generator.\n",
    "        self.name = name\n",
    "\n",
    "        # Regularizer for kernel weights.\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "\n",
    "        # Regularizer for bias weights.\n",
    "        self.bias_regularizer = bias_regularizer\n",
    "\n",
    "    def get_fake_images(self, Z, mode, params):\n",
    "        \"\"\"Creates generator network and returns generated images.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            mode: tf.estimator.ModeKeys with values of either TRAIN, EVAL, or\n",
    "                PREDICT.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Generated image tensor of shape\n",
    "                [cur_batch_size, height, width, depth].\n",
    "        \"\"\"\n",
    "        func_name = \"get_fake_images\"\n",
    "        # Create the input layer to our CNN.\n",
    "        # shape = (cur_batch_size, latent_size)\n",
    "        network = Z\n",
    "        print_obj(\"\\n\" + func_name, \"network\", network)\n",
    "\n",
    "        # Dictionary containing possible final activations.\n",
    "        final_activation_dict = {\n",
    "            \"sigmoid\": tf.nn.sigmoid, \"relu\": tf.nn.relu, \"tanh\": tf.nn.tanh\n",
    "        }\n",
    "\n",
    "        with tf.variable_scope(\"generator\", reuse=tf.AUTO_REUSE):\n",
    "            # Project latent vectors.\n",
    "            projection_height = params[\"generator_projection_dims\"][0]\n",
    "            projection_width = params[\"generator_projection_dims\"][1]\n",
    "            projection_depth = params[\"generator_projection_dims\"][2]\n",
    "\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     projection_height * projection_width * projection_depth\n",
    "            # )\n",
    "            projection = tf.layers.dense(\n",
    "                inputs=Z,\n",
    "                units=projection_height * projection_width * projection_depth,\n",
    "                activation=None,\n",
    "                kernel_regularizer=self.kernel_regularizer,\n",
    "                bias_regularizer=self.bias_regularizer,\n",
    "                name=\"projection_dense_layer\"\n",
    "            )\n",
    "            print_obj(func_name, \"projection\", projection)\n",
    "\n",
    "            if params[\"generator_use_leaky_relu\"]:\n",
    "                projection_activation = tf.nn.leaky_relu(\n",
    "                    features=projection,\n",
    "                    alpha=params[\"generator_leaky_relu_alpha\"],\n",
    "                    name=\"projection_leaky_relu\"\n",
    "                )\n",
    "            else:\n",
    "                projection_activation = tf.nn.relu(\n",
    "                    features=projection,\n",
    "                    name=\"projection_relu\"\n",
    "                )\n",
    "            print_obj(\n",
    "                func_name, \"projection_activation\", projection_activation\n",
    "            )\n",
    "\n",
    "            # Add batch normalization to keep the inputs from blowing up.\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     projection_height * projection_width * projection_depth\n",
    "            # )\n",
    "            projection_batch_norm = tf.layers.batch_normalization(\n",
    "                inputs=projection_activation,\n",
    "                training=(mode == tf.estimator.ModeKeys.TRAIN),\n",
    "                name=\"projection_batch_norm\"\n",
    "            )\n",
    "            print_obj(\n",
    "                func_name, \"projection_batch_norm\", projection_batch_norm\n",
    "            )\n",
    "\n",
    "            # Reshape projection into \"image\".\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     projection_height,\n",
    "            #     projection_width,\n",
    "            #     projection_depth\n",
    "            # )\n",
    "            network = tf.reshape(\n",
    "                tensor=projection_batch_norm,\n",
    "                shape=[\n",
    "                    -1, projection_height, projection_width, projection_depth\n",
    "                ],\n",
    "                name=\"projection_reshaped\"\n",
    "            )\n",
    "            print_obj(func_name, \"network\", network)\n",
    "\n",
    "            # Iteratively build upsampling layers.\n",
    "            for i in range(len(params[\"generator_num_filters\"]) - 1):\n",
    "                # Add conv transpose layers with given params per layer.\n",
    "                # shape = (\n",
    "                #     cur_batch_size,\n",
    "                #     generator_kernel_sizes[i - 1] * generator_strides[i],\n",
    "                #     generator_kernel_sizes[i - 1] * generator_strides[i],\n",
    "                #     generator_num_filters[i]\n",
    "                # )\n",
    "                network = tf.layers.conv2d_transpose(\n",
    "                    inputs=network,\n",
    "                    filters=params[\"generator_num_filters\"][i],\n",
    "                    kernel_size=params[\"generator_kernel_sizes\"][i],\n",
    "                    strides=params[\"generator_strides\"][i],\n",
    "                    padding=\"same\",\n",
    "                    activation=None,\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"layers_conv2d_tranpose_{}\".format(i)\n",
    "                )\n",
    "                print_obj(func_name, \"network\", network)\n",
    "\n",
    "                if params[\"generator_use_batch_norm\"][i]:\n",
    "                    # Add batch normalization to keep inputs from blowing up.\n",
    "                    if params[\"generator_batch_norm_before_act\"]:\n",
    "                        network = tf.layers.batch_normalization(\n",
    "                            inputs=network,\n",
    "                            training=(mode == tf.estimator.ModeKeys.TRAIN),\n",
    "                            name=\"layers_batch_norm_{}\".format(i)\n",
    "                        )\n",
    "                        print_obj(func_name, \"network\", network)\n",
    "\n",
    "                if params[\"generator_use_leaky_relu\"]:\n",
    "                    network = tf.nn.leaky_relu(\n",
    "                        features=network,\n",
    "                        alpha=params[\"generator_leaky_relu_alpha\"],\n",
    "                        name=\"leaky_relu_{}\".format(i)\n",
    "                    )\n",
    "                else:\n",
    "                    network = tf.nn.relu(\n",
    "                        features=network,\n",
    "                        name=\"relu_{}\".format(i)\n",
    "                    )\n",
    "                print_obj(func_name, \"network\", network)\n",
    "\n",
    "                if params[\"generator_use_batch_norm\"][i]:\n",
    "                    # Add batch normalization to keep inputs from blowing up.\n",
    "                    if not params[\"generator_batch_norm_before_act\"]:\n",
    "                        network = tf.layers.batch_normalization(\n",
    "                            inputs=network,\n",
    "                            training=(mode == tf.estimator.ModeKeys.TRAIN),\n",
    "                            name=\"layers_batch_norm_{}\".format(i)\n",
    "                        )\n",
    "                        print_obj(func_name, \"network\", network)\n",
    "\n",
    "            # Final conv2d transpose layer for image output.\n",
    "            # shape = (cur_batch_size, height, width, depth)\n",
    "            fake_images = tf.layers.conv2d_transpose(\n",
    "                inputs=network,\n",
    "                filters=params[\"generator_num_filters\"][-1],\n",
    "                kernel_size=params[\"generator_kernel_sizes\"][-1],\n",
    "                strides=params[\"generator_strides\"][-1],\n",
    "                padding=\"same\",\n",
    "                activation=final_activation_dict.get(\n",
    "                    params[\"generator_final_activation\"].lower(), None\n",
    "                ),\n",
    "                kernel_regularizer=self.kernel_regularizer,\n",
    "                bias_regularizer=self.bias_regularizer,\n",
    "                name=\"layers_conv2d_tranpose_fake_images\"\n",
    "            )\n",
    "            print_obj(func_name, \"fake_images\", fake_images)\n",
    "\n",
    "        return fake_images\n",
    "\n",
    "    def get_generator_loss(self, fake_logits, params):\n",
    "        \"\"\"Gets generator loss.\n",
    "\n",
    "        Args:\n",
    "            fake_logits: tensor, shape of\n",
    "                [cur_batch_size, 1].\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of generator's total loss of shape [].\n",
    "        \"\"\"\n",
    "        func_name = \"get_generator_loss\"\n",
    "        # Calculate base generator loss.\n",
    "        generator_loss = tf.losses.mean_squared_error(\n",
    "            labels=tf.ones_like(tensor=fake_logits) * params[\"loss_c\"],\n",
    "            predictions=fake_logits\n",
    "        )\n",
    "        print_obj(\"\\n\" + func_name, \"generator_loss\", generator_loss)\n",
    "\n",
    "        # Get regularization losses.\n",
    "        generator_reg_loss = tf.losses.get_regularization_loss(\n",
    "            scope=\"generator\",\n",
    "            name=\"generator_regularization_loss\"\n",
    "        )\n",
    "        print_obj(func_name, \"generator_reg_loss\", generator_reg_loss)\n",
    "\n",
    "        # Combine losses for total losses.\n",
    "        generator_total_loss = tf.math.add(\n",
    "            x=generator_loss,\n",
    "            y=generator_reg_loss,\n",
    "            name=\"generator_total_loss\"\n",
    "        )\n",
    "        print_obj(func_name, \"generator_total_loss\", generator_total_loss)\n",
    "\n",
    "        # Add summaries for TensorBoard.\n",
    "        tf.summary.scalar(\n",
    "            name=\"generator_loss\", tensor=generator_loss, family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"generator_reg_loss\",\n",
    "            tensor=generator_reg_loss,\n",
    "            family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"generator_total_loss\",\n",
    "            tensor=generator_total_loss,\n",
    "            family=\"total_losses\"\n",
    "        )\n",
    "\n",
    "        return generator_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## discriminator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(object):\n",
    "    \"\"\"Discriminator that takes image input and outputs logits.\n",
    "    Fields:\n",
    "        name: str, name of `Discriminator`.\n",
    "        kernel_regularizer: `l1_l2_regularizer` object, regularizar for kernel\n",
    "            variables.\n",
    "        bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "            variables.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_regularizer, bias_regularizer, name):\n",
    "        \"\"\"Instantiates and builds discriminator network.\n",
    "        Args:\n",
    "            kernel_regularizer: `l1_l2_regularizer` object, regularizar for\n",
    "                kernel variables.\n",
    "            bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "                variables.\n",
    "            name: str, name of discriminator.\n",
    "        \"\"\"\n",
    "        # Set name of discriminator.\n",
    "        self.name = name\n",
    "\n",
    "        # Regularizer for kernel weights.\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "\n",
    "        # Regularizer for bias weights.\n",
    "        self.bias_regularizer = bias_regularizer\n",
    "\n",
    "    def get_discriminator_logits(self, X, mode, params):\n",
    "        \"\"\"Creates discriminator network and returns logits.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, image tensors of shape\n",
    "                [cur_batch_size, height, width, depth].\n",
    "            mode: tf.estimator.ModeKeys with values of either TRAIN, EVAL, or\n",
    "                PREDICT.\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Logits tensor of shape [cur_batch_size, 1].\n",
    "        \"\"\"\n",
    "        func_name = \"get_discriminator_logits\"\n",
    "        # Create the input layer to our CNN.\n",
    "        # shape = (cur_batch_size, height * width * depth)\n",
    "        network = X\n",
    "        print_obj(\"\\n\" + func_name, \"network\", network)\n",
    "\n",
    "        with tf.variable_scope(\"discriminator\", reuse=tf.AUTO_REUSE):\n",
    "            # Iteratively build downsampling layers.\n",
    "            for i in range(len(params[\"discriminator_num_filters\"])):\n",
    "                # Add convolutional layers with given params per layer.\n",
    "                # shape = (\n",
    "                #     cur_batch_size,\n",
    "                #     discriminator_kernel_sizes[i - 1] / discriminator_strides[i],\n",
    "                #     discriminator_kernel_sizes[i - 1] / discriminator_strides[i],\n",
    "                #     discriminator_num_filters[i]\n",
    "                # )\n",
    "                network = tf.layers.conv2d(\n",
    "                    inputs=network,\n",
    "                    filters=params[\"discriminator_num_filters\"][i],\n",
    "                    kernel_size=params[\"discriminator_kernel_sizes\"][i],\n",
    "                    strides=params[\"discriminator_strides\"][i],\n",
    "                    padding=\"same\",\n",
    "                    activation=None,\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"layers_conv2d_{}\".format(i)\n",
    "                )\n",
    "                print_obj(func_name, \"network\", network)\n",
    "\n",
    "                if params[\"discriminator_use_batch_norm\"][i]:\n",
    "                    # Add batch normalization to keep inputs from blowing up.\n",
    "                    if params[\"discriminator_batch_norm_before_act\"]:\n",
    "                        network = tf.layers.batch_normalization(\n",
    "                            inputs=network,\n",
    "                            training=(mode == tf.estimator.ModeKeys.TRAIN),\n",
    "                            name=\"layers_batch_norm_{}\".format(i)\n",
    "                        )\n",
    "                        print_obj(func_name, \"network\", network)\n",
    "\n",
    "                if params[\"discriminator_use_leaky_relu\"]:\n",
    "                    network = tf.nn.leaky_relu(\n",
    "                        features=network,\n",
    "                        alpha=params[\"discriminator_leaky_relu_alpha\"],\n",
    "                        name=\"leaky_relu_{}\".format(i)\n",
    "                    )\n",
    "                else:\n",
    "                    network = tf.nn.relu(\n",
    "                        features=network,\n",
    "                        name=\"relu_{}\".format(i)\n",
    "                    )\n",
    "                print_obj(func_name, \"network\", network)\n",
    "\n",
    "                if params[\"discriminator_use_batch_norm\"][i]:\n",
    "                    # Add batch normalization to keep inputs from blowing up.\n",
    "                    if not params[\"discriminator_batch_norm_before_act\"]:\n",
    "                        network = tf.layers.batch_normalization(\n",
    "                            inputs=network,\n",
    "                            training=(mode == tf.estimator.ModeKeys.TRAIN),\n",
    "                            name=\"layers_batch_norm_{}\".format(i)\n",
    "                        )\n",
    "                        print_obj(func_name, \"network\", network)\n",
    "\n",
    "            # Flatten network output.\n",
    "            # shape = (\n",
    "            #     cur_batch_size,\n",
    "            #     (discriminator_kernel_sizes[-2] / discriminator_strides[-1]) ** 2 * discriminator_num_filters[-1]\n",
    "            # )\n",
    "            network_flat = tf.layers.Flatten()(inputs=network)\n",
    "            print_obj(func_name, \"network_flat\", network_flat)\n",
    "\n",
    "            # Final linear layer for logits.\n",
    "            # shape = (cur_batch_size, 1)\n",
    "            logits = tf.layers.dense(\n",
    "                inputs=network_flat,\n",
    "                units=1,\n",
    "                activation=None,\n",
    "                kernel_regularizer=self.kernel_regularizer,\n",
    "                bias_regularizer=self.bias_regularizer,\n",
    "                name=\"layers_dense_logits\"\n",
    "            )\n",
    "            print_obj(func_name, \"logits\", logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def get_discriminator_loss(self, fake_logits, real_logits, params):\n",
    "        \"\"\"Gets discriminator loss.\n",
    "\n",
    "        Args:\n",
    "            fake_logits: tensor, shape of [cur_batch_size, 1].\n",
    "            real_logits: tensor, shape of [cur_batch_size, 1].\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of discriminator's total loss of shape [].\n",
    "        \"\"\"\n",
    "        func_name = \"get_discriminator_loss\"\n",
    "        # Calculate base discriminator loss.\n",
    "        discriminator_real_loss = tf.losses.mean_squared_error(\n",
    "            labels=tf.ones_like(tensor=real_logits) * params[\"loss_b\"],\n",
    "            predictions=real_logits\n",
    "        )\n",
    "        print_obj(\n",
    "            \"\\n\" + func_name,\n",
    "            \"discriminator_real_loss\",\n",
    "            discriminator_real_loss\n",
    "        )\n",
    "\n",
    "        discriminator_fake_loss = tf.losses.mean_squared_error(\n",
    "            labels=tf.ones_like(tensor=fake_logits) * params[\"loss_a\"],\n",
    "            predictions=fake_logits\n",
    "        )\n",
    "        print_obj(\n",
    "            func_name, \"discriminator_fake_loss\", discriminator_fake_loss\n",
    "        )\n",
    "\n",
    "        discriminator_loss = tf.add(\n",
    "            x=discriminator_real_loss,\n",
    "            y=discriminator_fake_loss,\n",
    "            name=\"discriminator_loss\"\n",
    "        )\n",
    "        print_obj(func_name, \"discriminator_loss\", discriminator_loss)\n",
    "\n",
    "        # Get regularization losses.\n",
    "        discriminator_reg_loss = tf.losses.get_regularization_loss(\n",
    "            scope=\"discriminator\",\n",
    "            name=\"discriminator_reg_loss\"\n",
    "        )\n",
    "        print_obj(func_name, \"discriminator_reg_loss\", discriminator_reg_loss)\n",
    "\n",
    "        # Combine losses for total losses.\n",
    "        discriminator_total_loss = tf.math.add(\n",
    "            x=discriminator_loss,\n",
    "            y=discriminator_reg_loss,\n",
    "            name=\"discriminator_total_loss\"\n",
    "        )\n",
    "        print_obj(\n",
    "            func_name, \"discriminator_total_loss\", discriminator_total_loss\n",
    "        )\n",
    "\n",
    "        # Add summaries for TensorBoard.\n",
    "        tf.summary.scalar(\n",
    "            name=\"discriminator_real_loss\",\n",
    "            tensor=discriminator_real_loss,\n",
    "            family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"discriminator_fake_loss\",\n",
    "            tensor=discriminator_fake_loss,\n",
    "            family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"discriminator_loss\",\n",
    "            tensor=discriminator_loss,\n",
    "            family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"discriminator_reg_loss\",\n",
    "            tensor=discriminator_reg_loss,\n",
    "            family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"discriminator_total_loss\",\n",
    "            tensor=discriminator_total_loss,\n",
    "            family=\"total_losses\"\n",
    "        )\n",
    "\n",
    "        return discriminator_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_and_eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits_and_losses(features, generator, discriminator, mode, params):\n",
    "    \"\"\"Gets logits and losses for both train and eval modes.\n",
    "\n",
    "    Args:\n",
    "        features: dict, feature tensors from input function.\n",
    "        generator: instance of generator.`Generator`.\n",
    "        discriminator: instance of discriminator.`Discriminator`.\n",
    "        mode: tf.estimator.ModeKeys with values of either TRAIN or EVAL.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Real and fake logits and generator and discriminator losses.\n",
    "    \"\"\"\n",
    "    func_name = \"get_logits_and_losses\"\n",
    "    # Extract real images from features dictionary.\n",
    "    real_images = features[\"image\"]\n",
    "    print_obj(\"\\n\" + func_name, \"real_images\", real_images)\n",
    "\n",
    "    # Get dynamic batch size in case of partial batch.\n",
    "    cur_batch_size = tf.shape(\n",
    "        input=real_images,\n",
    "        out_type=tf.int32,\n",
    "        name=\"{}_cur_batch_size\".format(func_name)\n",
    "    )[0]\n",
    "\n",
    "    # Create random noise latent vector for each batch example.\n",
    "    Z = tf.random.normal(\n",
    "        shape=[cur_batch_size, params[\"latent_size\"]],\n",
    "        mean=0.0,\n",
    "        stddev=1.0,\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "    print_obj(func_name, \"Z\", Z)\n",
    "\n",
    "    # Get generated image from generator network from gaussian noise.\n",
    "    print(\"\\nCall generator with Z = {}.\".format(Z))\n",
    "    fake_images = generator.get_fake_images(Z=Z, mode=mode, params=params)\n",
    "\n",
    "    # Resize fake images to match real image sizes.\n",
    "    fake_images = resize_fake_images(fake_images, params)\n",
    "    print_obj(func_name, \"fake_images\", fake_images)\n",
    "\n",
    "    # Add summaries for TensorBoard.\n",
    "    tf.summary.image(\n",
    "        name=\"fake_images\",\n",
    "        tensor=tf.reshape(\n",
    "            tensor=fake_images,\n",
    "            shape=[-1, params[\"height\"], params[\"width\"], params[\"depth\"]]\n",
    "        ),\n",
    "        max_outputs=5,\n",
    "    )\n",
    "\n",
    "    # Get fake logits from discriminator using generator's output image.\n",
    "    print(\"\\nCall discriminator with fake_images = {}.\".format(fake_images))\n",
    "    fake_logits = discriminator.get_discriminator_logits(\n",
    "        X=fake_images, mode=mode, params=params\n",
    "    )\n",
    "\n",
    "    # Get real logits from discriminator using real image.\n",
    "    print(\n",
    "        \"\\nCall discriminator with real_images = {}.\".format(real_images)\n",
    "    )\n",
    "    real_logits = discriminator.get_discriminator_logits(\n",
    "        X=real_images, mode=mode, params=params\n",
    "    )\n",
    "\n",
    "    # Get generator total loss.\n",
    "    generator_total_loss = generator.get_generator_loss(\n",
    "        fake_logits=fake_logits, params=params\n",
    "    )\n",
    "\n",
    "    # Get discriminator total loss.\n",
    "    discriminator_total_loss = discriminator.get_discriminator_loss(\n",
    "        fake_logits=fake_logits, real_logits=real_logits, params=params\n",
    "    )\n",
    "\n",
    "    return (real_logits,\n",
    "            fake_logits,\n",
    "            generator_total_loss,\n",
    "            discriminator_total_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variables_and_gradients(loss, scope):\n",
    "    \"\"\"Gets variables and their gradients wrt. loss.\n",
    "    Args:\n",
    "        loss: tensor, shape of [].\n",
    "        scope: str, the network's name to find its variables to train.\n",
    "    Returns:\n",
    "        Lists of variables and their gradients.\n",
    "    \"\"\"\n",
    "    func_name = \"get_variables_and_gradients\"\n",
    "    # Get trainable variables.\n",
    "    variables = tf.trainable_variables(scope=scope)\n",
    "    print_obj(\"\\n{}_{}\".format(func_name, scope), \"variables\", variables)\n",
    "\n",
    "    # Get gradients.\n",
    "    gradients = tf.gradients(\n",
    "        ys=loss,\n",
    "        xs=variables,\n",
    "        name=\"{}_gradients\".format(scope)\n",
    "    )\n",
    "    print_obj(\"\\n{}_{}\".format(func_name, scope), \"gradients\", gradients)\n",
    "\n",
    "    # Add variable names back in for identification.\n",
    "    gradients = [\n",
    "        tf.identity(\n",
    "            input=g,\n",
    "            name=\"{}_{}_gradients\".format(func_name, v.name[:-2])\n",
    "        )\n",
    "        if tf.is_tensor(x=g) else g\n",
    "        for g, v in zip(gradients, variables)\n",
    "    ]\n",
    "    print_obj(\"\\n{}_{}\".format(func_name, scope), \"gradients\", gradients)\n",
    "\n",
    "    return variables, gradients\n",
    "\n",
    "\n",
    "def create_variable_and_gradient_histogram_summaries(loss_dict, params):\n",
    "    \"\"\"Creates variable and gradient histogram summaries.\n",
    "    Args:\n",
    "        loss_dict: dict, keys are scopes and values are scalar loss tensors\n",
    "            for each network kind.\n",
    "        params: dict, user passed parameters.\n",
    "    \"\"\"\n",
    "    for scope, loss in loss_dict.items():\n",
    "        # Get variables and their gradients wrt. loss.\n",
    "        variables, gradients = get_variables_and_gradients(loss, scope)\n",
    "\n",
    "        # Add summaries for TensorBoard.\n",
    "        for g, v in zip(gradients, variables):\n",
    "            tf.summary.histogram(\n",
    "                name=\"{}\".format(v.name[:-2]),\n",
    "                values=v,\n",
    "                family=\"{}_variables\".format(scope)\n",
    "            )\n",
    "            if tf.is_tensor(x=g):\n",
    "                tf.summary.histogram(\n",
    "                    name=\"{}\".format(v.name[:-2]),\n",
    "                    values=g,\n",
    "                    family=\"{}_gradients\".format(scope)\n",
    "                )\n",
    "\n",
    "\n",
    "def train_network(loss, global_step, params, scope):\n",
    "    \"\"\"Trains network and returns loss and train op.\n",
    "\n",
    "    Args:\n",
    "        loss: tensor, shape of [].\n",
    "        global_step: tensor, the current training step or batch in the\n",
    "            training loop.\n",
    "        params: dict, user passed parameters.\n",
    "        scope: str, the variables that to train.\n",
    "\n",
    "    Returns:\n",
    "        Loss tensor and training op.\n",
    "    \"\"\"\n",
    "    func_name = \"train_network\"\n",
    "    print_obj(\"\\n\" + func_name, \"scope\", scope)\n",
    "    # Create optimizer map.\n",
    "    optimizers = {\n",
    "        \"Adam\": tf.train.AdamOptimizer,\n",
    "        \"Adadelta\": tf.train.AdadeltaOptimizer,\n",
    "        \"AdagradDA\": tf.train.AdagradDAOptimizer,\n",
    "        \"Adagrad\": tf.train.AdagradOptimizer,\n",
    "        \"Ftrl\": tf.train.FtrlOptimizer,\n",
    "        \"GradientDescent\": tf.train.GradientDescentOptimizer,\n",
    "        \"Momentum\": tf.train.MomentumOptimizer,\n",
    "        \"ProximalAdagrad\": tf.train.ProximalAdagradOptimizer,\n",
    "        \"ProximalGradientDescent\": tf.train.ProximalGradientDescentOptimizer,\n",
    "        \"RMSProp\": tf.train.RMSPropOptimizer\n",
    "    }\n",
    "\n",
    "    # Get optimizer and instantiate it.\n",
    "    if params[\"{}_optimizer\".format(scope)] == \"Adam\":\n",
    "        optimizer = optimizers[params[\"{}_optimizer\".format(scope)]](\n",
    "            learning_rate=params[\"{}_learning_rate\".format(scope)],\n",
    "            beta1=params[\"{}_adam_beta1\".format(scope)],\n",
    "            beta2=params[\"{}_adam_beta2\".format(scope)],\n",
    "            epsilon=params[\"{}_adam_epsilon\".format(scope)],\n",
    "            name=\"{}_{}_optimizer\".format(\n",
    "                scope, params[\"{}_optimizer\".format(scope)].lower()\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        optimizer = optimizers[params[\"{}_optimizer\".format(scope)]](\n",
    "            learning_rate=params[\"{}_learning_rate\".format(scope)],\n",
    "            name=\"{}_{}_optimizer\".format(\n",
    "                scope, params[\"{}_optimizer\".format(scope)].lower()\n",
    "            )\n",
    "        )\n",
    "    print_obj(\"{}_{}\".format(func_name, scope), \"optimizer\", optimizer)\n",
    "\n",
    "    # Get gradients.\n",
    "    gradients = tf.gradients(\n",
    "        ys=loss,\n",
    "        xs=tf.trainable_variables(scope=scope),\n",
    "        name=\"{}_gradients\".format(scope)\n",
    "    )\n",
    "    print_obj(\"\\n{}_{}\".format(func_name, scope), \"gradients\", gradients)\n",
    "\n",
    "    # Clip gradients.\n",
    "    if params[\"{}_clip_gradients\".format(scope)]:\n",
    "        gradients, _ = tf.clip_by_global_norm(\n",
    "            t_list=gradients,\n",
    "            clip_norm=params[\"{}_clip_gradients\".format(scope)],\n",
    "            name=\"{}_clip_by_global_norm_gradients\".format(scope)\n",
    "        )\n",
    "        print_obj(\"\\n{}_{}\".format(func_name, scope), \"gradients\", gradients)\n",
    "\n",
    "    # Zip back together gradients and variables.\n",
    "    grads_and_vars = zip(gradients, tf.trainable_variables(scope=scope))\n",
    "    print_obj(\n",
    "        \"{}_{}\".format(func_name, scope), \"grads_and_vars\", grads_and_vars\n",
    "    )\n",
    "\n",
    "    # Create train op by applying gradients to variables and incrementing\n",
    "    # global step.\n",
    "    train_op = optimizer.apply_gradients(\n",
    "        grads_and_vars=grads_and_vars,\n",
    "        global_step=global_step,\n",
    "        name=\"{}_apply_gradients\".format(scope)\n",
    "    )\n",
    "\n",
    "    return loss, train_op\n",
    "\n",
    "\n",
    "def get_loss_and_train_op(\n",
    "        generator_total_loss, discriminator_total_loss, params):\n",
    "    \"\"\"Gets loss and train op for train mode.\n",
    "    Args:\n",
    "        generator_total_loss: tensor, scalar total loss of generator.\n",
    "        discriminator_total_loss: tensor, scalar total loss of discriminator.\n",
    "        params: dict, user passed parameters.\n",
    "    Returns:\n",
    "        Loss scalar tensor and train_op to be used by the EstimatorSpec.\n",
    "    \"\"\"\n",
    "    func_name = \"get_loss_and_train_op\"\n",
    "    # Get global step.\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    # Determine if it is time to train generator or discriminator.\n",
    "    cycle_step = tf.mod(\n",
    "        x=global_step,\n",
    "        y=tf.cast(\n",
    "            x=tf.add(\n",
    "                x=params[\"discriminator_train_steps\"],\n",
    "                y=params[\"generator_train_steps\"]\n",
    "            ),\n",
    "            dtype=tf.int64\n",
    "        ),\n",
    "        name=\"{}_cycle_step\".format(func_name)\n",
    "    )\n",
    "\n",
    "    # Create choose discriminator condition.\n",
    "    condition = tf.less(\n",
    "        x=cycle_step, y=params[\"discriminator_train_steps\"]\n",
    "    )\n",
    "\n",
    "    # Needed for batch normalization, but has no effect otherwise.\n",
    "    update_ops = tf.get_collection(key=tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "    # Ensure update ops get updated.\n",
    "    with tf.control_dependencies(control_inputs=update_ops):\n",
    "        # Conditionally choose to train generator or discriminator subgraph.\n",
    "        loss, train_op = tf.cond(\n",
    "            pred=condition,\n",
    "            true_fn=lambda: train_network(\n",
    "                loss=discriminator_total_loss,\n",
    "                global_step=global_step,\n",
    "                params=params,\n",
    "                scope=\"discriminator\"\n",
    "            ),\n",
    "            false_fn=lambda: train_network(\n",
    "                loss=generator_total_loss,\n",
    "                global_step=global_step,\n",
    "                params=params,\n",
    "                scope=\"generator\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return loss, train_op\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval_metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metric_ops(fake_logits, real_logits, params):\n",
    "    \"\"\"Gets eval metric ops.\n",
    "\n",
    "    Args:\n",
    "        fake_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "            discriminator having processed generator's output image.\n",
    "        real_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "            discriminator having processed real image.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of eval metric ops.\n",
    "    \"\"\"\n",
    "    func_name = \"get_eval_metric_ops\"\n",
    "    # Concatenate discriminator logits and labels.\n",
    "    discriminator_logits = tf.concat(\n",
    "        values=[real_logits, fake_logits],\n",
    "        axis=0,\n",
    "        name=\"discriminator_concat_logits\"\n",
    "    )\n",
    "    print_obj(\"\\n\" + func_name, \"discriminator_logits\", discriminator_logits)\n",
    "\n",
    "    discriminator_labels = tf.concat(\n",
    "        values=[\n",
    "            tf.ones_like(tensor=real_logits) * params[\"loss_b\"],\n",
    "            tf.ones_like(tensor=real_logits) * params[\"loss_a\"]\n",
    "        ],\n",
    "        axis=0,\n",
    "        name=\"discriminator_concat_labels\"\n",
    "    )\n",
    "    print_obj(func_name, \"discriminator_labels\", discriminator_labels)\n",
    "\n",
    "    # Calculate discriminator probabilities.\n",
    "    discriminator_probabilities = tf.nn.sigmoid(\n",
    "        x=discriminator_logits, name=\"discriminator_probabilities\"\n",
    "    )\n",
    "    print_obj(\n",
    "        func_name, \"discriminator_probabilities\", discriminator_probabilities\n",
    "    )\n",
    "\n",
    "    # Create eval metric ops dictionary.\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            name=\"discriminator_accuracy\"\n",
    "        ),\n",
    "        \"precision\": tf.metrics.precision(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            name=\"discriminator_precision\"\n",
    "        ),\n",
    "        \"recall\": tf.metrics.recall(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            name=\"discriminator_recall\"\n",
    "        ),\n",
    "        \"auc_roc\": tf.metrics.auc(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            num_thresholds=200,\n",
    "            curve=\"ROC\",\n",
    "            name=\"discriminator_auc_roc\"\n",
    "        ),\n",
    "        \"auc_pr\": tf.metrics.auc(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            num_thresholds=200,\n",
    "            curve=\"PR\",\n",
    "            name=\"discriminator_auc_pr\"\n",
    "        )\n",
    "    }\n",
    "    print_obj(func_name, \"eval_metric_ops\", eval_metric_ops)\n",
    "\n",
    "    return eval_metric_ops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_and_export_outputs(features, generator, params):\n",
    "    \"\"\"Gets predictions and serving export outputs.\n",
    "\n",
    "    Args:\n",
    "        features: dict, feature tensors from serving input function.\n",
    "        generator: instance of `Generator`.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Predictions dictionary and export outputs dictionary.\n",
    "    \"\"\"\n",
    "    func_name = \"get_predictions_and_export_outputs\"\n",
    "    # Extract given latent vectors from features dictionary.\n",
    "    Z = features[\"Z\"]\n",
    "    print_obj(\"\\n\" + func_name, \"Z\", Z)\n",
    "\n",
    "    # Get generated images from generator using latent vector.\n",
    "    generated_images = generator.get_fake_images(\n",
    "        Z=Z, mode=tf.estimator.ModeKeys.PREDICT, params=params\n",
    "    )\n",
    "    print_obj(func_name, \"generated_images\", generated_images)\n",
    "\n",
    "    # Resize generated images to match real image sizes.\n",
    "    generated_images = resize_fake_images(\n",
    "        fake_images=generated_images, params=params\n",
    "    )\n",
    "    print_obj(func_name, \"generated_images\", generated_images)\n",
    "\n",
    "    # Create predictions dictionary.\n",
    "    predictions_dict = {\n",
    "        \"generated_images\": generated_images\n",
    "    }\n",
    "    print_obj(func_name, \"predictions_dict\", predictions_dict)\n",
    "\n",
    "    # Create export outputs.\n",
    "    export_outputs = {\n",
    "        \"predict_export_outputs\": tf.estimator.export.PredictOutput(\n",
    "            outputs=predictions_dict)\n",
    "    }\n",
    "    print_obj(func_name, \"export_outputs\", export_outputs)\n",
    "\n",
    "    return predictions_dict, export_outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lsgan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsgan_model(features, labels, mode, params):\n",
    "    \"\"\"Least Squares Deep Convolutional GAN custom Estimator model function.\n",
    "\n",
    "    Args:\n",
    "        features: dict, keys are feature names and values are feature tensors.\n",
    "        labels: tensor, label data.\n",
    "        mode: tf.estimator.ModeKeys with values of either TRAIN, EVAL, or\n",
    "            PREDICT.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Instance of `tf.estimator.EstimatorSpec` class.\n",
    "    \"\"\"\n",
    "    func_name = \"lsgan_model\"\n",
    "    print_obj(\"\\n\" + func_name, \"features\", features)\n",
    "    print_obj(func_name, \"labels\", labels)\n",
    "    print_obj(func_name, \"mode\", mode)\n",
    "    print_obj(func_name, \"params\", params)\n",
    "\n",
    "    # Loss function, training/eval ops, etc.\n",
    "    predictions_dict = None\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = None\n",
    "    export_outputs = None\n",
    "\n",
    "    # Instantiate generator.\n",
    "    lsgan_generator = Generator(\n",
    "        kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(\n",
    "            scale_l1=params[\"generator_l1_regularization_scale\"],\n",
    "            scale_l2=params[\"generator_l2_regularization_scale\"]\n",
    "        ),\n",
    "        bias_regularizer=None,\n",
    "        name=\"generator\"\n",
    "    )\n",
    "\n",
    "    # Instantiate discriminator.\n",
    "    lsgan_discriminator = Discriminator(\n",
    "        kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(\n",
    "            scale_l1=params[\"discriminator_l1_regularization_scale\"],\n",
    "            scale_l2=params[\"discriminator_l2_regularization_scale\"]\n",
    "        ),\n",
    "        bias_regularizer=None,\n",
    "        name=\"discriminator\"\n",
    "    )\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # Get predictions and export outputs.\n",
    "        (predictions_dict,\n",
    "         export_outputs) = get_predictions_and_export_outputs(\n",
    "            features=features, generator=lsgan_generator, params=params\n",
    "        )\n",
    "    else:\n",
    "        # Get logits and losses from networks for train and eval modes.\n",
    "        (real_logits,\n",
    "         fake_logits,\n",
    "         generator_total_loss,\n",
    "         discriminator_total_loss) = get_logits_and_losses(\n",
    "            features=features,\n",
    "            generator=lsgan_generator,\n",
    "            discriminator=lsgan_discriminator,\n",
    "            mode=mode,\n",
    "            params=params\n",
    "        )\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            # Create variable and gradient histogram summaries.\n",
    "            create_variable_and_gradient_histogram_summaries(\n",
    "                loss_dict={\n",
    "                    \"generator\": generator_total_loss,\n",
    "                    \"discriminator\": discriminator_total_loss\n",
    "                },\n",
    "                params=params\n",
    "            )\n",
    "\n",
    "            # Get loss and train op for EstimatorSpec.\n",
    "            loss, train_op = get_loss_and_train_op(\n",
    "                generator_total_loss=generator_total_loss,\n",
    "                discriminator_total_loss=discriminator_total_loss,\n",
    "                params=params\n",
    "            )\n",
    "        else:\n",
    "            # Set eval loss.\n",
    "            loss = discriminator_total_loss\n",
    "\n",
    "            # Get eval metrics.\n",
    "            eval_metric_ops = get_eval_metric_ops(\n",
    "                real_logits=real_logits,\n",
    "                fake_logits=fake_logits,\n",
    "                params=params\n",
    "            )\n",
    "\n",
    "    # Return EstimatorSpec\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions_dict,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops,\n",
    "        export_outputs=export_outputs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## serving.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn(params):\n",
    "    \"\"\"Serving input function.\n",
    "\n",
    "    Args:\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        ServingInputReceiver object containing features and receiver tensors.\n",
    "    \"\"\"\n",
    "    func_name = \"serving_input_fn\"\n",
    "    # Create placeholders to accept data sent to the model at serving time.\n",
    "    # shape = (batch_size,)\n",
    "    feature_placeholders = {\n",
    "        \"Z\": tf.placeholder(\n",
    "            dtype=tf.float32,\n",
    "            shape=[None, params[\"latent_size\"]],\n",
    "            name=\"serving_input_placeholder_Z\"\n",
    "        )\n",
    "    }\n",
    "    print_obj(\"\\n\" + func_name, \"feature_placeholders\", feature_placeholders)\n",
    "\n",
    "    # Create clones of the feature placeholder tensors so that the SavedModel\n",
    "    # SignatureDef will point to the placeholder.\n",
    "    features = {\n",
    "        key: tf.identity(\n",
    "            input=value,\n",
    "            name=\"{}_identity_placeholder_{}\".format(func_name, key)\n",
    "        )\n",
    "        for key, value in feature_placeholders.items()\n",
    "    }\n",
    "    print_obj(func_name, \"features\", features)\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features=features, receiver_tensors=feature_placeholders\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(args):\n",
    "    \"\"\"Trains and evaluates custom Estimator model.\n",
    "\n",
    "    Args:\n",
    "        args: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        `Estimator` object.\n",
    "    \"\"\"\n",
    "    func_name = \"train_and_evaluate\"\n",
    "    print_obj(\"\\n\" + func_name, \"args\", args)\n",
    "    # Ensure filewriter cache is clear for TensorBoard events file.\n",
    "    tf.summary.FileWriterCache.clear()\n",
    "\n",
    "    # Set logging to be level of INFO.\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    # Create a RunConfig for Estimator.\n",
    "    config = tf.estimator.RunConfig(\n",
    "        model_dir=args[\"output_dir\"],\n",
    "        save_summary_steps=args[\"save_summary_steps\"],\n",
    "        save_checkpoints_steps=args[\"save_checkpoints_steps\"],\n",
    "        keep_checkpoint_max=args[\"keep_checkpoint_max\"]\n",
    "    )\n",
    "\n",
    "    # Create our custom estimator using our model function.\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn=lsgan_model,\n",
    "        model_dir=args[\"output_dir\"],\n",
    "        config=config,\n",
    "        params=args\n",
    "    )\n",
    "\n",
    "    # Create train spec to read in our training data.\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"train_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.TRAIN,\n",
    "            batch_size=args[\"train_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        max_steps=args[\"train_steps\"]\n",
    "    )\n",
    "\n",
    "    # Create exporter to save out the complete model to disk.\n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        name=\"exporter\",\n",
    "        serving_input_receiver_fn=lambda: serving_input_fn(args)\n",
    "    )\n",
    "\n",
    "    # Create eval spec to read in our validation data and export our model.\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"eval_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.EVAL,\n",
    "            batch_size=args[\"eval_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        steps=args[\"eval_steps\"],\n",
    "        start_delay_secs=args[\"start_delay_secs\"],\n",
    "        throttle_secs=args[\"throttle_secs\"],\n",
    "        exporters=exporter\n",
    "    )\n",
    "\n",
    "    # Create train and evaluate loop to train and evaluate our estimator.\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n",
    "\n",
    "    return estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OUTPUT_DIR\"] = arguments[\"output_dir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil -m rm -rf ${OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_and_evaluate: args = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/lsgan/trained_model', 'train_batch_size': 32, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 16, 'eval_steps': 10, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 100, 'generator_projection_dims': [7, 7, 256], 'generator_num_filters': [128, 64, 1], 'generator_kernel_sizes': [4, 4, 7], 'generator_strides': [2, 2, 1], 'generator_use_batch_norm': [True, True], 'generator_use_leaky_relu': False, 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_num_filters': [64, 128], 'discriminator_kernel_sizes': [4, 4], 'discriminator_strides': [2, 2], 'discriminator_use_batch_norm': [True, True], 'discriminator_use_leaky_relu': True, 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'loss_a': 0.0, 'loss_b': 1.0, 'loss_c': 1.0}\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'gs://machine-learning-1234-bucket/gan/lsgan/trained_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe517d60bd0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 5000 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-5-c725903d59ef>:88: shuffle_and_repeat (from tensorflow.contrib.data.python.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.shuffle_and_repeat(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/shuffle_ops.py:54: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From <ipython-input-5-c725903d59ef>:100: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(28, 28, 1), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "WARNING:tensorflow:From <ipython-input-5-c725903d59ef>:108: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "lsgan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 28, 28, 1) dtype=float32>}\n",
      "lsgan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "lsgan_model: mode = train\n",
      "lsgan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/lsgan/trained_model', 'train_batch_size': 32, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 16, 'eval_steps': 10, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 100, 'generator_projection_dims': [7, 7, 256], 'generator_num_filters': [128, 64, 1], 'generator_kernel_sizes': [4, 4, 7], 'generator_strides': [2, 2, 1], 'generator_use_batch_norm': [True, True], 'generator_use_leaky_relu': False, 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_num_filters': [64, 128], 'discriminator_kernel_sizes': [4, 4], 'discriminator_strides': [2, 2], 'discriminator_use_batch_norm': [True, True], 'discriminator_use_leaky_relu': True, 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'loss_a': 0.0, 'loss_b': 1.0, 'loss_c': 1.0}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 100), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 100), dtype=float32).\n",
      "\n",
      "get_fake_images: network = Tensor(\"random_normal:0\", shape=(?, 100), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-6-702ccdc6e218>:68: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: projection_activation = Tensor(\"generator/projection_relu:0\", shape=(?, 12544), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-6-702ccdc6e218>:95: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 7, 7, 256), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-6-702ccdc6e218>:135: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/relu_0:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/relu_1:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "get_logits_and_losses: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "\n",
      "Call discriminator with fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-7-3609ca82623b>:66: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_conv2d_0/BiasAdd:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_0:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_conv2d_1/BiasAdd:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_1:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network_flat = Tensor(\"discriminator/flatten/Reshape:0\", shape=(?, 6272), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call discriminator with real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_conv2d_0/BiasAdd:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_0:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_conv2d_1/BiasAdd:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_1:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network_flat = Tensor(\"discriminator_1/flatten/Reshape:0\", shape=(?, 6272), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"mean_squared_error/value:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"mean_squared_error_1/value:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_fake_loss = Tensor(\"mean_squared_error_2/value:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_variables_and_gradients_generator: variables = [<tf.Variable 'generator/projection_dense_layer/kernel:0' shape=(100, 12544) dtype=float32_ref>, <tf.Variable 'generator/projection_dense_layer/bias:0' shape=(12544,) dtype=float32_ref>, <tf.Variable 'generator/projection_batch_norm/gamma:0' shape=(12544,) dtype=float32_ref>, <tf.Variable 'generator/projection_batch_norm/beta:0' shape=(12544,) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_0/kernel:0' shape=(4, 4, 128, 256) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_0/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'generator/layers_batch_norm_0/gamma:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'generator/layers_batch_norm_0/beta:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_1/kernel:0' shape=(4, 4, 64, 128) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_1/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'generator/layers_batch_norm_1/gamma:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'generator/layers_batch_norm_1/beta:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_fake_images/kernel:0' shape=(7, 7, 1, 64) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_fake_images/bias:0' shape=(1,) dtype=float32_ref>]\n",
      "\n",
      "get_variables_and_gradients_generator: gradients = [<tf.Tensor 'generator_gradients/generator/projection_dense_layer/MatMul_grad/MatMul_1:0' shape=(100, 12544) dtype=float32>, <tf.Tensor 'generator_gradients/generator/projection_dense_layer/BiasAdd_grad/BiasAddGrad:0' shape=(12544,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/projection_batch_norm/batchnorm/mul_grad/Mul_1:0' shape=(12544,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/projection_batch_norm/batchnorm/add_1_grad/Reshape_1:0' shape=(12544,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_0/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(4, 4, 128, 256) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_0/BiasAdd_grad/BiasAddGrad:0' shape=(128,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_batch_norm_0/FusedBatchNormV3_grad/FusedBatchNormGradV3:1' shape=(128,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_batch_norm_0/FusedBatchNormV3_grad/FusedBatchNormGradV3:2' shape=(128,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_1/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(4, 4, 64, 128) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_1/BiasAdd_grad/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_batch_norm_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:1' shape=(64,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_batch_norm_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:2' shape=(64,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_fake_images/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(7, 7, 1, 64) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_fake_images/BiasAdd_grad/BiasAddGrad:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "get_variables_and_gradients_generator: gradients = [<tf.Tensor 'get_variables_and_gradients_generator/projection_dense_layer/kernel_gradients:0' shape=(100, 12544) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/projection_dense_layer/bias_gradients:0' shape=(12544,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/projection_batch_norm/gamma_gradients:0' shape=(12544,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/projection_batch_norm/beta_gradients:0' shape=(12544,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_0/kernel_gradients:0' shape=(4, 4, 128, 256) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_0/bias_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_batch_norm_0/gamma_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_batch_norm_0/beta_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_1/kernel_gradients:0' shape=(4, 4, 64, 128) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_1/bias_gradients:0' shape=(64,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_batch_norm_1/gamma_gradients:0' shape=(64,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_batch_norm_1/beta_gradients:0' shape=(64,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_fake_images/kernel_gradients:0' shape=(7, 7, 1, 64) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_fake_images/bias_gradients:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "get_variables_and_gradients_discriminator: variables = [<tf.Variable 'discriminator/layers_conv2d_0/kernel:0' shape=(4, 4, 1, 64) dtype=float32_ref>, <tf.Variable 'discriminator/layers_conv2d_0/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'discriminator/layers_batch_norm_0/gamma:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'discriminator/layers_batch_norm_0/beta:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'discriminator/layers_conv2d_1/kernel:0' shape=(4, 4, 64, 128) dtype=float32_ref>, <tf.Variable 'discriminator/layers_conv2d_1/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'discriminator/layers_batch_norm_1/gamma:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'discriminator/layers_batch_norm_1/beta:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'discriminator/layers_dense_logits/kernel:0' shape=(6272, 1) dtype=float32_ref>, <tf.Variable 'discriminator/layers_dense_logits/bias:0' shape=(1,) dtype=float32_ref>]\n",
      "\n",
      "get_variables_and_gradients_discriminator: gradients = [<tf.Tensor 'discriminator_gradients/AddN_9:0' shape=(4, 4, 1, 64) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_8:0' shape=(64,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_6:0' shape=(64,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_7:0' shape=(64,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_5:0' shape=(4, 4, 64, 128) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_4:0' shape=(128,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_2:0' shape=(128,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_3:0' shape=(128,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_1:0' shape=(6272, 1) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "get_variables_and_gradients_discriminator: gradients = [<tf.Tensor 'get_variables_and_gradients_discriminator/layers_conv2d_0/kernel_gradients:0' shape=(4, 4, 1, 64) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_conv2d_0/bias_gradients:0' shape=(64,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_batch_norm_0/gamma_gradients:0' shape=(64,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_batch_norm_0/beta_gradients:0' shape=(64,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_conv2d_1/kernel_gradients:0' shape=(4, 4, 64, 128) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_conv2d_1/bias_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_batch_norm_1/gamma_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_batch_norm_1/beta_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_logits/kernel_gradients:0' shape=(6272, 1) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_logits/bias_gradients:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "train_network: scope = discriminator\n",
      "train_network_discriminator: optimizer = <tensorflow.python.training.adam.AdamOptimizer object at 0x7fe50abc5150>\n",
      "\n",
      "train_network_discriminator: gradients = [<tf.Tensor 'cond/discriminator_gradients/AddN_9:0' shape=(4, 4, 1, 64) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_8:0' shape=(64,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_6:0' shape=(64,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_7:0' shape=(64,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_5:0' shape=(4, 4, 64, 128) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_4:0' shape=(128,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_2:0' shape=(128,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_3:0' shape=(128,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_1:0' shape=(6272, 1) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN:0' shape=(1,) dtype=float32>]\n",
      "train_network_discriminator: grads_and_vars = <zip object at 0x7fe50abdc6e0>\n",
      "\n",
      "train_network: scope = generator\n",
      "train_network_generator: optimizer = <tensorflow.python.training.adam.AdamOptimizer object at 0x7fe50aabe710>\n",
      "\n",
      "train_network_generator: gradients = [<tf.Tensor 'cond/generator_gradients/generator/projection_dense_layer/MatMul_grad/MatMul_1:0' shape=(100, 12544) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/projection_dense_layer/BiasAdd_grad/BiasAddGrad:0' shape=(12544,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/projection_batch_norm/batchnorm/mul_grad/Mul_1:0' shape=(12544,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/projection_batch_norm/batchnorm/add_1_grad/Reshape_1:0' shape=(12544,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_0/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(4, 4, 128, 256) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_0/BiasAdd_grad/BiasAddGrad:0' shape=(128,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_batch_norm_0/FusedBatchNormV3_grad/FusedBatchNormGradV3:1' shape=(128,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_batch_norm_0/FusedBatchNormV3_grad/FusedBatchNormGradV3:2' shape=(128,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_1/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(4, 4, 64, 128) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_1/BiasAdd_grad/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_batch_norm_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:1' shape=(64,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_batch_norm_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:2' shape=(64,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_fake_images/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(7, 7, 1, 64) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_fake_images/BiasAdd_grad/BiasAddGrad:0' shape=(1,) dtype=float32>]\n",
      "train_network_generator: grads_and_vars = <zip object at 0x7fe50ababcd0>\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into gs://machine-learning-1234-bucket/gan/lsgan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 4.2903438, step = 1\n",
      "INFO:tensorflow:global_step/sec: 8.79786\n",
      "INFO:tensorflow:loss = 1.1159332, step = 101 (11.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.24661\n",
      "INFO:tensorflow:loss = 0.7660542, step = 201 (10.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4135\n",
      "INFO:tensorflow:loss = 0.6893762, step = 301 (9.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.116\n",
      "INFO:tensorflow:loss = 0.8084532, step = 401 (8.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5049\n",
      "INFO:tensorflow:loss = 0.4838346, step = 501 (8.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.383\n",
      "INFO:tensorflow:loss = 0.65273356, step = 601 (8.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1934\n",
      "INFO:tensorflow:loss = 0.40907246, step = 701 (9.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.147\n",
      "INFO:tensorflow:loss = 0.3756132, step = 801 (9.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.691\n",
      "INFO:tensorflow:loss = 0.31494159, step = 901 (9.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.68814\n",
      "INFO:tensorflow:loss = 0.3635519, step = 1001 (10.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.38266\n",
      "INFO:tensorflow:loss = 0.30872467, step = 1101 (10.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.98693\n",
      "INFO:tensorflow:loss = 0.35806763, step = 1201 (12.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.651\n",
      "INFO:tensorflow:loss = 0.23258984, step = 1301 (13.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.07094\n",
      "INFO:tensorflow:loss = 0.21556388, step = 1401 (19.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13433\n",
      "INFO:tensorflow:loss = 0.2166565, step = 1501 (16.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.96599\n",
      "INFO:tensorflow:loss = 0.3001853, step = 1601 (11.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.88653\n",
      "INFO:tensorflow:loss = 0.13835292, step = 1701 (14.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.84809\n",
      "INFO:tensorflow:loss = 0.16494837, step = 1801 (10.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1774\n",
      "INFO:tensorflow:loss = 0.18950862, step = 1901 (9.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.30012\n",
      "INFO:tensorflow:loss = 0.2135563, step = 2001 (10.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.42519\n",
      "INFO:tensorflow:loss = 0.20332497, step = 2101 (11.015 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2101 vs previous value: 2101. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 10.345\n",
      "INFO:tensorflow:loss = 0.19118133, step = 2201 (9.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.37605\n",
      "INFO:tensorflow:loss = 0.17268252, step = 2301 (10.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.6971\n",
      "INFO:tensorflow:loss = 0.21238932, step = 2401 (11.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0432\n",
      "INFO:tensorflow:loss = 0.13783735, step = 2501 (9.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3459\n",
      "INFO:tensorflow:loss = 0.23874164, step = 2601 (8.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.01\n",
      "INFO:tensorflow:loss = 0.31157035, step = 2701 (8.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7302\n",
      "INFO:tensorflow:loss = 0.351859, step = 2801 (8.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4028\n",
      "INFO:tensorflow:loss = 0.12649965, step = 2901 (8.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0833\n",
      "INFO:tensorflow:loss = 0.1305691, step = 3001 (9.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0817\n",
      "INFO:tensorflow:loss = 0.27597374, step = 3101 (9.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.47114\n",
      "INFO:tensorflow:loss = 0.17181933, step = 3201 (11.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.54137\n",
      "INFO:tensorflow:loss = 0.1913703, step = 3301 (13.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.75299\n",
      "INFO:tensorflow:loss = 0.32030356, step = 3401 (13.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2241\n",
      "INFO:tensorflow:loss = 0.15493697, step = 3501 (8.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.11119\n",
      "INFO:tensorflow:loss = 0.28933766, step = 3601 (10.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0067\n",
      "INFO:tensorflow:loss = 0.17702459, step = 3701 (9.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0622\n",
      "INFO:tensorflow:loss = 0.21979986, step = 3801 (8.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.69937\n",
      "INFO:tensorflow:loss = 0.14289315, step = 3901 (10.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7766\n",
      "INFO:tensorflow:loss = 0.14692034, step = 4001 (8.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.504\n",
      "INFO:tensorflow:loss = 0.23809694, step = 4101 (8.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4524\n",
      "INFO:tensorflow:loss = 0.16179825, step = 4201 (8.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7004\n",
      "INFO:tensorflow:loss = 0.1336763, step = 4301 (9.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.209\n",
      "INFO:tensorflow:loss = 0.11997364, step = 4401 (9.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9812\n",
      "INFO:tensorflow:loss = 0.11367551, step = 4501 (8.346 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 4501 vs previous value: 4501. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 9.41884\n",
      "INFO:tensorflow:loss = 0.1470018, step = 4601 (10.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3086\n",
      "INFO:tensorflow:loss = 0.13725705, step = 4701 (10.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.61724\n",
      "INFO:tensorflow:loss = 0.10505137, step = 4801 (9.982 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4851\n",
      "INFO:tensorflow:loss = 0.18063608, step = 4901 (8.703 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into gs://machine-learning-1234-bucket/gan/lsgan/trained_model/model.ckpt.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(28, 28, 1), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "lsgan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 28, 28, 1) dtype=float32>}\n",
      "lsgan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "lsgan_model: mode = eval\n",
      "lsgan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/lsgan/trained_model', 'train_batch_size': 32, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 16, 'eval_steps': 10, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 100, 'generator_projection_dims': [7, 7, 256], 'generator_num_filters': [128, 64, 1], 'generator_kernel_sizes': [4, 4, 7], 'generator_strides': [2, 2, 1], 'generator_use_batch_norm': [True, True], 'generator_use_leaky_relu': False, 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_num_filters': [64, 128], 'discriminator_kernel_sizes': [4, 4], 'discriminator_strides': [2, 2], 'discriminator_use_batch_norm': [True, True], 'discriminator_use_leaky_relu': True, 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'loss_a': 0.0, 'loss_b': 1.0, 'loss_c': 1.0}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 100), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 100), dtype=float32).\n",
      "\n",
      "get_fake_images: network = Tensor(\"random_normal:0\", shape=(?, 100), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: projection_activation = Tensor(\"generator/projection_relu:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 7, 7, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/relu_0:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/relu_1:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "get_logits_and_losses: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "\n",
      "Call discriminator with fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_conv2d_0/BiasAdd:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_0:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_conv2d_1/BiasAdd:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_1:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network_flat = Tensor(\"discriminator/flatten/Reshape:0\", shape=(?, 6272), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call discriminator with real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_conv2d_0/BiasAdd:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_0:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_conv2d_1/BiasAdd:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_1:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network_flat = Tensor(\"discriminator_1/flatten/Reshape:0\", shape=(?, 6272), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"mean_squared_error/value:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"mean_squared_error_1/value:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_fake_loss = Tensor(\"mean_squared_error_2/value:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_eval_metric_ops: discriminator_logits = Tensor(\"discriminator_concat_logits:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_labels = Tensor(\"discriminator_concat_labels:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_probabilities = Tensor(\"discriminator_probabilities:0\", shape=(?, 1), dtype=float32)\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "get_eval_metric_ops: eval_metric_ops = {'accuracy': (<tf.Tensor 'discriminator_accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_accuracy/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'discriminator_precision/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'discriminator_recall/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_recall/update_op:0' shape=() dtype=float32>), 'auc_roc': (<tf.Tensor 'discriminator_auc_roc/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_roc/update_op:0' shape=() dtype=float32>), 'auc_pr': (<tf.Tensor 'discriminator_auc_pr/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_pr/update_op:0' shape=() dtype=float32>)}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-25T00:43:42Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/lsgan/trained_model/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-25-00:43:45\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.0, auc_pr = 0.85543346, auc_roc = 0.8508203, global_step = 5000, loss = 0.3608516, precision = 0.5, recall = 1.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: gs://machine-learning-1234-bucket/gan/lsgan/trained_model/model.ckpt-5000\n",
      "\n",
      "serving_input_fn: feature_placeholders = {'Z': <tf.Tensor 'serving_input_placeholder_Z:0' shape=(?, 100) dtype=float32>}\n",
      "serving_input_fn: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 100) dtype=float32>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "lsgan_model: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 100) dtype=float32>}\n",
      "lsgan_model: labels = None\n",
      "lsgan_model: mode = infer\n",
      "lsgan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/lsgan/trained_model', 'train_batch_size': 32, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 16, 'eval_steps': 10, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 100, 'generator_projection_dims': [7, 7, 256], 'generator_num_filters': [128, 64, 1], 'generator_kernel_sizes': [4, 4, 7], 'generator_strides': [2, 2, 1], 'generator_use_batch_norm': [True, True], 'generator_use_leaky_relu': False, 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_num_filters': [64, 128], 'discriminator_kernel_sizes': [4, 4], 'discriminator_strides': [2, 2], 'discriminator_use_batch_norm': [True, True], 'discriminator_use_leaky_relu': True, 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'loss_a': 0.0, 'loss_b': 1.0, 'loss_c': 1.0}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_predictions_and_export_outputs: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 100), dtype=float32)\n",
      "\n",
      "get_fake_images: network = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 100), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: projection_activation = Tensor(\"generator/projection_relu:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 7, 7, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/relu_0:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/relu_1:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "get_predictions_and_export_outputs: generated_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "get_predictions_and_export_outputs: predictions_dict = {'generated_images': <tf.Tensor 'generator/layers_conv2d_tranpose_fake_images/Tanh:0' shape=(?, 28, 28, 1) dtype=float32>}\n",
      "get_predictions_and_export_outputs: export_outputs = {'predict_export_outputs': <tensorflow.python.saved_model.model_utils.export_output.PredictOutput object at 0x7fe45c34e690>}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/lsgan/trained_model/model.ckpt-5000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://machine-learning-1234-bucket/gan/lsgan/trained_model/export/exporter/temp-b'1593045827'/saved_model.pb\n",
      "INFO:tensorflow:global_step/sec: 3.50699\n",
      "INFO:tensorflow:loss = 0.1835385, step = 5001 (28.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4036\n",
      "INFO:tensorflow:loss = 0.15768397, step = 5101 (8.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7421\n",
      "INFO:tensorflow:loss = 0.24173707, step = 5201 (8.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6949\n",
      "INFO:tensorflow:loss = 0.3075483, step = 5301 (8.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.303\n",
      "INFO:tensorflow:loss = 0.17807622, step = 5401 (8.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5632\n",
      "INFO:tensorflow:loss = 0.23049593, step = 5501 (7.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.8939\n",
      "INFO:tensorflow:loss = 0.8997177, step = 5601 (8.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4742\n",
      "INFO:tensorflow:loss = 0.24172392, step = 5701 (8.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9116\n",
      "INFO:tensorflow:loss = 0.23960462, step = 5801 (8.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6507\n",
      "INFO:tensorflow:loss = 0.30850786, step = 5901 (9.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9004\n",
      "INFO:tensorflow:loss = 0.27943477, step = 6001 (8.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6964\n",
      "INFO:tensorflow:loss = 0.3027799, step = 6101 (7.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8196\n",
      "INFO:tensorflow:loss = 0.3423419, step = 6201 (7.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4728\n",
      "INFO:tensorflow:loss = 0.33617038, step = 6301 (8.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.649\n",
      "INFO:tensorflow:loss = 0.23856737, step = 6401 (8.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.874\n",
      "INFO:tensorflow:loss = 0.4446922, step = 6501 (7.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2552\n",
      "INFO:tensorflow:loss = 0.33515343, step = 6601 (8.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4256\n",
      "INFO:tensorflow:loss = 0.23820516, step = 6701 (8.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7173\n",
      "INFO:tensorflow:loss = 0.18976368, step = 6801 (8.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4684\n",
      "INFO:tensorflow:loss = 0.39976418, step = 6901 (8.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1453\n",
      "INFO:tensorflow:loss = 0.22570795, step = 7001 (7.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2301\n",
      "INFO:tensorflow:loss = 0.2946869, step = 7101 (8.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9574\n",
      "INFO:tensorflow:loss = 0.27254218, step = 7201 (8.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4728\n",
      "INFO:tensorflow:loss = 0.20807053, step = 7301 (8.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6046\n",
      "INFO:tensorflow:loss = 0.15999472, step = 7401 (8.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9337\n",
      "INFO:tensorflow:loss = 0.3289609, step = 7501 (8.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3596\n",
      "INFO:tensorflow:loss = 0.38564187, step = 7601 (8.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1968\n",
      "INFO:tensorflow:loss = 0.25107512, step = 7701 (8.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7767\n",
      "INFO:tensorflow:loss = 0.24733625, step = 7801 (7.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0807\n",
      "INFO:tensorflow:loss = 0.31678784, step = 7901 (8.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2908\n",
      "INFO:tensorflow:loss = 0.26804385, step = 8001 (8.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2024\n",
      "INFO:tensorflow:loss = 0.34711266, step = 8101 (8.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.43\n",
      "INFO:tensorflow:loss = 0.24017216, step = 8201 (8.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1754\n",
      "INFO:tensorflow:loss = 0.2991434, step = 8301 (8.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7598\n",
      "INFO:tensorflow:loss = 0.19285582, step = 8401 (7.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2598\n",
      "INFO:tensorflow:loss = 0.23406564, step = 8501 (8.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3573\n",
      "INFO:tensorflow:loss = 0.30669057, step = 8601 (7.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6655\n",
      "INFO:tensorflow:loss = 0.24273178, step = 8701 (7.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4565\n",
      "INFO:tensorflow:loss = 0.18342201, step = 8801 (8.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4571\n",
      "INFO:tensorflow:loss = 0.31434083, step = 8901 (8.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.483\n",
      "INFO:tensorflow:loss = 0.29706448, step = 9001 (8.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2146\n",
      "INFO:tensorflow:loss = 0.16611984, step = 9101 (8.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9857\n",
      "INFO:tensorflow:loss = 0.7777457, step = 9201 (7.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9273\n",
      "INFO:tensorflow:loss = 0.16781269, step = 9301 (8.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9386\n",
      "INFO:tensorflow:loss = 0.36779618, step = 9401 (8.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2334\n",
      "INFO:tensorflow:loss = 0.21091573, step = 9501 (8.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.584\n",
      "INFO:tensorflow:loss = 0.20512676, step = 9601 (7.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.804\n",
      "INFO:tensorflow:loss = 0.38145125, step = 9701 (8.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0379\n",
      "INFO:tensorflow:loss = 0.2956422, step = 9801 (7.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0205\n",
      "INFO:tensorflow:loss = 0.24972583, step = 9901 (7.681 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into gs://machine-learning-1234-bucket/gan/lsgan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 7.38291\n",
      "INFO:tensorflow:loss = 0.31854767, step = 10001 (13.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.256\n",
      "INFO:tensorflow:loss = 0.25828046, step = 10101 (8.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3343\n",
      "INFO:tensorflow:loss = 0.29130453, step = 10201 (8.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.8388\n",
      "INFO:tensorflow:loss = 0.17216492, step = 10301 (8.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4111\n",
      "INFO:tensorflow:loss = 0.3050338, step = 10401 (8.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3866\n",
      "INFO:tensorflow:loss = 0.31260735, step = 10501 (8.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9042\n",
      "INFO:tensorflow:loss = 0.30108, step = 10601 (8.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7653\n",
      "INFO:tensorflow:loss = 0.46601355, step = 10701 (8.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4\n",
      "INFO:tensorflow:loss = 0.31261748, step = 10801 (8.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.396\n",
      "INFO:tensorflow:loss = 0.44886875, step = 10901 (8.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3218\n",
      "INFO:tensorflow:loss = 0.22692181, step = 11001 (8.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7076\n",
      "INFO:tensorflow:loss = 0.29929507, step = 11101 (7.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6409\n",
      "INFO:tensorflow:loss = 0.3415009, step = 11201 (8.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4696\n",
      "INFO:tensorflow:loss = 0.4350967, step = 11301 (8.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4243\n",
      "INFO:tensorflow:loss = 0.3222364, step = 11401 (8.046 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.8802\n",
      "INFO:tensorflow:loss = 0.20438093, step = 11501 (8.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5301\n",
      "INFO:tensorflow:loss = 0.25597593, step = 11601 (7.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.577\n",
      "INFO:tensorflow:loss = 0.34444284, step = 11701 (8.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1582\n",
      "INFO:tensorflow:loss = 0.13269246, step = 11801 (7.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4586\n",
      "INFO:tensorflow:loss = 0.20505694, step = 11901 (8.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.8092\n",
      "INFO:tensorflow:loss = 0.23995787, step = 12001 (8.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9911\n",
      "INFO:tensorflow:loss = 0.29243088, step = 12101 (8.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9309\n",
      "INFO:tensorflow:loss = 0.28235906, step = 12201 (9.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4773\n",
      "INFO:tensorflow:loss = 0.33028638, step = 12301 (8.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5607\n",
      "INFO:tensorflow:loss = 0.18456933, step = 12401 (8.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1578\n",
      "INFO:tensorflow:loss = 0.23352826, step = 12501 (8.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.779\n",
      "INFO:tensorflow:loss = 0.3228929, step = 12601 (7.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3827\n",
      "INFO:tensorflow:loss = 0.22958946, step = 12701 (8.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2734\n",
      "INFO:tensorflow:loss = 0.33661294, step = 12801 (7.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2194\n",
      "INFO:tensorflow:loss = 0.4193787, step = 12901 (7.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4958\n",
      "INFO:tensorflow:loss = 0.16182312, step = 13001 (8.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5211\n",
      "INFO:tensorflow:loss = 0.17291948, step = 13101 (7.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0349\n",
      "INFO:tensorflow:loss = 0.19567025, step = 13201 (8.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0459\n",
      "INFO:tensorflow:loss = 0.35478318, step = 13301 (8.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3988\n",
      "INFO:tensorflow:loss = 0.27829036, step = 13401 (8.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9984\n",
      "INFO:tensorflow:loss = 0.3052834, step = 13501 (7.951 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6358\n",
      "INFO:tensorflow:loss = 0.30214342, step = 13601 (8.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.8384\n",
      "INFO:tensorflow:loss = 0.35476106, step = 13701 (8.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6992\n",
      "INFO:tensorflow:loss = 0.33729798, step = 13801 (8.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1145\n",
      "INFO:tensorflow:loss = 0.32453224, step = 13901 (8.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1765\n",
      "INFO:tensorflow:loss = 0.38127103, step = 14001 (8.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0465\n",
      "INFO:tensorflow:loss = 0.276722, step = 14101 (8.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2879\n",
      "INFO:tensorflow:loss = 0.2613996, step = 14201 (8.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3606\n",
      "INFO:tensorflow:loss = 0.25555086, step = 14301 (7.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9477\n",
      "INFO:tensorflow:loss = 0.1948083, step = 14401 (8.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2895\n",
      "INFO:tensorflow:loss = 0.2740659, step = 14501 (8.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.801\n",
      "INFO:tensorflow:loss = 0.28696567, step = 14601 (8.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0739\n",
      "INFO:tensorflow:loss = 0.21110468, step = 14701 (7.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5693\n",
      "INFO:tensorflow:loss = 0.3100149, step = 14801 (7.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.915\n",
      "INFO:tensorflow:loss = 0.28571522, step = 14901 (8.801 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into gs://machine-learning-1234-bucket/gan/lsgan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 7.57806\n",
      "INFO:tensorflow:loss = 0.23321268, step = 15001 (12.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5645\n",
      "INFO:tensorflow:loss = 0.4531107, step = 15101 (7.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4678\n",
      "INFO:tensorflow:loss = 0.18185017, step = 15201 (8.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.15\n",
      "INFO:tensorflow:loss = 0.2758381, step = 15301 (7.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5503\n",
      "INFO:tensorflow:loss = 0.3100295, step = 15401 (7.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4186\n",
      "INFO:tensorflow:loss = 0.173919, step = 15501 (8.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2691\n",
      "INFO:tensorflow:loss = 0.29076675, step = 15601 (7.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5759\n",
      "INFO:tensorflow:loss = 0.53846496, step = 15701 (8.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6767\n",
      "INFO:tensorflow:loss = 0.28817135, step = 15801 (7.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.8174\n",
      "INFO:tensorflow:loss = 0.33403516, step = 15901 (8.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7415\n",
      "INFO:tensorflow:loss = 0.27246583, step = 16001 (7.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8719\n",
      "INFO:tensorflow:loss = 0.2720702, step = 16101 (7.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1005\n",
      "INFO:tensorflow:loss = 0.34933662, step = 16201 (9.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6164\n",
      "INFO:tensorflow:loss = 0.25738996, step = 16301 (7.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8935\n",
      "INFO:tensorflow:loss = 0.21385905, step = 16401 (7.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2973\n",
      "INFO:tensorflow:loss = 0.31262755, step = 16501 (7.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4953\n",
      "INFO:tensorflow:loss = 0.2772466, step = 16601 (8.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3972\n",
      "INFO:tensorflow:loss = 0.18804927, step = 16701 (8.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4672\n",
      "INFO:tensorflow:loss = 0.22816105, step = 16801 (8.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.765\n",
      "INFO:tensorflow:loss = 0.28265482, step = 16901 (7.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0189\n",
      "INFO:tensorflow:loss = 0.18726271, step = 17001 (7.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.972\n",
      "INFO:tensorflow:loss = 0.24625424, step = 17101 (7.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6694\n",
      "INFO:tensorflow:loss = 0.47175434, step = 17201 (7.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7009\n",
      "INFO:tensorflow:loss = 0.25575036, step = 17301 (7.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9032\n",
      "INFO:tensorflow:loss = 0.29046452, step = 17401 (7.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8698\n",
      "INFO:tensorflow:loss = 0.30638984, step = 17501 (7.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9251\n",
      "INFO:tensorflow:loss = 0.17193964, step = 17601 (7.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9761\n",
      "INFO:tensorflow:loss = 0.17768806, step = 17701 (8.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1907\n",
      "INFO:tensorflow:loss = 0.1643207, step = 17801 (8.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.496\n",
      "INFO:tensorflow:loss = 0.4008583, step = 17901 (8.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4615\n",
      "INFO:tensorflow:loss = 0.26413974, step = 18001 (8.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.558\n",
      "INFO:tensorflow:loss = 0.39629075, step = 18101 (8.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.464\n",
      "INFO:tensorflow:loss = 0.46372208, step = 18201 (8.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0034\n",
      "INFO:tensorflow:loss = 0.37678018, step = 18301 (8.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8345\n",
      "INFO:tensorflow:loss = 0.22637819, step = 18401 (7.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6525\n",
      "INFO:tensorflow:loss = 0.31702688, step = 18501 (7.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2862\n",
      "INFO:tensorflow:loss = 0.34413677, step = 18601 (8.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3619\n",
      "INFO:tensorflow:loss = 0.35397673, step = 18701 (8.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.963\n",
      "INFO:tensorflow:loss = 0.28575146, step = 18801 (8.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2117\n",
      "INFO:tensorflow:loss = 0.59697664, step = 18901 (8.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.725\n",
      "INFO:tensorflow:loss = 0.37636736, step = 19001 (8.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0573\n",
      "INFO:tensorflow:loss = 0.49890888, step = 19101 (8.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7834\n",
      "INFO:tensorflow:loss = 0.1809895, step = 19201 (8.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.276\n",
      "INFO:tensorflow:loss = 0.5046977, step = 19301 (8.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9616\n",
      "INFO:tensorflow:loss = 0.29537717, step = 19401 (7.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4477\n",
      "INFO:tensorflow:loss = 0.32897395, step = 19501 (8.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7784\n",
      "INFO:tensorflow:loss = 0.29309714, step = 19601 (8.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5277\n",
      "INFO:tensorflow:loss = 0.23210078, step = 19701 (7.983 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.148\n",
      "INFO:tensorflow:loss = 0.33464944, step = 19801 (8.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9983\n",
      "INFO:tensorflow:loss = 0.27059296, step = 19901 (7.693 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into gs://machine-learning-1234-bucket/gan/lsgan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 7.53402\n",
      "INFO:tensorflow:loss = 0.20764352, step = 20001 (13.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1993\n",
      "INFO:tensorflow:loss = 0.22670656, step = 20101 (7.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7405\n",
      "INFO:tensorflow:loss = 0.39559492, step = 20201 (8.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7188\n",
      "INFO:tensorflow:loss = 0.38685665, step = 20301 (8.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7921\n",
      "INFO:tensorflow:loss = 0.36237878, step = 20401 (7.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.381\n",
      "INFO:tensorflow:loss = 0.23289338, step = 20501 (8.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4595\n",
      "INFO:tensorflow:loss = 0.227249, step = 20601 (8.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9723\n",
      "INFO:tensorflow:loss = 0.30833757, step = 20701 (8.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4946\n",
      "INFO:tensorflow:loss = 0.5033969, step = 20801 (8.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6843\n",
      "INFO:tensorflow:loss = 0.26928797, step = 20901 (7.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.142\n",
      "INFO:tensorflow:loss = 0.3346709, step = 21001 (8.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5654\n",
      "INFO:tensorflow:loss = 0.3138546, step = 21101 (8.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8141\n",
      "INFO:tensorflow:loss = 0.1786142, step = 21201 (7.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5497\n",
      "INFO:tensorflow:loss = 0.2872393, step = 21301 (8.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5586\n",
      "INFO:tensorflow:loss = 0.23246491, step = 21401 (7.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2684\n",
      "INFO:tensorflow:loss = 0.40294555, step = 21501 (8.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1113\n",
      "INFO:tensorflow:loss = 0.4577704, step = 21601 (8.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.657\n",
      "INFO:tensorflow:loss = 0.49075922, step = 21701 (8.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8884\n",
      "INFO:tensorflow:loss = 0.22437687, step = 21801 (7.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6799\n",
      "INFO:tensorflow:loss = 0.39787728, step = 21901 (7.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4007\n",
      "INFO:tensorflow:loss = 0.24096422, step = 22001 (8.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2679\n",
      "INFO:tensorflow:loss = 0.59400374, step = 22101 (8.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4036\n",
      "INFO:tensorflow:loss = 0.41713387, step = 22201 (8.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1402\n",
      "INFO:tensorflow:loss = 0.24878502, step = 22301 (8.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2913\n",
      "INFO:tensorflow:loss = 0.2658376, step = 22401 (7.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7046\n",
      "INFO:tensorflow:loss = 0.28477728, step = 22501 (8.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.441\n",
      "INFO:tensorflow:loss = 0.24185303, step = 22601 (8.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0243\n",
      "INFO:tensorflow:loss = 0.19220452, step = 22701 (8.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7289\n",
      "INFO:tensorflow:loss = 0.25867492, step = 22801 (7.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2099\n",
      "INFO:tensorflow:loss = 0.26514113, step = 22901 (8.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0273\n",
      "INFO:tensorflow:loss = 0.4668386, step = 23001 (8.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4529\n",
      "INFO:tensorflow:loss = 0.28928795, step = 23101 (8.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7337\n",
      "INFO:tensorflow:loss = 0.31704664, step = 23201 (8.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5883\n",
      "INFO:tensorflow:loss = 0.28361872, step = 23301 (8.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0661\n",
      "INFO:tensorflow:loss = 0.32624018, step = 23401 (7.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4902\n",
      "INFO:tensorflow:loss = 0.29724577, step = 23501 (8.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1037\n",
      "INFO:tensorflow:loss = 0.19089308, step = 23601 (8.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0066\n",
      "INFO:tensorflow:loss = 0.28805563, step = 23701 (8.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9575\n",
      "INFO:tensorflow:loss = 0.41007668, step = 23801 (8.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4705\n",
      "INFO:tensorflow:loss = 0.24530143, step = 23901 (7.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6954\n",
      "INFO:tensorflow:loss = 0.29523343, step = 24001 (8.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3782\n",
      "INFO:tensorflow:loss = 0.26414683, step = 24101 (8.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9544\n",
      "INFO:tensorflow:loss = 0.3520436, step = 24201 (8.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1808\n",
      "INFO:tensorflow:loss = 0.1640304, step = 24301 (8.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0676\n",
      "INFO:tensorflow:loss = 0.19896328, step = 24401 (8.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4636\n",
      "INFO:tensorflow:loss = 0.33417648, step = 24501 (8.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2376\n",
      "INFO:tensorflow:loss = 0.18582454, step = 24601 (7.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7259\n",
      "INFO:tensorflow:loss = 0.3627132, step = 24701 (7.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0994\n",
      "INFO:tensorflow:loss = 0.31859782, step = 24801 (8.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1229\n",
      "INFO:tensorflow:loss = 0.36409956, step = 24901 (8.249 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into gs://machine-learning-1234-bucket/gan/lsgan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 7.18468\n",
      "INFO:tensorflow:loss = 0.28465074, step = 25001 (13.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9451\n",
      "INFO:tensorflow:loss = 0.39859405, step = 25101 (8.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0241\n",
      "INFO:tensorflow:loss = 0.22425288, step = 25201 (8.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2701\n",
      "INFO:tensorflow:loss = 0.320502, step = 25301 (8.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.474\n",
      "INFO:tensorflow:loss = 0.41993624, step = 25401 (8.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2889\n",
      "INFO:tensorflow:loss = 0.42140836, step = 25501 (8.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1587\n",
      "INFO:tensorflow:loss = 0.25709742, step = 25601 (8.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5263\n",
      "INFO:tensorflow:loss = 0.32567498, step = 25701 (7.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4354\n",
      "INFO:tensorflow:loss = 0.41675746, step = 25801 (8.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.033\n",
      "INFO:tensorflow:loss = 0.27922794, step = 25901 (7.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1816\n",
      "INFO:tensorflow:loss = 0.37153792, step = 26001 (8.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3718\n",
      "INFO:tensorflow:loss = 0.30562925, step = 26101 (7.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0535\n",
      "INFO:tensorflow:loss = 0.2802776, step = 26201 (8.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4043\n",
      "INFO:tensorflow:loss = 0.24454816, step = 26301 (8.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0042\n",
      "INFO:tensorflow:loss = 0.3075095, step = 26401 (8.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9771\n",
      "INFO:tensorflow:loss = 0.28053993, step = 26501 (8.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4039\n",
      "INFO:tensorflow:loss = 0.30352896, step = 26601 (8.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7179\n",
      "INFO:tensorflow:loss = 0.3030716, step = 26701 (7.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9826\n",
      "INFO:tensorflow:loss = 0.34424943, step = 26801 (7.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2754\n",
      "INFO:tensorflow:loss = 0.1823883, step = 26901 (8.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9869\n",
      "INFO:tensorflow:loss = 0.28107888, step = 27001 (8.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9519\n",
      "INFO:tensorflow:loss = 0.29607475, step = 27101 (7.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0589\n",
      "INFO:tensorflow:loss = 0.18627496, step = 27201 (8.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4923\n",
      "INFO:tensorflow:loss = 0.2311076, step = 27301 (8.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4132\n",
      "INFO:tensorflow:loss = 0.38127902, step = 27401 (8.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5937\n",
      "INFO:tensorflow:loss = 0.32933748, step = 27501 (7.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4453\n",
      "INFO:tensorflow:loss = 0.26154804, step = 27601 (8.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.8694\n",
      "INFO:tensorflow:loss = 0.36456937, step = 27701 (8.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0781\n",
      "INFO:tensorflow:loss = 0.482314, step = 27801 (7.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4254\n",
      "INFO:tensorflow:loss = 0.23455542, step = 27901 (8.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3147\n",
      "INFO:tensorflow:loss = 0.28816834, step = 28001 (8.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1393\n",
      "INFO:tensorflow:loss = 0.1656293, step = 28101 (8.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.742\n",
      "INFO:tensorflow:loss = 0.3954946, step = 28201 (8.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6918\n",
      "INFO:tensorflow:loss = 0.36494926, step = 28301 (7.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9989\n",
      "INFO:tensorflow:loss = 0.3316595, step = 28401 (8.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3562\n",
      "INFO:tensorflow:loss = 0.6734752, step = 28501 (8.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.739\n",
      "INFO:tensorflow:loss = 0.25508496, step = 28601 (8.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3002\n",
      "INFO:tensorflow:loss = 0.2592364, step = 28701 (8.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2967\n",
      "INFO:tensorflow:loss = 0.26132184, step = 28801 (8.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0993\n",
      "INFO:tensorflow:loss = 0.3472357, step = 28901 (8.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4014\n",
      "INFO:tensorflow:loss = 0.4235342, step = 29001 (8.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3825\n",
      "INFO:tensorflow:loss = 0.33908933, step = 29101 (8.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3881\n",
      "INFO:tensorflow:loss = 0.33516985, step = 29201 (8.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8366\n",
      "INFO:tensorflow:loss = 0.26048627, step = 29301 (7.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2549\n",
      "INFO:tensorflow:loss = 0.33511177, step = 29401 (7.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.8037\n",
      "INFO:tensorflow:loss = 0.2985551, step = 29501 (8.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9609\n",
      "INFO:tensorflow:loss = 0.100484386, step = 29601 (8.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6774\n",
      "INFO:tensorflow:loss = 0.26226053, step = 29701 (8.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0863\n",
      "INFO:tensorflow:loss = 0.27602527, step = 29801 (8.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3257\n",
      "INFO:tensorflow:loss = 0.20466673, step = 29901 (8.667 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into gs://machine-learning-1234-bucket/gan/lsgan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 6.90808\n",
      "INFO:tensorflow:loss = 0.3244469, step = 30001 (13.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.8008\n",
      "INFO:tensorflow:loss = 0.23848905, step = 30101 (8.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3348\n",
      "INFO:tensorflow:loss = 0.28812948, step = 30201 (8.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4244\n",
      "INFO:tensorflow:loss = 0.31421816, step = 30301 (8.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9469\n",
      "INFO:tensorflow:loss = 0.21022807, step = 30401 (8.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7299\n",
      "INFO:tensorflow:loss = 0.37832826, step = 30501 (8.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3612\n",
      "INFO:tensorflow:loss = 0.29899478, step = 30601 (8.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6101\n",
      "INFO:tensorflow:loss = 0.39500344, step = 30701 (8.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.8857\n",
      "INFO:tensorflow:loss = 0.4289522, step = 30801 (8.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7065\n",
      "INFO:tensorflow:loss = 0.5524996, step = 30901 (8.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2051\n",
      "INFO:tensorflow:loss = 0.3454414, step = 31001 (7.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7375\n",
      "INFO:tensorflow:loss = 0.31803763, step = 31101 (8.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2868\n",
      "INFO:tensorflow:loss = 0.38530594, step = 31201 (8.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6879\n",
      "INFO:tensorflow:loss = 0.39775687, step = 31301 (8.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7038\n",
      "INFO:tensorflow:loss = 0.32379985, step = 31401 (8.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0228\n",
      "INFO:tensorflow:loss = 0.32090774, step = 31501 (8.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9431\n",
      "INFO:tensorflow:loss = 0.22765434, step = 31601 (8.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6528\n",
      "INFO:tensorflow:loss = 0.3356834, step = 31701 (7.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7503\n",
      "INFO:tensorflow:loss = 0.27093664, step = 31801 (8.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4656\n",
      "INFO:tensorflow:loss = 0.20276628, step = 31901 (8.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9408\n",
      "INFO:tensorflow:loss = 0.2894476, step = 32001 (8.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2769\n",
      "INFO:tensorflow:loss = 0.3090152, step = 32101 (8.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1899\n",
      "INFO:tensorflow:loss = 0.3561461, step = 32201 (8.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0959\n",
      "INFO:tensorflow:loss = 0.4085647, step = 32301 (8.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6459\n",
      "INFO:tensorflow:loss = 0.45470655, step = 32401 (8.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7376\n",
      "INFO:tensorflow:loss = 0.25037587, step = 32501 (8.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.76\n",
      "INFO:tensorflow:loss = 0.3131534, step = 32601 (7.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4852\n",
      "INFO:tensorflow:loss = 0.55799484, step = 32701 (8.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.8613\n",
      "INFO:tensorflow:loss = 0.3530481, step = 32801 (9.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4115\n",
      "INFO:tensorflow:loss = 0.36203015, step = 32901 (8.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5091\n",
      "INFO:tensorflow:loss = 0.24365942, step = 33001 (8.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9868\n",
      "INFO:tensorflow:loss = 0.34489504, step = 33101 (8.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9582\n",
      "INFO:tensorflow:loss = 0.21091735, step = 33201 (7.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2576\n",
      "INFO:tensorflow:loss = 0.23969626, step = 33301 (8.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0027\n",
      "INFO:tensorflow:loss = 0.29337573, step = 33401 (8.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4597\n",
      "INFO:tensorflow:loss = 0.25297475, step = 33501 (8.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2339\n",
      "INFO:tensorflow:loss = 0.26195765, step = 33601 (8.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5518\n",
      "INFO:tensorflow:loss = 0.27340344, step = 33701 (8.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3566\n",
      "INFO:tensorflow:loss = 0.3947577, step = 33801 (8.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3057\n",
      "INFO:tensorflow:loss = 0.32005623, step = 33901 (7.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4323\n",
      "INFO:tensorflow:loss = 0.17988464, step = 34001 (8.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8426\n",
      "INFO:tensorflow:loss = 0.28068542, step = 34101 (7.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7245\n",
      "INFO:tensorflow:loss = 0.31245348, step = 34201 (7.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0263\n",
      "INFO:tensorflow:loss = 0.31369266, step = 34301 (8.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9668\n",
      "INFO:tensorflow:loss = 0.3752254, step = 34401 (7.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3241\n",
      "INFO:tensorflow:loss = 0.38057104, step = 34501 (8.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6858\n",
      "INFO:tensorflow:loss = 0.27641505, step = 34601 (7.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7784\n",
      "INFO:tensorflow:loss = 0.26343912, step = 34701 (7.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6759\n",
      "INFO:tensorflow:loss = 0.31629393, step = 34801 (8.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2639\n",
      "INFO:tensorflow:loss = 0.34470904, step = 34901 (8.154 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 35000 into gs://machine-learning-1234-bucket/gan/lsgan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 7.05039\n",
      "INFO:tensorflow:loss = 0.27749282, step = 35001 (14.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0435\n",
      "INFO:tensorflow:loss = 0.37875742, step = 35101 (7.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7063\n",
      "INFO:tensorflow:loss = 0.36440745, step = 35201 (8.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1211\n",
      "INFO:tensorflow:loss = 0.38139263, step = 35301 (8.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5803\n",
      "INFO:tensorflow:loss = 0.32522443, step = 35401 (7.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2103\n",
      "INFO:tensorflow:loss = 0.33504373, step = 35501 (8.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0279\n",
      "INFO:tensorflow:loss = 0.39570916, step = 35601 (8.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0471\n",
      "INFO:tensorflow:loss = 0.25710028, step = 35701 (8.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.75211\n",
      "INFO:tensorflow:loss = 0.33682615, step = 35801 (9.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.8735\n",
      "INFO:tensorflow:loss = 0.34123898, step = 35901 (8.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9134\n",
      "INFO:tensorflow:loss = 0.25881767, step = 36001 (8.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6843\n",
      "INFO:tensorflow:loss = 0.3064004, step = 36101 (8.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9883\n",
      "INFO:tensorflow:loss = 0.27285665, step = 36201 (8.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9682\n",
      "INFO:tensorflow:loss = 0.19893049, step = 36301 (8.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9306\n",
      "INFO:tensorflow:loss = 0.2930518, step = 36401 (8.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7818\n",
      "INFO:tensorflow:loss = 0.31170934, step = 36501 (7.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9067\n",
      "INFO:tensorflow:loss = 0.27004486, step = 36601 (8.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9496\n",
      "INFO:tensorflow:loss = 0.43379387, step = 36701 (7.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9374\n",
      "INFO:tensorflow:loss = 0.38557994, step = 36801 (7.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4844\n",
      "INFO:tensorflow:loss = 0.24704058, step = 36901 (7.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4116\n",
      "INFO:tensorflow:loss = 0.29565853, step = 37001 (8.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9702\n",
      "INFO:tensorflow:loss = 0.38029182, step = 37101 (8.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9485\n",
      "INFO:tensorflow:loss = 0.26437697, step = 37201 (9.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6586\n",
      "INFO:tensorflow:loss = 0.41368937, step = 37301 (7.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7533\n",
      "INFO:tensorflow:loss = 0.2291722, step = 37401 (8.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.811\n",
      "INFO:tensorflow:loss = 0.31316698, step = 37501 (8.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3496\n",
      "INFO:tensorflow:loss = 0.46380872, step = 37601 (8.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.804\n",
      "INFO:tensorflow:loss = 0.30912974, step = 37701 (8.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.8819\n",
      "INFO:tensorflow:loss = 0.15490147, step = 37801 (8.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6594\n",
      "INFO:tensorflow:loss = 0.37494338, step = 37901 (8.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2353\n",
      "INFO:tensorflow:loss = 0.2505251, step = 38001 (8.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6715\n",
      "INFO:tensorflow:loss = 0.23252274, step = 38101 (8.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8782\n",
      "INFO:tensorflow:loss = 0.38576412, step = 38201 (7.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2344\n",
      "INFO:tensorflow:loss = 0.31719342, step = 38301 (8.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5834\n",
      "INFO:tensorflow:loss = 0.39327154, step = 38401 (7.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7266\n",
      "INFO:tensorflow:loss = 0.35690254, step = 38501 (7.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9508\n",
      "INFO:tensorflow:loss = 0.24394521, step = 38601 (8.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3227\n",
      "INFO:tensorflow:loss = 0.26563153, step = 38701 (8.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8872\n",
      "INFO:tensorflow:loss = 0.32876882, step = 38801 (8.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9467\n",
      "INFO:tensorflow:loss = 0.2090739, step = 38901 (8.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.092\n",
      "INFO:tensorflow:loss = 0.33915386, step = 39001 (8.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5847\n",
      "INFO:tensorflow:loss = 0.23024465, step = 39101 (7.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7472\n",
      "INFO:tensorflow:loss = 0.2925889, step = 39201 (7.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7399\n",
      "INFO:tensorflow:loss = 0.3671609, step = 39301 (8.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.542\n",
      "INFO:tensorflow:loss = 0.22987852, step = 39401 (7.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2769\n",
      "INFO:tensorflow:loss = 0.18977235, step = 39501 (8.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8962\n",
      "INFO:tensorflow:loss = 0.37675393, step = 39601 (7.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7617\n",
      "INFO:tensorflow:loss = 0.34657595, step = 39701 (7.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1654\n",
      "INFO:tensorflow:loss = 0.3749953, step = 39801 (7.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3622\n",
      "INFO:tensorflow:loss = 0.22956367, step = 39901 (8.092 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into gs://machine-learning-1234-bucket/gan/lsgan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(28, 28, 1), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "lsgan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 28, 28, 1) dtype=float32>}\n",
      "lsgan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "lsgan_model: mode = eval\n",
      "lsgan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/lsgan/trained_model', 'train_batch_size': 32, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 16, 'eval_steps': 10, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 100, 'generator_projection_dims': [7, 7, 256], 'generator_num_filters': [128, 64, 1], 'generator_kernel_sizes': [4, 4, 7], 'generator_strides': [2, 2, 1], 'generator_use_batch_norm': [True, True], 'generator_use_leaky_relu': False, 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_num_filters': [64, 128], 'discriminator_kernel_sizes': [4, 4], 'discriminator_strides': [2, 2], 'discriminator_use_batch_norm': [True, True], 'discriminator_use_leaky_relu': True, 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'loss_a': 0.0, 'loss_b': 1.0, 'loss_c': 1.0}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 100), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 100), dtype=float32).\n",
      "\n",
      "get_fake_images: network = Tensor(\"random_normal:0\", shape=(?, 100), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: projection_activation = Tensor(\"generator/projection_relu:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 7, 7, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/relu_0:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/relu_1:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "get_logits_and_losses: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "\n",
      "Call discriminator with fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_conv2d_0/BiasAdd:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_0:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_conv2d_1/BiasAdd:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_1:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network_flat = Tensor(\"discriminator/flatten/Reshape:0\", shape=(?, 6272), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call discriminator with real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_conv2d_0/BiasAdd:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_0:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_conv2d_1/BiasAdd:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_1:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network_flat = Tensor(\"discriminator_1/flatten/Reshape:0\", shape=(?, 6272), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"mean_squared_error/value:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"mean_squared_error_1/value:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_fake_loss = Tensor(\"mean_squared_error_2/value:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_eval_metric_ops: discriminator_logits = Tensor(\"discriminator_concat_logits:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_labels = Tensor(\"discriminator_concat_labels:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_probabilities = Tensor(\"discriminator_probabilities:0\", shape=(?, 1), dtype=float32)\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "get_eval_metric_ops: eval_metric_ops = {'accuracy': (<tf.Tensor 'discriminator_accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_accuracy/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'discriminator_precision/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'discriminator_recall/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_recall/update_op:0' shape=() dtype=float32>), 'auc_roc': (<tf.Tensor 'discriminator_auc_roc/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_roc/update_op:0' shape=() dtype=float32>), 'auc_pr': (<tf.Tensor 'discriminator_auc_pr/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_pr/update_op:0' shape=() dtype=float32>)}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-25T01:32:26Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/lsgan/trained_model/model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-25-01:32:29\n",
      "INFO:tensorflow:Saving dict for global step 40000: accuracy = 0.0, auc_pr = 0.76481545, auc_roc = 0.8002539, global_step = 40000, loss = 0.50249183, precision = 0.5, recall = 1.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40000: gs://machine-learning-1234-bucket/gan/lsgan/trained_model/model.ckpt-40000\n",
      "\n",
      "serving_input_fn: feature_placeholders = {'Z': <tf.Tensor 'serving_input_placeholder_Z:0' shape=(?, 100) dtype=float32>}\n",
      "serving_input_fn: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 100) dtype=float32>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "lsgan_model: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 100) dtype=float32>}\n",
      "lsgan_model: labels = None\n",
      "lsgan_model: mode = infer\n",
      "lsgan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/lsgan/trained_model', 'train_batch_size': 32, 'train_steps': 40000, 'save_summary_steps': 100, 'save_checkpoints_steps': 5000, 'keep_checkpoint_max': 10, 'eval_batch_size': 16, 'eval_steps': 10, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 100, 'generator_projection_dims': [7, 7, 256], 'generator_num_filters': [128, 64, 1], 'generator_kernel_sizes': [4, 4, 7], 'generator_strides': [2, 2, 1], 'generator_use_batch_norm': [True, True], 'generator_use_leaky_relu': False, 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_num_filters': [64, 128], 'discriminator_kernel_sizes': [4, 4], 'discriminator_strides': [2, 2], 'discriminator_use_batch_norm': [True, True], 'discriminator_use_leaky_relu': True, 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'loss_a': 0.0, 'loss_b': 1.0, 'loss_c': 1.0}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_predictions_and_export_outputs: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 100), dtype=float32)\n",
      "\n",
      "get_fake_images: network = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 100), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: projection_activation = Tensor(\"generator/projection_relu:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 7, 7, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/relu_0:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/relu_1:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "get_predictions_and_export_outputs: generated_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "get_predictions_and_export_outputs: predictions_dict = {'generated_images': <tf.Tensor 'generator/layers_conv2d_tranpose_fake_images/Tanh:0' shape=(?, 28, 28, 1) dtype=float32>}\n",
      "get_predictions_and_export_outputs: export_outputs = {'predict_export_outputs': <tensorflow.python.saved_model.model_utils.export_output.PredictOutput object at 0x7fe45c076a10>}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/lsgan/trained_model/model.ckpt-40000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://machine-learning-1234-bucket/gan/lsgan/trained_model/export/exporter/temp-b'1593048749'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 0.5560198.\n"
     ]
    }
   ],
   "source": [
    "estimator = train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://machine-learning-1234-bucket/gan/lsgan/trained_model/export/exporter/\n",
      "gs://machine-learning-1234-bucket/gan/lsgan/trained_model/export/exporter/1593045827/\n",
      "gs://machine-learning-1234-bucket/gan/lsgan/trained_model/export/exporter/1593048749/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://machine-learning-1234-bucket/gan/lsgan/trained_model/export/exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/lsgan/trained_model/export/exporter/1593048749/variables/variables\n"
     ]
    }
   ],
   "source": [
    "predict_fn = tf.contrib.predictor.from_saved_model(\n",
    "    \"gs://machine-learning-1234-bucket/gan/lsgan/trained_model/export/exporter/1593048749\"\n",
    ")\n",
    "predictions = predict_fn(\n",
    "    {\n",
    "        \"Z\": np.random.normal(size=(10, arguments[\"latent_size\"]))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = np.clip(\n",
    "    a=((predictions[\"generated_images\"] + 1.0) * (255. / 2)).astype(np.int32),\n",
    "    a_min=0,\n",
    "    a_max=255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(generated_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, color=True):\n",
    "    \"\"\"Plots images.\n",
    "\n",
    "    Args:\n",
    "        images: np.array, array of images of\n",
    "            [num_images, image_size, image_size, num_channels].\n",
    "    \"\"\"\n",
    "    num_images = len(images)\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(num_images):\n",
    "        image = images[i]\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        if color:\n",
    "            plt.imshow(\n",
    "                image,\n",
    "                cmap=plt.cm.binary\n",
    "            )\n",
    "        else:\n",
    "            plt.imshow(\n",
    "                image.reshape(image.shape[:-1]),\n",
    "                cmap=\"gray_r\"\n",
    "            )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(images=generated_images, color=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
