{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model module locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Import os environment variables for file hyperparameters.\n",
    "os.environ[\"TRAIN_FILE_PATTERN\"] = \"gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord\"\n",
    "os.environ[\"EVAL_FILE_PATTERN\"] = \"gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord\"\n",
    "os.environ[\"OUTPUT_DIR\"] = \"gs://machine-learning-1234-bucket/gan/lsgan/trained_model2\"\n",
    "\n",
    "# Import os environment variables for train hyperparameters.\n",
    "os.environ[\"TRAIN_BATCH_SIZE\"] = str(16)\n",
    "os.environ[\"TRAIN_STEPS\"] = str(200)\n",
    "os.environ[\"SAVE_SUMMARY_STEPS\"] = str(100)\n",
    "os.environ[\"SAVE_CHECKPOINTS_STEPS\"] = str(1000)\n",
    "os.environ[\"KEEP_CHECKPOINT_MAX\"] = str(10)\n",
    "\n",
    "# Import os environment variables for eval hyperparameters.\n",
    "os.environ[\"EVAL_BATCH_SIZE\"] = str(32)\n",
    "os.environ[\"EVAL_STEPS\"] = str(100)\n",
    "os.environ[\"START_DELAY_SECS\"] = str(60)\n",
    "os.environ[\"THROTTLE_SECS\"] = str(120)\n",
    "\n",
    "# Import os environment variables for image hyperparameters.\n",
    "os.environ[\"HEIGHT\"] = str(28)\n",
    "os.environ[\"WIDTH\"] = str(28)\n",
    "depth = 1\n",
    "os.environ[\"DEPTH\"] = str(depth)\n",
    "\n",
    "# Import os environment variables for generator hyperparameters.\n",
    "os.environ[\"LATENT_SIZE\"] = str(1024)\n",
    "os.environ[\"GENERATOR_PROJECTION_DIMS\"] = \"7,7,256\"\n",
    "os.environ[\"GENERATOR_NUM_FILTERS\"] = \"128,64,{}\".format(depth)\n",
    "os.environ[\"GENERATOR_KERNEL_SIZES\"] = \"4,4,7\"\n",
    "os.environ[\"GENERATOR_STRIDES\"] = \"2,2,1\"\n",
    "os.environ[\"GENERATOR_USE_BATCH_NORM\"] = \"true,true\"\n",
    "os.environ[\"GENERATOR_BATCH_NORM_BEFORE_ACT\"] = \"false\"\n",
    "os.environ[\"GENERATOR_USE_LEAKY_RELU\"] = \"false\"\n",
    "os.environ[\"GENERATOR_LEAKY_RELU_ALPHA\"] = str(0.2)\n",
    "os.environ[\"GENERATOR_FINAL_ACTIVATION\"] = \"tanh\"\n",
    "os.environ[\"GENERATOR_L1_REGULARIZATION_SCALE\"] = str(0.)\n",
    "os.environ[\"GENERATOR_L2_REGULARIZATION_SCALE\"] = str(0.)\n",
    "os.environ[\"GENERATOR_OPTIMIZER\"] = \"Adam\"\n",
    "os.environ[\"GENERATOR_LEARNING_RATE\"] = str(0.0002)\n",
    "os.environ[\"GENERATOR_ADAM_BETA1\"] = str(0.5)\n",
    "os.environ[\"GENERATOR_ADAM_BETA2\"] = str(0.999)\n",
    "os.environ[\"GENERATOR_ADAM_EPSILON\"] = str(1e-8)\n",
    "os.environ[\"GENERATOR_CLIP_GRADIENTS\"] = \"None\"\n",
    "os.environ[\"GENERATOR_TRAIN_STEPS\"] = str(1)\n",
    "\n",
    "# Import os environment variables for discriminator hyperparameters.\n",
    "os.environ[\"DISCRIMINATOR_NUM_FILTERS\"] = \"64,128\"\n",
    "os.environ[\"DISCRIMINATOR_KERNEL_SIZES\"] = \"4,4\"\n",
    "os.environ[\"DISCRIMINATOR_STRIDES\"] = \"2,2\"\n",
    "os.environ[\"DISCRIMINATOR_USE_BATCH_NORM\"] = \"true,true\"\n",
    "os.environ[\"DISCRIMINATOR_BATCH_NORM_BEFORE_ACT\"] = \"false\"\n",
    "os.environ[\"DISCRIMINATOR_USE_LEAKY_RELU\"] = \"true\"\n",
    "os.environ[\"DISCRIMINATOR_LEAKY_RELU_ALPHA\"] = str(0.2)\n",
    "os.environ[\"DISCRIMINATOR_L1_REGULARIZATION_SCALE\"] = str(0.)\n",
    "os.environ[\"DISCRIMINATOR_L2_REGULARIZATION_SCALE\"] = str(0.)\n",
    "os.environ[\"DISCRIMINATOR_OPTIMIZER\"] = \"Adam\"\n",
    "os.environ[\"DISCRIMINATOR_LEARNING_RATE\"] = str(0.0002)\n",
    "os.environ[\"DISCRIMINATOR_ADAM_BETA1\"] = str(0.5)\n",
    "os.environ[\"DISCRIMINATOR_ADAM_BETA2\"] = str(0.999)\n",
    "os.environ[\"DISCRIMINATOR_ADAM_EPSILON\"] = str(1e-8)\n",
    "os.environ[\"DISCRIMINATOR_CLIP_GRADIENTS\"] = \"None\"\n",
    "os.environ[\"DISCRIMINATOR_TRAIN_STEPS\"] = str(1)\n",
    "\n",
    "# Import os environment variables for loss hyperparameters.\n",
    "os.environ[\"DISCRIMINATOR_LOSS_A\"] = str(0.0)\n",
    "os.environ[\"DISCRIMINATOR_LOSS_B\"] = str(1.0)\n",
    "os.environ[\"DISCRIMINATOR_LOSS_C\"] = str(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train lsgan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_and_evaluate: args = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/', 'train_batch_size': 16, 'train_steps': 200, 'save_summary_steps': 100, 'save_checkpoints_steps': 1000, 'keep_checkpoint_max': 10, 'eval_batch_size': 32, 'eval_steps': 100, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 1024, 'generator_projection_dims': [7, 7, 256], 'generator_num_filters': [128, 64, 1], 'generator_kernel_sizes': [4, 4, 7], 'generator_strides': [2, 2, 1], 'generator_use_batch_norm': [True, True], 'generator_use_leaky_relu': False, 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_num_filters': [64, 128], 'discriminator_kernel_sizes': [4, 4], 'discriminator_strides': [2, 2], 'discriminator_use_batch_norm': [True, True], 'discriminator_use_leaky_relu': True, 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'loss_a': 0.0, 'loss_b': 1.0, 'loss_c': 1.0}\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(28, 28, 1), dtype=uint8)\n",
      "\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "\n",
      "lsgan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 28, 28, 1) dtype=float32>}\n",
      "lsgan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "lsgan_model: mode = train\n",
      "lsgan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/', 'train_batch_size': 16, 'train_steps': 200, 'save_summary_steps': 100, 'save_checkpoints_steps': 1000, 'keep_checkpoint_max': 10, 'eval_batch_size': 32, 'eval_steps': 100, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 1024, 'generator_projection_dims': [7, 7, 256], 'generator_num_filters': [128, 64, 1], 'generator_kernel_sizes': [4, 4, 7], 'generator_strides': [2, 2, 1], 'generator_use_batch_norm': [True, True], 'generator_use_leaky_relu': False, 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_num_filters': [64, 128], 'discriminator_kernel_sizes': [4, 4], 'discriminator_strides': [2, 2], 'discriminator_use_batch_norm': [True, True], 'discriminator_use_leaky_relu': True, 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'loss_a': 0.0, 'loss_b': 1.0, 'loss_c': 1.0}\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 1024), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 1024), dtype=float32).\n",
      "\n",
      "get_fake_images: network = Tensor(\"random_normal:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: projection_activation = Tensor(\"generator/projection_relu:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 7, 7, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/relu_0:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/relu_1:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "get_logits_and_losses: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "\n",
      "Call discriminator with fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_conv2d_0/BiasAdd:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_0:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_conv2d_1/BiasAdd:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_1:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network_flat = Tensor(\"discriminator/flatten/Reshape:0\", shape=(?, 6272), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call discriminator with real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_conv2d_0/BiasAdd:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_0:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_conv2d_1/BiasAdd:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_1:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network_flat = Tensor(\"discriminator_1/flatten/Reshape:0\", shape=(?, 6272), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"mean_squared_error/value:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"mean_squared_error_1/value:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_fake_loss = Tensor(\"mean_squared_error_2/value:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_variables_and_gradients_generator: variables = [<tf.Variable 'generator/projection_dense_layer/kernel:0' shape=(1024, 12544) dtype=float32_ref>, <tf.Variable 'generator/projection_dense_layer/bias:0' shape=(12544,) dtype=float32_ref>, <tf.Variable 'generator/projection_batch_norm/gamma:0' shape=(12544,) dtype=float32_ref>, <tf.Variable 'generator/projection_batch_norm/beta:0' shape=(12544,) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_0/kernel:0' shape=(4, 4, 128, 256) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_0/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'generator/layers_batch_norm_0/gamma:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'generator/layers_batch_norm_0/beta:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_1/kernel:0' shape=(4, 4, 64, 128) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_1/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'generator/layers_batch_norm_1/gamma:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'generator/layers_batch_norm_1/beta:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_fake_images/kernel:0' shape=(7, 7, 1, 64) dtype=float32_ref>, <tf.Variable 'generator/layers_conv2d_tranpose_fake_images/bias:0' shape=(1,) dtype=float32_ref>]\n",
      "\n",
      "get_variables_and_gradients_generator: gradients = [<tf.Tensor 'generator_gradients/generator/projection_dense_layer/MatMul_grad/MatMul_1:0' shape=(1024, 12544) dtype=float32>, <tf.Tensor 'generator_gradients/generator/projection_dense_layer/BiasAdd_grad/BiasAddGrad:0' shape=(12544,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/projection_batch_norm/batchnorm/mul_grad/Mul_1:0' shape=(12544,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/projection_batch_norm/batchnorm/add_1_grad/Reshape_1:0' shape=(12544,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_0/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(4, 4, 128, 256) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_0/BiasAdd_grad/BiasAddGrad:0' shape=(128,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_batch_norm_0/FusedBatchNormV3_grad/FusedBatchNormGradV3:1' shape=(128,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_batch_norm_0/FusedBatchNormV3_grad/FusedBatchNormGradV3:2' shape=(128,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_1/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(4, 4, 64, 128) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_1/BiasAdd_grad/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_batch_norm_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:1' shape=(64,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_batch_norm_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:2' shape=(64,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_fake_images/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(7, 7, 1, 64) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_conv2d_tranpose_fake_images/BiasAdd_grad/BiasAddGrad:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "get_variables_and_gradients_generator: gradients = [<tf.Tensor 'get_variables_and_gradients_generator/projection_dense_layer/kernel_gradients:0' shape=(1024, 12544) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/projection_dense_layer/bias_gradients:0' shape=(12544,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/projection_batch_norm/gamma_gradients:0' shape=(12544,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/projection_batch_norm/beta_gradients:0' shape=(12544,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_0/kernel_gradients:0' shape=(4, 4, 128, 256) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_0/bias_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_batch_norm_0/gamma_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_batch_norm_0/beta_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_1/kernel_gradients:0' shape=(4, 4, 64, 128) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_1/bias_gradients:0' shape=(64,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_batch_norm_1/gamma_gradients:0' shape=(64,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_batch_norm_1/beta_gradients:0' shape=(64,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_fake_images/kernel_gradients:0' shape=(7, 7, 1, 64) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_conv2d_tranpose_fake_images/bias_gradients:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "get_variables_and_gradients_discriminator: variables = [<tf.Variable 'discriminator/layers_conv2d_0/kernel:0' shape=(4, 4, 1, 64) dtype=float32_ref>, <tf.Variable 'discriminator/layers_conv2d_0/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'discriminator/layers_batch_norm_0/gamma:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'discriminator/layers_batch_norm_0/beta:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'discriminator/layers_conv2d_1/kernel:0' shape=(4, 4, 64, 128) dtype=float32_ref>, <tf.Variable 'discriminator/layers_conv2d_1/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'discriminator/layers_batch_norm_1/gamma:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'discriminator/layers_batch_norm_1/beta:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'discriminator/layers_dense_logits/kernel:0' shape=(6272, 1) dtype=float32_ref>, <tf.Variable 'discriminator/layers_dense_logits/bias:0' shape=(1,) dtype=float32_ref>]\n",
      "\n",
      "get_variables_and_gradients_discriminator: gradients = [<tf.Tensor 'discriminator_gradients/AddN_9:0' shape=(4, 4, 1, 64) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_8:0' shape=(64,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_6:0' shape=(64,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_7:0' shape=(64,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_5:0' shape=(4, 4, 64, 128) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_4:0' shape=(128,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_2:0' shape=(128,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_3:0' shape=(128,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_1:0' shape=(6272, 1) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "get_variables_and_gradients_discriminator: gradients = [<tf.Tensor 'get_variables_and_gradients_discriminator/layers_conv2d_0/kernel_gradients:0' shape=(4, 4, 1, 64) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_conv2d_0/bias_gradients:0' shape=(64,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_batch_norm_0/gamma_gradients:0' shape=(64,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_batch_norm_0/beta_gradients:0' shape=(64,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_conv2d_1/kernel_gradients:0' shape=(4, 4, 64, 128) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_conv2d_1/bias_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_batch_norm_1/gamma_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_batch_norm_1/beta_gradients:0' shape=(128,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_logits/kernel_gradients:0' shape=(6272, 1) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_logits/bias_gradients:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "train_network: scope = discriminator\n",
      "train_network_discriminator: optimizer = <tensorflow.python.training.adam.AdamOptimizer object at 0x7ff17c787a50>\n",
      "\n",
      "train_network_discriminator: gradients = [<tf.Tensor 'cond/discriminator_gradients/AddN_9:0' shape=(4, 4, 1, 64) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_8:0' shape=(64,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_6:0' shape=(64,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_7:0' shape=(64,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_5:0' shape=(4, 4, 64, 128) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_4:0' shape=(128,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_2:0' shape=(128,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_3:0' shape=(128,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_1:0' shape=(6272, 1) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN:0' shape=(1,) dtype=float32>]\n",
      "train_network_discriminator: grads_and_vars = <zip object at 0x7ff17c7a2320>\n",
      "\n",
      "train_network: scope = generator\n",
      "train_network_generator: optimizer = <tensorflow.python.training.adam.AdamOptimizer object at 0x7ff17c79fe10>\n",
      "\n",
      "train_network_generator: gradients = [<tf.Tensor 'cond/generator_gradients/generator/projection_dense_layer/MatMul_grad/MatMul_1:0' shape=(1024, 12544) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/projection_dense_layer/BiasAdd_grad/BiasAddGrad:0' shape=(12544,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/projection_batch_norm/batchnorm/mul_grad/Mul_1:0' shape=(12544,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/projection_batch_norm/batchnorm/add_1_grad/Reshape_1:0' shape=(12544,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_0/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(4, 4, 128, 256) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_0/BiasAdd_grad/BiasAddGrad:0' shape=(128,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_batch_norm_0/FusedBatchNormV3_grad/FusedBatchNormGradV3:1' shape=(128,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_batch_norm_0/FusedBatchNormV3_grad/FusedBatchNormGradV3:2' shape=(128,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_1/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(4, 4, 64, 128) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_1/BiasAdd_grad/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_batch_norm_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:1' shape=(64,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_batch_norm_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:2' shape=(64,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_fake_images/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(7, 7, 1, 64) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_conv2d_tranpose_fake_images/BiasAdd_grad/BiasAddGrad:0' shape=(1,) dtype=float32>]\n",
      "train_network_generator: grads_and_vars = <zip object at 0x7ff17c7739b0>\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(28, 28, 1), dtype=uint8)\n",
      "\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "\n",
      "lsgan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 28, 28, 1) dtype=float32>}\n",
      "lsgan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "lsgan_model: mode = eval\n",
      "lsgan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/', 'train_batch_size': 16, 'train_steps': 200, 'save_summary_steps': 100, 'save_checkpoints_steps': 1000, 'keep_checkpoint_max': 10, 'eval_batch_size': 32, 'eval_steps': 100, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 1024, 'generator_projection_dims': [7, 7, 256], 'generator_num_filters': [128, 64, 1], 'generator_kernel_sizes': [4, 4, 7], 'generator_strides': [2, 2, 1], 'generator_use_batch_norm': [True, True], 'generator_use_leaky_relu': False, 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_num_filters': [64, 128], 'discriminator_kernel_sizes': [4, 4], 'discriminator_strides': [2, 2], 'discriminator_use_batch_norm': [True, True], 'discriminator_use_leaky_relu': True, 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'loss_a': 0.0, 'loss_b': 1.0, 'loss_c': 1.0}\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 1024), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 1024), dtype=float32).\n",
      "\n",
      "get_fake_images: network = Tensor(\"random_normal:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: projection_activation = Tensor(\"generator/projection_relu:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 7, 7, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/relu_0:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/relu_1:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "get_logits_and_losses: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "\n",
      "Call discriminator with fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_conv2d_0/BiasAdd:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_0:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_conv2d_1/BiasAdd:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_1:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network_flat = Tensor(\"discriminator/flatten/Reshape:0\", shape=(?, 6272), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call discriminator with real_images = Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_conv2d_0/BiasAdd:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_0:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_conv2d_1/BiasAdd:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_1:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "get_discriminator_logits: network_flat = Tensor(\"discriminator_1/flatten/Reshape:0\", shape=(?, 6272), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"mean_squared_error/value:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"mean_squared_error_1/value:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_fake_loss = Tensor(\"mean_squared_error_2/value:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_eval_metric_ops: discriminator_logits = Tensor(\"discriminator_concat_logits:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_labels = Tensor(\"discriminator_concat_labels:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_probabilities = Tensor(\"discriminator_probabilities:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: eval_metric_ops = {'accuracy': (<tf.Tensor 'discriminator_accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_accuracy/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'discriminator_precision/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'discriminator_recall/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_recall/update_op:0' shape=() dtype=float32>), 'auc_roc': (<tf.Tensor 'discriminator_auc_roc/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_roc/update_op:0' shape=() dtype=float32>), 'auc_pr': (<tf.Tensor 'discriminator_auc_pr/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_pr/update_op:0' shape=() dtype=float32>)}\n",
      "\n",
      "serving_input_fn: feature_placeholders = {'Z': <tf.Tensor 'serving_input_placeholder_Z:0' shape=(?, 1024) dtype=float32>}\n",
      "serving_input_fn: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 1024) dtype=float32>}\n",
      "\n",
      "lsgan_model: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 1024) dtype=float32>}\n",
      "lsgan_model: labels = None\n",
      "lsgan_model: mode = infer\n",
      "lsgan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/', 'train_batch_size': 16, 'train_steps': 200, 'save_summary_steps': 100, 'save_checkpoints_steps': 1000, 'keep_checkpoint_max': 10, 'eval_batch_size': 32, 'eval_steps': 100, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 1024, 'generator_projection_dims': [7, 7, 256], 'generator_num_filters': [128, 64, 1], 'generator_kernel_sizes': [4, 4, 7], 'generator_strides': [2, 2, 1], 'generator_use_batch_norm': [True, True], 'generator_use_leaky_relu': False, 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_num_filters': [64, 128], 'discriminator_kernel_sizes': [4, 4], 'discriminator_strides': [2, 2], 'discriminator_use_batch_norm': [True, True], 'discriminator_use_leaky_relu': True, 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'loss_a': 0.0, 'loss_b': 1.0, 'loss_c': 1.0}\n",
      "\n",
      "get_predictions_and_export_outputs: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 1024), dtype=float32)\n",
      "\n",
      "get_fake_images: network = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: projection = Tensor(\"generator/projection_dense_layer/BiasAdd:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: projection_activation = Tensor(\"generator/projection_relu:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: projection_batch_norm = Tensor(\"generator/projection_batch_norm/batchnorm/add_1:0\", shape=(?, 12544), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/projection_reshaped:0\", shape=(?, 7, 7, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_0/BiasAdd:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/relu_0:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_0/FusedBatchNormV3:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_conv2d_tranpose_1/BiasAdd:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/relu_1:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_batch_norm_1/FusedBatchNormV3:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "get_fake_images: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "\n",
      "resize_real_image: fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "resize_real_image: resized_fake_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "get_predictions_and_export_outputs: generated_images = Tensor(\"generator/layers_conv2d_tranpose_fake_images/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "get_predictions_and_export_outputs: predictions_dict = {'generated_images': <tf.Tensor 'generator/layers_conv2d_tranpose_fake_images/Tanh:0' shape=(?, 28, 28, 1) dtype=float32>}\n",
      "get_predictions_and_export_outputs: export_outputs = {'predict_export_outputs': <tensorflow.python.saved_model.model_utils.export_output.PredictOutput object at 0x7ff138789750>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/#1593044896227878...\n",
      "Removing gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/checkpoint#1593045073313200...\n",
      "Removing gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/events.out.tfevents.1593044896.tf-1-15#1593045075248425...\n",
      "Removing gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/graph.pbtxt#1593044901104943...\n",
      "Removing gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/model.ckpt-0.data-00000-of-00001#1593044905296945...\n",
      "Removing gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/model.ckpt-0.index#1593044905649779...\n",
      "Removing gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/model.ckpt-0.meta#1593044909356867...\n",
      "Removing gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/model.ckpt-200.data-00000-of-00001#1593045071752765...\n",
      "Removing gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/model.ckpt-200.meta#1593045074748050...\n",
      "Removing gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/model.ckpt-200.index#1593045072183681...\n",
      "/ [10/10 objects] 100% Done                                                     \n",
      "Operation completed over 10 objects.                                             \n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/model.py:21: The name tf.summary.FileWriterCache is deprecated. Please use tf.compat.v1.summary.FileWriterCache instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/model.py:24: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/model.py:24: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff18c79ac10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/input.py:82: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/input.py:94: shuffle_and_repeat (from tensorflow.contrib.data.python.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.shuffle_and_repeat(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/shuffle_ops.py:54: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/input.py:106: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/input.py:114: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/generator.py:57: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/generator.py:57: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/generator.py:73: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/generator.py:100: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/generator.py:140: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/train_and_eval.py:50: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/discriminator.py:71: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/discriminator.py:102: The name tf.layers.Flatten is deprecated. Please use tf.compat.v1.layers.Flatten instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/generator.py:198: The name tf.losses.mean_squared_error is deprecated. Please use tf.compat.v1.losses.mean_squared_error instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/generator.py:205: The name tf.losses.get_regularization_loss is deprecated. Please use tf.compat.v1.losses.get_regularization_loss instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/generator.py:220: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/train.py:16: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/train.py:54: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/train.py:162: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/train.py:165: The name tf.mod is deprecated. Please use tf.math.mod instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/train.py:183: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/train.py:183: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/train.py:84: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/train.py:85: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/train.py:86: The name tf.train.AdagradDAOptimizer is deprecated. Please use tf.compat.v1.train.AdagradDAOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/train.py:87: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/train.py:88: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/train.py:89: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/train.py:90: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/train.py:91: The name tf.train.ProximalAdagradOptimizer is deprecated. Please use tf.compat.v1.train.ProximalAdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/train.py:92: The name tf.train.ProximalGradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.ProximalGradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/train.py:93: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2020-06-25 00:36:48.039718: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200190000 Hz\n",
      "2020-06-25 00:36:48.040698: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563423be5810 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-06-25 00:36:48.041048: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-06-25 00:36:48.041292: I tensorflow/core/common_runtime/process_util.cc:136] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/model.ckpt.\n",
      "INFO:tensorflow:loss = 5.70704, step = 1\n",
      "INFO:tensorflow:global_step/sec: 4.30565\n",
      "INFO:tensorflow:loss = 2.055966, step = 101 (23.226 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/eval_metrics.py:48: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/eval_metrics.py:53: The name tf.metrics.precision is deprecated. Please use tf.compat.v1.metrics.precision instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/eval_metrics.py:58: The name tf.metrics.recall is deprecated. Please use tf.compat.v1.metrics.recall instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/eval_metrics.py:63: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\n",
      "\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-25T00:37:56Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-25-00:38:12\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.0, auc_pr = 0.99574184, auc_roc = 0.9954678, global_step = 200, loss = 1.5145744, precision = 0.5, recall = 1.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/model.ckpt-200\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/lsgan/lsgan_module/trainer/serving.py:19: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/model.ckpt-200\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://machine-learning-1234-bucket/gan/lsgan/trained_model2/export/exporter/temp-b'1593045495'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 1.0230224.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil -m rm -rf ${OUTPUT_DIR}\n",
    "export PYTHONPATH=$PYTHONPATH:$PWD/lsgan_module\n",
    "python3 -m trainer.task \\\n",
    "    --train_file_pattern=${TRAIN_FILE_PATTERN} \\\n",
    "    --eval_file_pattern=${EVAL_FILE_PATTERN} \\\n",
    "    --output_dir=${OUTPUT_DIR} \\\n",
    "    --job-dir=./tmp \\\n",
    "    \\\n",
    "    --train_batch_size=${TRAIN_BATCH_SIZE} \\\n",
    "    --train_steps=${TRAIN_STEPS} \\\n",
    "    --save_summary_steps=${SAVE_SUMMARY_STEPS} \\\n",
    "    --save_checkpoints_steps=${SAVE_CHECKPOINTS_STEPS} \\\n",
    "    --keep_checkpoint_max=${KEEP_CHECKPOINT_MAX} \\\n",
    "    \\\n",
    "    --eval_batch_size=${EVAL_BATCH_SIZE} \\\n",
    "    --eval_steps=${EVAL_STEPS} \\\n",
    "    --start_delay_secs=${START_DELAY_SECS} \\\n",
    "    --throttle_secs=${THROTTLE_SECS} \\\n",
    "    \\\n",
    "    --height=${HEIGHT} \\\n",
    "    --width=${WIDTH} \\\n",
    "    --depth=${DEPTH} \\\n",
    "    \\\n",
    "    --latent_size=${LATENT_SIZE} \\\n",
    "    --generator_projection_dims=${GENERATOR_PROJECTION_DIMS} \\\n",
    "    --generator_num_filters=${GENERATOR_NUM_FILTERS} \\\n",
    "    --generator_kernel_sizes=${GENERATOR_KERNEL_SIZES} \\\n",
    "    --generator_strides=${GENERATOR_STRIDES} \\\n",
    "    --generator_use_batch_norm=${GENERATOR_USE_BATCH_NORM} \\\n",
    "    --generator_batch_norm_before_act=${GENERATOR_BATCH_NORM_BEFORE_ACT} \\\n",
    "    --generator_use_leaky_relu=${GENERATOR_USE_LEAKY_RELU} \\\n",
    "    --generator_leaky_relu_alpha=${GENERATOR_LEAKY_RELU_ALPHA} \\\n",
    "    --generator_final_activation=${GENERATOR_FINAL_ACTIVATION} \\\n",
    "    --generator_l1_regularization_scale=${GENERATOR_L1_REGULARIZATION_SCALE} \\\n",
    "    --generator_l2_regularization_scale=${GENERATOR_L2_REGULARIZATION_SCALE} \\\n",
    "    --generator_optimizer=${GENERATOR_OPTIMIZER} \\\n",
    "    --generator_learning_rate=${GENERATOR_LEARNING_RATE} \\\n",
    "    --generator_adam_beta1=${GENERATOR_ADAM_BETA1} \\\n",
    "    --generator_adam_beta2=${GENERATOR_ADAM_BETA2} \\\n",
    "    --generator_adam_epsilon=${GENERATOR_ADAM_EPSILON} \\\n",
    "    --generator_clip_gradients=${GENERATOR_CLIP_GRADIENTS} \\\n",
    "    --generator_train_steps=${GENERATOR_TRAIN_STEPS} \\\n",
    "    \\\n",
    "    --discriminator_num_filters=${DISCRIMINATOR_NUM_FILTERS} \\\n",
    "    --discriminator_kernel_sizes=${DISCRIMINATOR_KERNEL_SIZES} \\\n",
    "    --discriminator_strides=${DISCRIMINATOR_STRIDES} \\\n",
    "    --discriminator_use_batch_norm=${DISCRIMINATOR_USE_BATCH_NORM} \\\n",
    "    --discriminator_batch_norm_before_act=${DISCRIMINATOR_BATCH_NORM_BEFORE_ACT} \\\n",
    "    --discriminator_use_leaky_relu=${DISCRIMINATOR_USE_LEAKY_RELU} \\\n",
    "    --discriminator_leaky_relu_alpha=${DISCRIMINATOR_LEAKY_RELU_ALPHA} \\\n",
    "    --discriminator_l1_regularization_scale=${DISCRIMINATOR_L1_REGULARIZATION_SCALE} \\\n",
    "    --discriminator_l2_regularization_scale=${DISCRIMINATOR_L2_REGULARIZATION_SCALE} \\\n",
    "    --discriminator_optimizer=${DISCRIMINATOR_OPTIMIZER} \\\n",
    "    --discriminator_learning_rate=${DISCRIMINATOR_LEARNING_RATE} \\\n",
    "    --discriminator_adam_beta1=${DISCRIMINATOR_ADAM_BETA1} \\\n",
    "    --discriminator_adam_beta2=${DISCRIMINATOR_ADAM_BETA2} \\\n",
    "    --discriminator_adam_epsilon=${DISCRIMINATOR_ADAM_EPSILON} \\\n",
    "    --discriminator_clip_gradients=${DISCRIMINATOR_CLIP_GRADIENTS} \\\n",
    "    --discriminator_train_steps=${DISCRIMINATOR_TRAIN_STEPS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://machine-learning-1234-bucket/gan/lsgan/trained_model/export/exporter/\n",
      "gs://machine-learning-1234-bucket/gan/lsgan/trained_model/export/exporter/1593045827/\n",
      "gs://machine-learning-1234-bucket/gan/lsgan/trained_model/export/exporter/1593048749/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://machine-learning-1234-bucket/gan/lsgan/trained_model/export/exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/predictor/saved_model_predictor.py:153: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/lsgan/trained_model/export/exporter/1593048749/variables/variables\n"
     ]
    }
   ],
   "source": [
    "predict_fn = tf.contrib.predictor.from_saved_model(\n",
    "    \"gs://machine-learning-1234-bucket/gan/lsgan/trained_model/export/exporter/1593048749\"\n",
    ")\n",
    "predictions = predict_fn(\n",
    "    {\n",
    "        \"Z\": np.random.normal(size=(10, 100))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['generated_images']\n"
     ]
    }
   ],
   "source": [
    "print(list(predictions.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = np.clip(\n",
    "    a=((predictions[\"generated_images\"] + 1.0) * (255. / 2)).astype(np.int32),\n",
    "    a_min=0,\n",
    "    a_max=255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(generated_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, color=True):\n",
    "    \"\"\"Plots images.\n",
    "\n",
    "    Args:\n",
    "        images: np.array, array of images of\n",
    "            [num_images, image_size, image_size, num_channels].\n",
    "    \"\"\"\n",
    "    num_images = len(images)\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(num_images):\n",
    "        image = images[i]\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        if color:\n",
    "            plt.imshow(\n",
    "                image,\n",
    "                cmap=plt.cm.binary\n",
    "            )\n",
    "        else:\n",
    "            plt.imshow(\n",
    "                image.reshape(image.shape[:-1]),\n",
    "                cmap=\"gray_r\"\n",
    "            )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(images=generated_images, color=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
