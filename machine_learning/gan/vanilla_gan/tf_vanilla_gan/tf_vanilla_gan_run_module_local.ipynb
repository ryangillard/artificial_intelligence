{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model module locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Import os environment variables for file hyperparameters.\n",
    "os.environ[\"TRAIN_FILE_PATTERN\"] = \"gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord\"\n",
    "os.environ[\"EVAL_FILE_PATTERN\"] = \"gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord\"\n",
    "os.environ[\"OUTPUT_DIR\"] = \"gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model\"\n",
    "\n",
    "# Import os environment variables for train hyperparameters.\n",
    "os.environ[\"TRAIN_BATCH_SIZE\"] = str(16)\n",
    "os.environ[\"TRAIN_STEPS\"] = str(37500)\n",
    "os.environ[\"SAVE_SUMMARY_STEPS\"] = str(100)\n",
    "os.environ[\"SAVE_CHECKPOINTS_STEPS\"] = str(1000)\n",
    "os.environ[\"KEEP_CHECKPOINT_MAX\"] = str(10)\n",
    "os.environ[\"INPUT_FN_AUTOTUNE\"] = \"False\"\n",
    "\n",
    "# Import os environment variables for eval hyperparameters.\n",
    "os.environ[\"EVAL_BATCH_SIZE\"] = str(16)\n",
    "os.environ[\"EVAL_STEPS\"] = str(10)\n",
    "os.environ[\"START_DELAY_SECS\"] = str(6000)\n",
    "os.environ[\"THROTTLE_SECS\"] = str(6000)\n",
    "\n",
    "# Import os environment variables for image hyperparameters.\n",
    "os.environ[\"HEIGHT\"] = str(28)\n",
    "os.environ[\"WIDTH\"] = str(28)\n",
    "os.environ[\"DEPTH\"] = str(1)\n",
    "\n",
    "# Import os environment variables for generator hyperparameters.\n",
    "os.environ[\"LATENT_SIZE\"] = str(512)\n",
    "os.environ[\"GENERATOR_HIDDEN_UNITS\"] = \"256,512,1024\"\n",
    "os.environ[\"GENERATOR_LEAKY_RELU_ALPHA\"] = str(0.2)\n",
    "os.environ[\"GENERATOR_FINAL_ACTIVATION\"] = \"tanh\"\n",
    "os.environ[\"GENERATOR_L1_REGULARIZATION_SCALE\"] = str(0.)\n",
    "os.environ[\"GENERATOR_L2_REGULARIZATION_SCALE\"] = str(0.)\n",
    "os.environ[\"GENERATOR_OPTIMIZER\"] = \"Adam\"\n",
    "os.environ[\"GENERATOR_LEARNING_RATE\"] = str(0.0002)\n",
    "os.environ[\"GENERATOR_ADAM_BETA1\"] = str(0.5)\n",
    "os.environ[\"GENERATOR_ADAM_BETA2\"] = str(0.999)\n",
    "os.environ[\"GENERATOR_ADAM_EPSILON\"] = str(1e-8)\n",
    "os.environ[\"GENERATOR_CLIP_GRADIENTS\"] = \"None\"\n",
    "os.environ[\"GENERATOR_TRAIN_STEPS\"] = str(1)\n",
    "\n",
    "# Import os environment variables for discriminator hyperparameters.\n",
    "os.environ[\"DISCRIMINATOR_HIDDEN_UNITS\"] = \"1024,512,256\"\n",
    "os.environ[\"DISCRIMINATOR_LEAKY_RELU_ALPHA\"] = str(0.2)\n",
    "os.environ[\"DISCRIMINATOR_L1_REGULARIZATION_SCALE\"] = str(0.)\n",
    "os.environ[\"DISCRIMINATOR_L2_REGULARIZATION_SCALE\"] = str(0.)\n",
    "os.environ[\"DISCRIMINATOR_OPTIMIZER\"] = \"Adam\"\n",
    "os.environ[\"DISCRIMINATOR_LEARNING_RATE\"] = str(0.0002)\n",
    "os.environ[\"DISCRIMINATOR_ADAM_BETA1\"] = str(0.5)\n",
    "os.environ[\"DISCRIMINATOR_ADAM_BETA2\"] = str(0.999)\n",
    "os.environ[\"DISCRIMINATOR_ADAM_EPSILON\"] = str(1e-8)\n",
    "os.environ[\"DISCRIMINATOR_CLIP_GRADIENTS\"] = \"None\"\n",
    "os.environ[\"DISCRIMINATOR_TRAIN_STEPS\"] = str(1)\n",
    "os.environ[\"LABEL_SMOOTHING\"] = str(0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Vanilla GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(28, 28, 1), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "\n",
      "vanilla_gan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 28, 28, 1) dtype=float32>}\n",
      "vanilla_gan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "vanilla_gan_model: mode = train\n",
      "vanilla_gan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/', 'train_batch_size': 16, 'train_steps': 37500, 'save_summary_steps': 100, 'save_checkpoints_steps': 1000, 'keep_checkpoint_max': 10, 'eval_batch_size': 16, 'eval_steps': 10, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 512, 'generator_hidden_units': [256, 512, 1024], 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_hidden_units': [1024, 512, 256], 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'label_smoothing': 0.9}\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"Reshape:0\", shape=(?, 784), dtype=float32)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_fake_images: network = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_0/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_2/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: generated_outputs = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32)\n",
      "\n",
      "Call discriminator with fake_images = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_0/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_0:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_2/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_2:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call discriminator with real_images = Tensor(\"Reshape:0\", shape=(?, 784), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"Reshape:0\", shape=(?, 784), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_0/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_0:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_2/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_2:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"generator_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_fake_loss = Tensor(\"discriminator_fake_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"Const_5:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_variables_and_gradients_generator: variables = [<tf.Variable 'generator/layers_dense_0/kernel:0' shape=(512, 256) dtype=float32_ref>, <tf.Variable 'generator/layers_dense_0/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'generator/layers_dense_1/kernel:0' shape=(256, 512) dtype=float32_ref>, <tf.Variable 'generator/layers_dense_1/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/layers_dense_2/kernel:0' shape=(512, 1024) dtype=float32_ref>, <tf.Variable 'generator/layers_dense_2/bias:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'generator/layers_dense_generated_outputs/kernel:0' shape=(1024, 784) dtype=float32_ref>, <tf.Variable 'generator/layers_dense_generated_outputs/bias:0' shape=(784,) dtype=float32_ref>]\n",
      "\n",
      "get_variables_and_gradients_generator: gradients = [<tf.Tensor 'generator_gradients/generator/layers_dense_0/MatMul_grad/MatMul_1:0' shape=(512, 256) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_0/BiasAdd_grad/BiasAddGrad:0' shape=(256,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_1/MatMul_grad/MatMul_1:0' shape=(256, 512) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_1/BiasAdd_grad/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_2/MatMul_grad/MatMul_1:0' shape=(512, 1024) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_2/BiasAdd_grad/BiasAddGrad:0' shape=(1024,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_generated_outputs/MatMul_grad/MatMul_1:0' shape=(1024, 784) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_generated_outputs/BiasAdd_grad/BiasAddGrad:0' shape=(784,) dtype=float32>]\n",
      "\n",
      "get_variables_and_gradients_generator: gradients = [<tf.Tensor 'get_variables_and_gradients_generator/layers_dense_0/kernel_gradients:0' shape=(512, 256) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_dense_0/bias_gradients:0' shape=(256,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_dense_1/kernel_gradients:0' shape=(256, 512) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_dense_1/bias_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_dense_2/kernel_gradients:0' shape=(512, 1024) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_dense_2/bias_gradients:0' shape=(1024,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_dense_generated_outputs/kernel_gradients:0' shape=(1024, 784) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_dense_generated_outputs/bias_gradients:0' shape=(784,) dtype=float32>]\n",
      "\n",
      "get_variables_and_gradients_discriminator: variables = [<tf.Variable 'discriminator/layers_dense_0/kernel:0' shape=(784, 1024) dtype=float32_ref>, <tf.Variable 'discriminator/layers_dense_0/bias:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'discriminator/layers_dense_1/kernel:0' shape=(1024, 512) dtype=float32_ref>, <tf.Variable 'discriminator/layers_dense_1/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/layers_dense_2/kernel:0' shape=(512, 256) dtype=float32_ref>, <tf.Variable 'discriminator/layers_dense_2/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'discriminator/layers_dense_logits/kernel:0' shape=(256, 1) dtype=float32_ref>, <tf.Variable 'discriminator/layers_dense_logits/bias:0' shape=(1,) dtype=float32_ref>]\n",
      "\n",
      "get_variables_and_gradients_discriminator: gradients = [<tf.Tensor 'discriminator_gradients/AddN_9:0' shape=(784, 1024) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_8:0' shape=(1024,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_7:0' shape=(1024, 512) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_6:0' shape=(512,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_5:0' shape=(512, 256) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_4:0' shape=(256,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_3:0' shape=(256, 1) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_2:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "get_variables_and_gradients_discriminator: gradients = [<tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_0/kernel_gradients:0' shape=(784, 1024) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_0/bias_gradients:0' shape=(1024,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_1/kernel_gradients:0' shape=(1024, 512) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_1/bias_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_2/kernel_gradients:0' shape=(512, 256) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_2/bias_gradients:0' shape=(256,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_logits/kernel_gradients:0' shape=(256, 1) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_logits/bias_gradients:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "train_network: scope = discriminator\n",
      "train_network_discriminator: optimizer = <tensorflow.python.training.adam.AdamOptimizer object at 0x7fef1a2f03d0>\n",
      "\n",
      "train_network_discriminator: gradients = [<tf.Tensor 'cond/discriminator_gradients/AddN_9:0' shape=(784, 1024) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_8:0' shape=(1024,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_7:0' shape=(1024, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_6:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_5:0' shape=(512, 256) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_4:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_3:0' shape=(256, 1) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_2:0' shape=(1,) dtype=float32>]\n",
      "train_network_discriminator: grads_and_vars = <zip object at 0x7fef1a2fe0a0>\n",
      "\n",
      "train_network: scope = generator\n",
      "train_network_generator: optimizer = <tensorflow.python.training.adam.AdamOptimizer object at 0x7fef1a302ad0>\n",
      "\n",
      "train_network_generator: gradients = [<tf.Tensor 'cond/generator_gradients/generator/layers_dense_0/MatMul_grad/MatMul_1:0' shape=(512, 256) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_dense_0/BiasAdd_grad/BiasAddGrad:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_dense_1/MatMul_grad/MatMul_1:0' shape=(256, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_dense_1/BiasAdd_grad/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_dense_2/MatMul_grad/MatMul_1:0' shape=(512, 1024) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_dense_2/BiasAdd_grad/BiasAddGrad:0' shape=(1024,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_dense_generated_outputs/MatMul_grad/MatMul_1:0' shape=(1024, 784) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_dense_generated_outputs/BiasAdd_grad/BiasAddGrad:0' shape=(784,) dtype=float32>]\n",
      "train_network_generator: grads_and_vars = <zip object at 0x7fef1a268190>\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(28, 28, 1), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "\n",
      "vanilla_gan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 28, 28, 1) dtype=float32>}\n",
      "vanilla_gan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "vanilla_gan_model: mode = eval\n",
      "vanilla_gan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/', 'train_batch_size': 16, 'train_steps': 37500, 'save_summary_steps': 100, 'save_checkpoints_steps': 1000, 'keep_checkpoint_max': 10, 'eval_batch_size': 16, 'eval_steps': 10, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 512, 'generator_hidden_units': [256, 512, 1024], 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_hidden_units': [1024, 512, 256], 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'label_smoothing': 0.9}\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"Reshape:0\", shape=(?, 784), dtype=float32)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_fake_images: network = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_0/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_2/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: generated_outputs = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32)\n",
      "\n",
      "Call discriminator with fake_images = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_0/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_0:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_2/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_2:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call discriminator with real_images = Tensor(\"Reshape:0\", shape=(?, 784), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"Reshape:0\", shape=(?, 784), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_0/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_0:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_2/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_2:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"generator_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_fake_loss = Tensor(\"discriminator_fake_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"Const_5:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_eval_metric_ops: discriminator_logits = Tensor(\"discriminator_concat_logits:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_labels = Tensor(\"discriminator_concat_labels:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_probabilities = Tensor(\"discriminator_probabilities:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: eval_metric_ops = {'accuracy': (<tf.Tensor 'discriminator_accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_accuracy/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'discriminator_precision/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'discriminator_recall/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_recall/update_op:0' shape=() dtype=float32>), 'auc_roc': (<tf.Tensor 'discriminator_auc_roc/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_roc/update_op:0' shape=() dtype=float32>), 'auc_pr': (<tf.Tensor 'discriminator_auc_pr/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_pr/update_op:0' shape=() dtype=float32>)}\n",
      "\n",
      "serving_input_fn: feature_placeholders = {'Z': <tf.Tensor 'serving_input_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "serving_input_fn: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "\n",
      "vanilla_gan_model: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "vanilla_gan_model: labels = None\n",
      "vanilla_gan_model: mode = infer\n",
      "vanilla_gan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/', 'train_batch_size': 16, 'train_steps': 37500, 'save_summary_steps': 100, 'save_checkpoints_steps': 1000, 'keep_checkpoint_max': 10, 'eval_batch_size': 16, 'eval_steps': 10, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 512, 'generator_hidden_units': [256, 512, 1024], 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_hidden_units': [1024, 512, 256], 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'label_smoothing': 0.9}\n",
      "\n",
      "get_predictions_and_export_outputs: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "get_fake_images: network = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_0/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_2/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: generated_outputs = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32)\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(28, 28, 1), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "\n",
      "vanilla_gan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 28, 28, 1) dtype=float32>}\n",
      "vanilla_gan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "vanilla_gan_model: mode = eval\n",
      "vanilla_gan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/', 'train_batch_size': 16, 'train_steps': 37500, 'save_summary_steps': 100, 'save_checkpoints_steps': 1000, 'keep_checkpoint_max': 10, 'eval_batch_size': 16, 'eval_steps': 10, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 512, 'generator_hidden_units': [256, 512, 1024], 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_hidden_units': [1024, 512, 256], 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'label_smoothing': 0.9}\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"Reshape:0\", shape=(?, 784), dtype=float32)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_fake_images: network = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_0/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_2/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: generated_outputs = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32)\n",
      "\n",
      "Call discriminator with fake_images = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_0/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_0:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_2/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_2:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call discriminator with real_images = Tensor(\"Reshape:0\", shape=(?, 784), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"Reshape:0\", shape=(?, 784), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_0/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_0:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_2/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_2:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"generator_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_fake_loss = Tensor(\"discriminator_fake_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"Const_5:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_eval_metric_ops: discriminator_logits = Tensor(\"discriminator_concat_logits:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_labels = Tensor(\"discriminator_concat_labels:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_probabilities = Tensor(\"discriminator_probabilities:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: eval_metric_ops = {'accuracy': (<tf.Tensor 'discriminator_accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_accuracy/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'discriminator_precision/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'discriminator_recall/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_recall/update_op:0' shape=() dtype=float32>), 'auc_roc': (<tf.Tensor 'discriminator_auc_roc/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_roc/update_op:0' shape=() dtype=float32>), 'auc_pr': (<tf.Tensor 'discriminator_auc_pr/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_pr/update_op:0' shape=() dtype=float32>)}\n",
      "\n",
      "serving_input_fn: feature_placeholders = {'Z': <tf.Tensor 'serving_input_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "serving_input_fn: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "\n",
      "vanilla_gan_model: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "vanilla_gan_model: labels = None\n",
      "vanilla_gan_model: mode = infer\n",
      "vanilla_gan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/', 'train_batch_size': 16, 'train_steps': 37500, 'save_summary_steps': 100, 'save_checkpoints_steps': 1000, 'keep_checkpoint_max': 10, 'eval_batch_size': 16, 'eval_steps': 10, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 512, 'generator_hidden_units': [256, 512, 1024], 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_hidden_units': [1024, 512, 256], 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'label_smoothing': 0.9}\n",
      "\n",
      "get_predictions_and_export_outputs: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "get_fake_images: network = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_0/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_2/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: generated_outputs = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/#1592450289772205...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/checkpoint#1592451115805874...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/eval/#1592450326864932...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/events.out.tfevents.1592450289.tf-1-15#1592451128753853...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/eval/events.out.tfevents.1592450326.tf-1-15#1592451121135362...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/#1592450329179569...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/#1592450329517672...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1592450328/#1592450335428684...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1592450328/saved_model.pb#1592450335634110...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1592450328/variables/#1592450335852423...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1592450328/variables/variables.data-00000-of-00001#1592450336064292...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1592450328/variables/variables.index#1592450336262053...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1592451121/#1592451127193453...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1592451121/saved_model.pb#1592451127399928...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1592451121/variables/#1592451127620983...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1592451121/variables/variables.data-00000-of-00001#1592451127859860...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1592451121/variables/variables.index#1592451128099309...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/graph.pbtxt#1592450292369763...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-29000.data-00000-of-00001#1592450931275178...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-29000.index#1592450931577893...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-29000.meta#1592450933535116...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-30000.data-00000-of-00001#1592450952087501...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-30000.index#1592450952419375...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-30000.meta#1592450954479482...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-31000.index#1592450973092002...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-31000.data-00000-of-00001#1592450972758785...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-31000.meta#1592450975166219...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-32000.data-00000-of-00001#1592450993495502...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-32000.index#1592450993798545...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-32000.meta#1592450995788591...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-33000.data-00000-of-00001#1592451014157579...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-33000.index#1592451014485199...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-33000.meta#1592451016551122...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-34000.data-00000-of-00001#1592451035945506...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-34000.index#1592451036268909...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-34000.meta#1592451038308435...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-35000.data-00000-of-00001#1592451056976959...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-35000.index#1592451057308858...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-35000.meta#1592451059269887...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-36000.data-00000-of-00001#1592451078607859...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-36000.index#1592451078916705...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-36000.meta#1592451080872491...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-37000.data-00000-of-00001#1592451101088237...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-37000.index#1592451101442574...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-37000.meta#1592451103366559...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-37500.data-00000-of-00001#1592451114646594...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-37500.index#1592451115007520...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-37500.meta#1592451117094385...\n",
      "/ [48/48 objects] 100% Done                                                     \n",
      "Operation completed over 48 objects.                                             \n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/model.py:18: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/model.py:18: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fef2e182e90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/input.py:101: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/input.py:113: shuffle_and_repeat (from tensorflow.contrib.data.python.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.shuffle_and_repeat(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/shuffle_ops.py:54: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/input.py:125: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/input.py:133: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/generator.py:55: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/generator.py:55: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/generator.py:65: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/train_and_eval.py:47: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/generator.py:114: The name tf.losses.get_regularization_loss is deprecated. Please use tf.compat.v1.losses.get_regularization_loss instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/generator.py:129: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/train.py:16: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/train.py:54: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/train.py:162: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/train.py:165: The name tf.mod is deprecated. Please use tf.math.mod instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/train.py:84: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/train.py:85: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/train.py:86: The name tf.train.AdagradDAOptimizer is deprecated. Please use tf.compat.v1.train.AdagradDAOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/train.py:87: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/train.py:88: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/train.py:89: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/train.py:90: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/train.py:91: The name tf.train.ProximalAdagradOptimizer is deprecated. Please use tf.compat.v1.train.ProximalAdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/train.py:92: The name tf.train.ProximalGradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.ProximalGradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/train.py:93: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2020-06-18 03:35:25.821396: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200190000 Hz\n",
      "2020-06-18 03:35:25.822464: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561dbb8a85b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-06-18 03:35:25.822496: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-06-18 03:35:25.822583: I tensorflow/core/common_runtime/process_util.cc:136] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.3616006, step = 1\n",
      "INFO:tensorflow:global_step/sec: 38.1792\n",
      "INFO:tensorflow:loss = 1.4305182, step = 101 (2.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.7082\n",
      "INFO:tensorflow:loss = 1.3715968, step = 201 (1.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.3588\n",
      "INFO:tensorflow:loss = 1.2414306, step = 301 (1.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.8029\n",
      "INFO:tensorflow:loss = 1.3098816, step = 401 (1.592 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 401 vs previous value: 401. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 55.326\n",
      "INFO:tensorflow:loss = 1.1400774, step = 501 (1.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.7691\n",
      "INFO:tensorflow:loss = 1.2126613, step = 601 (1.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.7839\n",
      "INFO:tensorflow:loss = 0.88823515, step = 701 (1.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.9794\n",
      "INFO:tensorflow:loss = 0.87518907, step = 801 (1.613 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 801 vs previous value: 801. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 69.009\n",
      "INFO:tensorflow:loss = 1.1249946, step = 901 (1.450 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/eval_metrics.py:48: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/eval_metrics.py:53: The name tf.metrics.precision is deprecated. Please use tf.compat.v1.metrics.precision instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/eval_metrics.py:58: The name tf.metrics.recall is deprecated. Please use tf.compat.v1.metrics.recall instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/eval_metrics.py:63: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\n",
      "\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-18T03:35:56Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-18-03:35:58\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.0, auc_pr = 0.95776546, auc_roc = 0.9460156, global_step = 1000, loss = 1.0011299, precision = 0.5, recall = 1.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-1000\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf_vanilla_gan/vanilla_gan_module/trainer/serving.py:19: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/temp-b'1592451361'/saved_model.pb\n",
      "INFO:tensorflow:global_step/sec: 5.17475\n",
      "INFO:tensorflow:loss = 1.0498748, step = 1001 (19.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.0644\n",
      "INFO:tensorflow:loss = 0.90299296, step = 1101 (1.753 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1101 vs previous value: 1101. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 61.2321\n",
      "INFO:tensorflow:loss = 0.9611307, step = 1201 (1.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.2364\n",
      "INFO:tensorflow:loss = 1.0584311, step = 1301 (1.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.8985\n",
      "INFO:tensorflow:loss = 0.92794764, step = 1401 (1.642 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1427 vs previous value: 1427. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 47.6172\n",
      "INFO:tensorflow:loss = 1.3627731, step = 1501 (2.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.8265\n",
      "INFO:tensorflow:loss = 0.93472934, step = 1601 (1.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.9941\n",
      "INFO:tensorflow:loss = 1.27022, step = 1701 (1.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.2689\n",
      "INFO:tensorflow:loss = 1.0218484, step = 1801 (1.716 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1801 vs previous value: 1801. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 78.3151\n",
      "INFO:tensorflow:loss = 1.4183836, step = 1901 (1.277 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 16.3127\n",
      "INFO:tensorflow:loss = 0.91937613, step = 2001 (6.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.2333\n",
      "INFO:tensorflow:loss = 0.9173888, step = 2101 (1.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.6503\n",
      "INFO:tensorflow:loss = 0.90812004, step = 2201 (1.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.6533\n",
      "INFO:tensorflow:loss = 0.87854314, step = 2301 (1.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.826\n",
      "INFO:tensorflow:loss = 1.1245947, step = 2401 (1.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.2299\n",
      "INFO:tensorflow:loss = 0.9421387, step = 2501 (1.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.2321\n",
      "INFO:tensorflow:loss = 1.0139, step = 2601 (1.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.3842\n",
      "INFO:tensorflow:loss = 0.7919345, step = 2701 (1.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.5729\n",
      "INFO:tensorflow:loss = 0.86298406, step = 2801 (1.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.4755\n",
      "INFO:tensorflow:loss = 1.1391572, step = 2901 (1.626 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 15.458\n",
      "INFO:tensorflow:loss = 0.9194466, step = 3001 (6.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.4395\n",
      "INFO:tensorflow:loss = 0.79274523, step = 3101 (1.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.8613\n",
      "INFO:tensorflow:loss = 0.79976773, step = 3201 (1.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.1873\n",
      "INFO:tensorflow:loss = 0.7880647, step = 3301 (1.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.3278\n",
      "INFO:tensorflow:loss = 1.0634382, step = 3401 (1.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.9001\n",
      "INFO:tensorflow:loss = 0.7914263, step = 3501 (1.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.353\n",
      "INFO:tensorflow:loss = 0.9695231, step = 3601 (1.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.8556\n",
      "INFO:tensorflow:loss = 0.9394772, step = 3701 (1.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.8963\n",
      "INFO:tensorflow:loss = 0.79229563, step = 3801 (1.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.1654\n",
      "INFO:tensorflow:loss = 0.9283141, step = 3901 (1.917 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.9494\n",
      "INFO:tensorflow:loss = 1.1006625, step = 4001 (6.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.9474\n",
      "INFO:tensorflow:loss = 1.2480125, step = 4101 (1.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.3613\n",
      "INFO:tensorflow:loss = 0.8399844, step = 4201 (1.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.8876\n",
      "INFO:tensorflow:loss = 0.8467821, step = 4301 (1.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.3335\n",
      "INFO:tensorflow:loss = 0.7927712, step = 4401 (1.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.8111\n",
      "INFO:tensorflow:loss = 1.037388, step = 4501 (1.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.7495\n",
      "INFO:tensorflow:loss = 0.7228684, step = 4601 (1.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.8668\n",
      "INFO:tensorflow:loss = 0.90197265, step = 4701 (1.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.3041\n",
      "INFO:tensorflow:loss = 0.88921404, step = 4801 (1.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.2772\n",
      "INFO:tensorflow:loss = 0.9254099, step = 4901 (1.822 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.43\n",
      "INFO:tensorflow:loss = 1.2500842, step = 5001 (6.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.2002\n",
      "INFO:tensorflow:loss = 1.150421, step = 5101 (1.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.4266\n",
      "INFO:tensorflow:loss = 0.8787863, step = 5201 (1.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.0848\n",
      "INFO:tensorflow:loss = 0.83775544, step = 5301 (1.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5596\n",
      "INFO:tensorflow:loss = 0.9497901, step = 5401 (1.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.7712\n",
      "INFO:tensorflow:loss = 0.759234, step = 5501 (1.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5483\n",
      "INFO:tensorflow:loss = 0.88478243, step = 5601 (1.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.7024\n",
      "INFO:tensorflow:loss = 0.88382274, step = 5701 (1.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.1044\n",
      "INFO:tensorflow:loss = 0.7697681, step = 5801 (1.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.0692\n",
      "INFO:tensorflow:loss = 1.0587331, step = 5901 (1.665 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.4209\n",
      "INFO:tensorflow:loss = 0.78243566, step = 6001 (6.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.6432\n",
      "INFO:tensorflow:loss = 0.8707448, step = 6101 (2.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.8802\n",
      "INFO:tensorflow:loss = 1.012625, step = 6201 (1.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.3238\n",
      "INFO:tensorflow:loss = 0.9552236, step = 6301 (2.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.6278\n",
      "INFO:tensorflow:loss = 0.83555275, step = 6401 (1.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.0708\n",
      "INFO:tensorflow:loss = 0.7399752, step = 6501 (1.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.8895\n",
      "INFO:tensorflow:loss = 0.73563516, step = 6601 (1.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.4921\n",
      "INFO:tensorflow:loss = 0.98357856, step = 6701 (1.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.7583\n",
      "INFO:tensorflow:loss = 0.806481, step = 6801 (2.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.6775\n",
      "INFO:tensorflow:loss = 0.8065592, step = 6901 (1.340 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 15.4382\n",
      "INFO:tensorflow:loss = 0.9744001, step = 7001 (6.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.0646\n",
      "INFO:tensorflow:loss = 0.78368014, step = 7101 (2.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.092\n",
      "INFO:tensorflow:loss = 0.9081276, step = 7201 (1.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.6964\n",
      "INFO:tensorflow:loss = 0.9419875, step = 7301 (1.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.185\n",
      "INFO:tensorflow:loss = 0.930862, step = 7401 (1.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.1016\n",
      "INFO:tensorflow:loss = 0.8002715, step = 7501 (1.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.1955\n",
      "INFO:tensorflow:loss = 1.1301827, step = 7601 (1.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.7379\n",
      "INFO:tensorflow:loss = 0.88183296, step = 7701 (1.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.5965\n",
      "INFO:tensorflow:loss = 0.89847547, step = 7801 (1.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.8411\n",
      "INFO:tensorflow:loss = 1.1335042, step = 7901 (1.700 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 15.8251\n",
      "INFO:tensorflow:loss = 1.0808452, step = 8001 (6.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.4567\n",
      "INFO:tensorflow:loss = 1.2204914, step = 8101 (1.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.7024\n",
      "INFO:tensorflow:loss = 0.9885035, step = 8201 (1.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.1309\n",
      "INFO:tensorflow:loss = 1.3087654, step = 8301 (1.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.4911\n",
      "INFO:tensorflow:loss = 1.0981131, step = 8401 (2.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.3782\n",
      "INFO:tensorflow:loss = 1.0662587, step = 8501 (1.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.1525\n",
      "INFO:tensorflow:loss = 1.0480177, step = 8601 (1.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.441\n",
      "INFO:tensorflow:loss = 1.0321825, step = 8701 (1.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.8939\n",
      "INFO:tensorflow:loss = 1.0286226, step = 8801 (1.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.7961\n",
      "INFO:tensorflow:loss = 1.3451881, step = 8901 (1.393 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 15.3575\n",
      "INFO:tensorflow:loss = 1.065934, step = 9001 (6.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.4367\n",
      "INFO:tensorflow:loss = 1.0944326, step = 9101 (1.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.7164\n",
      "INFO:tensorflow:loss = 0.9294576, step = 9201 (1.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.7273\n",
      "INFO:tensorflow:loss = 1.5155644, step = 9301 (1.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.9285\n",
      "INFO:tensorflow:loss = 1.18538, step = 9401 (1.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.4692\n",
      "INFO:tensorflow:loss = 1.2665505, step = 9501 (1.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.8551\n",
      "INFO:tensorflow:loss = 1.0829725, step = 9601 (1.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.8582\n",
      "INFO:tensorflow:loss = 1.0766621, step = 9701 (1.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.5702\n",
      "INFO:tensorflow:loss = 1.2296174, step = 9801 (1.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.092\n",
      "INFO:tensorflow:loss = 1.1891367, step = 9901 (1.752 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 15.5161\n",
      "INFO:tensorflow:loss = 0.940148, step = 10001 (6.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.9502\n",
      "INFO:tensorflow:loss = 1.0900364, step = 10101 (1.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.1128\n",
      "INFO:tensorflow:loss = 1.1481645, step = 10201 (1.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.3501\n",
      "INFO:tensorflow:loss = 1.0629718, step = 10301 (1.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.5618\n",
      "INFO:tensorflow:loss = 1.0413071, step = 10401 (1.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.4636\n",
      "INFO:tensorflow:loss = 1.0486182, step = 10501 (1.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.2528\n",
      "INFO:tensorflow:loss = 0.7804318, step = 10601 (1.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.9519\n",
      "INFO:tensorflow:loss = 1.0436764, step = 10701 (1.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.9195\n",
      "INFO:tensorflow:loss = 0.9143921, step = 10801 (1.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.5554\n",
      "INFO:tensorflow:loss = 1.1712629, step = 10901 (1.625 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 15.1605\n",
      "INFO:tensorflow:loss = 1.3396877, step = 11001 (6.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.8042\n",
      "INFO:tensorflow:loss = 0.8802638, step = 11101 (1.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.4401\n",
      "INFO:tensorflow:loss = 1.2074735, step = 11201 (1.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.9397\n",
      "INFO:tensorflow:loss = 1.2097615, step = 11301 (1.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.9613\n",
      "INFO:tensorflow:loss = 1.1029578, step = 11401 (1.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.6138\n",
      "INFO:tensorflow:loss = 1.2267607, step = 11501 (1.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.0323\n",
      "INFO:tensorflow:loss = 1.203433, step = 11601 (1.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.3467\n",
      "INFO:tensorflow:loss = 1.1074611, step = 11701 (1.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.6104\n",
      "INFO:tensorflow:loss = 0.93472004, step = 11801 (1.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.5068\n",
      "INFO:tensorflow:loss = 1.1683476, step = 11901 (1.527 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.886\n",
      "INFO:tensorflow:loss = 0.93915975, step = 12001 (6.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.4723\n",
      "INFO:tensorflow:loss = 1.0164431, step = 12101 (1.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.2638\n",
      "INFO:tensorflow:loss = 1.327637, step = 12201 (1.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.5321\n",
      "INFO:tensorflow:loss = 1.120821, step = 12301 (1.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.3958\n",
      "INFO:tensorflow:loss = 0.94624794, step = 12401 (1.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.5189\n",
      "INFO:tensorflow:loss = 1.2079363, step = 12501 (1.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.5612\n",
      "INFO:tensorflow:loss = 1.0934578, step = 12601 (1.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.9538\n",
      "INFO:tensorflow:loss = 0.8748785, step = 12701 (1.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.9375\n",
      "INFO:tensorflow:loss = 1.2037411, step = 12801 (1.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.638\n",
      "INFO:tensorflow:loss = 1.136229, step = 12901 (1.864 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 13.7767\n",
      "INFO:tensorflow:loss = 1.3446593, step = 13001 (7.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.9001\n",
      "INFO:tensorflow:loss = 1.3713582, step = 13101 (1.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.8641\n",
      "INFO:tensorflow:loss = 1.2507055, step = 13201 (1.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.1987\n",
      "INFO:tensorflow:loss = 1.1230204, step = 13301 (1.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5436\n",
      "INFO:tensorflow:loss = 1.2219105, step = 13401 (1.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.0551\n",
      "INFO:tensorflow:loss = 0.958447, step = 13501 (1.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.9477\n",
      "INFO:tensorflow:loss = 1.1599782, step = 13601 (1.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.429\n",
      "INFO:tensorflow:loss = 1.1981521, step = 13701 (1.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.9001\n",
      "INFO:tensorflow:loss = 1.1362975, step = 13801 (1.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.6169\n",
      "INFO:tensorflow:loss = 1.0762031, step = 13901 (1.457 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.6458\n",
      "INFO:tensorflow:loss = 1.0867934, step = 14001 (6.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.5194\n",
      "INFO:tensorflow:loss = 1.1990182, step = 14101 (1.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.1724\n",
      "INFO:tensorflow:loss = 1.2599905, step = 14201 (1.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.7195\n",
      "INFO:tensorflow:loss = 1.0924551, step = 14301 (1.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.9616\n",
      "INFO:tensorflow:loss = 0.9191491, step = 14401 (1.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.5709\n",
      "INFO:tensorflow:loss = 1.0118788, step = 14501 (1.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.6552\n",
      "INFO:tensorflow:loss = 1.3720956, step = 14601 (1.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.6977\n",
      "INFO:tensorflow:loss = 1.0341952, step = 14701 (2.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.756\n",
      "INFO:tensorflow:loss = 0.9322137, step = 14801 (1.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.0191\n",
      "INFO:tensorflow:loss = 1.1668198, step = 14901 (1.408 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 13.6046\n",
      "INFO:tensorflow:loss = 0.86742693, step = 15001 (7.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.6609\n",
      "INFO:tensorflow:loss = 0.99850774, step = 15101 (1.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.2609\n",
      "INFO:tensorflow:loss = 1.4043872, step = 15201 (1.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.8487\n",
      "INFO:tensorflow:loss = 1.2581185, step = 15301 (1.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.0755\n",
      "INFO:tensorflow:loss = 1.1163511, step = 15401 (1.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.3056\n",
      "INFO:tensorflow:loss = 1.453599, step = 15501 (1.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.3666\n",
      "INFO:tensorflow:loss = 1.0610952, step = 15601 (1.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.8841\n",
      "INFO:tensorflow:loss = 1.0101049, step = 15701 (1.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.236\n",
      "INFO:tensorflow:loss = 1.1067557, step = 15801 (1.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.3298\n",
      "INFO:tensorflow:loss = 1.0475471, step = 15901 (1.630 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 13.8187\n",
      "INFO:tensorflow:loss = 1.1038975, step = 16001 (7.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.2601\n",
      "INFO:tensorflow:loss = 1.036991, step = 16101 (1.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.8771\n",
      "INFO:tensorflow:loss = 1.063572, step = 16201 (1.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.4342\n",
      "INFO:tensorflow:loss = 1.0089031, step = 16301 (1.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.2271\n",
      "INFO:tensorflow:loss = 0.87598646, step = 16401 (1.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.7749\n",
      "INFO:tensorflow:loss = 1.2999278, step = 16501 (1.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.5847\n",
      "INFO:tensorflow:loss = 1.0004082, step = 16601 (2.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.656\n",
      "INFO:tensorflow:loss = 1.0377908, step = 16701 (1.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.6535\n",
      "INFO:tensorflow:loss = 1.0848677, step = 16801 (1.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.7553\n",
      "INFO:tensorflow:loss = 0.88439214, step = 16901 (1.544 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.2097\n",
      "INFO:tensorflow:loss = 1.0055557, step = 17001 (7.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.8986\n",
      "INFO:tensorflow:loss = 0.9981657, step = 17101 (1.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.01\n",
      "INFO:tensorflow:loss = 0.83262455, step = 17201 (1.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.1964\n",
      "INFO:tensorflow:loss = 0.92019314, step = 17301 (1.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.9042\n",
      "INFO:tensorflow:loss = 1.0392258, step = 17401 (1.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.653\n",
      "INFO:tensorflow:loss = 1.2213968, step = 17501 (1.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.6896\n",
      "INFO:tensorflow:loss = 1.1667298, step = 17601 (2.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.5019\n",
      "INFO:tensorflow:loss = 1.1501915, step = 17701 (1.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.0766\n",
      "INFO:tensorflow:loss = 1.1956874, step = 17801 (1.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.9941\n",
      "INFO:tensorflow:loss = 0.9538209, step = 17901 (1.491 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.1637\n",
      "INFO:tensorflow:loss = 1.0507498, step = 18001 (7.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.1681\n",
      "INFO:tensorflow:loss = 1.3594811, step = 18101 (1.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.258\n",
      "INFO:tensorflow:loss = 1.1372013, step = 18201 (1.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.951\n",
      "INFO:tensorflow:loss = 0.9578167, step = 18301 (1.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.8378\n",
      "INFO:tensorflow:loss = 1.0462577, step = 18401 (1.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.5898\n",
      "INFO:tensorflow:loss = 1.0480611, step = 18501 (1.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.6705\n",
      "INFO:tensorflow:loss = 1.1101284, step = 18601 (1.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.7184\n",
      "INFO:tensorflow:loss = 1.040192, step = 18701 (1.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.4989\n",
      "INFO:tensorflow:loss = 1.1525191, step = 18801 (1.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.7965\n",
      "INFO:tensorflow:loss = 0.89356315, step = 18901 (1.930 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 13.8468\n",
      "INFO:tensorflow:loss = 0.8789894, step = 19001 (7.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.3467\n",
      "INFO:tensorflow:loss = 1.1165102, step = 19101 (1.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.4873\n",
      "INFO:tensorflow:loss = 1.0469803, step = 19201 (1.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.255\n",
      "INFO:tensorflow:loss = 1.0585003, step = 19301 (1.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.9249\n",
      "INFO:tensorflow:loss = 1.2911096, step = 19401 (1.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.9366\n",
      "INFO:tensorflow:loss = 1.2040167, step = 19501 (1.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.316\n",
      "INFO:tensorflow:loss = 1.0685385, step = 19601 (1.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.049\n",
      "INFO:tensorflow:loss = 0.91369426, step = 19701 (1.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.7643\n",
      "INFO:tensorflow:loss = 1.0627639, step = 19801 (1.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.9854\n",
      "INFO:tensorflow:loss = 0.99848324, step = 19901 (1.564 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 15.0716\n",
      "INFO:tensorflow:loss = 1.0615349, step = 20001 (6.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.942\n",
      "INFO:tensorflow:loss = 1.1981767, step = 20101 (1.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.4296\n",
      "INFO:tensorflow:loss = 1.0607877, step = 20201 (1.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.3904\n",
      "INFO:tensorflow:loss = 0.9762782, step = 20301 (1.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.7092\n",
      "INFO:tensorflow:loss = 0.99673086, step = 20401 (1.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.2512\n",
      "INFO:tensorflow:loss = 1.1544158, step = 20501 (1.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.9235\n",
      "INFO:tensorflow:loss = 1.0270522, step = 20601 (1.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.7278\n",
      "INFO:tensorflow:loss = 1.2322028, step = 20701 (1.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.8317\n",
      "INFO:tensorflow:loss = 1.0837293, step = 20801 (1.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.4858\n",
      "INFO:tensorflow:loss = 1.0133666, step = 20901 (1.869 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.9141\n",
      "INFO:tensorflow:loss = 1.0112574, step = 21001 (6.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.0242\n",
      "INFO:tensorflow:loss = 0.9791854, step = 21101 (1.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.2959\n",
      "INFO:tensorflow:loss = 0.86239547, step = 21201 (1.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.3808\n",
      "INFO:tensorflow:loss = 1.1920223, step = 21301 (1.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.3862\n",
      "INFO:tensorflow:loss = 1.0790138, step = 21401 (1.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.3766\n",
      "INFO:tensorflow:loss = 0.8662571, step = 21501 (1.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.9493\n",
      "INFO:tensorflow:loss = 1.055424, step = 21601 (1.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.4174\n",
      "INFO:tensorflow:loss = 0.8148622, step = 21701 (1.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.0516\n",
      "INFO:tensorflow:loss = 1.1762006, step = 21801 (1.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.771\n",
      "INFO:tensorflow:loss = 0.99895304, step = 21901 (1.587 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 13.4339\n",
      "INFO:tensorflow:loss = 0.99363095, step = 22001 (7.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.9957\n",
      "INFO:tensorflow:loss = 1.0883186, step = 22101 (1.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.646\n",
      "INFO:tensorflow:loss = 0.990624, step = 22201 (1.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.7223\n",
      "INFO:tensorflow:loss = 1.0317478, step = 22301 (1.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.8848\n",
      "INFO:tensorflow:loss = 1.0751247, step = 22401 (1.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.3956\n",
      "INFO:tensorflow:loss = 1.0473114, step = 22501 (1.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.9211\n",
      "INFO:tensorflow:loss = 0.9512303, step = 22601 (1.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.2137\n",
      "INFO:tensorflow:loss = 1.0374008, step = 22701 (1.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.7574\n",
      "INFO:tensorflow:loss = 0.9476885, step = 22801 (1.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.7921\n",
      "INFO:tensorflow:loss = 1.0997161, step = 22901 (1.673 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.0415\n",
      "INFO:tensorflow:loss = 1.2589288, step = 23001 (7.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.9532\n",
      "INFO:tensorflow:loss = 1.1571827, step = 23101 (1.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.6262\n",
      "INFO:tensorflow:loss = 0.9426855, step = 23201 (1.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.8795\n",
      "INFO:tensorflow:loss = 1.208264, step = 23301 (1.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.6746\n",
      "INFO:tensorflow:loss = 1.2811084, step = 23401 (1.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.2763\n",
      "INFO:tensorflow:loss = 1.2164626, step = 23501 (1.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.0202\n",
      "INFO:tensorflow:loss = 1.1812994, step = 23601 (1.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.7068\n",
      "INFO:tensorflow:loss = 0.9514209, step = 23701 (1.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.4394\n",
      "INFO:tensorflow:loss = 0.9665115, step = 23801 (1.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.457\n",
      "INFO:tensorflow:loss = 1.20879, step = 23901 (1.601 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.4316\n",
      "INFO:tensorflow:loss = 1.0213232, step = 24001 (6.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.7199\n",
      "INFO:tensorflow:loss = 1.0756688, step = 24101 (1.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.6193\n",
      "INFO:tensorflow:loss = 1.1441758, step = 24201 (1.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.2797\n",
      "INFO:tensorflow:loss = 1.0391177, step = 24301 (1.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.7594\n",
      "INFO:tensorflow:loss = 0.8752753, step = 24401 (1.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.0507\n",
      "INFO:tensorflow:loss = 0.90534145, step = 24501 (1.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.8392\n",
      "INFO:tensorflow:loss = 1.3087971, step = 24601 (1.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.6078\n",
      "INFO:tensorflow:loss = 1.1347466, step = 24701 (1.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5429\n",
      "INFO:tensorflow:loss = 1.2189931, step = 24801 (1.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.8285\n",
      "INFO:tensorflow:loss = 0.9924932, step = 24901 (1.412 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 13.6656\n",
      "INFO:tensorflow:loss = 0.9707234, step = 25001 (7.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.2084\n",
      "INFO:tensorflow:loss = 0.8604084, step = 25101 (1.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.0963\n",
      "INFO:tensorflow:loss = 0.94041145, step = 25201 (1.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.3791\n",
      "INFO:tensorflow:loss = 1.1024841, step = 25301 (1.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.9088\n",
      "INFO:tensorflow:loss = 1.1752855, step = 25401 (1.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.0807\n",
      "INFO:tensorflow:loss = 1.117025, step = 25501 (1.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.9773\n",
      "INFO:tensorflow:loss = 1.0329261, step = 25601 (1.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.3137\n",
      "INFO:tensorflow:loss = 0.8007759, step = 25701 (1.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.9369\n",
      "INFO:tensorflow:loss = 0.92055684, step = 25801 (1.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.5331\n",
      "INFO:tensorflow:loss = 1.1797621, step = 25901 (1.625 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 15.552\n",
      "INFO:tensorflow:loss = 0.9511105, step = 26001 (6.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.643\n",
      "INFO:tensorflow:loss = 1.0497084, step = 26101 (1.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.9565\n",
      "INFO:tensorflow:loss = 1.0497597, step = 26201 (1.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.5216\n",
      "INFO:tensorflow:loss = 0.8458673, step = 26301 (1.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.8702\n",
      "INFO:tensorflow:loss = 0.9428385, step = 26401 (1.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.1167\n",
      "INFO:tensorflow:loss = 1.2029326, step = 26501 (1.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.2958\n",
      "INFO:tensorflow:loss = 1.0241853, step = 26601 (1.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.754\n",
      "INFO:tensorflow:loss = 1.3504772, step = 26701 (1.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.7897\n",
      "INFO:tensorflow:loss = 1.0659888, step = 26801 (1.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.7115\n",
      "INFO:tensorflow:loss = 0.9531187, step = 26901 (1.703 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.8373\n",
      "INFO:tensorflow:loss = 1.3391281, step = 27001 (6.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.4049\n",
      "INFO:tensorflow:loss = 1.2387737, step = 27101 (2.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.0699\n",
      "INFO:tensorflow:loss = 1.1266859, step = 27201 (1.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7748\n",
      "INFO:tensorflow:loss = 1.1148996, step = 27301 (2.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.9793\n",
      "INFO:tensorflow:loss = 1.0866321, step = 27401 (1.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.6402\n",
      "INFO:tensorflow:loss = 1.0656183, step = 27501 (1.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.8781\n",
      "INFO:tensorflow:loss = 1.182235, step = 27601 (1.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.9421\n",
      "INFO:tensorflow:loss = 1.0725219, step = 27701 (1.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.8556\n",
      "INFO:tensorflow:loss = 1.1495918, step = 27801 (1.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.5586\n",
      "INFO:tensorflow:loss = 1.5332751, step = 27901 (1.867 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.7502\n",
      "INFO:tensorflow:loss = 1.042894, step = 28001 (6.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.813\n",
      "INFO:tensorflow:loss = 0.9874126, step = 28101 (1.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.282\n",
      "INFO:tensorflow:loss = 0.8898985, step = 28201 (1.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.1733\n",
      "INFO:tensorflow:loss = 0.9554161, step = 28301 (1.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.9268\n",
      "INFO:tensorflow:loss = 1.2388189, step = 28401 (1.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.5126\n",
      "INFO:tensorflow:loss = 0.9390596, step = 28501 (2.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.6551\n",
      "INFO:tensorflow:loss = 1.3527515, step = 28601 (1.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.123\n",
      "INFO:tensorflow:loss = 0.9370469, step = 28701 (1.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.5692\n",
      "INFO:tensorflow:loss = 0.9197998, step = 28801 (1.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.9189\n",
      "INFO:tensorflow:loss = 1.0970051, step = 28901 (1.821 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 12.0267\n",
      "INFO:tensorflow:loss = 1.1889329, step = 29001 (8.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.7495\n",
      "INFO:tensorflow:loss = 1.1223383, step = 29101 (1.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.6631\n",
      "INFO:tensorflow:loss = 1.1682131, step = 29201 (1.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.9076\n",
      "INFO:tensorflow:loss = 1.2081673, step = 29301 (1.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.7662\n",
      "INFO:tensorflow:loss = 0.9283657, step = 29401 (1.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.8571\n",
      "INFO:tensorflow:loss = 1.1891353, step = 29501 (1.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.1347\n",
      "INFO:tensorflow:loss = 1.2687144, step = 29601 (1.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.7922\n",
      "INFO:tensorflow:loss = 1.260648, step = 29701 (1.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.4633\n",
      "INFO:tensorflow:loss = 1.061218, step = 29801 (1.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.2513\n",
      "INFO:tensorflow:loss = 1.1887577, step = 29901 (1.556 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 13.1994\n",
      "INFO:tensorflow:loss = 1.0644714, step = 30001 (7.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.9578\n",
      "INFO:tensorflow:loss = 1.2463138, step = 30101 (1.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.973\n",
      "INFO:tensorflow:loss = 1.175581, step = 30201 (1.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.764\n",
      "INFO:tensorflow:loss = 1.1540446, step = 30301 (1.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.2935\n",
      "INFO:tensorflow:loss = 1.0179973, step = 30401 (1.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.6653\n",
      "INFO:tensorflow:loss = 0.8577169, step = 30501 (1.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.0608\n",
      "INFO:tensorflow:loss = 1.2172505, step = 30601 (1.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.388\n",
      "INFO:tensorflow:loss = 0.98040324, step = 30701 (1.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.5981\n",
      "INFO:tensorflow:loss = 0.9830624, step = 30801 (1.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.1128\n",
      "INFO:tensorflow:loss = 1.0056455, step = 30901 (1.751 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 31000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 15.8503\n",
      "INFO:tensorflow:loss = 0.93579745, step = 31001 (6.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.4168\n",
      "INFO:tensorflow:loss = 1.0611008, step = 31101 (1.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.041\n",
      "INFO:tensorflow:loss = 1.0957749, step = 31201 (1.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.8068\n",
      "INFO:tensorflow:loss = 1.0047185, step = 31301 (1.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.8001\n",
      "INFO:tensorflow:loss = 1.2553846, step = 31401 (1.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.2615\n",
      "INFO:tensorflow:loss = 1.10937, step = 31501 (1.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.6851\n",
      "INFO:tensorflow:loss = 0.9294076, step = 31601 (1.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.8395\n",
      "INFO:tensorflow:loss = 1.0453755, step = 31701 (1.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.7526\n",
      "INFO:tensorflow:loss = 1.1067264, step = 31801 (1.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.2327\n",
      "INFO:tensorflow:loss = 0.88730943, step = 31901 (1.533 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.4931\n",
      "INFO:tensorflow:loss = 1.2821872, step = 32001 (6.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.1836\n",
      "INFO:tensorflow:loss = 1.2243958, step = 32101 (1.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.4408\n",
      "INFO:tensorflow:loss = 1.2675138, step = 32201 (1.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.8838\n",
      "INFO:tensorflow:loss = 1.2193776, step = 32301 (1.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.768\n",
      "INFO:tensorflow:loss = 1.0950105, step = 32401 (1.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.5207\n",
      "INFO:tensorflow:loss = 0.97577953, step = 32501 (1.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.1213\n",
      "INFO:tensorflow:loss = 0.95154494, step = 32601 (1.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.5569\n",
      "INFO:tensorflow:loss = 1.0677183, step = 32701 (1.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.8135\n",
      "INFO:tensorflow:loss = 0.866681, step = 32801 (1.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.388\n",
      "INFO:tensorflow:loss = 0.88120604, step = 32901 (2.189 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 33000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 12.9824\n",
      "INFO:tensorflow:loss = 1.2020204, step = 33001 (7.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.6394\n",
      "INFO:tensorflow:loss = 1.0253967, step = 33101 (1.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.2509\n",
      "INFO:tensorflow:loss = 1.0176806, step = 33201 (1.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.6956\n",
      "INFO:tensorflow:loss = 0.9966488, step = 33301 (1.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.4201\n",
      "INFO:tensorflow:loss = 0.96679693, step = 33401 (1.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.542\n",
      "INFO:tensorflow:loss = 1.1803992, step = 33501 (2.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.1208\n",
      "INFO:tensorflow:loss = 1.2128187, step = 33601 (1.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.3142\n",
      "INFO:tensorflow:loss = 1.028993, step = 33701 (1.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.362\n",
      "INFO:tensorflow:loss = 1.1354228, step = 33801 (1.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.5183\n",
      "INFO:tensorflow:loss = 1.2969315, step = 33901 (1.599 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.9276\n",
      "INFO:tensorflow:loss = 1.0883225, step = 34001 (6.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.8934\n",
      "INFO:tensorflow:loss = 1.1255312, step = 34101 (1.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.0137\n",
      "INFO:tensorflow:loss = 1.4234008, step = 34201 (1.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.282\n",
      "INFO:tensorflow:loss = 1.2652056, step = 34301 (1.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.7418\n",
      "INFO:tensorflow:loss = 1.0100977, step = 34401 (1.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.7289\n",
      "INFO:tensorflow:loss = 1.3957541, step = 34501 (1.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.7971\n",
      "INFO:tensorflow:loss = 1.3731772, step = 34601 (1.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.9632\n",
      "INFO:tensorflow:loss = 1.0800917, step = 34701 (1.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.0832\n",
      "INFO:tensorflow:loss = 1.1812738, step = 34801 (1.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.7973\n",
      "INFO:tensorflow:loss = 1.0443761, step = 34901 (1.859 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 35000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.4082\n",
      "INFO:tensorflow:loss = 1.1540537, step = 35001 (6.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.3453\n",
      "INFO:tensorflow:loss = 0.99207854, step = 35101 (1.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.3431\n",
      "INFO:tensorflow:loss = 0.9875492, step = 35201 (1.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.8513\n",
      "INFO:tensorflow:loss = 1.0128983, step = 35301 (1.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.5334\n",
      "INFO:tensorflow:loss = 0.8553127, step = 35401 (1.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.2803\n",
      "INFO:tensorflow:loss = 1.0783145, step = 35501 (1.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.5854\n",
      "INFO:tensorflow:loss = 0.992285, step = 35601 (1.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.2108\n",
      "INFO:tensorflow:loss = 1.1883025, step = 35701 (1.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.1111\n",
      "INFO:tensorflow:loss = 1.159783, step = 35801 (1.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.7034\n",
      "INFO:tensorflow:loss = 1.0262133, step = 35901 (1.704 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 15.2814\n",
      "INFO:tensorflow:loss = 1.2319468, step = 36001 (6.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.6264\n",
      "INFO:tensorflow:loss = 1.3248234, step = 36101 (1.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.3597\n",
      "INFO:tensorflow:loss = 1.1023655, step = 36201 (1.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.4807\n",
      "INFO:tensorflow:loss = 1.2101827, step = 36301 (1.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.5591\n",
      "INFO:tensorflow:loss = 1.1476929, step = 36401 (1.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.1766\n",
      "INFO:tensorflow:loss = 1.2045643, step = 36501 (2.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.0452\n",
      "INFO:tensorflow:loss = 1.1962115, step = 36601 (1.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.3806\n",
      "INFO:tensorflow:loss = 0.94949776, step = 36701 (1.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.8395\n",
      "INFO:tensorflow:loss = 1.0764351, step = 36801 (1.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.0254\n",
      "INFO:tensorflow:loss = 1.1528845, step = 36901 (1.586 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 37000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.4938\n",
      "INFO:tensorflow:loss = 1.1021059, step = 37001 (6.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.2554\n",
      "INFO:tensorflow:loss = 1.0120354, step = 37101 (1.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5577\n",
      "INFO:tensorflow:loss = 1.1529247, step = 37201 (1.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.8699\n",
      "INFO:tensorflow:loss = 0.81015724, step = 37301 (1.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.3497\n",
      "INFO:tensorflow:loss = 0.9940262, step = 37401 (1.463 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 37500 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-18T03:49:22Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-37500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-18-03:49:25\n",
      "INFO:tensorflow:Saving dict for global step 37500: accuracy = 0.0, auc_pr = 0.8172682, auc_roc = 0.79339844, global_step = 37500, loss = 1.3940343, precision = 0.5, recall = 1.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 37500: gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-37500\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-37500\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/temp-b'1592452165'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 2.21731.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil -m rm -rf ${OUTPUT_DIR}\n",
    "export PYTHONPATH=$PYTHONPATH:$PWD/vanilla_gan_module\n",
    "python3 -m trainer.task \\\n",
    "    --train_file_pattern=${TRAIN_FILE_PATTERN} \\\n",
    "    --eval_file_pattern=${EVAL_FILE_PATTERN} \\\n",
    "    --output_dir=${OUTPUT_DIR} \\\n",
    "    --job-dir=./tmp \\\n",
    "    \\\n",
    "    --train_batch_size=${TRAIN_BATCH_SIZE} \\\n",
    "    --train_steps=${TRAIN_STEPS} \\\n",
    "    --save_summary_steps=${SAVE_SUMMARY_STEPS} \\\n",
    "    --save_checkpoints_steps=${SAVE_CHECKPOINTS_STEPS} \\\n",
    "    --keep_checkpoint_max=${KEEP_CHECKPOINT_MAX} \\\n",
    "    --input_fn_autotune=${INPUT_FN_AUTOTUNE} \\\n",
    "    \\\n",
    "    --eval_batch_size=${EVAL_BATCH_SIZE} \\\n",
    "    --eval_steps=${EVAL_STEPS} \\\n",
    "    --start_delay_secs=${START_DELAY_SECS} \\\n",
    "    --throttle_secs=${THROTTLE_SECS} \\\n",
    "    \\\n",
    "    --height=${HEIGHT} \\\n",
    "    --width=${WIDTH} \\\n",
    "    --depth=${DEPTH} \\\n",
    "    \\\n",
    "    --latent_size=${LATENT_SIZE} \\\n",
    "    --generator_hidden_units=${GENERATOR_HIDDEN_UNITS} \\\n",
    "    --generator_leaky_relu_alpha=${GENERATOR_LEAKY_RELU_ALPHA} \\\n",
    "    --generator_final_activation=${GENERATOR_FINAL_ACTIVATION} \\\n",
    "    --generator_l1_regularization_scale=${GENERATOR_L1_REGULARIZATION_SCALE} \\\n",
    "    --generator_l2_regularization_scale=${GENERATOR_L2_REGULARIZATION_SCALE} \\\n",
    "    --generator_optimizer=${GENERATOR_OPTIMIZER} \\\n",
    "    --generator_learning_rate=${GENERATOR_LEARNING_RATE} \\\n",
    "    --generator_adam_beta1=${GENERATOR_ADAM_BETA1} \\\n",
    "    --generator_adam_beta2=${GENERATOR_ADAM_BETA2} \\\n",
    "    --generator_adam_epsilon=${GENERATOR_ADAM_EPSILON} \\\n",
    "    --generator_clip_gradients=${GENERATOR_CLIP_GRADIENTS} \\\n",
    "    --generator_train_steps=${GENERATOR_TRAIN_STEPS} \\\n",
    "    \\\n",
    "    --discriminator_hidden_units=${DISCRIMINATOR_HIDDEN_UNITS} \\\n",
    "    --discriminator_leaky_relu_alpha=${DISCRIMINATOR_LEAKY_RELU_ALPHA} \\\n",
    "    --discriminator_l1_regularization_scale=${DISCRIMINATOR_L1_REGULARIZATION_SCALE} \\\n",
    "    --discriminator_l2_regularization_scale=${DISCRIMINATOR_L2_REGULARIZATION_SCALE} \\\n",
    "    --discriminator_optimizer=${DISCRIMINATOR_OPTIMIZER} \\\n",
    "    --discriminator_learning_rate=${DISCRIMINATOR_LEARNING_RATE} \\\n",
    "    --discriminator_adam_beta1=${DISCRIMINATOR_ADAM_BETA1} \\\n",
    "    --discriminator_adam_beta2=${DISCRIMINATOR_ADAM_BETA2} \\\n",
    "    --discriminator_adam_epsilon=${DISCRIMINATOR_ADAM_EPSILON} \\\n",
    "    --discriminator_clip_gradients=${DISCRIMINATOR_CLIP_GRADIENTS} \\\n",
    "    --discriminator_train_steps=${DISCRIMINATOR_TRAIN_STEPS} \\\n",
    "    --label_smoothing=${LABEL_SMOOTHING}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/\n",
      "gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1592451361/\n",
      "gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1592452165/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1592452165/variables/variables\n"
     ]
    }
   ],
   "source": [
    "predict_fn = tf.contrib.predictor.from_saved_model(\n",
    "    \"gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1592452165\"\n",
    ")\n",
    "predictions = predict_fn(\n",
    "    {\n",
    "        \"Z\": np.random.normal(size=(10, 512))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['generated_images']\n"
     ]
    }
   ],
   "source": [
    "print(list(predictions.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = np.clip(\n",
    "    a=((predictions[\"generated_images\"] + 1.0) * (255. / 2)).astype(np.int32),\n",
    "    a_min=0,\n",
    "    a_max=255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(generated_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "    \"\"\"Plots images.\n",
    "\n",
    "    Args:\n",
    "        images: np.array, array of images of\n",
    "            [num_images, height, width, depth].\n",
    "        \n",
    "    \"\"\"\n",
    "    num_images = len(images)\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(num_images):\n",
    "        image = images[i]\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(\n",
    "            image.reshape(image.shape[:-1]),\n",
    "            cmap=\"gray_r\"\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Final Activation: Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(generated_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Final Activation: Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
