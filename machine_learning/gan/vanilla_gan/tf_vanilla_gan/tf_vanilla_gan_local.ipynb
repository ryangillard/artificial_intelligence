{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2-dlenv_tfe\n",
      "1.18.1\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and modules\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {}\n",
    "# File arguments.\n",
    "arguments[\"train_file_pattern\"] = \"data/train.tfrecord\"\n",
    "arguments[\"eval_file_pattern\"] = \"data/eval.tfrecord\"\n",
    "arguments[\"output_dir\"] = \"trained_model\"\n",
    "\n",
    "# Training parameters.\n",
    "arguments[\"train_batch_size\"] = 32\n",
    "arguments[\"train_steps\"] = 200\n",
    "\n",
    "# Eval parameters.\n",
    "arguments[\"eval_batch_size\"] = 32\n",
    "arguments[\"eval_steps\"] = 100\n",
    "arguments[\"start_delay_secs\"] = 60\n",
    "arguments[\"throttle_secs\"] = 120\n",
    "\n",
    "# Image parameters.\n",
    "arguments[\"height\"] = 32\n",
    "arguments[\"width\"] = 32\n",
    "arguments[\"depth\"] = 3\n",
    "\n",
    "# Generator parameters.\n",
    "arguments[\"latent_size\"] = 512\n",
    "arguments[\"generator_hidden_units\"] = [2, 4, 8]\n",
    "arguments[\"generator_l1_regularization_scale\"] = 0.01\n",
    "arguments[\"generator_l2_regularization_scale\"] = 0.01\n",
    "arguments[\"generator_optimizer\"] = \"Adam\"\n",
    "arguments[\"generator_learning_rate\"] = 0.0001\n",
    "arguments[\"generator_clip_gradients\"] = 5.0\n",
    "arguments[\"generator_train_steps\"] = 40\n",
    "\n",
    "# Discriminator hyperparameters.\n",
    "arguments[\"discriminator_hidden_units\"] = [8, 4, 2]\n",
    "arguments[\"discriminator_l1_regularization_scale\"] = 0.01\n",
    "arguments[\"discriminator_l2_regularization_scale\"] = 0.01\n",
    "arguments[\"discriminator_optimizer\"] = \"Adam\"\n",
    "arguments[\"discriminator_learning_rate\"] = 0.0001\n",
    "arguments[\"discriminator_clip_gradients\"] = 5.0\n",
    "arguments[\"discriminator_train_steps\"] = 25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print_object.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_obj(function_name, object_name, object_value):\n",
    "    \"\"\"Prints enclosing function, object name, and object value.\n",
    "\n",
    "    Args:\n",
    "        function_name: str, name of function.\n",
    "        object_name: str, name of object.\n",
    "        object_value: object, value of passed object.\n",
    "    \"\"\"\n",
    "#     pass\n",
    "    print(\"{}: {} = {}\".format(function_name, object_name, object_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_example(protos, params):\n",
    "    \"\"\"Decodes TFRecord file into tensors.\n",
    "\n",
    "    Given protobufs, decode into image and label tensors.\n",
    "\n",
    "    Args:\n",
    "        protos: protobufs from TFRecord file.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Image and label tensors.\n",
    "    \"\"\"\n",
    "    # Create feature schema map for protos.\n",
    "    features = {\n",
    "        \"image_raw\": tf.FixedLenFeature(shape=[], dtype=tf.string),\n",
    "        \"label\": tf.FixedLenFeature(shape=[], dtype=tf.int64)\n",
    "    }\n",
    "\n",
    "    # Parse features from tf.Example.\n",
    "    parsed_features = tf.parse_single_example(\n",
    "        serialized=protos, features=features\n",
    "    )\n",
    "    print_obj(\"\\ndecode_example\", \"features\", features)\n",
    "\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length height * width * depth) to a uint8 tensor with shape\n",
    "    # [height * width * depth].\n",
    "    image = tf.decode_raw(\n",
    "        input_bytes=parsed_features[\"image_raw\"], out_type=tf.uint8\n",
    "    )\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Reshape flattened image back into normal dimensions.\n",
    "    image = tf.reshape(\n",
    "        tensor=image,\n",
    "        shape=[params[\"height\"], params[\"width\"], params[\"depth\"]]\n",
    "    )\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Convert from [0, 255] -> [-1.0, 1.0] floats.\n",
    "    image = tf.cast(x=image, dtype=tf.float32) * (2. / 255) - 1.0\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "    label = tf.cast(x=parsed_features[\"label\"], dtype=tf.int32)\n",
    "    print_obj(\"decode_example\", \"label\", label)\n",
    "\n",
    "    return {\"image\": image}, label\n",
    "\n",
    "\n",
    "def read_dataset(filename, mode, batch_size, params):\n",
    "    \"\"\"Reads CSV time series data using tf.data, doing necessary preprocessing.\n",
    "\n",
    "    Given filename, mode, batch size, and other parameters, read CSV dataset\n",
    "    using Dataset API, apply necessary preprocessing, and return an input\n",
    "    function to the Estimator API.\n",
    "\n",
    "    Args:\n",
    "        filename: str, file pattern that to read into our tf.data dataset.\n",
    "        mode: The estimator ModeKeys. Can be TRAIN or EVAL.\n",
    "        batch_size: int, number of examples per batch.\n",
    "        params: dict, dictionary of user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        An input function.\n",
    "    \"\"\"\n",
    "    def _input_fn():\n",
    "        \"\"\"Wrapper input function used by Estimator API to get data tensors.\n",
    "\n",
    "        Returns:\n",
    "            Batched dataset object of dictionary of feature tensors and label\n",
    "                tensor.\n",
    "        \"\"\"\n",
    "        # Create list of files that match pattern.\n",
    "        file_list = tf.gfile.Glob(filename=filename)\n",
    "\n",
    "        # Create dataset from file list.\n",
    "        dataset = tf.data.TFRecordDataset(\n",
    "            filenames=file_list, num_parallel_reads=40\n",
    "        )\n",
    "\n",
    "        # Shuffle and repeat if training with fused op.\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            dataset = dataset.apply(\n",
    "                tf.contrib.data.shuffle_and_repeat(\n",
    "                    buffer_size=50 * batch_size,\n",
    "                    count=None  # indefinitely\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Decode CSV file into a features dictionary of tensors, then batch.\n",
    "        dataset = dataset.apply(\n",
    "            tf.contrib.data.map_and_batch(\n",
    "                map_func=lambda x: decode_example(\n",
    "                    protos=x,\n",
    "                    params=params\n",
    "                ),\n",
    "                batch_size=batch_size,\n",
    "                num_parallel_calls=4\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Prefetch data to improve latency.\n",
    "        dataset = dataset.prefetch(buffer_size=2)\n",
    "\n",
    "        # Create a iterator, then get batch of features from example queue.\n",
    "        batched_dataset = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        return batched_dataset\n",
    "    return _input_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_network(Z, params, reuse=False):\n",
    "    \"\"\"Creates generator network and returns generated output.\n",
    "\n",
    "    Args:\n",
    "        Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "        params: dict, user passed parameters.\n",
    "        reuse: bool, whether to reuse variables or not.\n",
    "\n",
    "    Returns:\n",
    "        Generated outputs tensor of shape\n",
    "            [cur_batch_size, height * width * depth].\n",
    "    \"\"\"\n",
    "    # Create the input layer to our DNN.\n",
    "    # shape = (cur_batch_size, latent_size)\n",
    "    network = Z\n",
    "    print_obj(\"\\ngenerator_network\", \"network\", network)\n",
    "\n",
    "    # Create regularizer for dense layer kernel weights.\n",
    "    regularizer = tf.contrib.layers.l1_l2_regularizer(\n",
    "        scale_l1=params[\"generator_l1_regularization_scale\"],\n",
    "        scale_l2=params[\"generator_l2_regularization_scale\"]\n",
    "    )\n",
    "\n",
    "    with tf.variable_scope(\"generator\", reuse=reuse):\n",
    "        # Add hidden layers with the given number of units/neurons per layer.\n",
    "        for i, units in enumerate(params[\"generator_hidden_units\"]):\n",
    "            # shape = (cur_batch_size, generator_hidden_units[i])\n",
    "            network = tf.layers.dense(\n",
    "                inputs=network,\n",
    "                units=units,\n",
    "                activation=tf.nn.leaky_relu,\n",
    "                kernel_regularizer=regularizer,\n",
    "                name=\"layers_dense_{}\".format(i)\n",
    "            )\n",
    "            print_obj(\"generator_network\", \"network\", network)\n",
    "\n",
    "        # Final linear layer for outputs.\n",
    "        # shape = (cur_batch_size, height * width * depth)\n",
    "        generated_outputs = tf.layers.dense(\n",
    "            inputs=network,\n",
    "            units=params[\"height\"] * params[\"width\"] * params[\"depth\"],\n",
    "            activation=None,\n",
    "            kernel_regularizer=regularizer,\n",
    "            name=\"layers_dense_generated_outputs\"\n",
    "        )\n",
    "        print_obj(\"generator_network\", \"generated_outputs\", generated_outputs)\n",
    "\n",
    "    return generated_outputs\n",
    "\n",
    "\n",
    "def get_generator_loss(generated_logits):\n",
    "    \"\"\"Gets generator loss.\n",
    "\n",
    "    Args:\n",
    "        generated_logits: tensor, shape of\n",
    "            [cur_batch_size, height * width * depth].\n",
    "\n",
    "    Returns:\n",
    "        Tensor of generator's total loss of shape [].\n",
    "    \"\"\"\n",
    "    # Calculate base generator loss.\n",
    "    generator_loss = tf.reduce_mean(\n",
    "        input_tensor=tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=generated_logits,\n",
    "            labels=tf.ones_like(tensor=generated_logits)\n",
    "        ),\n",
    "        name=\"generator_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"\\nget_generator_loss\",\n",
    "        \"generator_loss\",\n",
    "        generator_loss\n",
    "    )\n",
    "\n",
    "    # Get regularization losses.\n",
    "    generator_regularization_loss = tf.losses.get_regularization_loss(\n",
    "        scope=\"generator\",\n",
    "        name=\"generator_regularization_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_generator_loss\",\n",
    "        \"generator_regularization_loss\",\n",
    "        generator_regularization_loss\n",
    "    )\n",
    "\n",
    "    # Combine losses for total losses.\n",
    "    generator_total_loss = tf.math.add(\n",
    "        x=generator_loss,\n",
    "        y=generator_regularization_loss,\n",
    "        name=\"generator_total_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_generator_loss\", \"generator_total_loss\", generator_total_loss\n",
    "    )\n",
    "\n",
    "    return generator_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## discriminator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_network(X, params, reuse=False):\n",
    "    \"\"\"Creates discriminator network and returns logits.\n",
    "\n",
    "    Args:\n",
    "        X: tensor, image tensors of shape\n",
    "            [cur_batch_size, height * width * depth].\n",
    "        params: dict, user passed parameters.\n",
    "        reuse: bool, whether to reuse variables or not.\n",
    "\n",
    "    Returns:\n",
    "        Logits tensor of shape [cur_batch_size, 1].\n",
    "    \"\"\"\n",
    "    # Create the input layer to our DNN.\n",
    "    # shape = (cur_batch_size, height * width * depth)\n",
    "    network = X\n",
    "    print_obj(\"\\ndiscriminator_network\", \"network\", network)\n",
    "\n",
    "    # Create regularizer for dense layer kernel weights.\n",
    "    regularizer = tf.contrib.layers.l1_l2_regularizer(\n",
    "        scale_l1=params[\"discriminator_l1_regularization_scale\"],\n",
    "        scale_l2=params[\"discriminator_l2_regularization_scale\"]\n",
    "    )\n",
    "\n",
    "    with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
    "        # Add hidden layers with the given number of units/neurons per layer.\n",
    "        for i, units in enumerate(params[\"discriminator_hidden_units\"]):\n",
    "            # shape = (cur_batch_size, discriminator_hidden_units[i])\n",
    "            network = tf.layers.dense(\n",
    "                inputs=network,\n",
    "                units=units,\n",
    "                activation=tf.nn.leaky_relu,\n",
    "                kernel_regularizer=regularizer,\n",
    "                name=\"layers_dense_{}\".format(i)\n",
    "            )\n",
    "            print_obj(\"discriminator_network\", \"network\", network)\n",
    "\n",
    "        # Final linear layer for logits.\n",
    "        # shape = (cur_batch_size, 1)\n",
    "        logits = tf.layers.dense(\n",
    "            inputs=network,\n",
    "            units=1,\n",
    "            activation=None,\n",
    "            kernel_regularizer=regularizer,\n",
    "            name=\"layers_dense_logits\"\n",
    "        )\n",
    "        print_obj(\"discriminator_network\", \"logits\", logits)\n",
    "\n",
    "    return logits\n",
    "\n",
    "\n",
    "def get_discriminator_loss(generated_logits, real_logits):\n",
    "    \"\"\"Gets discriminator loss.\n",
    "\n",
    "    Args:\n",
    "        generated_logits: tensor, shape of\n",
    "            [cur_batch_size, height * width * depth].\n",
    "        real_logits: tensor, shape of\n",
    "            [cur_batch_size, height * width * depth].\n",
    "\n",
    "    Returns:\n",
    "        Tensor of discriminator's total loss of shape [].\n",
    "    \"\"\"\n",
    "    # Calculate base discriminator loss.\n",
    "    discriminator_real_loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=real_logits,\n",
    "        labels=tf.ones_like(tensor=real_logits),\n",
    "        name=\"discriminator_real_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"\\nget_discriminator_loss\",\n",
    "        \"discriminator_real_loss\",\n",
    "        discriminator_real_loss\n",
    "    )\n",
    "\n",
    "    discriminator_generated_loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=generated_logits,\n",
    "        labels=tf.zeros_like(tensor=generated_logits),\n",
    "        name=\"discriminator_generated_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_discriminator_loss\",\n",
    "        \"discriminator_generated_loss\",\n",
    "        discriminator_generated_loss\n",
    "    )\n",
    "\n",
    "    discriminator_loss = tf.reduce_mean(\n",
    "        input_tensor=tf.add(\n",
    "            x=discriminator_real_loss, y=discriminator_generated_loss\n",
    "        ),\n",
    "        name=\"discriminator_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_discriminator_loss\",\n",
    "        \"discriminator_loss\",\n",
    "        discriminator_loss\n",
    "    )\n",
    "\n",
    "    # Get regularization losses.\n",
    "    discriminator_regularization_loss = tf.losses.get_regularization_loss(\n",
    "        scope=\"discriminator\",\n",
    "        name=\"discriminator_regularization_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_discriminator_loss\",\n",
    "        \"discriminator_regularization_loss\",\n",
    "        discriminator_regularization_loss\n",
    "    )\n",
    "\n",
    "    # Combine losses for total losses.\n",
    "    discriminator_total_loss = tf.math.add(\n",
    "        x=discriminator_loss,\n",
    "        y=discriminator_regularization_loss,\n",
    "        name=\"discriminator_total_loss\"\n",
    "    )\n",
    "    print_obj(\n",
    "        \"get_discriminator_loss\",\n",
    "        \"discriminator_total_loss\",\n",
    "        discriminator_total_loss\n",
    "    )\n",
    "\n",
    "    return discriminator_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vanilla_gan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(loss, global_step, params, scope):\n",
    "    \"\"\"Trains network and returns loss and train op.\n",
    "\n",
    "    Args:\n",
    "        loss: tensor, shape of [].\n",
    "        global_step: tensor, the current training step or batch in the\n",
    "            training loop.\n",
    "        params: dict, user passed parameters.\n",
    "        scope: str, the variables that to train.\n",
    "\n",
    "    Returns:\n",
    "        Loss tensor and training op.\n",
    "    \"\"\"\n",
    "    # Create optimizer map.\n",
    "    optimizers = {\n",
    "        \"Adam\": tf.train.AdamOptimizer,\n",
    "        \"Adadelta\": tf.train.AdadeltaOptimizer,\n",
    "        \"AdagradDA\": tf.train.AdagradDAOptimizer,\n",
    "        \"Adagrad\": tf.train.AdagradOptimizer,\n",
    "        \"Ftrl\": tf.train.FtrlOptimizer,\n",
    "        \"GradientDescent\": tf.train.GradientDescentOptimizer,\n",
    "        \"Momentum\": tf.train.MomentumOptimizer,\n",
    "        \"ProximalAdagrad\": tf.train.ProximalAdagradOptimizer,\n",
    "        \"ProximalGradientDescent\": tf.train.ProximalGradientDescentOptimizer,\n",
    "        \"RMSProp\": tf.train.RMSPropOptimizer\n",
    "    }\n",
    "\n",
    "    # Get gradients.\n",
    "    gradients = tf.gradients(\n",
    "        ys=loss,\n",
    "        xs=tf.trainable_variables(scope=scope),\n",
    "        name=\"{}_gradients\".format(scope)\n",
    "    )\n",
    "\n",
    "    # Clip gradients.\n",
    "    if params[\"{}_clip_gradients\".format(scope)]:\n",
    "        gradients, _ = tf.clip_by_global_norm(\n",
    "            t_list=gradients,\n",
    "            clip_norm=params[\"{}_clip_gradients\".format(scope)],\n",
    "            name=\"{}_clip_by_global_norm_gradients\".format(scope)\n",
    "        )\n",
    "\n",
    "    # Zip back together gradients and variables.\n",
    "    grads_and_vars = zip(gradients, tf.trainable_variables(scope=scope))\n",
    "\n",
    "    # Get optimizer and instantiate it.\n",
    "    optimizer = optimizers[params[\"{}_optimizer\".format(scope)]](\n",
    "        learning_rate=params[\"{}_learning_rate\".format(scope)]\n",
    "    )\n",
    "\n",
    "    # Create train op by applying gradients to variables and incrementing\n",
    "    # global step.\n",
    "    train_op = optimizer.apply_gradients(\n",
    "        grads_and_vars=grads_and_vars,\n",
    "        global_step=global_step,\n",
    "        name=\"{}_apply_gradients\".format(scope)\n",
    "    )\n",
    "\n",
    "    return loss, train_op\n",
    "\n",
    "\n",
    "def vanilla_gan_model(features, labels, mode, params):\n",
    "    \"\"\"Vanilla GAN custom Estimator model function.\n",
    "\n",
    "    Args:\n",
    "        features: dict, keys are feature names and values are feature tensors.\n",
    "        labels: tensor, label data.\n",
    "        mode: tf.estimator.ModeKeys with values of either TRAIN, EVAL, or\n",
    "            PREDICT.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Instance of `tf.estimator.EstimatorSpec` class.\n",
    "    \"\"\"\n",
    "    print_obj(\"\\nvanilla_gan_model\", \"features\", features)\n",
    "    print_obj(\"vanilla_gan_model\", \"labels\", labels)\n",
    "    print_obj(\"vanilla_gan_model\", \"mode\", mode)\n",
    "    print_obj(\"vanilla_gan_model\", \"params\", params)\n",
    "\n",
    "    # Loss function, training/eval ops, etc.\n",
    "    predictions_dict = None\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = None\n",
    "    export_outputs = None\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # Extract given latent vectors from features dictionary.\n",
    "        Z = tf.cast(x=features[\"Z\"], dtype=tf.float32)\n",
    "\n",
    "        # Establish generator network subgraph.\n",
    "        generator_outputs = generator_network(Z, params, reuse=False)\n",
    "\n",
    "        generated_images = tf.reshape(\n",
    "            tensor=generator_outputs,\n",
    "            shape=[-1, params[\"height\"], params[\"width\"], params[\"depth\"]]\n",
    "        )\n",
    "\n",
    "        # Create predictions dictionary.\n",
    "        predictions_dict = {\n",
    "            \"generated_images\": generated_images\n",
    "        }\n",
    "\n",
    "        # Create export outputs.\n",
    "        export_outputs = {\n",
    "            \"predict_export_outputs\": tf.estimator.export.PredictOutput(\n",
    "                outputs=predictions_dict)\n",
    "        }\n",
    "    else:\n",
    "        # Extract image from features dictionary.\n",
    "        X = tf.reshape(\n",
    "            tensor=features[\"image\"],\n",
    "            shape=[-1, params[\"height\"] * params[\"width\"] * params[\"depth\"]]\n",
    "        )\n",
    "\n",
    "        # Get dynamic batch size in case of partial batch.\n",
    "        cur_batch_size = tf.shape(\n",
    "            input=X,\n",
    "            out_type=tf.int32,\n",
    "            name=\"vanilla_gan_model_cur_batch_size\"\n",
    "        )[0]\n",
    "\n",
    "        # Create random noise latent vector for each batch example.\n",
    "        Z = tf.random.normal(\n",
    "            shape=[cur_batch_size, params[\"latent_size\"]],\n",
    "            mean=0.0,\n",
    "            stddev=1.0,\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        # Establish generator network subgraph.\n",
    "        generator_outputs = generator_network(Z, params, reuse=False)\n",
    "\n",
    "        # Establish discriminator network subgraph.\n",
    "        real_logits = discriminator_network(X, params, reuse=False)\n",
    "\n",
    "        # Get generated logits too.\n",
    "        generated_logits = discriminator_network(\n",
    "            generator_outputs, params, reuse=True\n",
    "        )\n",
    "\n",
    "        # Get generator total loss.\n",
    "        generator_total_loss = get_generator_loss(generated_logits)\n",
    "\n",
    "        # Get discriminator total loss.\n",
    "        discriminator_total_loss = get_discriminator_loss(\n",
    "            generated_logits, real_logits\n",
    "        )\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            # Get global step.\n",
    "            global_step = tf.train.get_global_step()\n",
    "\n",
    "            # Determine if it is time to train generator or discriminator.\n",
    "            cycle_step = tf.mod(\n",
    "                x=global_step,\n",
    "                y=tf.cast(\n",
    "                    x=tf.add(\n",
    "                        x=params[\"generator_train_steps\"],\n",
    "                        y=params[\"discriminator_train_steps\"]\n",
    "                    ),\n",
    "                    dtype=tf.int64\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Create choose generator condition.\n",
    "            condition = tf.less(\n",
    "                x=cycle_step, y=params[\"generator_train_steps\"]\n",
    "            )\n",
    "\n",
    "            # Conditionally choose to train generator or discriminator subgraph.\n",
    "            loss, train_op = tf.cond(\n",
    "                pred=condition,\n",
    "                true_fn=lambda: train_network(\n",
    "                    loss=generator_total_loss,\n",
    "                    global_step=global_step,\n",
    "                    params=params,\n",
    "                    scope=\"generator\"\n",
    "                ),\n",
    "                false_fn=lambda: train_network(\n",
    "                    loss=discriminator_total_loss,\n",
    "                    global_step=global_step,\n",
    "                    params=params,\n",
    "                    scope=\"discriminator\"\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            loss = discriminator_total_loss\n",
    "\n",
    "            # Concatenate discriminator logits and labels.\n",
    "            discriminator_logits = tf.concat(\n",
    "                values=[real_logits, generated_logits],\n",
    "                axis=0,\n",
    "                name=\"discriminator_concat_logits\"\n",
    "            )\n",
    "\n",
    "            discriminator_labels = tf.concat(\n",
    "                values=[\n",
    "                    tf.ones_like(tensor=real_logits),\n",
    "                    tf.zeros_like(tensor=generated_logits)\n",
    "                ],\n",
    "                axis=0,\n",
    "                name=\"discriminator_concat_labels\"\n",
    "            )\n",
    "\n",
    "            # Calculate discriminator probabilities.\n",
    "            discriminator_probabilities = tf.nn.sigmoid(\n",
    "                x=discriminator_logits, name=\"discriminator_probabilities\"\n",
    "            )\n",
    "\n",
    "            # Create eval metric ops dictionary.\n",
    "            eval_metric_ops = {\n",
    "                \"accuracy\": tf.metrics.accuracy(\n",
    "                    labels=discriminator_labels,\n",
    "                    predictions=discriminator_probabilities,\n",
    "                    name=\"vanilla_gan_model_accuracy\"\n",
    "                ),\n",
    "                \"precision\": tf.metrics.precision(\n",
    "                    labels=discriminator_labels,\n",
    "                    predictions=discriminator_probabilities,\n",
    "                    name=\"vanilla_gan_model_precision\"\n",
    "                ),\n",
    "                \"recall\": tf.metrics.recall(\n",
    "                    labels=discriminator_labels,\n",
    "                    predictions=discriminator_probabilities,\n",
    "                    name=\"vanilla_gan_model_recall\"\n",
    "                ),\n",
    "                \"auc_roc\": tf.metrics.auc(\n",
    "                    labels=discriminator_labels,\n",
    "                    predictions=discriminator_probabilities,\n",
    "                    num_thresholds=200,\n",
    "                    curve=\"ROC\",\n",
    "                    name=\"vanilla_gan_model_auc_roc\"\n",
    "                ),\n",
    "                \"auc_pr\": tf.metrics.auc(\n",
    "                    labels=discriminator_labels,\n",
    "                    predictions=discriminator_probabilities,\n",
    "                    num_thresholds=200,\n",
    "                    curve=\"PR\",\n",
    "                    name=\"vanilla_gan_model_auc_pr\"\n",
    "                )\n",
    "            }\n",
    "\n",
    "    # Return EstimatorSpec\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions_dict,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops,\n",
    "        export_outputs=export_outputs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## serving.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn(params):\n",
    "    \"\"\"Serving input function.\n",
    "\n",
    "    Args:\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        ServingInputReceiver object containing features and receiver tensors.\n",
    "    \"\"\"\n",
    "    # Create placeholders to accept data sent to the model at serving time.\n",
    "    # shape = (batch_size,)\n",
    "    feature_placeholders = {\n",
    "        \"Z\": tf.placeholder(\n",
    "            dtype=tf.float32,\n",
    "            shape=[None, params[\"latent_size\"]],\n",
    "            name=\"serving_input_placeholder_Z\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    print_obj(\n",
    "        \"serving_input_fn\",\n",
    "        \"feature_placeholders\",\n",
    "        feature_placeholders\n",
    "    )\n",
    "\n",
    "    # Create clones of the feature placeholder tensors so that the SavedModel\n",
    "    # SignatureDef will point to the placeholder.\n",
    "    features = {\n",
    "        key: tf.identity(\n",
    "            input=value,\n",
    "            name=\"serving_input_fn_identity_placeholder_{}\".format(key)\n",
    "        )\n",
    "        for key, value in feature_placeholders.items()\n",
    "    }\n",
    "\n",
    "    print_obj(\n",
    "        \"serving_input_fn\",\n",
    "        \"features\",\n",
    "        features\n",
    "    )\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features=features, receiver_tensors=feature_placeholders\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(args):\n",
    "    \"\"\"Trains and evaluates custom Estimator model.\n",
    "\n",
    "    Args:\n",
    "        args: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        `Estimator` object.\n",
    "    \"\"\"\n",
    "    # Set logging to be level of INFO.\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    # Create our custom estimator using our model function.\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn=vanilla_gan_model,\n",
    "        model_dir=args[\"output_dir\"],\n",
    "        params=args\n",
    "    )\n",
    "\n",
    "    # Create train spec to read in our training data.\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"train_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.TRAIN,\n",
    "            batch_size=args[\"train_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        max_steps=args[\"train_steps\"]\n",
    "    )\n",
    "\n",
    "    # Create exporter to save out the complete model to disk.\n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        name=\"exporter\",\n",
    "        serving_input_receiver_fn=lambda: serving_input_fn(args)\n",
    "    )\n",
    "\n",
    "    # Create eval spec to read in our validation data and export our model.\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"eval_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.EVAL,\n",
    "            batch_size=args[\"eval_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        steps=args[\"eval_steps\"],\n",
    "        start_delay_secs=args[\"start_delay_secs\"],\n",
    "        throttle_secs=args[\"throttle_secs\"],\n",
    "        exporters=exporter\n",
    "    )\n",
    "\n",
    "    # Create train and evaluate loop to train and evaluate our estimator.\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n",
    "\n",
    "    return estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'trained_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3335751890>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-4-90b050af9c1b>:87: shuffle_and_repeat (from tensorflow.contrib.data.python.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.shuffle_and_repeat(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/shuffle_ops.py:54: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From <ipython-input-4-90b050af9c1b>:99: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "WARNING:tensorflow:From <ipython-input-4-90b050af9c1b>:107: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "vanilla_gan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "vanilla_gan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "vanilla_gan_model: mode = train\n",
      "vanilla_gan_model: params = {'output_dir': 'trained_model', 'train_batch_size': 32, 'eval_batch_size': 32, 'train_steps': 200, 'eval_steps': 100, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_hidden_units': [2, 4, 8], 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_learning_rate': 0.0001, 'generator_optimizer': 'Adam', 'generator_clip_gradients': 5.0, 'generator_train_steps': 40, 'discriminator_hidden_units': [8, 4, 2], 'discriminator_l1_regularization_scale': 0.01, 'discriminator_l2_regularization_scale': 0.01, 'discriminator_learning_rate': 0.0001, 'discriminator_optimizer': 'Adam', 'discriminator_clip_gradients': 5.0, 'discriminator_train_steps': 25}\n",
      "\n",
      "generator_network: network = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-5-51611cc7ecc7>:33: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "generator_network: network = Tensor(\"generator/layers_dense_0/LeakyRelu:0\", shape=(?, 2), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_dense_1/LeakyRelu:0\", shape=(?, 4), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_dense_2/LeakyRelu:0\", shape=(?, 8), dtype=float32)\n",
      "generator_network: generated_outputs = Tensor(\"generator/layers_dense_generated_outputs/BiasAdd:0\", shape=(?, 3072), dtype=float32)\n",
      "\n",
      "discriminator_network: network = Tensor(\"Reshape:0\", shape=(?, 3072), dtype=float32)\n",
      "discriminator_network: network = Tensor(\"discriminator/layers_dense_0/LeakyRelu:0\", shape=(?, 8), dtype=float32)\n",
      "discriminator_network: network = Tensor(\"discriminator/layers_dense_1/LeakyRelu:0\", shape=(?, 4), dtype=float32)\n",
      "discriminator_network: network = Tensor(\"discriminator/layers_dense_2/LeakyRelu:0\", shape=(?, 2), dtype=float32)\n",
      "discriminator_network: logits = Tensor(\"discriminator/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "discriminator_network: network = Tensor(\"generator/layers_dense_generated_outputs/BiasAdd:0\", shape=(?, 3072), dtype=float32)\n",
      "discriminator_network: network = Tensor(\"discriminator_1/layers_dense_0/LeakyRelu:0\", shape=(?, 8), dtype=float32)\n",
      "discriminator_network: network = Tensor(\"discriminator_1/layers_dense_1/LeakyRelu:0\", shape=(?, 4), dtype=float32)\n",
      "discriminator_network: network = Tensor(\"discriminator_1/layers_dense_2/LeakyRelu:0\", shape=(?, 2), dtype=float32)\n",
      "discriminator_network: logits = Tensor(\"discriminator_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"generator_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_regularization_loss = Tensor(\"generator_regularization_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(?, 1), dtype=float32)\n",
      "get_discriminator_loss: discriminator_generated_loss = Tensor(\"discriminator_generated_loss:0\", shape=(?, 1), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_regularization_loss = Tensor(\"discriminator_regularization_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 6.9740405, step = 1\n",
      "INFO:tensorflow:global_step/sec: 37.2643\n",
      "INFO:tensorflow:loss = 4.94795, step = 101 (2.686 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into trained_model/model.ckpt.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(32, 32, 3), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "vanilla_gan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "vanilla_gan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "vanilla_gan_model: mode = eval\n",
      "vanilla_gan_model: params = {'output_dir': 'trained_model', 'train_batch_size': 32, 'eval_batch_size': 32, 'train_steps': 200, 'eval_steps': 100, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_hidden_units': [2, 4, 8], 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_learning_rate': 0.0001, 'generator_optimizer': 'Adam', 'generator_clip_gradients': 5.0, 'generator_train_steps': 40, 'discriminator_hidden_units': [8, 4, 2], 'discriminator_l1_regularization_scale': 0.01, 'discriminator_l2_regularization_scale': 0.01, 'discriminator_learning_rate': 0.0001, 'discriminator_optimizer': 'Adam', 'discriminator_clip_gradients': 5.0, 'discriminator_train_steps': 25}\n",
      "\n",
      "generator_network: network = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_dense_0/LeakyRelu:0\", shape=(?, 2), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_dense_1/LeakyRelu:0\", shape=(?, 4), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_dense_2/LeakyRelu:0\", shape=(?, 8), dtype=float32)\n",
      "generator_network: generated_outputs = Tensor(\"generator/layers_dense_generated_outputs/BiasAdd:0\", shape=(?, 3072), dtype=float32)\n",
      "\n",
      "discriminator_network: network = Tensor(\"Reshape:0\", shape=(?, 3072), dtype=float32)\n",
      "discriminator_network: network = Tensor(\"discriminator/layers_dense_0/LeakyRelu:0\", shape=(?, 8), dtype=float32)\n",
      "discriminator_network: network = Tensor(\"discriminator/layers_dense_1/LeakyRelu:0\", shape=(?, 4), dtype=float32)\n",
      "discriminator_network: network = Tensor(\"discriminator/layers_dense_2/LeakyRelu:0\", shape=(?, 2), dtype=float32)\n",
      "discriminator_network: logits = Tensor(\"discriminator/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "discriminator_network: network = Tensor(\"generator/layers_dense_generated_outputs/BiasAdd:0\", shape=(?, 3072), dtype=float32)\n",
      "discriminator_network: network = Tensor(\"discriminator_1/layers_dense_0/LeakyRelu:0\", shape=(?, 8), dtype=float32)\n",
      "discriminator_network: network = Tensor(\"discriminator_1/layers_dense_1/LeakyRelu:0\", shape=(?, 4), dtype=float32)\n",
      "discriminator_network: network = Tensor(\"discriminator_1/layers_dense_2/LeakyRelu:0\", shape=(?, 2), dtype=float32)\n",
      "discriminator_network: logits = Tensor(\"discriminator_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"generator_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_regularization_loss = Tensor(\"generator_regularization_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(?, 1), dtype=float32)\n",
      "get_discriminator_loss: discriminator_generated_loss = Tensor(\"discriminator_generated_loss:0\", shape=(?, 1), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_regularization_loss = Tensor(\"discriminator_regularization_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-01T05:33:43Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-01-05:33:45\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.0, auc_pr = 0.8872658, auc_roc = 0.7875422, global_step = 200, loss = 5.8556666, precision = 0.5, recall = 1.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: trained_model/model.ckpt-200\n",
      "serving_input_fn: feature_placeholders = {'Z': <tf.Tensor 'serving_input_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "serving_input_fn: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "vanilla_gan_model: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "vanilla_gan_model: labels = None\n",
      "vanilla_gan_model: mode = infer\n",
      "vanilla_gan_model: params = {'output_dir': 'trained_model', 'train_batch_size': 32, 'eval_batch_size': 32, 'train_steps': 200, 'eval_steps': 100, 'start_delay_secs': 60, 'throttle_secs': 120, 'height': 32, 'width': 32, 'depth': 3, 'latent_size': 512, 'generator_hidden_units': [2, 4, 8], 'generator_l1_regularization_scale': 0.01, 'generator_l2_regularization_scale': 0.01, 'generator_learning_rate': 0.0001, 'generator_optimizer': 'Adam', 'generator_clip_gradients': 5.0, 'generator_train_steps': 40, 'discriminator_hidden_units': [8, 4, 2], 'discriminator_l1_regularization_scale': 0.01, 'discriminator_l2_regularization_scale': 0.01, 'discriminator_learning_rate': 0.0001, 'discriminator_optimizer': 'Adam', 'discriminator_clip_gradients': 5.0, 'discriminator_train_steps': 25}\n",
      "\n",
      "generator_network: network = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_dense_0/LeakyRelu:0\", shape=(?, 2), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_dense_1/LeakyRelu:0\", shape=(?, 4), dtype=float32)\n",
      "generator_network: network = Tensor(\"generator/layers_dense_2/LeakyRelu:0\", shape=(?, 8), dtype=float32)\n",
      "generator_network: generated_outputs = Tensor(\"generator/layers_dense_generated_outputs/BiasAdd:0\", shape=(?, 3072), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-200\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: trained_model/export/exporter/temp-b'1590989625'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 3.902944.\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree(path=arguments[\"output_dir\"], ignore_errors=True)\n",
    "estimator = train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1590989625\n"
     ]
    }
   ],
   "source": [
    "!ls trained_model/export/exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/predictor/saved_model_predictor.py:153: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from trained_model/export/exporter/1590989625/variables/variables\n"
     ]
    }
   ],
   "source": [
    "predict_fn = tf.contrib.predictor.from_saved_model(\n",
    "    \"trained_model/export/exporter/1590989625\"\n",
    ")\n",
    "predictions = predict_fn(\n",
    "    {\n",
    "        \"Z\": np.random.normal(size=(500, 512))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = np.clip(\n",
    "    a=((predictions[\"generated_images\"] + 1.0) * (255. / 2)).astype(np.int32),\n",
    "    a_min=0,\n",
    "    a_max=255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(generated_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(generated_images[i], cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
