{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18.1\n",
      "1.15.2-dlenv_tfe\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(np.__version__)\n",
    "print(tf.__version__)\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {}\n",
    "# File arguments.\n",
    "arguments[\"train_file_pattern\"] = \"gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord\"\n",
    "arguments[\"eval_file_pattern\"] = \"gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord\"\n",
    "arguments[\"output_dir\"] = \"gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model\"\n",
    "\n",
    "# Training parameters.\n",
    "arguments[\"train_batch_size\"] = 16\n",
    "arguments[\"train_steps\"] = 37500\n",
    "arguments[\"save_summary_steps\"] = 100\n",
    "arguments[\"save_checkpoints_steps\"] = 10000\n",
    "arguments[\"keep_checkpoint_max\"] = 10\n",
    "arguments[\"input_fn_autotune\"] = False\n",
    "\n",
    "# Eval parameters.\n",
    "arguments[\"eval_batch_size\"] = 32\n",
    "arguments[\"eval_steps\"] = 100\n",
    "arguments[\"start_delay_secs\"] = 6000\n",
    "arguments[\"throttle_secs\"] = 6000\n",
    "\n",
    "# Image parameters.\n",
    "arguments[\"height\"] = 28\n",
    "arguments[\"width\"] = 28\n",
    "arguments[\"depth\"] = 1\n",
    "\n",
    "# Generator parameters.\n",
    "arguments[\"latent_size\"] = 512\n",
    "arguments[\"generator_hidden_units\"] = [256, 512, 1024]\n",
    "arguments[\"generator_leaky_relu_alpha\"] = 0.2\n",
    "arguments[\"generator_final_activation\"] = \"tanh\"\n",
    "arguments[\"generator_l1_regularization_scale\"] = 0.\n",
    "arguments[\"generator_l2_regularization_scale\"] = 0.\n",
    "arguments[\"generator_optimizer\"] = \"Adam\"\n",
    "arguments[\"generator_learning_rate\"] = 0.0002\n",
    "arguments[\"generator_adam_beta1\"] = 0.5\n",
    "arguments[\"generator_adam_beta2\"] = 0.999\n",
    "arguments[\"generator_adam_epsilon\"] = 1e-8\n",
    "arguments[\"generator_clip_gradients\"] = None\n",
    "arguments[\"generator_train_steps\"] = 1\n",
    "\n",
    "# Discriminator hyperparameters.\n",
    "arguments[\"discriminator_hidden_units\"] = [1024, 512, 256]\n",
    "arguments[\"discriminator_leaky_relu_alpha\"] = 0.2\n",
    "arguments[\"discriminator_l1_regularization_scale\"] = 0.\n",
    "arguments[\"discriminator_l2_regularization_scale\"] = 0.\n",
    "arguments[\"discriminator_optimizer\"] = \"Adam\"\n",
    "arguments[\"discriminator_learning_rate\"] = 0.0002\n",
    "arguments[\"discriminator_adam_beta1\"] = 0.5\n",
    "arguments[\"discriminator_adam_beta2\"] = 0.999\n",
    "arguments[\"discriminator_adam_epsilon\"] = 1e-8\n",
    "arguments[\"discriminator_clip_gradients\"] = None\n",
    "arguments[\"discriminator_train_steps\"] = 1\n",
    "arguments[\"label_smoothing\"] = 0.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print_object.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_obj(function_name, object_name, object_value):\n",
    "    \"\"\"Prints enclosing function, object name, and object value.\n",
    "\n",
    "    Args:\n",
    "        function_name: str, name of function.\n",
    "        object_name: str, name of object.\n",
    "        object_value: object, value of passed object.\n",
    "    \"\"\"\n",
    "#     pass\n",
    "    print(\"{}: {} = {}\".format(function_name, object_name, object_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, params):\n",
    "    \"\"\"Preprocess image tensor.\n",
    "\n",
    "    Args:\n",
    "        image: tensor, input image with shape\n",
    "            [cur_batch_size, height, width, depth].\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Preprocessed image tensor with shape\n",
    "            [cur_batch_size, height, width, depth].\n",
    "    \"\"\"\n",
    "    func_name = \"preprocess_image\"\n",
    "    # Convert from [0, 255] -> [-1.0, 1.0] floats.\n",
    "    image = tf.cast(x=image, dtype=tf.float32) * (2. / 255) - 1.0\n",
    "    print_obj(func_name, \"image\", image)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def decode_example(protos, params):\n",
    "    \"\"\"Decodes TFRecord file into tensors.\n",
    "\n",
    "    Given protobufs, decode into image and label tensors.\n",
    "\n",
    "    Args:\n",
    "        protos: protobufs from TFRecord file.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Image and label tensors.\n",
    "    \"\"\"\n",
    "    func_name = \"decode_example\"\n",
    "    # Create feature schema map for protos.\n",
    "    features = {\n",
    "        \"image_raw\": tf.FixedLenFeature(shape=[], dtype=tf.string),\n",
    "        \"label\": tf.FixedLenFeature(shape=[], dtype=tf.int64)\n",
    "    }\n",
    "\n",
    "    # Parse features from tf.Example.\n",
    "    parsed_features = tf.parse_single_example(\n",
    "        serialized=protos, features=features\n",
    "    )\n",
    "    print_obj(\"\\n\" + func_name, \"features\", features)\n",
    "\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length height * width * depth) to a uint8 tensor with shape\n",
    "    # [height * width * depth].\n",
    "    image = tf.decode_raw(\n",
    "        input_bytes=parsed_features[\"image_raw\"], out_type=tf.uint8\n",
    "    )\n",
    "    print_obj(func_name, \"image\", image)\n",
    "\n",
    "    # Reshape flattened image back into normal dimensions.\n",
    "    image = tf.reshape(\n",
    "        tensor=image,\n",
    "        shape=[params[\"height\"], params[\"width\"], params[\"depth\"]]\n",
    "    )\n",
    "    print_obj(func_name, \"image\", image)\n",
    "\n",
    "    # Preprocess image.\n",
    "    image = preprocess_image(image=image, params=params)\n",
    "    print_obj(func_name, \"image\", image)\n",
    "\n",
    "    # Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "    label = tf.cast(x=parsed_features[\"label\"], dtype=tf.int32)\n",
    "    print_obj(func_name, \"label\", label)\n",
    "\n",
    "    return {\"image\": image}, label\n",
    "\n",
    "\n",
    "def read_dataset(filename, mode, batch_size, params):\n",
    "    \"\"\"Reads TF Record data using tf.data, doing necessary preprocessing.\n",
    "\n",
    "    Given filename, mode, batch size, and other parameters, read TF Record\n",
    "    dataset using Dataset API, apply necessary preprocessing, and return an\n",
    "    input function to the Estimator API.\n",
    "\n",
    "    Args:\n",
    "        filename: str, file pattern that to read into our tf.data dataset.\n",
    "        mode: The estimator ModeKeys. Can be TRAIN or EVAL.\n",
    "        batch_size: int, number of examples per batch.\n",
    "        params: dict, dictionary of user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        An input function.\n",
    "    \"\"\"\n",
    "    def _input_fn():\n",
    "        \"\"\"Wrapper input function used by Estimator API to get data tensors.\n",
    "\n",
    "        Returns:\n",
    "            Batched dataset object of dictionary of feature tensors and label\n",
    "                tensor.\n",
    "        \"\"\"\n",
    "        # Create list of files that match pattern.\n",
    "        file_list = tf.gfile.Glob(filename=filename)\n",
    "\n",
    "        # Create dataset from file list.\n",
    "        if params[\"input_fn_autotune\"]:\n",
    "            dataset = tf.data.TFRecordDataset(\n",
    "                filenames=file_list,\n",
    "                num_parallel_reads=tf.contrib.data.AUTOTUNE\n",
    "            )\n",
    "        else:\n",
    "            dataset = tf.data.TFRecordDataset(filenames=file_list)\n",
    "\n",
    "        # Shuffle and repeat if training with fused op.\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            dataset = dataset.apply(\n",
    "                tf.contrib.data.shuffle_and_repeat(\n",
    "                    buffer_size=50 * batch_size,\n",
    "                    count=None  # indefinitely\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Decode CSV file into a features dictionary of tensors, then batch.\n",
    "        if params[\"input_fn_autotune\"]:\n",
    "            dataset = dataset.apply(\n",
    "                tf.contrib.data.map_and_batch(\n",
    "                    map_func=lambda x: decode_example(\n",
    "                        protos=x,\n",
    "                        params=params\n",
    "                    ),\n",
    "                    batch_size=batch_size,\n",
    "                    num_parallel_calls=tf.contrib.data.AUTOTUNE\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            dataset = dataset.apply(\n",
    "                tf.contrib.data.map_and_batch(\n",
    "                    map_func=lambda x: decode_example(\n",
    "                        protos=x,\n",
    "                        params=params\n",
    "                    ),\n",
    "                    batch_size=batch_size\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Prefetch data to improve latency.\n",
    "        if params[\"input_fn_autotune\"]:\n",
    "            dataset = dataset.prefetch(buffer_size=tf.contrib.data.AUTOTUNE)\n",
    "        else:\n",
    "            dataset = dataset.prefetch(buffer_size=1)\n",
    "\n",
    "        # Create a iterator, then get batch of features from example queue.\n",
    "        batched_dataset = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        return batched_dataset\n",
    "    return _input_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(object):\n",
    "    \"\"\"Generator that takes latent vector input and outputs image.\n",
    "    Fields:\n",
    "        name: str, name of `Generator`.\n",
    "        kernel_regularizer: `l1_l2_regularizer` object, regularizar for kernel\n",
    "            variables.\n",
    "        bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "            variables.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_regularizer, bias_regularizer, name):\n",
    "        \"\"\"Instantiates and builds generator network.\n",
    "        Args:\n",
    "            kernel_regularizer: `l1_l2_regularizer` object, regularizar for\n",
    "                kernel variables.\n",
    "            bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "                variables.\n",
    "            name: str, name of generator.\n",
    "        \"\"\"\n",
    "        # Set name of generator.\n",
    "        self.name = name\n",
    "\n",
    "        # Regularizer for kernel weights.\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "\n",
    "        # Regularizer for bias weights.\n",
    "        self.bias_regularizer = bias_regularizer\n",
    "\n",
    "    def get_fake_images(self, Z, params):\n",
    "        \"\"\"Creates generator network and returns generated images.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Generated image tensor of shape\n",
    "                [cur_batch_size, height * width * depth].\n",
    "        \"\"\"\n",
    "        func_name = \"get_fake_images\"\n",
    "        # Create the input layer to our DNN.\n",
    "        # shape = (cur_batch_size, latent_size)\n",
    "        network = Z\n",
    "        print_obj(\"\\n\" + func_name, \"network\", network)\n",
    "\n",
    "        # Dictionary containing possible final activations.\n",
    "        final_activation_dict = {\n",
    "            \"sigmoid\": tf.nn.sigmoid, \"relu\": tf.nn.relu, \"tanh\": tf.nn.tanh\n",
    "        }\n",
    "\n",
    "        with tf.variable_scope(\"generator\", reuse=tf.AUTO_REUSE):\n",
    "            # Add hidden layers with given number of units/neurons per layer.\n",
    "            for i, units in enumerate(params[\"generator_hidden_units\"]):\n",
    "                # shape = (cur_batch_size, generator_hidden_units[i])\n",
    "                network = tf.layers.dense(\n",
    "                    inputs=network,\n",
    "                    units=units,\n",
    "                    activation=None,\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"layers_dense_{}\".format(i)\n",
    "                )\n",
    "                print_obj(func_name, \"network\", network)\n",
    "\n",
    "                network = tf.nn.leaky_relu(\n",
    "                    features=network,\n",
    "                    alpha=params[\"generator_leaky_relu_alpha\"],\n",
    "                    name=\"leaky_relu_{}\".format(i)\n",
    "                )\n",
    "                print_obj(func_name, \"network\", network)\n",
    "\n",
    "            # Final linear layer for outputs.\n",
    "            # shape = (cur_batch_size, height * width * depth)\n",
    "            generated_outputs = tf.layers.dense(\n",
    "                inputs=network,\n",
    "                units=params[\"height\"] * params[\"width\"] * params[\"depth\"],\n",
    "                activation=final_activation_dict.get(\n",
    "                    params[\"generator_final_activation\"].lower(), None\n",
    "                ),\n",
    "                kernel_regularizer=self.kernel_regularizer,\n",
    "                bias_regularizer=self.bias_regularizer,\n",
    "                name=\"layers_dense_generated_outputs\"\n",
    "            )\n",
    "            print_obj(func_name, \"generated_outputs\", generated_outputs)\n",
    "\n",
    "        return generated_outputs\n",
    "\n",
    "    def get_generator_loss(self, fake_logits):\n",
    "        \"\"\"Gets generator loss.\n",
    "\n",
    "        Args:\n",
    "            fake_logits: tensor, shape of\n",
    "                [cur_batch_size, 1].\n",
    "\n",
    "        Returns:\n",
    "            Tensor of generator's total loss of shape [].\n",
    "        \"\"\"\n",
    "        func_name = \"get_generator_loss\"\n",
    "        # Calculate base generator loss.\n",
    "        generator_loss = tf.reduce_mean(\n",
    "            input_tensor=tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                logits=fake_logits,\n",
    "                labels=tf.ones_like(tensor=fake_logits)\n",
    "            ),\n",
    "            name=\"generator_loss\"\n",
    "        )\n",
    "        print_obj(\"\\n\" + func_name, \"generator_loss\", generator_loss)\n",
    "\n",
    "        # Get regularization losses.\n",
    "        generator_reg_loss = tf.losses.get_regularization_loss(\n",
    "            scope=\"generator\",\n",
    "            name=\"generator_regularization_loss\"\n",
    "        )\n",
    "        print_obj(func_name, \"generator_reg_loss\", generator_reg_loss)\n",
    "\n",
    "        # Combine losses for total losses.\n",
    "        generator_total_loss = tf.math.add(\n",
    "            x=generator_loss,\n",
    "            y=generator_reg_loss,\n",
    "            name=\"generator_total_loss\"\n",
    "        )\n",
    "        print_obj(func_name, \"generator_total_loss\", generator_total_loss)\n",
    "\n",
    "        # Add summaries for TensorBoard.\n",
    "        tf.summary.scalar(\n",
    "            name=\"generator_loss\", tensor=generator_loss, family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"generator_reg_loss\",\n",
    "            tensor=generator_reg_loss,\n",
    "            family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"generator_total_loss\",\n",
    "            tensor=generator_total_loss,\n",
    "            family=\"total_losses\"\n",
    "        )\n",
    "\n",
    "        return generator_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## discriminator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(object):\n",
    "    \"\"\"Discriminator that takes image input and outputs logits.\n",
    "    Fields:\n",
    "        name: str, name of `Discriminator`.\n",
    "        kernel_regularizer: `l1_l2_regularizer` object, regularizar for kernel\n",
    "            variables.\n",
    "        bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "            variables.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_regularizer, bias_regularizer, name):\n",
    "        \"\"\"Instantiates and builds discriminator network.\n",
    "        Args:\n",
    "            kernel_regularizer: `l1_l2_regularizer` object, regularizar for\n",
    "                kernel variables.\n",
    "            bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "                variables.\n",
    "            name: str, name of discriminator.\n",
    "        \"\"\"\n",
    "        # Set name of discriminator.\n",
    "        self.name = name\n",
    "\n",
    "        # Regularizer for kernel weights.\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "\n",
    "        # Regularizer for bias weights.\n",
    "        self.bias_regularizer = bias_regularizer\n",
    "\n",
    "    def get_discriminator_logits(self, X, params):\n",
    "        \"\"\"Creates discriminator network and returns logits.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, image tensors of shape\n",
    "                [cur_batch_size, height * width * depth].\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Logits tensor of shape [cur_batch_size, 1].\n",
    "        \"\"\"\n",
    "        func_name = \"get_discriminator_logits\"\n",
    "        # Create the input layer to our DNN.\n",
    "        # shape = (cur_batch_size, height * width * depth)\n",
    "        network = X\n",
    "        print_obj(\"\\n\" + func_name, \"network\", network)\n",
    "\n",
    "        with tf.variable_scope(\"discriminator\", reuse=tf.AUTO_REUSE):\n",
    "            # Add hidden layers with given number of units/neurons per layer.\n",
    "            for i, units in enumerate(params[\"discriminator_hidden_units\"]):\n",
    "                # shape = (cur_batch_size, discriminator_hidden_units[i])\n",
    "                network = tf.layers.dense(\n",
    "                    inputs=network,\n",
    "                    units=units,\n",
    "                    activation=None,\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"layers_dense_{}\".format(i)\n",
    "                )\n",
    "                print_obj(func_name, \"network\", network)\n",
    "\n",
    "                network = tf.nn.leaky_relu(\n",
    "                    features=network,\n",
    "                    alpha=params[\"discriminator_leaky_relu_alpha\"],\n",
    "                    name=\"leaky_relu_{}\".format(i)\n",
    "                )\n",
    "                print_obj(func_name, \"network\", network)\n",
    "\n",
    "            # Final linear layer for logits.\n",
    "            # shape = (cur_batch_size, 1)\n",
    "            logits = tf.layers.dense(\n",
    "                inputs=network,\n",
    "                units=1,\n",
    "                activation=None,\n",
    "                kernel_regularizer=self.kernel_regularizer,\n",
    "                bias_regularizer=self.bias_regularizer,\n",
    "                name=\"layers_dense_logits\"\n",
    "            )\n",
    "            print_obj(func_name, \"logits\", logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def get_discriminator_loss(self, fake_logits, real_logits, params):\n",
    "        \"\"\"Gets discriminator loss.\n",
    "\n",
    "        Args:\n",
    "            fake_logits: tensor, shape of\n",
    "                [cur_batch_size, 1].\n",
    "            real_logits: tensor, shape of\n",
    "                [cur_batch_size, 1].\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of discriminator's total loss of shape [].\n",
    "        \"\"\"\n",
    "        func_name = \"get_discriminator_loss\"\n",
    "        # Calculate base discriminator loss.\n",
    "        discriminator_real_loss = tf.reduce_mean(\n",
    "            input_tensor=tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                logits=real_logits,\n",
    "                labels=tf.multiply(\n",
    "                    x=tf.ones_like(tensor=real_logits),\n",
    "                    y=params[\"label_smoothing\"]\n",
    "                )\n",
    "            ),\n",
    "            name=\"discriminator_real_loss\"\n",
    "        )\n",
    "        print_obj(\n",
    "            \"\\n\" + func_name,\n",
    "            \"discriminator_real_loss\",\n",
    "            discriminator_real_loss\n",
    "        )\n",
    "\n",
    "        discriminator_fake_loss = tf.reduce_mean(\n",
    "            input_tensor=tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                logits=fake_logits,\n",
    "                labels=tf.zeros_like(tensor=fake_logits)\n",
    "            ),\n",
    "            name=\"discriminator_fake_loss\"\n",
    "        )\n",
    "        print_obj(\n",
    "            func_name, \"discriminator_fake_loss\", discriminator_fake_loss\n",
    "        )\n",
    "\n",
    "        discriminator_loss = tf.add(\n",
    "            x=discriminator_real_loss,\n",
    "            y=discriminator_fake_loss,\n",
    "            name=\"discriminator_loss\"\n",
    "        )\n",
    "        print_obj(func_name, \"discriminator_loss\", discriminator_loss)\n",
    "\n",
    "        # Get regularization losses.\n",
    "        discriminator_reg_loss = tf.losses.get_regularization_loss(\n",
    "            scope=\"discriminator\",\n",
    "            name=\"discriminator_reg_loss\"\n",
    "        )\n",
    "        print_obj(func_name, \"discriminator_reg_loss\", discriminator_reg_loss)\n",
    "\n",
    "        # Combine losses for total losses.\n",
    "        discriminator_total_loss = tf.math.add(\n",
    "            x=discriminator_loss,\n",
    "            y=discriminator_reg_loss,\n",
    "            name=\"discriminator_total_loss\"\n",
    "        )\n",
    "        print_obj(\n",
    "            func_name, \"discriminator_total_loss\", discriminator_total_loss\n",
    "        )\n",
    "\n",
    "        # Add summaries for TensorBoard.\n",
    "        tf.summary.scalar(\n",
    "            name=\"discriminator_real_loss\",\n",
    "            tensor=discriminator_real_loss,\n",
    "            family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"discriminator_fake_loss\",\n",
    "            tensor=discriminator_fake_loss,\n",
    "            family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"discriminator_loss\",\n",
    "            tensor=discriminator_loss,\n",
    "            family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"discriminator_reg_loss\",\n",
    "            tensor=discriminator_reg_loss,\n",
    "            family=\"losses\"\n",
    "        )\n",
    "        tf.summary.scalar(\n",
    "            name=\"discriminator_total_loss\",\n",
    "            tensor=discriminator_total_loss,\n",
    "            family=\"total_losses\"\n",
    "        )\n",
    "\n",
    "        return discriminator_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_and_eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits_and_losses(features, generator, discriminator, params):\n",
    "    \"\"\"Gets logits and losses for both train and eval modes.\n",
    "\n",
    "    Args:\n",
    "        features: dict, feature tensors from input function.\n",
    "        generator: instance of generator.`Generator`.\n",
    "        discriminator: instance of discriminator.`Discriminator`.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Real and fake logits and generator and discriminator losses.\n",
    "    \"\"\"\n",
    "    func_name = \"get_logits_and_losses\"\n",
    "    # Extract real images from features dictionary.\n",
    "    real_images = tf.reshape(\n",
    "        tensor=features[\"image\"],\n",
    "        shape=[-1, params[\"height\"] * params[\"width\"] * params[\"depth\"]]\n",
    "    )\n",
    "    print_obj(\"\\n\" + func_name, \"real_images\", real_images)\n",
    "\n",
    "    # Get dynamic batch size in case of partial batch.\n",
    "    cur_batch_size = tf.shape(\n",
    "        input=real_images,\n",
    "        out_type=tf.int32,\n",
    "        name=\"{}_cur_batch_size\".format(func_name)\n",
    "    )[0]\n",
    "\n",
    "    # Create random noise latent vector for each batch example.\n",
    "    Z = tf.random.normal(\n",
    "        shape=[cur_batch_size, params[\"latent_size\"]],\n",
    "        mean=0.0,\n",
    "        stddev=1.0,\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "    print_obj(func_name, \"Z\", Z)\n",
    "\n",
    "    # Get generated image from generator network from gaussian noise.\n",
    "    print(\"\\nCall generator with Z = {}.\".format(Z))\n",
    "    fake_images = generator.get_fake_images(Z=Z, params=params)\n",
    "\n",
    "    # Add summaries for TensorBoard.\n",
    "    tf.summary.image(\n",
    "        name=\"fake_images\",\n",
    "        tensor=tf.reshape(\n",
    "            tensor=fake_images,\n",
    "            shape=[-1, params[\"height\"], params[\"width\"], params[\"depth\"]]\n",
    "        ),\n",
    "        max_outputs=5,\n",
    "    )\n",
    "\n",
    "    # Get fake logits from discriminator using generator's output image.\n",
    "    print(\"\\nCall discriminator with fake_images = {}.\".format(fake_images))\n",
    "    fake_logits = discriminator.get_discriminator_logits(\n",
    "        X=fake_images, params=params\n",
    "    )\n",
    "\n",
    "    # Get real logits from discriminator using real image.\n",
    "    print(\n",
    "        \"\\nCall discriminator with real_images = {}.\".format(real_images)\n",
    "    )\n",
    "    real_logits = discriminator.get_discriminator_logits(\n",
    "        X=real_images, params=params\n",
    "    )\n",
    "\n",
    "    # Get generator total loss.\n",
    "    generator_total_loss = generator.get_generator_loss(\n",
    "        fake_logits=fake_logits\n",
    "    )\n",
    "\n",
    "    # Get discriminator total loss.\n",
    "    discriminator_total_loss = discriminator.get_discriminator_loss(\n",
    "        fake_logits=fake_logits, real_logits=real_logits, params=params\n",
    "    )\n",
    "\n",
    "    return (real_logits,\n",
    "            fake_logits,\n",
    "            generator_total_loss,\n",
    "            discriminator_total_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variables_and_gradients(loss, scope):\n",
    "    \"\"\"Gets variables and their gradients wrt. loss.\n",
    "    Args:\n",
    "        loss: tensor, shape of [].\n",
    "        scope: str, the network's name to find its variables to train.\n",
    "    Returns:\n",
    "        Lists of variables and their gradients.\n",
    "    \"\"\"\n",
    "    func_name = \"get_variables_and_gradients\"\n",
    "    # Get trainable variables.\n",
    "    variables = tf.trainable_variables(scope=scope)\n",
    "    print_obj(\"\\n{}_{}\".format(func_name, scope), \"variables\", variables)\n",
    "\n",
    "    # Get gradients.\n",
    "    gradients = tf.gradients(\n",
    "        ys=loss,\n",
    "        xs=variables,\n",
    "        name=\"{}_gradients\".format(scope)\n",
    "    )\n",
    "    print_obj(\"\\n{}_{}\".format(func_name, scope), \"gradients\", gradients)\n",
    "\n",
    "    # Add variable names back in for identification.\n",
    "    gradients = [\n",
    "        tf.identity(\n",
    "            input=g,\n",
    "            name=\"{}_{}_gradients\".format(func_name, v.name[:-2])\n",
    "        )\n",
    "        if tf.is_tensor(x=g) else g\n",
    "        for g, v in zip(gradients, variables)\n",
    "    ]\n",
    "    print_obj(\"\\n{}_{}\".format(func_name, scope), \"gradients\", gradients)\n",
    "\n",
    "    return variables, gradients\n",
    "\n",
    "\n",
    "def create_variable_and_gradient_histogram_summaries(loss_dict, params):\n",
    "    \"\"\"Creates variable and gradient histogram summaries.\n",
    "    Args:\n",
    "        loss_dict: dict, keys are scopes and values are scalar loss tensors\n",
    "            for each network kind.\n",
    "        params: dict, user passed parameters.\n",
    "    \"\"\"\n",
    "    for scope, loss in loss_dict.items():\n",
    "        # Get variables and their gradients wrt. loss.\n",
    "        variables, gradients = get_variables_and_gradients(loss, scope)\n",
    "\n",
    "        # Add summaries for TensorBoard.\n",
    "        for g, v in zip(gradients, variables):\n",
    "            tf.summary.histogram(\n",
    "                name=\"{}\".format(v.name[:-2]),\n",
    "                values=v,\n",
    "                family=\"{}_variables\".format(scope)\n",
    "            )\n",
    "            if tf.is_tensor(x=g):\n",
    "                tf.summary.histogram(\n",
    "                    name=\"{}\".format(v.name[:-2]),\n",
    "                    values=g,\n",
    "                    family=\"{}_gradients\".format(scope)\n",
    "                )\n",
    "\n",
    "\n",
    "def train_network(loss, global_step, params, scope):\n",
    "    \"\"\"Trains network and returns loss and train op.\n",
    "\n",
    "    Args:\n",
    "        loss: tensor, shape of [].\n",
    "        global_step: tensor, the current training step or batch in the\n",
    "            training loop.\n",
    "        params: dict, user passed parameters.\n",
    "        scope: str, the variables that to train.\n",
    "\n",
    "    Returns:\n",
    "        Loss tensor and training op.\n",
    "    \"\"\"\n",
    "    func_name = \"train_network\"\n",
    "    print_obj(\"\\n\" + func_name, \"scope\", scope)\n",
    "    # Create optimizer map.\n",
    "    optimizers = {\n",
    "        \"Adam\": tf.train.AdamOptimizer,\n",
    "        \"Adadelta\": tf.train.AdadeltaOptimizer,\n",
    "        \"AdagradDA\": tf.train.AdagradDAOptimizer,\n",
    "        \"Adagrad\": tf.train.AdagradOptimizer,\n",
    "        \"Ftrl\": tf.train.FtrlOptimizer,\n",
    "        \"GradientDescent\": tf.train.GradientDescentOptimizer,\n",
    "        \"Momentum\": tf.train.MomentumOptimizer,\n",
    "        \"ProximalAdagrad\": tf.train.ProximalAdagradOptimizer,\n",
    "        \"ProximalGradientDescent\": tf.train.ProximalGradientDescentOptimizer,\n",
    "        \"RMSProp\": tf.train.RMSPropOptimizer\n",
    "    }\n",
    "\n",
    "    # Get optimizer and instantiate it.\n",
    "    if params[\"{}_optimizer\".format(scope)] == \"Adam\":\n",
    "        optimizer = optimizers[params[\"{}_optimizer\".format(scope)]](\n",
    "            learning_rate=params[\"{}_learning_rate\".format(scope)],\n",
    "            beta1=params[\"{}_adam_beta1\".format(scope)],\n",
    "            beta2=params[\"{}_adam_beta2\".format(scope)],\n",
    "            epsilon=params[\"{}_adam_epsilon\".format(scope)],\n",
    "            name=\"{}_{}_optimizer\".format(\n",
    "                scope, params[\"{}_optimizer\".format(scope)].lower()\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        optimizer = optimizers[params[\"{}_optimizer\".format(scope)]](\n",
    "            learning_rate=params[\"{}_learning_rate\".format(scope)],\n",
    "            name=\"{}_{}_optimizer\".format(\n",
    "                scope, params[\"{}_optimizer\".format(scope)].lower()\n",
    "            )\n",
    "        )\n",
    "    print_obj(\"{}_{}\".format(func_name, scope), \"optimizer\", optimizer)\n",
    "\n",
    "    # Get gradients.\n",
    "    gradients = tf.gradients(\n",
    "        ys=loss,\n",
    "        xs=tf.trainable_variables(scope=scope),\n",
    "        name=\"{}_gradients\".format(scope)\n",
    "    )\n",
    "    print_obj(\"\\n{}_{}\".format(func_name, scope), \"gradients\", gradients)\n",
    "\n",
    "    # Clip gradients.\n",
    "    if params[\"{}_clip_gradients\".format(scope)]:\n",
    "        gradients, _ = tf.clip_by_global_norm(\n",
    "            t_list=gradients,\n",
    "            clip_norm=params[\"{}_clip_gradients\".format(scope)],\n",
    "            name=\"{}_clip_by_global_norm_gradients\".format(scope)\n",
    "        )\n",
    "        print_obj(\"\\n{}_{}\".format(func_name, scope), \"gradients\", gradients)\n",
    "\n",
    "    # Zip back together gradients and variables.\n",
    "    grads_and_vars = zip(gradients, tf.trainable_variables(scope=scope))\n",
    "    print_obj(\n",
    "        \"{}_{}\".format(func_name, scope), \"grads_and_vars\", grads_and_vars\n",
    "    )\n",
    "\n",
    "    # Create train op by applying gradients to variables and incrementing\n",
    "    # global step.\n",
    "    train_op = optimizer.apply_gradients(\n",
    "        grads_and_vars=grads_and_vars,\n",
    "        global_step=global_step,\n",
    "        name=\"{}_apply_gradients\".format(scope)\n",
    "    )\n",
    "\n",
    "    return loss, train_op\n",
    "\n",
    "\n",
    "def get_loss_and_train_op(\n",
    "        generator_total_loss, discriminator_total_loss, params):\n",
    "    \"\"\"Gets loss and train op for train mode.\n",
    "    Args:\n",
    "        generator_total_loss: tensor, scalar total loss of generator.\n",
    "        discriminator_total_loss: tensor, scalar total loss of discriminator.\n",
    "        params: dict, user passed parameters.\n",
    "    Returns:\n",
    "        Loss scalar tensor and train_op to be used by the EstimatorSpec.\n",
    "    \"\"\"\n",
    "    func_name = \"get_loss_and_train_op\"\n",
    "    # Get global step.\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    # Determine if it is time to train generator or discriminator.\n",
    "    cycle_step = tf.mod(\n",
    "        x=global_step,\n",
    "        y=tf.cast(\n",
    "            x=tf.add(\n",
    "                x=params[\"discriminator_train_steps\"],\n",
    "                y=params[\"generator_train_steps\"]\n",
    "            ),\n",
    "            dtype=tf.int64\n",
    "        ),\n",
    "        name=\"{}_cycle_step\".format(func_name)\n",
    "    )\n",
    "\n",
    "    # Create choose discriminator condition.\n",
    "    condition = tf.less(\n",
    "        x=cycle_step, y=params[\"discriminator_train_steps\"]\n",
    "    )\n",
    "\n",
    "    # Conditionally choose to train generator or discriminator subgraph.\n",
    "    loss, train_op = tf.cond(\n",
    "        pred=condition,\n",
    "        true_fn=lambda: train_network(\n",
    "            loss=discriminator_total_loss,\n",
    "            global_step=global_step,\n",
    "            params=params,\n",
    "            scope=\"discriminator\"\n",
    "        ),\n",
    "        false_fn=lambda: train_network(\n",
    "            loss=generator_total_loss,\n",
    "            global_step=global_step,\n",
    "            params=params,\n",
    "            scope=\"generator\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return loss, train_op\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval_metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metric_ops(fake_logits, real_logits, params):\n",
    "    \"\"\"Gets eval metric ops.\n",
    "\n",
    "    Args:\n",
    "        fake_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "            discriminator having processed generator's output image.\n",
    "        real_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "            discriminator having processed real image.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of eval metric ops.\n",
    "    \"\"\"\n",
    "    func_name = \"get_eval_metric_ops\"\n",
    "    # Concatenate discriminator logits and labels.\n",
    "    discriminator_logits = tf.concat(\n",
    "        values=[real_logits, fake_logits],\n",
    "        axis=0,\n",
    "        name=\"discriminator_concat_logits\"\n",
    "    )\n",
    "    print_obj(\"\\n\" + func_name, \"discriminator_logits\", discriminator_logits)\n",
    "\n",
    "    discriminator_labels = tf.concat(\n",
    "        values=[\n",
    "            tf.ones_like(tensor=real_logits) * params[\"label_smoothing\"],\n",
    "            tf.zeros_like(tensor=fake_logits)\n",
    "        ],\n",
    "        axis=0,\n",
    "        name=\"discriminator_concat_labels\"\n",
    "    )\n",
    "    print_obj(func_name, \"discriminator_labels\", discriminator_labels)\n",
    "\n",
    "    # Calculate discriminator probabilities.\n",
    "    discriminator_probabilities = tf.nn.sigmoid(\n",
    "        x=discriminator_logits, name=\"discriminator_probabilities\"\n",
    "    )\n",
    "    print_obj(\n",
    "        func_name, \"discriminator_probabilities\", discriminator_probabilities\n",
    "    )\n",
    "\n",
    "    # Create eval metric ops dictionary.\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            name=\"discriminator_accuracy\"\n",
    "        ),\n",
    "        \"precision\": tf.metrics.precision(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            name=\"discriminator_precision\"\n",
    "        ),\n",
    "        \"recall\": tf.metrics.recall(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            name=\"discriminator_recall\"\n",
    "        ),\n",
    "        \"auc_roc\": tf.metrics.auc(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            num_thresholds=200,\n",
    "            curve=\"ROC\",\n",
    "            name=\"discriminator_auc_roc\"\n",
    "        ),\n",
    "        \"auc_pr\": tf.metrics.auc(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            num_thresholds=200,\n",
    "            curve=\"PR\",\n",
    "            name=\"discriminator_auc_pr\"\n",
    "        )\n",
    "    }\n",
    "    print_obj(func_name, \"eval_metric_ops\", eval_metric_ops)\n",
    "\n",
    "    return eval_metric_ops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_and_export_outputs(features, generator, params):\n",
    "    \"\"\"Gets predictions and serving export outputs.\n",
    "\n",
    "    Args:\n",
    "        features: dict, feature tensors from serving input function.\n",
    "        generator: instance of `Generator`.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Predictions dictionary and export outputs dictionary.\n",
    "    \"\"\"\n",
    "    func_name = \"get_predictions_and_export_outputs\"\n",
    "\n",
    "    # Extract given latent vectors from features dictionary.\n",
    "    Z = features[\"Z\"]\n",
    "    print_obj(\"\\n\" + func_name, \"Z\", Z)\n",
    "\n",
    "    # Establish generator network subgraph.\n",
    "    fake_images = generator.get_fake_images(Z=Z, params=params)\n",
    "    print_obj(func_name, \"fake_images\", fake_images)\n",
    "\n",
    "    # Reshape into a rank 4 image.\n",
    "    generated_images = tf.reshape(\n",
    "        tensor=fake_images,\n",
    "        shape=[-1, params[\"height\"], params[\"width\"], params[\"depth\"]]\n",
    "    )\n",
    "    print_obj(func_name, \"generated_images\", generated_images)\n",
    "\n",
    "    # Create predictions dictionary.\n",
    "    predictions_dict = {\n",
    "        \"generated_images\": generated_images\n",
    "    }\n",
    "    print_obj(func_name, \"predictions_dict\", predictions_dict)\n",
    "\n",
    "    # Create export outputs.\n",
    "    export_outputs = {\n",
    "        \"predict_export_outputs\": tf.estimator.export.PredictOutput(\n",
    "            outputs=predictions_dict)\n",
    "    }\n",
    "    print_obj(func_name, \"export_outputs\", export_outputs)\n",
    "\n",
    "    return predictions_dict, export_outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vanilla_gan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_gan_model(features, labels, mode, params):\n",
    "    \"\"\"Vanilla GAN custom Estimator model function.\n",
    "\n",
    "    Args:\n",
    "        features: dict, keys are feature names and values are feature tensors.\n",
    "        labels: tensor, label data.\n",
    "        mode: tf.estimator.ModeKeys with values of either TRAIN, EVAL, or\n",
    "            PREDICT.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Instance of `tf.estimator.EstimatorSpec` class.\n",
    "    \"\"\"\n",
    "    func_name = \"vanilla_gan_model\"\n",
    "    print_obj(\"\\n\" + func_name, \"features\", features)\n",
    "    print_obj(func_name, \"labels\", labels)\n",
    "    print_obj(func_name, \"mode\", mode)\n",
    "    print_obj(func_name, \"params\", params)\n",
    "\n",
    "    # Loss function, training/eval ops, etc.\n",
    "    predictions_dict = None\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = None\n",
    "    export_outputs = None\n",
    "\n",
    "    # Instantiate generator.\n",
    "    vanilla_generator = Generator(\n",
    "        kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(\n",
    "            scale_l1=params[\"generator_l1_regularization_scale\"],\n",
    "            scale_l2=params[\"generator_l2_regularization_scale\"]\n",
    "        ),\n",
    "        bias_regularizer=None,\n",
    "        name=\"generator\"\n",
    "    )\n",
    "\n",
    "    # Instantiate discriminator.\n",
    "    vanilla_discriminator = Discriminator(\n",
    "        kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(\n",
    "            scale_l1=params[\"discriminator_l1_regularization_scale\"],\n",
    "            scale_l2=params[\"discriminator_l2_regularization_scale\"]\n",
    "        ),\n",
    "        bias_regularizer=None,\n",
    "        name=\"discriminator\"\n",
    "    )\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # Get predictions and export outputs.\n",
    "        (predictions_dict,\n",
    "         export_outputs) = get_predictions_and_export_outputs(\n",
    "            features=features, generator=vanilla_generator, params=params\n",
    "        )\n",
    "    else:\n",
    "        # Get logits and losses from networks for train and eval modes.\n",
    "        (real_logits,\n",
    "         fake_logits,\n",
    "         generator_total_loss,\n",
    "         discriminator_total_loss) = get_logits_and_losses(\n",
    "            features=features,\n",
    "            generator=vanilla_generator,\n",
    "            discriminator=vanilla_discriminator,\n",
    "            params=params\n",
    "        )\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            # Create variable and gradient histogram summaries.\n",
    "            create_variable_and_gradient_histogram_summaries(\n",
    "                loss_dict={\n",
    "                    \"generator\": generator_total_loss,\n",
    "                    \"discriminator\": discriminator_total_loss\n",
    "                },\n",
    "                params=params\n",
    "            )\n",
    "\n",
    "            # Get loss and train op for EstimatorSpec.\n",
    "            loss, train_op = get_loss_and_train_op(\n",
    "                generator_total_loss=generator_total_loss,\n",
    "                discriminator_total_loss=discriminator_total_loss,\n",
    "                params=params\n",
    "            )\n",
    "        else:\n",
    "            # Set eval loss.\n",
    "            loss = discriminator_total_loss\n",
    "\n",
    "            # Get eval metrics.\n",
    "            eval_metric_ops = get_eval_metric_ops(\n",
    "                real_logits=real_logits,\n",
    "                fake_logits=fake_logits,\n",
    "                params=params\n",
    "            )\n",
    "\n",
    "    # Return EstimatorSpec\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions_dict,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops,\n",
    "        export_outputs=export_outputs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## serving.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn(params):\n",
    "    \"\"\"Serving input function.\n",
    "\n",
    "    Args:\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        ServingInputReceiver object containing features and receiver tensors.\n",
    "    \"\"\"\n",
    "    func_name = \"serving_input_fn\"\n",
    "    # Create placeholders to accept data sent to the model at serving time.\n",
    "    # shape = (batch_size,)\n",
    "    feature_placeholders = {\n",
    "        \"Z\": tf.placeholder(\n",
    "            dtype=tf.float32,\n",
    "            shape=[None, params[\"latent_size\"]],\n",
    "            name=\"serving_input_placeholder_Z\"\n",
    "        )\n",
    "    }\n",
    "    print_obj(\"\\n\" + func_name, \"feature_placeholders\", feature_placeholders)\n",
    "\n",
    "    # Create clones of the feature placeholder tensors so that the SavedModel\n",
    "    # SignatureDef will point to the placeholder.\n",
    "    features = {\n",
    "        key: tf.identity(\n",
    "            input=value,\n",
    "            name=\"{}_identity_placeholder_{}\".format(func_name, key)\n",
    "        )\n",
    "        for key, value in feature_placeholders.items()\n",
    "    }\n",
    "    print_obj(func_name, \"features\", features)\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features=features, receiver_tensors=feature_placeholders\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(args):\n",
    "    \"\"\"Trains and evaluates custom Estimator model.\n",
    "\n",
    "    Args:\n",
    "        args: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        `Estimator` object.\n",
    "    \"\"\"\n",
    "    func_name = \"train_and_evaluate\"\n",
    "    print_obj(\"\\n\" + func_name, \"args\", args)\n",
    "    # Ensure filewriter cache is clear for TensorBoard events file.\n",
    "    tf.summary.FileWriterCache.clear()\n",
    "\n",
    "    # Set logging to be level of INFO.\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    # Create a RunConfig for Estimator.\n",
    "    config = tf.estimator.RunConfig(\n",
    "        model_dir=args[\"output_dir\"],\n",
    "        save_summary_steps=args[\"save_summary_steps\"],\n",
    "        save_checkpoints_steps=args[\"save_checkpoints_steps\"],\n",
    "        keep_checkpoint_max=args[\"keep_checkpoint_max\"]\n",
    "    )\n",
    "\n",
    "    # Create our custom estimator using our model function.\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn=vanilla_gan_model,\n",
    "        model_dir=args[\"output_dir\"],\n",
    "        config=config,\n",
    "        params=args\n",
    "    )\n",
    "\n",
    "    # Create train spec to read in our training data.\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"train_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.TRAIN,\n",
    "            batch_size=args[\"train_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        max_steps=args[\"train_steps\"]\n",
    "    )\n",
    "\n",
    "    # Create exporter to save out the complete model to disk.\n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        name=\"exporter\",\n",
    "        serving_input_receiver_fn=lambda: serving_input_fn(args)\n",
    "    )\n",
    "\n",
    "    # Create eval spec to read in our validation data and export our model.\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"eval_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.EVAL,\n",
    "            batch_size=args[\"eval_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        steps=args[\"eval_steps\"],\n",
    "        start_delay_secs=args[\"start_delay_secs\"],\n",
    "        throttle_secs=args[\"throttle_secs\"],\n",
    "        exporters=exporter\n",
    "    )\n",
    "\n",
    "    # Create train and evaluate loop to train and evaluate our estimator.\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n",
    "\n",
    "    return estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OUTPUT_DIR\"] = arguments[\"output_dir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil -m rm -rf ${OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f45f57c8390>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 10000 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-4-9b982c577a8a>:108: shuffle_and_repeat (from tensorflow.contrib.data.python.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.shuffle_and_repeat(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/shuffle_ops.py:54: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From <ipython-input-4-9b982c577a8a>:120: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(28, 28, 1), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "WARNING:tensorflow:From <ipython-input-4-9b982c577a8a>:128: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "vanilla_gan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 28, 28, 1) dtype=float32>}\n",
      "vanilla_gan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "vanilla_gan_model: mode = train\n",
      "vanilla_gan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model', 'train_batch_size': 16, 'train_steps': 37500, 'save_summary_steps': 100, 'save_checkpoints_steps': 10000, 'keep_checkpoint_max': 10, 'eval_batch_size': 32, 'eval_steps': 100, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 512, 'generator_hidden_units': [256, 512, 1024], 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_hidden_units': [1024, 512, 256], 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'label_smoothing': 0.9}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"Reshape:0\", shape=(?, 784), dtype=float32)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_fake_images: network = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-5-4208f87e6300>:60: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_0/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_2/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: generated_outputs = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32)\n",
      "\n",
      "Call discriminator with fake_images = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_0/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_0:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_2/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_2:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call discriminator with real_images = Tensor(\"Reshape:0\", shape=(?, 784), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"Reshape:0\", shape=(?, 784), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_0/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_0:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_2/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_2:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"generator_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_fake_loss = Tensor(\"discriminator_fake_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"Const_5:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_variables_and_gradients_generator: variables = [<tf.Variable 'generator/layers_dense_0/kernel:0' shape=(512, 256) dtype=float32_ref>, <tf.Variable 'generator/layers_dense_0/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'generator/layers_dense_1/kernel:0' shape=(256, 512) dtype=float32_ref>, <tf.Variable 'generator/layers_dense_1/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'generator/layers_dense_2/kernel:0' shape=(512, 1024) dtype=float32_ref>, <tf.Variable 'generator/layers_dense_2/bias:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'generator/layers_dense_generated_outputs/kernel:0' shape=(1024, 784) dtype=float32_ref>, <tf.Variable 'generator/layers_dense_generated_outputs/bias:0' shape=(784,) dtype=float32_ref>]\n",
      "\n",
      "get_variables_and_gradients_generator: gradients = [<tf.Tensor 'generator_gradients/generator/layers_dense_0/MatMul_grad/MatMul_1:0' shape=(512, 256) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_0/BiasAdd_grad/BiasAddGrad:0' shape=(256,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_1/MatMul_grad/MatMul_1:0' shape=(256, 512) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_1/BiasAdd_grad/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_2/MatMul_grad/MatMul_1:0' shape=(512, 1024) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_2/BiasAdd_grad/BiasAddGrad:0' shape=(1024,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_generated_outputs/MatMul_grad/MatMul_1:0' shape=(1024, 784) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_generated_outputs/BiasAdd_grad/BiasAddGrad:0' shape=(784,) dtype=float32>]\n",
      "\n",
      "get_variables_and_gradients_generator: gradients = [<tf.Tensor 'get_variables_and_gradients_generator/layers_dense_0/kernel_gradients:0' shape=(512, 256) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_dense_0/bias_gradients:0' shape=(256,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_dense_1/kernel_gradients:0' shape=(256, 512) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_dense_1/bias_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_dense_2/kernel_gradients:0' shape=(512, 1024) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_dense_2/bias_gradients:0' shape=(1024,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_dense_generated_outputs/kernel_gradients:0' shape=(1024, 784) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_generator/layers_dense_generated_outputs/bias_gradients:0' shape=(784,) dtype=float32>]\n",
      "\n",
      "get_variables_and_gradients_discriminator: variables = [<tf.Variable 'discriminator/layers_dense_0/kernel:0' shape=(784, 1024) dtype=float32_ref>, <tf.Variable 'discriminator/layers_dense_0/bias:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'discriminator/layers_dense_1/kernel:0' shape=(1024, 512) dtype=float32_ref>, <tf.Variable 'discriminator/layers_dense_1/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/layers_dense_2/kernel:0' shape=(512, 256) dtype=float32_ref>, <tf.Variable 'discriminator/layers_dense_2/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'discriminator/layers_dense_logits/kernel:0' shape=(256, 1) dtype=float32_ref>, <tf.Variable 'discriminator/layers_dense_logits/bias:0' shape=(1,) dtype=float32_ref>]\n",
      "\n",
      "get_variables_and_gradients_discriminator: gradients = [<tf.Tensor 'discriminator_gradients/AddN_9:0' shape=(784, 1024) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_8:0' shape=(1024,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_7:0' shape=(1024, 512) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_6:0' shape=(512,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_5:0' shape=(512, 256) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_4:0' shape=(256,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_3:0' shape=(256, 1) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_2:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "get_variables_and_gradients_discriminator: gradients = [<tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_0/kernel_gradients:0' shape=(784, 1024) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_0/bias_gradients:0' shape=(1024,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_1/kernel_gradients:0' shape=(1024, 512) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_1/bias_gradients:0' shape=(512,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_2/kernel_gradients:0' shape=(512, 256) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_2/bias_gradients:0' shape=(256,) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_logits/kernel_gradients:0' shape=(256, 1) dtype=float32>, <tf.Tensor 'get_variables_and_gradients_discriminator/layers_dense_logits/bias_gradients:0' shape=(1,) dtype=float32>]\n",
      "\n",
      "train_network: scope = discriminator\n",
      "train_network_discriminator: optimizer = <tensorflow.python.training.adam.AdamOptimizer object at 0x7f45e8821c90>\n",
      "\n",
      "train_network_discriminator: gradients = [<tf.Tensor 'cond/discriminator_gradients/AddN_9:0' shape=(784, 1024) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_8:0' shape=(1024,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_7:0' shape=(1024, 512) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_6:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_5:0' shape=(512, 256) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_4:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_3:0' shape=(256, 1) dtype=float32>, <tf.Tensor 'cond/discriminator_gradients/AddN_2:0' shape=(1,) dtype=float32>]\n",
      "train_network_discriminator: grads_and_vars = <zip object at 0x7f45e88320f0>\n",
      "\n",
      "train_network: scope = generator\n",
      "train_network_generator: optimizer = <tensorflow.python.training.adam.AdamOptimizer object at 0x7f45e87b98d0>\n",
      "\n",
      "train_network_generator: gradients = [<tf.Tensor 'cond/generator_gradients/generator/layers_dense_0/MatMul_grad/MatMul_1:0' shape=(512, 256) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_dense_0/BiasAdd_grad/BiasAddGrad:0' shape=(256,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_dense_1/MatMul_grad/MatMul_1:0' shape=(256, 512) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_dense_1/BiasAdd_grad/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_dense_2/MatMul_grad/MatMul_1:0' shape=(512, 1024) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_dense_2/BiasAdd_grad/BiasAddGrad:0' shape=(1024,) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_dense_generated_outputs/MatMul_grad/MatMul_1:0' shape=(1024, 784) dtype=float32>, <tf.Tensor 'cond/generator_gradients/generator/layers_dense_generated_outputs/BiasAdd_grad/BiasAddGrad:0' shape=(784,) dtype=float32>]\n",
      "train_network_generator: grads_and_vars = <zip object at 0x7f45e879c1e0>\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.8370155, step = 1\n",
      "INFO:tensorflow:global_step/sec: 29.1342\n",
      "INFO:tensorflow:loss = 1.4437075, step = 101 (3.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.3408\n",
      "INFO:tensorflow:loss = 1.3291749, step = 201 (1.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.5735\n",
      "INFO:tensorflow:loss = 1.1153747, step = 301 (1.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.5539\n",
      "INFO:tensorflow:loss = 1.0718046, step = 401 (1.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.5169\n",
      "INFO:tensorflow:loss = 0.90019715, step = 501 (1.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.996\n",
      "INFO:tensorflow:loss = 0.9344959, step = 601 (1.725 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 601 vs previous value: 601. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 59.5116\n",
      "INFO:tensorflow:loss = 1.1002727, step = 701 (1.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.5547\n",
      "INFO:tensorflow:loss = 0.9866803, step = 801 (1.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.1597\n",
      "INFO:tensorflow:loss = 0.8967838, step = 901 (1.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.5373\n",
      "INFO:tensorflow:loss = 0.78030026, step = 1001 (1.769 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1001 vs previous value: 1001. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 65.5055\n",
      "INFO:tensorflow:loss = 0.917928, step = 1101 (1.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.403\n",
      "INFO:tensorflow:loss = 0.8673883, step = 1201 (1.396 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1201 vs previous value: 1201. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 65.1838\n",
      "INFO:tensorflow:loss = 1.2234137, step = 1301 (1.535 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1301 vs previous value: 1301. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 51.723\n",
      "INFO:tensorflow:loss = 0.96751875, step = 1401 (1.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.6276\n",
      "INFO:tensorflow:loss = 1.2667878, step = 1501 (1.416 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1501 vs previous value: 1501. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 61.4706\n",
      "INFO:tensorflow:loss = 1.2521956, step = 1601 (1.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5256\n",
      "INFO:tensorflow:loss = 0.9023652, step = 1701 (1.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.5452\n",
      "INFO:tensorflow:loss = 0.9854267, step = 1801 (1.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.7001\n",
      "INFO:tensorflow:loss = 1.1086385, step = 1901 (1.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.6195\n",
      "INFO:tensorflow:loss = 1.098, step = 2001 (1.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.0982\n",
      "INFO:tensorflow:loss = 0.9110359, step = 2101 (2.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.5267\n",
      "INFO:tensorflow:loss = 1.0166339, step = 2201 (1.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.1031\n",
      "INFO:tensorflow:loss = 1.0312608, step = 2301 (1.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.2425\n",
      "INFO:tensorflow:loss = 1.0556492, step = 2401 (1.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7573\n",
      "INFO:tensorflow:loss = 0.7220144, step = 2501 (2.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.7881\n",
      "INFO:tensorflow:loss = 0.92595565, step = 2601 (1.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.724\n",
      "INFO:tensorflow:loss = 0.9235128, step = 2701 (1.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.5331\n",
      "INFO:tensorflow:loss = 1.3189449, step = 2801 (1.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.0651\n",
      "INFO:tensorflow:loss = 1.2277229, step = 2901 (1.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.7537\n",
      "INFO:tensorflow:loss = 0.9056751, step = 3001 (1.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.1122\n",
      "INFO:tensorflow:loss = 0.981907, step = 3101 (1.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.7647\n",
      "INFO:tensorflow:loss = 0.83166605, step = 3201 (1.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.9543\n",
      "INFO:tensorflow:loss = 0.8487132, step = 3301 (1.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.6826\n",
      "INFO:tensorflow:loss = 1.1272534, step = 3401 (1.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.291\n",
      "INFO:tensorflow:loss = 1.8527406, step = 3501 (1.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.5018\n",
      "INFO:tensorflow:loss = 0.8184557, step = 3601 (1.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.2197\n",
      "INFO:tensorflow:loss = 0.95232725, step = 3701 (1.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.1011\n",
      "INFO:tensorflow:loss = 0.82543164, step = 3801 (1.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.8935\n",
      "INFO:tensorflow:loss = 0.8239314, step = 3901 (1.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.8551\n",
      "INFO:tensorflow:loss = 0.8396388, step = 4001 (1.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.4681\n",
      "INFO:tensorflow:loss = 0.75139344, step = 4101 (1.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.066\n",
      "INFO:tensorflow:loss = 0.9978949, step = 4201 (1.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.1558\n",
      "INFO:tensorflow:loss = 1.9048349, step = 4301 (1.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.1102\n",
      "INFO:tensorflow:loss = 1.2936808, step = 4401 (1.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.3638\n",
      "INFO:tensorflow:loss = 0.8308629, step = 4501 (1.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.7282\n",
      "INFO:tensorflow:loss = 0.8137164, step = 4601 (1.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.0851\n",
      "INFO:tensorflow:loss = 0.7902036, step = 4701 (1.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.5232\n",
      "INFO:tensorflow:loss = 1.1349324, step = 4801 (1.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.0538\n",
      "INFO:tensorflow:loss = 0.876382, step = 4901 (1.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.3085\n",
      "INFO:tensorflow:loss = 1.2140882, step = 5001 (1.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.4616\n",
      "INFO:tensorflow:loss = 0.76099265, step = 5101 (1.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.2647\n",
      "INFO:tensorflow:loss = 0.62790966, step = 5201 (1.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.1686\n",
      "INFO:tensorflow:loss = 0.9564694, step = 5301 (1.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.5619\n",
      "INFO:tensorflow:loss = 0.8075, step = 5401 (1.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.0466\n",
      "INFO:tensorflow:loss = 0.97612655, step = 5501 (1.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.1348\n",
      "INFO:tensorflow:loss = 0.9337123, step = 5601 (1.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.9093\n",
      "INFO:tensorflow:loss = 1.0009971, step = 5701 (1.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.2786\n",
      "INFO:tensorflow:loss = 0.8430575, step = 5801 (1.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.5419\n",
      "INFO:tensorflow:loss = 0.92418146, step = 5901 (1.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.9128\n",
      "INFO:tensorflow:loss = 0.9447068, step = 6001 (1.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.9074\n",
      "INFO:tensorflow:loss = 0.90018284, step = 6101 (1.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.9627\n",
      "INFO:tensorflow:loss = 1.0953164, step = 6201 (2.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.3269\n",
      "INFO:tensorflow:loss = 0.99871683, step = 6301 (1.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.4496\n",
      "INFO:tensorflow:loss = 1.2192085, step = 6401 (2.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.7914\n",
      "INFO:tensorflow:loss = 1.2299879, step = 6501 (1.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.4428\n",
      "INFO:tensorflow:loss = 0.8226308, step = 6601 (1.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.9712\n",
      "INFO:tensorflow:loss = 1.2139413, step = 6701 (2.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.6186\n",
      "INFO:tensorflow:loss = 1.047329, step = 6801 (2.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.4219\n",
      "INFO:tensorflow:loss = 1.9183009, step = 6901 (1.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.0584\n",
      "INFO:tensorflow:loss = 1.3443042, step = 7001 (1.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.5922\n",
      "INFO:tensorflow:loss = 1.1909593, step = 7101 (1.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.2476\n",
      "INFO:tensorflow:loss = 0.9336554, step = 7201 (1.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.0625\n",
      "INFO:tensorflow:loss = 1.003392, step = 7301 (1.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.941\n",
      "INFO:tensorflow:loss = 0.86455333, step = 7401 (1.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.0405\n",
      "INFO:tensorflow:loss = 1.001652, step = 7501 (1.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.4704\n",
      "INFO:tensorflow:loss = 1.3237871, step = 7601 (1.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.8837\n",
      "INFO:tensorflow:loss = 0.95791316, step = 7701 (1.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.8414\n",
      "INFO:tensorflow:loss = 0.840914, step = 7801 (2.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.4999\n",
      "INFO:tensorflow:loss = 1.1102533, step = 7901 (1.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.2532\n",
      "INFO:tensorflow:loss = 1.0890197, step = 8001 (1.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.5934\n",
      "INFO:tensorflow:loss = 1.2947773, step = 8101 (1.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.7738\n",
      "INFO:tensorflow:loss = 1.029661, step = 8201 (1.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.4052\n",
      "INFO:tensorflow:loss = 1.3969829, step = 8301 (1.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.5679\n",
      "INFO:tensorflow:loss = 0.9512205, step = 8401 (1.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.3567\n",
      "INFO:tensorflow:loss = 0.95138264, step = 8501 (1.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.1526\n",
      "INFO:tensorflow:loss = 1.1463032, step = 8601 (1.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.505\n",
      "INFO:tensorflow:loss = 1.000595, step = 8701 (2.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.3011\n",
      "INFO:tensorflow:loss = 1.0765424, step = 8801 (1.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.8836\n",
      "INFO:tensorflow:loss = 1.0772023, step = 8901 (1.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.234\n",
      "INFO:tensorflow:loss = 1.2726672, step = 9001 (1.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.5369\n",
      "INFO:tensorflow:loss = 1.3810577, step = 9101 (1.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.7683\n",
      "INFO:tensorflow:loss = 1.111953, step = 9201 (1.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.4878\n",
      "INFO:tensorflow:loss = 0.86448574, step = 9301 (1.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.4692\n",
      "INFO:tensorflow:loss = 1.4371899, step = 9401 (2.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.0265\n",
      "INFO:tensorflow:loss = 1.1916108, step = 9501 (1.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.763\n",
      "INFO:tensorflow:loss = 1.0573196, step = 9601 (1.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.7512\n",
      "INFO:tensorflow:loss = 1.010344, step = 9701 (1.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.6581\n",
      "INFO:tensorflow:loss = 1.1814265, step = 9801 (1.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.0749\n",
      "INFO:tensorflow:loss = 1.2551336, step = 9901 (1.849 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(28, 28, 1), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "vanilla_gan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 28, 28, 1) dtype=float32>}\n",
      "vanilla_gan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "vanilla_gan_model: mode = eval\n",
      "vanilla_gan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model', 'train_batch_size': 16, 'train_steps': 37500, 'save_summary_steps': 100, 'save_checkpoints_steps': 10000, 'keep_checkpoint_max': 10, 'eval_batch_size': 32, 'eval_steps': 100, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 512, 'generator_hidden_units': [256, 512, 1024], 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_hidden_units': [1024, 512, 256], 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'label_smoothing': 0.9}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"Reshape:0\", shape=(?, 784), dtype=float32)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_fake_images: network = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_0/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_2/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: generated_outputs = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32)\n",
      "\n",
      "Call discriminator with fake_images = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_0/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_0:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_2/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_2:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call discriminator with real_images = Tensor(\"Reshape:0\", shape=(?, 784), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"Reshape:0\", shape=(?, 784), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_0/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_0:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_2/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_2:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"generator_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_fake_loss = Tensor(\"discriminator_fake_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"Const_5:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_eval_metric_ops: discriminator_logits = Tensor(\"discriminator_concat_logits:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_labels = Tensor(\"discriminator_concat_labels:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_probabilities = Tensor(\"discriminator_probabilities:0\", shape=(?, 1), dtype=float32)\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "get_eval_metric_ops: eval_metric_ops = {'accuracy': (<tf.Tensor 'discriminator_accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_accuracy/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'discriminator_precision/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'discriminator_recall/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_recall/update_op:0' shape=() dtype=float32>), 'auc_roc': (<tf.Tensor 'discriminator_auc_roc/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_roc/update_op:0' shape=() dtype=float32>), 'auc_pr': (<tf.Tensor 'discriminator_auc_pr/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_pr/update_op:0' shape=() dtype=float32>)}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-17T23:30:40Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-17-23:30:43\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.0, auc_pr = 0.83313936, auc_roc = 0.81080663, global_step = 10000, loss = 1.118719, precision = 0.5, recall = 1.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-10000\n",
      "\n",
      "serving_input_fn: feature_placeholders = {'Z': <tf.Tensor 'serving_input_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "serving_input_fn: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "vanilla_gan_model: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "vanilla_gan_model: labels = None\n",
      "vanilla_gan_model: mode = infer\n",
      "vanilla_gan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model', 'train_batch_size': 16, 'train_steps': 37500, 'save_summary_steps': 100, 'save_checkpoints_steps': 10000, 'keep_checkpoint_max': 10, 'eval_batch_size': 32, 'eval_steps': 100, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 512, 'generator_hidden_units': [256, 512, 1024], 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_hidden_units': [1024, 512, 256], 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'label_smoothing': 0.9}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_predictions_and_export_outputs: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "get_fake_images: network = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_0/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_2/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: generated_outputs = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-10000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/temp-b'1592436645'/saved_model.pb\n",
      "INFO:tensorflow:global_step/sec: 4.83516\n",
      "INFO:tensorflow:loss = 0.9810518, step = 10001 (20.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.9144\n",
      "INFO:tensorflow:loss = 0.95723546, step = 10101 (1.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.9769\n",
      "INFO:tensorflow:loss = 1.0905662, step = 10201 (1.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.7823\n",
      "INFO:tensorflow:loss = 1.1121445, step = 10301 (1.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.3996\n",
      "INFO:tensorflow:loss = 1.0348524, step = 10401 (1.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.2429\n",
      "INFO:tensorflow:loss = 1.089367, step = 10501 (1.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.5311\n",
      "INFO:tensorflow:loss = 1.0419135, step = 10601 (1.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.8057\n",
      "INFO:tensorflow:loss = 1.2274171, step = 10701 (1.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.0852\n",
      "INFO:tensorflow:loss = 1.0160017, step = 10801 (1.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.7806\n",
      "INFO:tensorflow:loss = 1.0621016, step = 10901 (1.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.0605\n",
      "INFO:tensorflow:loss = 1.0611727, step = 11001 (1.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.5112\n",
      "INFO:tensorflow:loss = 1.0232574, step = 11101 (1.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.6525\n",
      "INFO:tensorflow:loss = 0.9647077, step = 11201 (1.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.323\n",
      "INFO:tensorflow:loss = 1.2253335, step = 11301 (1.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.842\n",
      "INFO:tensorflow:loss = 1.1902351, step = 11401 (1.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.219\n",
      "INFO:tensorflow:loss = 1.3455606, step = 11501 (0.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.8461\n",
      "INFO:tensorflow:loss = 1.1300299, step = 11601 (1.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.9981\n",
      "INFO:tensorflow:loss = 0.90826535, step = 11701 (1.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.5827\n",
      "INFO:tensorflow:loss = 1.131964, step = 11801 (1.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.4044\n",
      "INFO:tensorflow:loss = 1.1008409, step = 11901 (1.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.4829\n",
      "INFO:tensorflow:loss = 1.2831905, step = 12001 (1.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.8493\n",
      "INFO:tensorflow:loss = 0.90844315, step = 12101 (1.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.7745\n",
      "INFO:tensorflow:loss = 1.0321331, step = 12201 (1.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.3287\n",
      "INFO:tensorflow:loss = 0.8785731, step = 12301 (1.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.6908\n",
      "INFO:tensorflow:loss = 1.3981903, step = 12401 (1.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.0793\n",
      "INFO:tensorflow:loss = 0.92339516, step = 12501 (1.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.075\n",
      "INFO:tensorflow:loss = 1.0621641, step = 12601 (1.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.3964\n",
      "INFO:tensorflow:loss = 0.92318106, step = 12701 (1.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.521\n",
      "INFO:tensorflow:loss = 1.0684762, step = 12801 (1.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.2902\n",
      "INFO:tensorflow:loss = 1.0715759, step = 12901 (1.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.1279\n",
      "INFO:tensorflow:loss = 1.1184871, step = 13001 (1.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.9468\n",
      "INFO:tensorflow:loss = 1.0568681, step = 13101 (1.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.7601\n",
      "INFO:tensorflow:loss = 0.88089395, step = 13201 (1.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.8774\n",
      "INFO:tensorflow:loss = 0.89067847, step = 13301 (1.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.5071\n",
      "INFO:tensorflow:loss = 0.86732924, step = 13401 (1.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.1745\n",
      "INFO:tensorflow:loss = 0.98735964, step = 13501 (1.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.796\n",
      "INFO:tensorflow:loss = 1.2385093, step = 13601 (0.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.3297\n",
      "INFO:tensorflow:loss = 0.9230348, step = 13701 (1.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.0975\n",
      "INFO:tensorflow:loss = 1.036484, step = 13801 (1.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.5136\n",
      "INFO:tensorflow:loss = 1.1757607, step = 13901 (1.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.4792\n",
      "INFO:tensorflow:loss = 1.2651227, step = 14001 (1.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.9335\n",
      "INFO:tensorflow:loss = 1.0574338, step = 14101 (1.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.1075\n",
      "INFO:tensorflow:loss = 1.0700753, step = 14201 (1.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.4324\n",
      "INFO:tensorflow:loss = 1.2908285, step = 14301 (1.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.528\n",
      "INFO:tensorflow:loss = 0.97718394, step = 14401 (1.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.0972\n",
      "INFO:tensorflow:loss = 1.2041926, step = 14501 (1.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.8503\n",
      "INFO:tensorflow:loss = 0.993446, step = 14601 (1.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.8095\n",
      "INFO:tensorflow:loss = 0.98736215, step = 14701 (1.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.4586\n",
      "INFO:tensorflow:loss = 0.8893044, step = 14801 (1.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.9673\n",
      "INFO:tensorflow:loss = 0.99332774, step = 14901 (1.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.7117\n",
      "INFO:tensorflow:loss = 1.0296156, step = 15001 (1.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.5664\n",
      "INFO:tensorflow:loss = 1.0610337, step = 15101 (1.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.7305\n",
      "INFO:tensorflow:loss = 0.8448324, step = 15201 (1.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.1362\n",
      "INFO:tensorflow:loss = 0.908088, step = 15301 (1.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.2216\n",
      "INFO:tensorflow:loss = 0.9161373, step = 15401 (1.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.9367\n",
      "INFO:tensorflow:loss = 0.77811956, step = 15501 (1.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.9135\n",
      "INFO:tensorflow:loss = 0.9308454, step = 15601 (1.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.1598\n",
      "INFO:tensorflow:loss = 1.3558149, step = 15701 (1.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.8837\n",
      "INFO:tensorflow:loss = 1.2248461, step = 15801 (1.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.36\n",
      "INFO:tensorflow:loss = 1.3781908, step = 15901 (1.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.4177\n",
      "INFO:tensorflow:loss = 0.95852184, step = 16001 (1.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.2775\n",
      "INFO:tensorflow:loss = 1.0077084, step = 16101 (1.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.5429\n",
      "INFO:tensorflow:loss = 1.2707372, step = 16201 (1.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.1069\n",
      "INFO:tensorflow:loss = 0.89214313, step = 16301 (1.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.9149\n",
      "INFO:tensorflow:loss = 1.0170459, step = 16401 (1.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.8551\n",
      "INFO:tensorflow:loss = 0.96688426, step = 16501 (1.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.5394\n",
      "INFO:tensorflow:loss = 1.2685854, step = 16601 (1.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.618\n",
      "INFO:tensorflow:loss = 0.8009106, step = 16701 (1.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.8468\n",
      "INFO:tensorflow:loss = 1.1570863, step = 16801 (1.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.0914\n",
      "INFO:tensorflow:loss = 0.9636754, step = 16901 (1.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.4787\n",
      "INFO:tensorflow:loss = 0.9341981, step = 17001 (1.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.6796\n",
      "INFO:tensorflow:loss = 0.85583454, step = 17101 (1.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.9564\n",
      "INFO:tensorflow:loss = 0.93604624, step = 17201 (1.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.7942\n",
      "INFO:tensorflow:loss = 1.0106461, step = 17301 (1.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.854\n",
      "INFO:tensorflow:loss = 1.032514, step = 17401 (1.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.952\n",
      "INFO:tensorflow:loss = 0.8061515, step = 17501 (1.011 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.2607\n",
      "INFO:tensorflow:loss = 1.0901023, step = 17601 (1.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.8423\n",
      "INFO:tensorflow:loss = 0.8750017, step = 17701 (1.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.4338\n",
      "INFO:tensorflow:loss = 0.9859776, step = 17801 (1.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.626\n",
      "INFO:tensorflow:loss = 1.122942, step = 17901 (1.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.7013\n",
      "INFO:tensorflow:loss = 1.3728828, step = 18001 (1.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.8256\n",
      "INFO:tensorflow:loss = 1.0347896, step = 18101 (1.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.4545\n",
      "INFO:tensorflow:loss = 1.1321489, step = 18201 (1.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.3041\n",
      "INFO:tensorflow:loss = 1.0104033, step = 18301 (1.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.6595\n",
      "INFO:tensorflow:loss = 0.8439008, step = 18401 (1.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.751\n",
      "INFO:tensorflow:loss = 1.3353127, step = 18501 (1.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.2754\n",
      "INFO:tensorflow:loss = 0.7449876, step = 18601 (1.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.2888\n",
      "INFO:tensorflow:loss = 0.8087934, step = 18701 (1.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.1911\n",
      "INFO:tensorflow:loss = 1.2587504, step = 18801 (1.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.6741\n",
      "INFO:tensorflow:loss = 1.0716202, step = 18901 (1.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.3099\n",
      "INFO:tensorflow:loss = 0.8596765, step = 19001 (1.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.7476\n",
      "INFO:tensorflow:loss = 0.8768561, step = 19101 (1.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.0617\n",
      "INFO:tensorflow:loss = 0.84267414, step = 19201 (1.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.2604\n",
      "INFO:tensorflow:loss = 1.1717091, step = 19301 (1.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.3298\n",
      "INFO:tensorflow:loss = 0.92334235, step = 19401 (1.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.9579\n",
      "INFO:tensorflow:loss = 0.7061062, step = 19501 (1.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.44\n",
      "INFO:tensorflow:loss = 0.9669993, step = 19601 (1.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.8457\n",
      "INFO:tensorflow:loss = 1.0748876, step = 19701 (1.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.2092\n",
      "INFO:tensorflow:loss = 0.87476146, step = 19801 (1.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.3877\n",
      "INFO:tensorflow:loss = 0.94750977, step = 19901 (1.685 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.7067\n",
      "INFO:tensorflow:loss = 0.85953265, step = 20001 (6.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.594\n",
      "INFO:tensorflow:loss = 0.74038804, step = 20101 (1.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.2528\n",
      "INFO:tensorflow:loss = 0.7196918, step = 20201 (1.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.4448\n",
      "INFO:tensorflow:loss = 0.83464026, step = 20301 (1.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.856\n",
      "INFO:tensorflow:loss = 0.7496836, step = 20401 (1.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.2408\n",
      "INFO:tensorflow:loss = 0.85403204, step = 20501 (1.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.7806\n",
      "INFO:tensorflow:loss = 0.9198278, step = 20601 (1.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.5312\n",
      "INFO:tensorflow:loss = 1.0757434, step = 20701 (1.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.3704\n",
      "INFO:tensorflow:loss = 0.7248291, step = 20801 (1.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.8713\n",
      "INFO:tensorflow:loss = 1.0053916, step = 20901 (1.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.0006\n",
      "INFO:tensorflow:loss = 0.8875221, step = 21001 (1.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.9859\n",
      "INFO:tensorflow:loss = 1.2655462, step = 21101 (1.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.4344\n",
      "INFO:tensorflow:loss = 0.75254107, step = 21201 (1.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.6751\n",
      "INFO:tensorflow:loss = 1.0882154, step = 21301 (1.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.0276\n",
      "INFO:tensorflow:loss = 0.9561525, step = 21401 (1.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.4932\n",
      "INFO:tensorflow:loss = 1.2099313, step = 21501 (1.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.3911\n",
      "INFO:tensorflow:loss = 1.1108046, step = 21601 (1.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.8337\n",
      "INFO:tensorflow:loss = 0.84095645, step = 21701 (1.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.4691\n",
      "INFO:tensorflow:loss = 0.72471565, step = 21801 (1.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.1696\n",
      "INFO:tensorflow:loss = 1.0258328, step = 21901 (1.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.6768\n",
      "INFO:tensorflow:loss = 0.9753052, step = 22001 (1.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.392\n",
      "INFO:tensorflow:loss = 0.81040937, step = 22101 (0.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.3445\n",
      "INFO:tensorflow:loss = 1.0033852, step = 22201 (1.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.2325\n",
      "INFO:tensorflow:loss = 0.88042414, step = 22301 (1.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.5995\n",
      "INFO:tensorflow:loss = 0.8226037, step = 22401 (1.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.5023\n",
      "INFO:tensorflow:loss = 0.8544252, step = 22501 (1.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.1574\n",
      "INFO:tensorflow:loss = 0.7840848, step = 22601 (1.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.8097\n",
      "INFO:tensorflow:loss = 0.9801772, step = 22701 (1.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.7886\n",
      "INFO:tensorflow:loss = 0.7803509, step = 22801 (1.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.8295\n",
      "INFO:tensorflow:loss = 0.9047003, step = 22901 (1.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.2277\n",
      "INFO:tensorflow:loss = 1.0046556, step = 23001 (1.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.8584\n",
      "INFO:tensorflow:loss = 0.80636775, step = 23101 (1.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.8841\n",
      "INFO:tensorflow:loss = 0.993602, step = 23201 (1.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.5256\n",
      "INFO:tensorflow:loss = 0.93726724, step = 23301 (1.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.2727\n",
      "INFO:tensorflow:loss = 0.6988913, step = 23401 (1.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.9314\n",
      "INFO:tensorflow:loss = 1.135179, step = 23501 (1.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.2191\n",
      "INFO:tensorflow:loss = 0.8603619, step = 23601 (1.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.5527\n",
      "INFO:tensorflow:loss = 0.9979793, step = 23701 (1.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.3244\n",
      "INFO:tensorflow:loss = 0.9697221, step = 23801 (1.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.0304\n",
      "INFO:tensorflow:loss = 0.8355705, step = 23901 (1.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.4473\n",
      "INFO:tensorflow:loss = 0.7830764, step = 24001 (1.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.5621\n",
      "INFO:tensorflow:loss = 0.8924613, step = 24101 (1.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.5803\n",
      "INFO:tensorflow:loss = 0.9409538, step = 24201 (1.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.045\n",
      "INFO:tensorflow:loss = 0.57641995, step = 24301 (1.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.6839\n",
      "INFO:tensorflow:loss = 0.7170088, step = 24401 (1.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.4778\n",
      "INFO:tensorflow:loss = 0.9623419, step = 24501 (1.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.5342\n",
      "INFO:tensorflow:loss = 0.82039785, step = 24601 (1.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.925\n",
      "INFO:tensorflow:loss = 0.9430851, step = 24701 (1.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.8232\n",
      "INFO:tensorflow:loss = 0.782782, step = 24801 (1.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.5332\n",
      "INFO:tensorflow:loss = 0.8885501, step = 24901 (1.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.01\n",
      "INFO:tensorflow:loss = 0.6882843, step = 25001 (0.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.6774\n",
      "INFO:tensorflow:loss = 0.8539329, step = 25101 (1.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.994\n",
      "INFO:tensorflow:loss = 0.81259084, step = 25201 (1.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.0544\n",
      "INFO:tensorflow:loss = 0.8699779, step = 25301 (1.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.3605\n",
      "INFO:tensorflow:loss = 1.0010296, step = 25401 (1.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.4224\n",
      "INFO:tensorflow:loss = 1.2301139, step = 25501 (1.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.3445\n",
      "INFO:tensorflow:loss = 0.8427766, step = 25601 (1.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.295\n",
      "INFO:tensorflow:loss = 0.7082795, step = 25701 (1.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.9196\n",
      "INFO:tensorflow:loss = 0.897323, step = 25801 (1.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.064\n",
      "INFO:tensorflow:loss = 1.1160983, step = 25901 (1.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.756\n",
      "INFO:tensorflow:loss = 0.8992513, step = 26001 (0.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.8811\n",
      "INFO:tensorflow:loss = 1.0441788, step = 26101 (1.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.8858\n",
      "INFO:tensorflow:loss = 1.1466982, step = 26201 (1.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.2553\n",
      "INFO:tensorflow:loss = 0.7609013, step = 26301 (1.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.6089\n",
      "INFO:tensorflow:loss = 0.73192555, step = 26401 (1.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.5079\n",
      "INFO:tensorflow:loss = 0.923424, step = 26501 (1.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.1407\n",
      "INFO:tensorflow:loss = 0.8026227, step = 26601 (1.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.7522\n",
      "INFO:tensorflow:loss = 0.7518732, step = 26701 (1.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.9708\n",
      "INFO:tensorflow:loss = 0.7956101, step = 26801 (1.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.0018\n",
      "INFO:tensorflow:loss = 1.0293491, step = 26901 (1.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.3084\n",
      "INFO:tensorflow:loss = 0.9124424, step = 27001 (1.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.346\n",
      "INFO:tensorflow:loss = 0.9473897, step = 27101 (1.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.7402\n",
      "INFO:tensorflow:loss = 1.0761274, step = 27201 (1.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.816\n",
      "INFO:tensorflow:loss = 1.2767832, step = 27301 (1.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.5902\n",
      "INFO:tensorflow:loss = 0.8900681, step = 27401 (1.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.1969\n",
      "INFO:tensorflow:loss = 0.8576255, step = 27501 (1.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.0744\n",
      "INFO:tensorflow:loss = 1.1491196, step = 27601 (1.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.3733\n",
      "INFO:tensorflow:loss = 0.6857638, step = 27701 (1.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.9997\n",
      "INFO:tensorflow:loss = 1.1395516, step = 27801 (1.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.5383\n",
      "INFO:tensorflow:loss = 0.63219863, step = 27901 (1.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.2194\n",
      "INFO:tensorflow:loss = 0.7669477, step = 28001 (1.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.788\n",
      "INFO:tensorflow:loss = 0.9996562, step = 28101 (1.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.6615\n",
      "INFO:tensorflow:loss = 0.95851123, step = 28201 (1.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.2803\n",
      "INFO:tensorflow:loss = 0.92030215, step = 28301 (1.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.158\n",
      "INFO:tensorflow:loss = 0.8716177, step = 28401 (1.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.7985\n",
      "INFO:tensorflow:loss = 0.82381654, step = 28501 (1.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.0008\n",
      "INFO:tensorflow:loss = 1.0171098, step = 28601 (1.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.6905\n",
      "INFO:tensorflow:loss = 1.079652, step = 28701 (1.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.8287\n",
      "INFO:tensorflow:loss = 0.8052591, step = 28801 (1.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.0506\n",
      "INFO:tensorflow:loss = 1.0360901, step = 28901 (1.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.1003\n",
      "INFO:tensorflow:loss = 1.0086688, step = 29001 (1.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.6304\n",
      "INFO:tensorflow:loss = 0.9728768, step = 29101 (1.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.451\n",
      "INFO:tensorflow:loss = 0.975952, step = 29201 (1.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.3397\n",
      "INFO:tensorflow:loss = 1.1622032, step = 29301 (1.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.8187\n",
      "INFO:tensorflow:loss = 1.0446366, step = 29401 (1.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.9412\n",
      "INFO:tensorflow:loss = 0.86137295, step = 29501 (1.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.8157\n",
      "INFO:tensorflow:loss = 0.90086436, step = 29601 (1.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.8271\n",
      "INFO:tensorflow:loss = 0.73649406, step = 29701 (1.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.3999\n",
      "INFO:tensorflow:loss = 0.9442558, step = 29801 (1.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.8332\n",
      "INFO:tensorflow:loss = 1.0042396, step = 29901 (1.318 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "INFO:tensorflow:global_step/sec: 16.6286\n",
      "INFO:tensorflow:loss = 1.2685952, step = 30001 (6.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.5123\n",
      "INFO:tensorflow:loss = 0.99021953, step = 30101 (1.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.8892\n",
      "INFO:tensorflow:loss = 0.99147034, step = 30201 (1.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.2057\n",
      "INFO:tensorflow:loss = 1.1606096, step = 30301 (1.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.8934\n",
      "INFO:tensorflow:loss = 1.1462226, step = 30401 (1.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.798\n",
      "INFO:tensorflow:loss = 0.9386066, step = 30501 (1.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.3798\n",
      "INFO:tensorflow:loss = 1.1097838, step = 30601 (1.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.646\n",
      "INFO:tensorflow:loss = 1.068773, step = 30701 (1.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.7413\n",
      "INFO:tensorflow:loss = 0.85831594, step = 30801 (1.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.3456\n",
      "INFO:tensorflow:loss = 0.8804836, step = 30901 (1.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.3889\n",
      "INFO:tensorflow:loss = 0.9793212, step = 31001 (1.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.8385\n",
      "INFO:tensorflow:loss = 0.93454134, step = 31101 (1.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.5766\n",
      "INFO:tensorflow:loss = 1.245296, step = 31201 (1.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.9711\n",
      "INFO:tensorflow:loss = 1.2377031, step = 31301 (1.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.5002\n",
      "INFO:tensorflow:loss = 1.1235473, step = 31401 (1.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.1497\n",
      "INFO:tensorflow:loss = 0.9346947, step = 31501 (1.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.5078\n",
      "INFO:tensorflow:loss = 0.7597662, step = 31601 (1.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.594\n",
      "INFO:tensorflow:loss = 1.2879355, step = 31701 (1.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.1906\n",
      "INFO:tensorflow:loss = 0.93691707, step = 31801 (1.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.6739\n",
      "INFO:tensorflow:loss = 0.961802, step = 31901 (1.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.3759\n",
      "INFO:tensorflow:loss = 0.88525206, step = 32001 (1.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.6472\n",
      "INFO:tensorflow:loss = 1.116505, step = 32101 (1.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.5959\n",
      "INFO:tensorflow:loss = 0.9111738, step = 32201 (1.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.7682\n",
      "INFO:tensorflow:loss = 1.1219006, step = 32301 (1.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.7246\n",
      "INFO:tensorflow:loss = 1.1104517, step = 32401 (1.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.8888\n",
      "INFO:tensorflow:loss = 0.9829144, step = 32501 (1.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.1362\n",
      "INFO:tensorflow:loss = 1.0988939, step = 32601 (1.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.0575\n",
      "INFO:tensorflow:loss = 1.0700965, step = 32701 (1.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.0579\n",
      "INFO:tensorflow:loss = 0.9258373, step = 32801 (1.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.7936\n",
      "INFO:tensorflow:loss = 0.97941256, step = 32901 (1.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.3882\n",
      "INFO:tensorflow:loss = 1.2667532, step = 33001 (1.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.9687\n",
      "INFO:tensorflow:loss = 0.9439629, step = 33101 (1.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.429\n",
      "INFO:tensorflow:loss = 1.4889922, step = 33201 (1.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.9007\n",
      "INFO:tensorflow:loss = 1.2709054, step = 33301 (1.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.3792\n",
      "INFO:tensorflow:loss = 0.94606876, step = 33401 (1.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.2282\n",
      "INFO:tensorflow:loss = 1.0157793, step = 33501 (1.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.9916\n",
      "INFO:tensorflow:loss = 1.1872793, step = 33601 (1.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.5812\n",
      "INFO:tensorflow:loss = 0.9516602, step = 33701 (1.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.7915\n",
      "INFO:tensorflow:loss = 0.9764055, step = 33801 (1.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.9027\n",
      "INFO:tensorflow:loss = 1.0068798, step = 33901 (1.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.9687\n",
      "INFO:tensorflow:loss = 0.9326792, step = 34001 (1.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.045\n",
      "INFO:tensorflow:loss = 0.9038124, step = 34101 (1.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.643\n",
      "INFO:tensorflow:loss = 1.1002183, step = 34201 (1.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.6979\n",
      "INFO:tensorflow:loss = 0.98089945, step = 34301 (1.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.0688\n",
      "INFO:tensorflow:loss = 0.94426805, step = 34401 (1.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.1908\n",
      "INFO:tensorflow:loss = 0.97818637, step = 34501 (1.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.6087\n",
      "INFO:tensorflow:loss = 1.1132506, step = 34601 (1.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.235\n",
      "INFO:tensorflow:loss = 1.248651, step = 34701 (1.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.3972\n",
      "INFO:tensorflow:loss = 1.2350068, step = 34801 (1.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.6222\n",
      "INFO:tensorflow:loss = 1.2707063, step = 34901 (1.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.5574\n",
      "INFO:tensorflow:loss = 0.9216203, step = 35001 (1.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.2288\n",
      "INFO:tensorflow:loss = 1.2153602, step = 35101 (1.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.7749\n",
      "INFO:tensorflow:loss = 1.1182761, step = 35201 (1.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.2267\n",
      "INFO:tensorflow:loss = 1.0845253, step = 35301 (1.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.0452\n",
      "INFO:tensorflow:loss = 1.0454375, step = 35401 (1.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.1797\n",
      "INFO:tensorflow:loss = 0.9147785, step = 35501 (1.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.1832\n",
      "INFO:tensorflow:loss = 0.9592153, step = 35601 (1.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.3514\n",
      "INFO:tensorflow:loss = 1.015737, step = 35701 (1.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.5311\n",
      "INFO:tensorflow:loss = 0.9476732, step = 35801 (1.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.5716\n",
      "INFO:tensorflow:loss = 1.200273, step = 35901 (1.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.1613\n",
      "INFO:tensorflow:loss = 1.1345692, step = 36001 (1.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.7702\n",
      "INFO:tensorflow:loss = 0.78547174, step = 36101 (1.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.9341\n",
      "INFO:tensorflow:loss = 0.93357444, step = 36201 (1.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.4605\n",
      "INFO:tensorflow:loss = 0.87438655, step = 36301 (1.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.0956\n",
      "INFO:tensorflow:loss = 0.9842137, step = 36401 (1.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.0079\n",
      "INFO:tensorflow:loss = 1.1161697, step = 36501 (1.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.1375\n",
      "INFO:tensorflow:loss = 0.962807, step = 36601 (1.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.8994\n",
      "INFO:tensorflow:loss = 1.4425054, step = 36701 (1.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.9492\n",
      "INFO:tensorflow:loss = 1.4472145, step = 36801 (1.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.4696\n",
      "INFO:tensorflow:loss = 1.1565169, step = 36901 (1.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.377\n",
      "INFO:tensorflow:loss = 0.94447494, step = 37001 (1.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.702\n",
      "INFO:tensorflow:loss = 1.024713, step = 37101 (1.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.1496\n",
      "INFO:tensorflow:loss = 1.040972, step = 37201 (1.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.8063\n",
      "INFO:tensorflow:loss = 1.0435818, step = 37301 (1.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.7366\n",
      "INFO:tensorflow:loss = 0.9724025, step = 37401 (1.703 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 37500 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (6000 secs).\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(28, 28, 1), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "vanilla_gan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(?, 28, 28, 1) dtype=float32>}\n",
      "vanilla_gan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=int32, device=/device:CPU:0)\n",
      "vanilla_gan_model: mode = eval\n",
      "vanilla_gan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model', 'train_batch_size': 16, 'train_steps': 37500, 'save_summary_steps': 100, 'save_checkpoints_steps': 10000, 'keep_checkpoint_max': 10, 'eval_batch_size': 32, 'eval_steps': 100, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 512, 'generator_hidden_units': [256, 512, 1024], 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_hidden_units': [1024, 512, 256], 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'label_smoothing': 0.9}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"Reshape:0\", shape=(?, 784), dtype=float32)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32).\n",
      "\n",
      "get_fake_images: network = Tensor(\"random_normal:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_0/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_2/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: generated_outputs = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32)\n",
      "\n",
      "Call discriminator with fake_images = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_0/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_0:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_2/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_2:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Call discriminator with real_images = Tensor(\"Reshape:0\", shape=(?, 784), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"Reshape:0\", shape=(?, 784), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_0/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_0:0\", shape=(?, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_2/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_2:0\", shape=(?, 256), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_1/layers_dense_logits/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"generator_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_fake_loss = Tensor(\"discriminator_fake_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"Const_5:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_eval_metric_ops: discriminator_logits = Tensor(\"discriminator_concat_logits:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_labels = Tensor(\"discriminator_concat_labels:0\", shape=(?, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_probabilities = Tensor(\"discriminator_probabilities:0\", shape=(?, 1), dtype=float32)\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "get_eval_metric_ops: eval_metric_ops = {'accuracy': (<tf.Tensor 'discriminator_accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_accuracy/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'discriminator_precision/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'discriminator_recall/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_recall/update_op:0' shape=() dtype=float32>), 'auc_roc': (<tf.Tensor 'discriminator_auc_roc/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_roc/update_op:0' shape=() dtype=float32>), 'auc_pr': (<tf.Tensor 'discriminator_auc_pr/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_pr/update_op:0' shape=() dtype=float32>)}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-17T23:36:47Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-37500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-17-23:36:51\n",
      "INFO:tensorflow:Saving dict for global step 37500: accuracy = 0.0, auc_pr = 0.8027281, auc_roc = 0.784305, global_step = 37500, loss = 1.2272723, precision = 0.5, recall = 1.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 37500: gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-37500\n",
      "\n",
      "serving_input_fn: feature_placeholders = {'Z': <tf.Tensor 'serving_input_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "serving_input_fn: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "vanilla_gan_model: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(?, 512) dtype=float32>}\n",
      "vanilla_gan_model: labels = None\n",
      "vanilla_gan_model: mode = infer\n",
      "vanilla_gan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model', 'train_batch_size': 16, 'train_steps': 37500, 'save_summary_steps': 100, 'save_checkpoints_steps': 10000, 'keep_checkpoint_max': 10, 'eval_batch_size': 32, 'eval_steps': 100, 'start_delay_secs': 6000, 'throttle_secs': 6000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 512, 'generator_hidden_units': [256, 512, 1024], 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_hidden_units': [1024, 512, 256], 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'label_smoothing': 0.9}\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\n",
      "get_predictions_and_export_outputs: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "\n",
      "get_fake_images: network = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_0/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(?, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(?, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_2/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(?, 1024), dtype=float32)\n",
      "get_fake_images: generated_outputs = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(?, 784), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-37500\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/temp-b'1592437011'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 1.7349223.\n"
     ]
    }
   ],
   "source": [
    "estimator = train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/\n",
      "gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1592436645/\n",
      "gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1592437011/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1592437011/variables/variables\n"
     ]
    }
   ],
   "source": [
    "predict_fn = tf.contrib.predictor.from_saved_model(\n",
    "    \"gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1592437011\"\n",
    ")\n",
    "predictions = predict_fn(\n",
    "    {\n",
    "        \"Z\": np.random.normal(size=(10, 512))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = np.clip(\n",
    "    a=((predictions[\"generated_images\"] + 1.0) * (255. / 2)).astype(np.int32),\n",
    "    a_min=0,\n",
    "    a_max=255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(generated_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "    \"\"\"Plots images.\n",
    "\n",
    "    Args:\n",
    "        images: np.array, array of images of\n",
    "            [num_images, image_size, image_size, num_channels].\n",
    "    \"\"\"\n",
    "    num_images = len(images)\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(num_images):\n",
    "        image = images[i]\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(\n",
    "            image.reshape(image.shape[:-1]),\n",
    "            cmap=\"gray_r\"\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
