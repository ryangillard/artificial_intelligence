{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18.5\n",
      "2.2.0-dlenv\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(np.__version__)\n",
    "print(tf.__version__)\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {}\n",
    "# File arguments.\n",
    "arguments[\"train_file_pattern\"] = \"gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord\"\n",
    "arguments[\"eval_file_pattern\"] = \"gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord\"\n",
    "arguments[\"output_dir\"] = \"gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model\"\n",
    "\n",
    "# Training parameters.\n",
    "arguments[\"train_batch_size\"] = 32\n",
    "arguments[\"train_steps\"] = 56250\n",
    "arguments[\"save_summary_steps\"] = 100\n",
    "arguments[\"save_checkpoints_steps\"] = 10000\n",
    "arguments[\"keep_checkpoint_max\"] = 10\n",
    "arguments[\"input_fn_autotune\"] = False\n",
    "\n",
    "# Eval parameters.\n",
    "arguments[\"eval_batch_size\"] = 32\n",
    "arguments[\"eval_steps\"] = 100\n",
    "arguments[\"start_delay_secs\"] = 60000\n",
    "arguments[\"throttle_secs\"] = 60000\n",
    "\n",
    "# Image parameters.\n",
    "arguments[\"height\"] = 28\n",
    "arguments[\"width\"] = 28\n",
    "arguments[\"depth\"] = 1\n",
    "\n",
    "# Generator parameters.\n",
    "arguments[\"latent_size\"] = 512\n",
    "arguments[\"generator_hidden_units\"] = [256, 512, 1024]\n",
    "arguments[\"generator_leaky_relu_alpha\"] = 0.2\n",
    "arguments[\"generator_final_activation\"] = \"tanh\"\n",
    "arguments[\"generator_l1_regularization_scale\"] = 0.\n",
    "arguments[\"generator_l2_regularization_scale\"] = 0.\n",
    "arguments[\"generator_optimizer\"] = \"Adam\"\n",
    "arguments[\"generator_learning_rate\"] = 0.0002\n",
    "arguments[\"generator_adam_beta1\"] = 0.5\n",
    "arguments[\"generator_adam_beta2\"] = 0.999\n",
    "arguments[\"generator_adam_epsilon\"] = 1e-8\n",
    "arguments[\"generator_clip_gradients\"] = None\n",
    "arguments[\"generator_train_steps\"] = 1\n",
    "\n",
    "# Discriminator hyperparameters.\n",
    "arguments[\"discriminator_hidden_units\"] = [1024, 512, 256]\n",
    "arguments[\"discriminator_leaky_relu_alpha\"] = 0.2\n",
    "arguments[\"discriminator_l1_regularization_scale\"] = 0.\n",
    "arguments[\"discriminator_l2_regularization_scale\"] = 0.\n",
    "arguments[\"discriminator_optimizer\"] = \"Adam\"\n",
    "arguments[\"discriminator_learning_rate\"] = 0.0002\n",
    "arguments[\"discriminator_adam_beta1\"] = 0.5\n",
    "arguments[\"discriminator_adam_beta2\"] = 0.999\n",
    "arguments[\"discriminator_adam_epsilon\"] = 1e-8\n",
    "arguments[\"discriminator_clip_gradients\"] = None\n",
    "arguments[\"discriminator_train_steps\"] = 1\n",
    "arguments[\"label_smoothing\"] = 0.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print_object.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_obj(function_name, object_name, object_value):\n",
    "    \"\"\"Prints enclosing function, object name, and object value.\n",
    "\n",
    "    Args:\n",
    "        function_name: str, name of function.\n",
    "        object_name: str, name of object.\n",
    "        object_value: object, value of passed object.\n",
    "    \"\"\"\n",
    "#     pass\n",
    "    print(\"{}: {} = {}\".format(function_name, object_name, object_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"Preprocess image tensor.\n",
    "\n",
    "    Args:\n",
    "        image: tensor, input image with shape\n",
    "            [cur_batch_size, height, width, depth].\n",
    "\n",
    "    Returns:\n",
    "        Preprocessed image tensor with shape\n",
    "            [cur_batch_size, height, width, depth].\n",
    "    \"\"\"\n",
    "    func_name = \"preprocess_image\"\n",
    "    # Convert from [0, 255] -> [-1.0, 1.0] floats.\n",
    "    image = tf.cast(x=image, dtype=tf.float32) * (2. / 255) - 1.0\n",
    "    print_obj(func_name, \"image\", image)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def decode_example(protos, params):\n",
    "    \"\"\"Decodes TFRecord file into tensors.\n",
    "\n",
    "    Given protobufs, decode into image and label tensors.\n",
    "\n",
    "    Args:\n",
    "        protos: protobufs from TFRecord file.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Image and label tensors.\n",
    "    \"\"\"\n",
    "    func_name = \"decode_example\"\n",
    "    # Create feature schema map for protos.\n",
    "    features = {\n",
    "        \"image_raw\": tf.io.FixedLenFeature(shape=[], dtype=tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature(shape=[], dtype=tf.int64)\n",
    "    }\n",
    "\n",
    "    # Parse features from tf.Example.\n",
    "    parsed_features = tf.io.parse_single_example(\n",
    "        serialized=protos, features=features\n",
    "    )\n",
    "    print_obj(\"\\n\" + func_name, \"features\", features)\n",
    "\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length height * width * depth) to a uint8 tensor with shape\n",
    "    # [height * width * depth].\n",
    "    image = tf.io.decode_raw(\n",
    "        input_bytes=parsed_features[\"image_raw\"], out_type=tf.uint8\n",
    "    )\n",
    "    print_obj(func_name, \"image\", image)\n",
    "\n",
    "    # Reshape flattened image back into normal dimensions.\n",
    "    image = tf.reshape(\n",
    "        tensor=image,\n",
    "        shape=[params[\"height\"], params[\"width\"], params[\"depth\"]]\n",
    "    )\n",
    "    print_obj(func_name, \"image\", image)\n",
    "\n",
    "    # Preprocess image.\n",
    "    image = preprocess_image(image=image)\n",
    "    print_obj(func_name, \"image\", image)\n",
    "\n",
    "    # Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "    label = tf.cast(x=parsed_features[\"label\"], dtype=tf.int32)\n",
    "    print_obj(func_name, \"label\", label)\n",
    "\n",
    "    return {\"image\": image}, label\n",
    "\n",
    "\n",
    "def read_dataset(filename, mode, batch_size, params):\n",
    "    \"\"\"Reads TF Record data using tf.data, doing necessary preprocessing.\n",
    "\n",
    "    Given filename, mode, batch size, and other parameters, read TF Record\n",
    "    dataset using Dataset API, apply necessary preprocessing, and return an\n",
    "    input function to the Estimator API.\n",
    "\n",
    "    Args:\n",
    "        filename: str, file pattern that to read into our tf.data dataset.\n",
    "        mode: The estimator ModeKeys. Can be TRAIN or EVAL.\n",
    "        batch_size: int, number of examples per batch.\n",
    "        params: dict, dictionary of user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        An input function.\n",
    "    \"\"\"\n",
    "    def _input_fn():\n",
    "        \"\"\"Wrapper input function used by Estimator API to get data tensors.\n",
    "\n",
    "        Returns:\n",
    "            Batched dataset object of dictionary of feature tensors and label\n",
    "                tensor.\n",
    "        \"\"\"\n",
    "        # Create list of files that match pattern.\n",
    "        file_list = tf.data.Dataset.list_files(file_pattern=filename)\n",
    "\n",
    "        # Create dataset from file list.\n",
    "        if params[\"input_fn_autotune\"]:\n",
    "            dataset = tf.data.TFRecordDataset(\n",
    "                filenames=file_list,\n",
    "                num_parallel_reads=tf.data.experimental.AUTOTUNE\n",
    "            )\n",
    "        else:\n",
    "            dataset = tf.data.TFRecordDataset(filenames=file_list)\n",
    "\n",
    "        # Shuffle and repeat if training with fused op.\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            dataset = dataset.apply(\n",
    "                tf.data.experimental.shuffle_and_repeat(\n",
    "                    buffer_size=50 * batch_size,\n",
    "                    count=None  # indefinitely\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Decode CSV file into a features dictionary of tensors, then batch.\n",
    "        if params[\"input_fn_autotune\"]:\n",
    "            dataset = dataset.apply(\n",
    "                tf.data.experimental.map_and_batch(\n",
    "                    map_func=lambda x: decode_example(\n",
    "                        protos=x,\n",
    "                        params=params\n",
    "                    ),\n",
    "                    batch_size=batch_size,\n",
    "                    num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            dataset = dataset.apply(\n",
    "                tf.data.experimental.map_and_batch(\n",
    "                    map_func=lambda x: decode_example(\n",
    "                        protos=x,\n",
    "                        params=params\n",
    "                    ),\n",
    "                    batch_size=batch_size\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Prefetch data to improve latency.\n",
    "        if params[\"input_fn_autotune\"]:\n",
    "            dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "        else:\n",
    "            dataset = dataset.prefetch(buffer_size=1)\n",
    "\n",
    "        return dataset\n",
    "    return _input_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(object):\n",
    "    \"\"\"Generator that takes latent vector input and outputs image.\n",
    "    Fields:\n",
    "        name: str, name of `Generator`.\n",
    "        kernel_regularizer: `l1_l2_regularizer` object, regularizar for kernel\n",
    "            variables.\n",
    "        bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "            variables.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_regularizer, bias_regularizer, name):\n",
    "        \"\"\"Instantiates and builds generator network.\n",
    "        Args:\n",
    "            kernel_regularizer: `l1_l2_regularizer` object, regularizar for\n",
    "                kernel variables.\n",
    "            bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "                variables.\n",
    "            name: str, name of generator.\n",
    "        \"\"\"\n",
    "        # Set name of generator.\n",
    "        self.name = name\n",
    "\n",
    "        # Regularizer for kernel weights.\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "\n",
    "        # Regularizer for bias weights.\n",
    "        self.bias_regularizer = bias_regularizer\n",
    "\n",
    "    def get_fake_images(self, Z, params):\n",
    "        \"\"\"Creates generator network and returns generated images.\n",
    "\n",
    "        Args:\n",
    "            Z: tensor, latent vectors of shape [cur_batch_size, latent_size].\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Generated image tensor of shape\n",
    "                [cur_batch_size, height * width * depth].\n",
    "        \"\"\"\n",
    "        func_name = \"get_fake_images\"\n",
    "        # Create the input layer to our DNN.\n",
    "        # shape = (cur_batch_size, latent_size)\n",
    "        network = Z\n",
    "        print_obj(\"\\n\" + func_name, \"network\", network)\n",
    "\n",
    "        # Dictionary containing possible final activations.\n",
    "        final_activation_dict = {\n",
    "            \"sigmoid\": tf.nn.sigmoid, \"relu\": tf.nn.relu, \"tanh\": tf.nn.tanh\n",
    "        }\n",
    "\n",
    "        with tf.compat.v1.variable_scope(\"generator\", reuse=tf.compat.v1.AUTO_REUSE):\n",
    "            # Add hidden layers with given number of units/neurons per layer.\n",
    "            for i, units in enumerate(params[\"generator_hidden_units\"]):\n",
    "                # shape = (cur_batch_size, generator_hidden_units[i])\n",
    "                network = tf.compat.v1.layers.dense(\n",
    "                    inputs=network,\n",
    "                    units=units,\n",
    "                    activation=None,\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"layers_dense_{}\".format(i)\n",
    "                )\n",
    "                print_obj(func_name, \"network\", network)\n",
    "\n",
    "                network = tf.nn.leaky_relu(\n",
    "                    features=network,\n",
    "                    alpha=params[\"generator_leaky_relu_alpha\"],\n",
    "                    name=\"leaky_relu_{}\".format(i)\n",
    "                )\n",
    "                print_obj(func_name, \"network\", network)\n",
    "\n",
    "            # Final linear layer for outputs.\n",
    "            # shape = (cur_batch_size, height * width * depth)\n",
    "            generated_outputs = tf.compat.v1.layers.dense(\n",
    "                inputs=network,\n",
    "                units=params[\"height\"] * params[\"width\"] * params[\"depth\"],\n",
    "                activation=final_activation_dict.get(\n",
    "                    params[\"generator_final_activation\"].lower(), None\n",
    "                ),\n",
    "                kernel_regularizer=self.kernel_regularizer,\n",
    "                bias_regularizer=self.bias_regularizer,\n",
    "                name=\"layers_dense_generated_outputs\"\n",
    "            )\n",
    "            print_obj(func_name, \"generated_outputs\", generated_outputs)\n",
    "\n",
    "        return generated_outputs\n",
    "\n",
    "    def get_generator_loss(self, fake_logits):\n",
    "        \"\"\"Gets generator loss.\n",
    "\n",
    "        Args:\n",
    "            fake_logits: tensor, shape of\n",
    "                [cur_batch_size, 1].\n",
    "\n",
    "        Returns:\n",
    "            Tensor of generator's total loss of shape [].\n",
    "        \"\"\"\n",
    "        func_name = \"get_generator_loss\"\n",
    "        # Calculate base generator loss.\n",
    "        generator_loss = tf.reduce_mean(\n",
    "            input_tensor=tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                logits=fake_logits,\n",
    "                labels=tf.ones_like(input=fake_logits)\n",
    "            ),\n",
    "            name=\"generator_loss\"\n",
    "        )\n",
    "        print_obj(\"\\n\" + func_name, \"generator_loss\", generator_loss)\n",
    "\n",
    "        # Get regularization losses.\n",
    "        generator_reg_loss = tf.compat.v1.losses.get_regularization_loss(\n",
    "            scope=\"generator\",\n",
    "            name=\"generator_regularization_loss\"\n",
    "        )\n",
    "        print_obj(func_name, \"generator_reg_loss\", generator_reg_loss)\n",
    "\n",
    "        # Combine losses for total losses.\n",
    "        generator_total_loss = tf.math.add(\n",
    "            x=generator_loss,\n",
    "            y=generator_reg_loss,\n",
    "            name=\"generator_total_loss\"\n",
    "        )\n",
    "        print_obj(func_name, \"generator_total_loss\", generator_total_loss)\n",
    "\n",
    "#         # Add summaries for TensorBoard.\n",
    "#         tf.summary.scalar(\n",
    "#             name=\"generator_loss\", tensor=generator_loss, family=\"losses\"\n",
    "#         )\n",
    "#         tf.summary.scalar(\n",
    "#             name=\"generator_reg_loss\",\n",
    "#             tensor=generator_reg_loss,\n",
    "#             family=\"losses\"\n",
    "#         )\n",
    "#         tf.summary.scalar(\n",
    "#             name=\"generator_total_loss\",\n",
    "#             tensor=generator_total_loss,\n",
    "#             family=\"total_losses\"\n",
    "#         )\n",
    "\n",
    "        return generator_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## discriminator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(object):\n",
    "    \"\"\"Discriminator that takes image input and outputs logits.\n",
    "    Fields:\n",
    "        name: str, name of `Discriminator`.\n",
    "        kernel_regularizer: `l1_l2_regularizer` object, regularizar for kernel\n",
    "            variables.\n",
    "        bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "            variables.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_regularizer, bias_regularizer, name):\n",
    "        \"\"\"Instantiates and builds discriminator network.\n",
    "        Args:\n",
    "            kernel_regularizer: `l1_l2_regularizer` object, regularizar for\n",
    "                kernel variables.\n",
    "            bias_regularizer: `l1_l2_regularizer` object, regularizar for bias\n",
    "                variables.\n",
    "            name: str, name of discriminator.\n",
    "        \"\"\"\n",
    "        # Set name of discriminator.\n",
    "        self.name = name\n",
    "\n",
    "        # Regularizer for kernel weights.\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "\n",
    "        # Regularizer for bias weights.\n",
    "        self.bias_regularizer = bias_regularizer\n",
    "\n",
    "    def get_discriminator_logits(self, X, params):\n",
    "        \"\"\"Creates discriminator network and returns logits.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, image tensors of shape\n",
    "                [cur_batch_size, height * width * depth].\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Logits tensor of shape [cur_batch_size, 1].\n",
    "        \"\"\"\n",
    "        func_name = \"get_discriminator_logits\"\n",
    "        # Create the input layer to our DNN.\n",
    "        # shape = (cur_batch_size, height * width * depth)\n",
    "        network = X\n",
    "        print_obj(\"\\n\" + func_name, \"network\", network)\n",
    "\n",
    "        with tf.compat.v1.variable_scope(\"discriminator\", reuse=tf.compat.v1.AUTO_REUSE):\n",
    "            # Add hidden layers with given number of units/neurons per layer.\n",
    "            for i, units in enumerate(params[\"discriminator_hidden_units\"]):\n",
    "                # shape = (cur_batch_size, discriminator_hidden_units[i])\n",
    "                network = tf.compat.v1.layers.dense(\n",
    "                    inputs=network,\n",
    "                    units=units,\n",
    "                    activation=None,\n",
    "                    kernel_regularizer=self.kernel_regularizer,\n",
    "                    bias_regularizer=self.bias_regularizer,\n",
    "                    name=\"layers_dense_{}\".format(i)\n",
    "                )\n",
    "                print_obj(func_name, \"network\", network)\n",
    "\n",
    "                network = tf.nn.leaky_relu(\n",
    "                    features=network,\n",
    "                    alpha=params[\"discriminator_leaky_relu_alpha\"],\n",
    "                    name=\"leaky_relu_{}\".format(i)\n",
    "                )\n",
    "                print_obj(func_name, \"network\", network)\n",
    "\n",
    "            # Final linear layer for logits.\n",
    "            # shape = (cur_batch_size, 1)\n",
    "            logits = tf.compat.v1.layers.dense(\n",
    "                inputs=network,\n",
    "                units=1,\n",
    "                activation=None,\n",
    "                kernel_regularizer=self.kernel_regularizer,\n",
    "                bias_regularizer=self.bias_regularizer,\n",
    "                name=\"layers_dense_logits\"\n",
    "            )\n",
    "            print_obj(func_name, \"logits\", logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def get_discriminator_loss(self, fake_logits, real_logits, params):\n",
    "        \"\"\"Gets discriminator loss.\n",
    "\n",
    "        Args:\n",
    "            fake_logits: tensor, shape of\n",
    "                [cur_batch_size, 1].\n",
    "            real_logits: tensor, shape of\n",
    "                [cur_batch_size, 1].\n",
    "            params: dict, user passed parameters.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of discriminator's total loss of shape [].\n",
    "        \"\"\"\n",
    "        func_name = \"get_discriminator_loss\"\n",
    "        # Calculate base discriminator loss.\n",
    "        discriminator_real_loss = tf.reduce_mean(\n",
    "            input_tensor=tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                logits=real_logits,\n",
    "                labels=tf.multiply(\n",
    "                    x=tf.ones_like(input=real_logits),\n",
    "                    y=params[\"label_smoothing\"]\n",
    "                )\n",
    "            ),\n",
    "            name=\"discriminator_real_loss\"\n",
    "        )\n",
    "        print_obj(\n",
    "            \"\\n\" + func_name,\n",
    "            \"discriminator_real_loss\",\n",
    "            discriminator_real_loss\n",
    "        )\n",
    "\n",
    "        discriminator_fake_loss = tf.reduce_mean(\n",
    "            input_tensor=tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                logits=fake_logits,\n",
    "                labels=tf.zeros_like(input=fake_logits)\n",
    "            ),\n",
    "            name=\"discriminator_fake_loss\"\n",
    "        )\n",
    "        print_obj(\n",
    "            func_name, \"discriminator_fake_loss\", discriminator_fake_loss\n",
    "        )\n",
    "\n",
    "        discriminator_loss = tf.add(\n",
    "            x=discriminator_real_loss,\n",
    "            y=discriminator_fake_loss,\n",
    "            name=\"discriminator_loss\"\n",
    "        )\n",
    "        print_obj(func_name, \"discriminator_loss\", discriminator_loss)\n",
    "\n",
    "        # Get regularization losses.\n",
    "        discriminator_reg_loss = tf.compat.v1.losses.get_regularization_loss(\n",
    "            scope=\"discriminator\",\n",
    "            name=\"discriminator_reg_loss\"\n",
    "        )\n",
    "        print_obj(func_name, \"discriminator_reg_loss\", discriminator_reg_loss)\n",
    "\n",
    "        # Combine losses for total losses.\n",
    "        discriminator_total_loss = tf.math.add(\n",
    "            x=discriminator_loss,\n",
    "            y=discriminator_reg_loss,\n",
    "            name=\"discriminator_total_loss\"\n",
    "        )\n",
    "        print_obj(\n",
    "            func_name, \"discriminator_total_loss\", discriminator_total_loss\n",
    "        )\n",
    "\n",
    "#         # Add summaries for TensorBoard.\n",
    "#         tf.summary.scalar(\n",
    "#             name=\"discriminator_real_loss\",\n",
    "#             tensor=discriminator_real_loss,\n",
    "#             family=\"losses\"\n",
    "#         )\n",
    "#         tf.summary.scalar(\n",
    "#             name=\"discriminator_fake_loss\",\n",
    "#             tensor=discriminator_fake_loss,\n",
    "#             family=\"losses\"\n",
    "#         )\n",
    "#         tf.summary.scalar(\n",
    "#             name=\"discriminator_loss\",\n",
    "#             tensor=discriminator_loss,\n",
    "#             family=\"losses\"\n",
    "#         )\n",
    "#         tf.summary.scalar(\n",
    "#             name=\"discriminator_reg_loss\",\n",
    "#             tensor=discriminator_reg_loss,\n",
    "#             family=\"losses\"\n",
    "#         )\n",
    "#         tf.summary.scalar(\n",
    "#             name=\"discriminator_total_loss\",\n",
    "#             tensor=discriminator_total_loss,\n",
    "#             family=\"total_losses\"\n",
    "#         )\n",
    "\n",
    "        return discriminator_total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_and_eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits_and_losses(features, generator, discriminator, params):\n",
    "    \"\"\"Gets logits and losses for both train and eval modes.\n",
    "\n",
    "    Args:\n",
    "        features: dict, feature tensors from input function.\n",
    "        generator: instance of generator.`Generator`.\n",
    "        discriminator: instance of discriminator.`Discriminator`.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Real and fake logits and generator and discriminator losses.\n",
    "    \"\"\"\n",
    "    func_name = \"get_logits_and_losses\"\n",
    "    # Extract real images from features dictionary.\n",
    "    real_images = tf.reshape(\n",
    "        tensor=features[\"image\"],\n",
    "        shape=[-1, params[\"height\"] * params[\"width\"] * params[\"depth\"]]\n",
    "    )\n",
    "    print_obj(\"\\n\" + func_name, \"real_images\", real_images)\n",
    "\n",
    "    # Get dynamic batch size in case of partial batch.\n",
    "    cur_batch_size = tf.shape(\n",
    "        input=real_images,\n",
    "        out_type=tf.int32,\n",
    "        name=\"{}_cur_batch_size\".format(func_name)\n",
    "    )[0]\n",
    "\n",
    "    # Create random noise latent vector for each batch example.\n",
    "    Z = tf.random.normal(\n",
    "        shape=[cur_batch_size, params[\"latent_size\"]],\n",
    "        mean=0.0,\n",
    "        stddev=1.0,\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "    print_obj(func_name, \"Z\", Z)\n",
    "\n",
    "    # Get generated image from generator network from gaussian noise.\n",
    "    print(\"\\nCall generator with Z = {}.\".format(Z))\n",
    "    fake_images = generator.get_fake_images(Z=Z, params=params)\n",
    "\n",
    "#     # Add summaries for TensorBoard.\n",
    "#     tf.summary.image(\n",
    "#         name=\"fake_images\",\n",
    "#         tensor=tf.reshape(\n",
    "#             tensor=fake_images,\n",
    "#             shape=[-1, params[\"height\"], params[\"width\"], params[\"depth\"]]\n",
    "#         ),\n",
    "#         max_outputs=5\n",
    "#     )\n",
    "\n",
    "    # Get fake logits from discriminator using generator's output image.\n",
    "    print(\"\\nCall discriminator with fake_images = {}.\".format(fake_images))\n",
    "    fake_logits = discriminator.get_discriminator_logits(\n",
    "        X=fake_images, params=params\n",
    "    )\n",
    "\n",
    "    # Get real logits from discriminator using real image.\n",
    "    print(\n",
    "        \"\\nCall discriminator with real_images = {}.\".format(real_images)\n",
    "    )\n",
    "    real_logits = discriminator.get_discriminator_logits(\n",
    "        X=real_images, params=params\n",
    "    )\n",
    "\n",
    "    # Get generator total loss.\n",
    "    generator_total_loss = generator.get_generator_loss(\n",
    "        fake_logits=fake_logits\n",
    "    )\n",
    "\n",
    "    # Get discriminator total loss.\n",
    "    discriminator_total_loss = discriminator.get_discriminator_loss(\n",
    "        fake_logits=fake_logits, real_logits=real_logits, params=params\n",
    "    )\n",
    "\n",
    "    return (real_logits,\n",
    "            fake_logits,\n",
    "            generator_total_loss,\n",
    "            discriminator_total_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variables_and_gradients(loss, scope):\n",
    "    \"\"\"Gets variables and their gradients wrt. loss.\n",
    "    Args:\n",
    "        loss: tensor, shape of [].\n",
    "        scope: str, the network's name to find its variables to train.\n",
    "    Returns:\n",
    "        Lists of variables and their gradients.\n",
    "    \"\"\"\n",
    "    func_name = \"get_variables_and_gradients\"\n",
    "    # Get trainable variables.\n",
    "    variables = tf.compat.v1.trainable_variables(scope=scope)\n",
    "    print_obj(\"\\n{}_{}\".format(func_name, scope), \"variables\", variables)\n",
    "\n",
    "    # Get gradients.\n",
    "    gradients = tf.gradients(\n",
    "        ys=loss,\n",
    "        xs=variables,\n",
    "        name=\"{}_gradients\".format(scope)\n",
    "    )\n",
    "    print_obj(\"\\n{}_{}\".format(func_name, scope), \"gradients\", gradients)\n",
    "\n",
    "    # Add variable names back in for identification.\n",
    "    gradients = [\n",
    "        tf.identity(\n",
    "            input=g,\n",
    "            name=\"{}_{}_gradients\".format(func_name, v.name[:-2])\n",
    "        )\n",
    "        if tf.is_tensor(x=g) else g\n",
    "        for g, v in zip(gradients, variables)\n",
    "    ]\n",
    "    print_obj(\"\\n{}_{}\".format(func_name, scope), \"gradients\", gradients)\n",
    "\n",
    "    return variables, gradients\n",
    "\n",
    "\n",
    "def create_variable_and_gradient_histogram_summaries(loss_dict, params):\n",
    "    \"\"\"Creates variable and gradient histogram summaries.\n",
    "    Args:\n",
    "        loss_dict: dict, keys are scopes and values are scalar loss tensors\n",
    "            for each network kind.\n",
    "        params: dict, user passed parameters.\n",
    "    \"\"\"\n",
    "    pass\n",
    "#     for scope, loss in loss_dict.items():\n",
    "#         # Get variables and their gradients wrt. loss.\n",
    "#         variables, gradients = get_variables_and_gradients(loss, scope)\n",
    "\n",
    "#         # Add summaries for TensorBoard.\n",
    "#         for g, v in zip(gradients, variables):\n",
    "#             tf.summary.histogram(\n",
    "#                 name=\"{}\".format(v.name[:-2]),\n",
    "#                 values=v,\n",
    "#                 family=\"{}_variables\".format(scope)\n",
    "#             )\n",
    "#             if tf.is_tensor(x=g):\n",
    "#                 tf.summary.histogram(\n",
    "#                     name=\"{}\".format(v.name[:-2]),\n",
    "#                     values=g,\n",
    "#                     family=\"{}_gradients\".format(scope)\n",
    "#                 )\n",
    "\n",
    "\n",
    "def train_network(loss, global_step, params, scope):\n",
    "    \"\"\"Trains network and returns loss and train op.\n",
    "\n",
    "    Args:\n",
    "        loss: tensor, shape of [].\n",
    "        global_step: tensor, the current training step or batch in the\n",
    "            training loop.\n",
    "        params: dict, user passed parameters.\n",
    "        scope: str, the variables that to train.\n",
    "\n",
    "    Returns:\n",
    "        Loss tensor and training op.\n",
    "    \"\"\"\n",
    "    func_name = \"train_network\"\n",
    "    print_obj(\"\\n\" + func_name, \"scope\", scope)\n",
    "    # Create optimizer map.\n",
    "    optimizers = {\n",
    "        \"Adam\": tf.compat.v1.train.AdamOptimizer,\n",
    "        \"Adadelta\": tf.compat.v1.train.AdadeltaOptimizer,\n",
    "        \"AdagradDA\": tf.compat.v1.train.AdagradDAOptimizer,\n",
    "        \"Adagrad\": tf.compat.v1.train.AdagradOptimizer,\n",
    "        \"Ftrl\": tf.compat.v1.train.FtrlOptimizer,\n",
    "        \"GradientDescent\": tf.compat.v1.train.GradientDescentOptimizer,\n",
    "        \"Momentum\": tf.compat.v1.train.MomentumOptimizer,\n",
    "        \"ProximalAdagrad\": tf.compat.v1.train.ProximalAdagradOptimizer,\n",
    "        \"ProximalGradientDescent\": tf.compat.v1.train.ProximalGradientDescentOptimizer,\n",
    "        \"RMSProp\": tf.compat.v1.train.RMSPropOptimizer\n",
    "    }\n",
    "\n",
    "    # Get optimizer and instantiate it.\n",
    "    if params[\"{}_optimizer\".format(scope)] == \"Adam\":\n",
    "        optimizer = optimizers[params[\"{}_optimizer\".format(scope)]](\n",
    "            learning_rate=params[\"{}_learning_rate\".format(scope)],\n",
    "            beta1=params[\"{}_adam_beta1\".format(scope)],\n",
    "            beta2=params[\"{}_adam_beta2\".format(scope)],\n",
    "            epsilon=params[\"{}_adam_epsilon\".format(scope)],\n",
    "            name=\"{}_{}_optimizer\".format(\n",
    "                scope, params[\"{}_optimizer\".format(scope)].lower()\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        optimizer = optimizers[params[\"{}_optimizer\".format(scope)]](\n",
    "            learning_rate=params[\"{}_learning_rate\".format(scope)],\n",
    "            name=\"{}_{}_optimizer\".format(\n",
    "                scope, params[\"{}_optimizer\".format(scope)].lower()\n",
    "            )\n",
    "        )\n",
    "    print_obj(\"{}_{}\".format(func_name, scope), \"optimizer\", optimizer)\n",
    "\n",
    "    # Get gradients.\n",
    "    gradients = tf.gradients(\n",
    "        ys=loss,\n",
    "        xs=tf.compat.v1.trainable_variables(scope=scope),\n",
    "        name=\"{}_gradients\".format(scope)\n",
    "    )\n",
    "    print_obj(\"\\n{}_{}\".format(func_name, scope), \"gradients\", gradients)\n",
    "\n",
    "    # Clip gradients.\n",
    "    if params[\"{}_clip_gradients\".format(scope)]:\n",
    "        gradients, _ = tf.clip_by_global_norm(\n",
    "            t_list=gradients,\n",
    "            clip_norm=params[\"{}_clip_gradients\".format(scope)],\n",
    "            name=\"{}_clip_by_global_norm_gradients\".format(scope)\n",
    "        )\n",
    "        print_obj(\"\\n{}_{}\".format(func_name, scope), \"gradients\", gradients)\n",
    "\n",
    "    # Zip back together gradients and variables.\n",
    "    grads_and_vars = zip(gradients, tf.compat.v1.trainable_variables(scope=scope))\n",
    "    print_obj(\n",
    "        \"{}_{}\".format(func_name, scope), \"grads_and_vars\", grads_and_vars\n",
    "    )\n",
    "\n",
    "    # Create train op by applying gradients to variables and incrementing\n",
    "    # global step.\n",
    "    train_op = optimizer.apply_gradients(\n",
    "        grads_and_vars=grads_and_vars,\n",
    "        global_step=global_step,\n",
    "        name=\"{}_apply_gradients\".format(scope)\n",
    "    )\n",
    "\n",
    "    return loss, train_op\n",
    "\n",
    "\n",
    "def get_loss_and_train_op(\n",
    "        generator_total_loss, discriminator_total_loss, params):\n",
    "    \"\"\"Gets loss and train op for train mode.\n",
    "    Args:\n",
    "        generator_total_loss: tensor, scalar total loss of generator.\n",
    "        discriminator_total_loss: tensor, scalar total loss of discriminator.\n",
    "        params: dict, user passed parameters.\n",
    "    Returns:\n",
    "        Loss scalar tensor and train_op to be used by the EstimatorSpec.\n",
    "    \"\"\"\n",
    "    func_name = \"get_loss_and_train_op\"\n",
    "    # Get global step.\n",
    "    global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "    # Determine if it is time to train generator or discriminator.\n",
    "    cycle_step = tf.math.mod(\n",
    "        x=global_step,\n",
    "        y=tf.cast(\n",
    "            x=tf.add(\n",
    "                x=params[\"discriminator_train_steps\"],\n",
    "                y=params[\"generator_train_steps\"]\n",
    "            ),\n",
    "            dtype=tf.int64\n",
    "        ),\n",
    "        name=\"{}_cycle_step\".format(func_name)\n",
    "    )\n",
    "\n",
    "    # Create choose discriminator condition.\n",
    "    condition = tf.less(\n",
    "        x=cycle_step, y=params[\"discriminator_train_steps\"]\n",
    "    )\n",
    "\n",
    "    # Conditionally choose to train generator or discriminator subgraph.\n",
    "    loss, train_op = tf.cond(\n",
    "        pred=condition,\n",
    "        true_fn=lambda: train_network(\n",
    "            loss=discriminator_total_loss,\n",
    "            global_step=global_step,\n",
    "            params=params,\n",
    "            scope=\"discriminator\"\n",
    "        ),\n",
    "        false_fn=lambda: train_network(\n",
    "            loss=generator_total_loss,\n",
    "            global_step=global_step,\n",
    "            params=params,\n",
    "            scope=\"generator\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return loss, train_op\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval_metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metric_ops(fake_logits, real_logits, params):\n",
    "    \"\"\"Gets eval metric ops.\n",
    "\n",
    "    Args:\n",
    "        fake_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "            discriminator having processed generator's output image.\n",
    "        real_logits: tensor, shape of [cur_batch_size, 1] that came from\n",
    "            discriminator having processed real image.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of eval metric ops.\n",
    "    \"\"\"\n",
    "    func_name = \"get_eval_metric_ops\"\n",
    "    # Concatenate discriminator logits and labels.\n",
    "    discriminator_logits = tf.concat(\n",
    "        values=[real_logits, fake_logits],\n",
    "        axis=0,\n",
    "        name=\"discriminator_concat_logits\"\n",
    "    )\n",
    "    print_obj(\"\\n\" + func_name, \"discriminator_logits\", discriminator_logits)\n",
    "\n",
    "    discriminator_labels = tf.concat(\n",
    "        values=[\n",
    "            tf.ones_like(input=real_logits) * params[\"label_smoothing\"],\n",
    "            tf.zeros_like(input=fake_logits)\n",
    "        ],\n",
    "        axis=0,\n",
    "        name=\"discriminator_concat_labels\"\n",
    "    )\n",
    "    print_obj(func_name, \"discriminator_labels\", discriminator_labels)\n",
    "\n",
    "    # Calculate discriminator probabilities.\n",
    "    discriminator_probabilities = tf.nn.sigmoid(\n",
    "        x=discriminator_logits, name=\"discriminator_probabilities\"\n",
    "    )\n",
    "    print_obj(\n",
    "        func_name, \"discriminator_probabilities\", discriminator_probabilities\n",
    "    )\n",
    "\n",
    "    # Create eval metric ops dictionary.\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.compat.v1.metrics.accuracy(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            name=\"discriminator_accuracy\"\n",
    "        ),\n",
    "        \"precision\": tf.compat.v1.metrics.precision(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            name=\"discriminator_precision\"\n",
    "        ),\n",
    "        \"recall\": tf.compat.v1.metrics.recall(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            name=\"discriminator_recall\"\n",
    "        ),\n",
    "        \"auc_roc\": tf.compat.v1.metrics.auc(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            num_thresholds=200,\n",
    "            curve=\"ROC\",\n",
    "            name=\"discriminator_auc_roc\"\n",
    "        ),\n",
    "        \"auc_pr\": tf.compat.v1.metrics.auc(\n",
    "            labels=discriminator_labels,\n",
    "            predictions=discriminator_probabilities,\n",
    "            num_thresholds=200,\n",
    "            curve=\"PR\",\n",
    "            name=\"discriminator_auc_pr\"\n",
    "        )\n",
    "    }\n",
    "    print_obj(func_name, \"eval_metric_ops\", eval_metric_ops)\n",
    "\n",
    "    return eval_metric_ops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_and_export_outputs(features, generator, params):\n",
    "    \"\"\"Gets predictions and serving export outputs.\n",
    "\n",
    "    Args:\n",
    "        features: dict, feature tensors from serving input function.\n",
    "        generator: instance of `Generator`.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Predictions dictionary and export outputs dictionary.\n",
    "    \"\"\"\n",
    "    func_name = \"get_predictions_and_export_outputs\"\n",
    "\n",
    "    # Extract given latent vectors from features dictionary.\n",
    "    Z = features[\"Z\"]\n",
    "    print_obj(\"\\n\" + func_name, \"Z\", Z)\n",
    "\n",
    "    # Establish generator network subgraph.\n",
    "    fake_images = generator.get_fake_images(Z=Z, params=params)\n",
    "    print_obj(func_name, \"fake_images\", fake_images)\n",
    "\n",
    "    # Reshape into a rank 4 image.\n",
    "    generated_images = tf.reshape(\n",
    "        tensor=fake_images,\n",
    "        shape=[-1, params[\"height\"], params[\"width\"], params[\"depth\"]]\n",
    "    )\n",
    "    print_obj(func_name, \"generated_images\", generated_images)\n",
    "\n",
    "    # Create predictions dictionary.\n",
    "    predictions_dict = {\n",
    "        \"generated_images\": generated_images\n",
    "    }\n",
    "    print_obj(func_name, \"predictions_dict\", predictions_dict)\n",
    "\n",
    "    # Create export outputs.\n",
    "    export_outputs = {\n",
    "        \"predict_export_outputs\": tf.estimator.export.PredictOutput(\n",
    "            outputs=predictions_dict)\n",
    "    }\n",
    "    print_obj(func_name, \"export_outputs\", export_outputs)\n",
    "\n",
    "    return predictions_dict, export_outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vanilla_gan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_gan_model(features, labels, mode, params):\n",
    "    \"\"\"Vanilla GAN custom Estimator model function.\n",
    "\n",
    "    Args:\n",
    "        features: dict, keys are feature names and values are feature tensors.\n",
    "        labels: tensor, label data.\n",
    "        mode: tf.estimator.ModeKeys with values of either TRAIN, EVAL, or\n",
    "            PREDICT.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Instance of `tf.estimator.EstimatorSpec` class.\n",
    "    \"\"\"\n",
    "    func_name = \"vanilla_gan_model\"\n",
    "    print_obj(\"\\n\" + func_name, \"features\", features)\n",
    "    print_obj(func_name, \"labels\", labels)\n",
    "    print_obj(func_name, \"mode\", mode)\n",
    "    print_obj(func_name, \"params\", params)\n",
    "\n",
    "    # Loss function, training/eval ops, etc.\n",
    "    predictions_dict = None\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = None\n",
    "    export_outputs = None\n",
    "\n",
    "    # Instantiate generator.\n",
    "    vanilla_generator = Generator(\n",
    "        kernel_regularizer=None,\n",
    "#         tf.contrib.layers.l1_l2_regularizer(\n",
    "#             scale_l1=params[\"generator_l1_regularization_scale\"],\n",
    "#             scale_l2=params[\"generator_l2_regularization_scale\"]\n",
    "#         ),\n",
    "        bias_regularizer=None,\n",
    "        name=\"generator\"\n",
    "    )\n",
    "\n",
    "    # Instantiate discriminator.\n",
    "    vanilla_discriminator = Discriminator(\n",
    "        kernel_regularizer=None,\n",
    "#         tf.contrib.layers.l1_l2_regularizer(\n",
    "#             scale_l1=params[\"discriminator_l1_regularization_scale\"],\n",
    "#             scale_l2=params[\"discriminator_l2_regularization_scale\"]\n",
    "#         ),\n",
    "        bias_regularizer=None,\n",
    "        name=\"discriminator\"\n",
    "    )\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # Get predictions and export outputs.\n",
    "        (predictions_dict,\n",
    "         export_outputs) = get_predictions_and_export_outputs(\n",
    "            features=features, generator=vanilla_generator, params=params\n",
    "        )\n",
    "    else:\n",
    "        # Get logits and losses from networks for train and eval modes.\n",
    "        (real_logits,\n",
    "         fake_logits,\n",
    "         generator_total_loss,\n",
    "         discriminator_total_loss) = get_logits_and_losses(\n",
    "            features=features,\n",
    "            generator=vanilla_generator,\n",
    "            discriminator=vanilla_discriminator,\n",
    "            params=params\n",
    "        )\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            # Create variable and gradient histogram summaries.\n",
    "            create_variable_and_gradient_histogram_summaries(\n",
    "                loss_dict={\n",
    "                    \"generator\": generator_total_loss,\n",
    "                    \"discriminator\": discriminator_total_loss\n",
    "                },\n",
    "                params=params\n",
    "            )\n",
    "\n",
    "            # Get loss and train op for EstimatorSpec.\n",
    "            loss, train_op = get_loss_and_train_op(\n",
    "                generator_total_loss=generator_total_loss,\n",
    "                discriminator_total_loss=discriminator_total_loss,\n",
    "                params=params\n",
    "            )\n",
    "        else:\n",
    "            # Set eval loss.\n",
    "            loss = discriminator_total_loss\n",
    "\n",
    "            # Get eval metrics.\n",
    "            eval_metric_ops = get_eval_metric_ops(\n",
    "                real_logits=real_logits,\n",
    "                fake_logits=fake_logits,\n",
    "                params=params\n",
    "            )\n",
    "\n",
    "    # Return EstimatorSpec\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions_dict,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops,\n",
    "        export_outputs=export_outputs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## serving.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn(params):\n",
    "    \"\"\"Serving input function.\n",
    "\n",
    "    Args:\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        ServingInputReceiver object containing features and receiver tensors.\n",
    "    \"\"\"\n",
    "    func_name = \"serving_input_fn\"\n",
    "    # Create placeholders to accept data sent to the model at serving time.\n",
    "    # shape = (batch_size,)\n",
    "    feature_placeholders = {\n",
    "        \"Z\": tf.compat.v1.placeholder(\n",
    "            dtype=tf.float32,\n",
    "            shape=[None, params[\"latent_size\"]],\n",
    "            name=\"serving_input_placeholder_Z\"\n",
    "        )\n",
    "    }\n",
    "    print_obj(\"\\n\" + func_name, \"feature_placeholders\", feature_placeholders)\n",
    "\n",
    "    # Create clones of the feature placeholder tensors so that the SavedModel\n",
    "    # SignatureDef will point to the placeholder.\n",
    "    features = {\n",
    "        key: tf.identity(\n",
    "            input=value,\n",
    "            name=\"{}_identity_placeholder_{}\".format(func_name, key)\n",
    "        )\n",
    "        for key, value in feature_placeholders.items()\n",
    "    }\n",
    "    print_obj(func_name, \"features\", features)\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features=features, receiver_tensors=feature_placeholders\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(args):\n",
    "    \"\"\"Trains and evaluates custom Estimator model.\n",
    "\n",
    "    Args:\n",
    "        args: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        `Estimator` object.\n",
    "    \"\"\"\n",
    "    func_name = \"train_and_evaluate\"\n",
    "    print_obj(\"\\n\" + func_name, \"args\", args)\n",
    "    # Ensure filewriter cache is clear for TensorBoard events file.\n",
    "#     tf.summary.FileWriterCache.clear()\n",
    "\n",
    "    # Set logging to be level of INFO.\n",
    "#     tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    # Create a RunConfig for Estimator.\n",
    "    config = tf.estimator.RunConfig(\n",
    "        model_dir=args[\"output_dir\"],\n",
    "        save_summary_steps=args[\"save_summary_steps\"],\n",
    "        save_checkpoints_steps=args[\"save_checkpoints_steps\"],\n",
    "        keep_checkpoint_max=args[\"keep_checkpoint_max\"]\n",
    "    )\n",
    "\n",
    "    # Create our custom estimator using our model function.\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn=vanilla_gan_model,\n",
    "        model_dir=args[\"output_dir\"],\n",
    "        config=config,\n",
    "        params=args\n",
    "    )\n",
    "\n",
    "    # Create train spec to read in our training data.\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"train_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.TRAIN,\n",
    "            batch_size=args[\"train_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        max_steps=args[\"train_steps\"]\n",
    "    )\n",
    "\n",
    "    # Create exporter to save out the complete model to disk.\n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        name=\"exporter\",\n",
    "        serving_input_receiver_fn=lambda: serving_input_fn(args)\n",
    "    )\n",
    "\n",
    "    # Create eval spec to read in our validation data and export our model.\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"eval_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.EVAL,\n",
    "            batch_size=args[\"eval_batch_size\"],\n",
    "            params=args\n",
    "        ),\n",
    "        steps=args[\"eval_steps\"],\n",
    "        start_delay_secs=args[\"start_delay_secs\"],\n",
    "        throttle_secs=args[\"throttle_secs\"],\n",
    "        exporters=exporter\n",
    "    )\n",
    "\n",
    "    # Create train and evaluate loop to train and evaluate our estimator.\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n",
    "\n",
    "    return estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OUTPUT_DIR\"] = arguments[\"output_dir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/checkpoint#1595549336880429...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/eval/#1595549340160019...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/eval/events.out.tfevents.1595549340.tensorflow-2-2-20200707-090436#1595549340908390...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/events.out.tfevents.1595549209.tensorflow-2-2-20200707-090436#1595549330068079...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/#1595549341665539...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/#1595549341897739...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/temp-1595549340/#1595549342115797...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/graph.pbtxt#1595549302077652...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-0.data-00000-of-00001#1595549304127644...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-0.index#1595549304365451...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-0.meta#1595549305315409...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-10000.data-00000-of-00001#1595549336239502...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-10000.index#1595549336407397...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-10000.meta#1595549337325631...\n",
      "/ [14/14 objects] 100% Done                                                     \n",
      "Operation completed over 14 objects.                                             \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil -m rm -rf ${OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_and_evaluate: args = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model', 'train_batch_size': 32, 'train_steps': 56250, 'save_summary_steps': 100, 'save_checkpoints_steps': 10000, 'keep_checkpoint_max': 10, 'input_fn_autotune': False, 'eval_batch_size': 32, 'eval_steps': 100, 'start_delay_secs': 60000, 'throttle_secs': 60000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 512, 'generator_hidden_units': [256, 512, 1024], 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_hidden_units': [1024, 512, 256], 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'label_smoothing': 0.9}\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 10000 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From <ipython-input-4-52033d9e690d>:111: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From <ipython-input-4-52033d9e690d>:134: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(None,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(28, 28, 1), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "vanilla_gan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(None, 28, 28, 1) dtype=float32>}\n",
      "vanilla_gan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=int32)\n",
      "vanilla_gan_model: mode = train\n",
      "vanilla_gan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model', 'train_batch_size': 32, 'train_steps': 56250, 'save_summary_steps': 100, 'save_checkpoints_steps': 10000, 'keep_checkpoint_max': 10, 'input_fn_autotune': False, 'eval_batch_size': 32, 'eval_steps': 100, 'start_delay_secs': 60000, 'throttle_secs': 60000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 512, 'generator_hidden_units': [256, 512, 1024], 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_hidden_units': [1024, 512, 256], 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'label_smoothing': 0.9}\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"Reshape:0\", shape=(None, 784), dtype=float32)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(None, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(None, 512), dtype=float32).\n",
      "\n",
      "get_fake_images: network = Tensor(\"random_normal:0\", shape=(None, 512), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-5-398137daed4b>:60: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_0/BiasAdd:0\", shape=(None, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(None, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_1/BiasAdd:0\", shape=(None, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(None, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_2/BiasAdd:0\", shape=(None, 1024), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(None, 1024), dtype=float32)\n",
      "get_fake_images: generated_outputs = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(None, 784), dtype=float32)\n",
      "\n",
      "Call discriminator with fake_images = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(None, 784), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(None, 784), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_0/BiasAdd:0\", shape=(None, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_0:0\", shape=(None, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_1/BiasAdd:0\", shape=(None, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_1:0\", shape=(None, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_2/BiasAdd:0\", shape=(None, 256), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_2:0\", shape=(None, 256), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/layers_dense_logits/BiasAdd:0\", shape=(None, 1), dtype=float32)\n",
      "\n",
      "Call discriminator with real_images = Tensor(\"Reshape:0\", shape=(None, 784), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"Reshape:0\", shape=(None, 784), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_0/BiasAdd:0\", shape=(None, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_0:0\", shape=(None, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_1/BiasAdd:0\", shape=(None, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_1:0\", shape=(None, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_2/BiasAdd:0\", shape=(None, 256), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_2:0\", shape=(None, 256), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_1/layers_dense_logits/BiasAdd:0\", shape=(None, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"generator_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_fake_loss = Tensor(\"discriminator_fake_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"Const_4:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "train_network: scope = discriminator\n",
      "train_network_discriminator: optimizer = <tensorflow.python.training.adam.AdamOptimizer object at 0x7f07e9c2ef90>\n",
      "\n",
      "train_network_discriminator: gradients = [<tf.Tensor 'discriminator_gradients/AddN_9:0' shape=(784, 1024) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_8:0' shape=(1024,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_7:0' shape=(1024, 512) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_6:0' shape=(512,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_5:0' shape=(512, 256) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_4:0' shape=(256,) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_3:0' shape=(256, 1) dtype=float32>, <tf.Tensor 'discriminator_gradients/AddN_2:0' shape=(1,) dtype=float32>]\n",
      "train_network_discriminator: grads_and_vars = <zip object at 0x7f07e992ac80>\n",
      "\n",
      "train_network: scope = generator\n",
      "train_network_generator: optimizer = <tensorflow.python.training.adam.AdamOptimizer object at 0x7f07e98adfd0>\n",
      "\n",
      "train_network_generator: gradients = [<tf.Tensor 'generator_gradients/generator/layers_dense_0/MatMul_grad/MatMul_1:0' shape=(512, 256) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_0/BiasAdd_grad/BiasAddGrad:0' shape=(256,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_1/MatMul_grad/MatMul_1:0' shape=(256, 512) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_1/BiasAdd_grad/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_2/MatMul_grad/MatMul_1:0' shape=(512, 1024) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_2/BiasAdd_grad/BiasAddGrad:0' shape=(1024,) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_generated_outputs/MatMul_grad/MatMul_1:0' shape=(1024, 784) dtype=float32>, <tf.Tensor 'generator_gradients/generator/layers_dense_generated_outputs/BiasAdd_grad/BiasAddGrad:0' shape=(784,) dtype=float32>]\n",
      "train_network_generator: grads_and_vars = <zip object at 0x7f07e9993cd0>\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.6783597, step = 0\n",
      "INFO:tensorflow:global_step/sec: 187.884\n",
      "INFO:tensorflow:loss = 1.4146522, step = 100 (0.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.29\n",
      "INFO:tensorflow:loss = 1.1655922, step = 200 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.527\n",
      "INFO:tensorflow:loss = 1.1388303, step = 300 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.3\n",
      "INFO:tensorflow:loss = 0.94181263, step = 400 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.172\n",
      "INFO:tensorflow:loss = 0.9471133, step = 500 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.177\n",
      "INFO:tensorflow:loss = 1.0776197, step = 600 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.985\n",
      "INFO:tensorflow:loss = 1.1414977, step = 700 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.297\n",
      "INFO:tensorflow:loss = 0.8701129, step = 800 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.732\n",
      "INFO:tensorflow:loss = 0.92916894, step = 900 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.123\n",
      "INFO:tensorflow:loss = 0.82630396, step = 1000 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.025\n",
      "INFO:tensorflow:loss = 0.8000124, step = 1100 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.061\n",
      "INFO:tensorflow:loss = 1.0007714, step = 1200 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.135\n",
      "INFO:tensorflow:loss = 0.9889116, step = 1300 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.428\n",
      "INFO:tensorflow:loss = 0.85279393, step = 1400 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.059\n",
      "INFO:tensorflow:loss = 0.85975635, step = 1500 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.95\n",
      "INFO:tensorflow:loss = 0.95591795, step = 1600 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.417\n",
      "INFO:tensorflow:loss = 0.7880587, step = 1700 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.9\n",
      "INFO:tensorflow:loss = 0.7408558, step = 1800 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.807\n",
      "INFO:tensorflow:loss = 1.2193019, step = 1900 (0.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.533\n",
      "INFO:tensorflow:loss = 0.75948584, step = 2000 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.077\n",
      "INFO:tensorflow:loss = 0.9345492, step = 2100 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.35\n",
      "INFO:tensorflow:loss = 1.1738211, step = 2200 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.798\n",
      "INFO:tensorflow:loss = 0.8416182, step = 2300 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.031\n",
      "INFO:tensorflow:loss = 0.818261, step = 2400 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.743\n",
      "INFO:tensorflow:loss = 0.8556186, step = 2500 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.943\n",
      "INFO:tensorflow:loss = 0.8121357, step = 2600 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.261\n",
      "INFO:tensorflow:loss = 0.7875591, step = 2700 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.778\n",
      "INFO:tensorflow:loss = 0.74380505, step = 2800 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.446\n",
      "INFO:tensorflow:loss = 0.8051708, step = 2900 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.703\n",
      "INFO:tensorflow:loss = 0.65318304, step = 3000 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.495\n",
      "INFO:tensorflow:loss = 0.73927474, step = 3100 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.879\n",
      "INFO:tensorflow:loss = 0.69126177, step = 3200 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.229\n",
      "INFO:tensorflow:loss = 0.7112443, step = 3300 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.126\n",
      "INFO:tensorflow:loss = 0.77803195, step = 3400 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.468\n",
      "INFO:tensorflow:loss = 0.81526965, step = 3500 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.456\n",
      "INFO:tensorflow:loss = 0.7812644, step = 3600 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.248\n",
      "INFO:tensorflow:loss = 0.6732077, step = 3700 (0.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.552\n",
      "INFO:tensorflow:loss = 0.79103494, step = 3800 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.556\n",
      "INFO:tensorflow:loss = 0.71357477, step = 3900 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.918\n",
      "INFO:tensorflow:loss = 0.84349644, step = 4000 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.544\n",
      "INFO:tensorflow:loss = 0.644444, step = 4100 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.499\n",
      "INFO:tensorflow:loss = 0.8965486, step = 4200 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.638\n",
      "INFO:tensorflow:loss = 0.77435315, step = 4300 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.702\n",
      "INFO:tensorflow:loss = 0.7869276, step = 4400 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.072\n",
      "INFO:tensorflow:loss = 0.8268868, step = 4500 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.479\n",
      "INFO:tensorflow:loss = 0.6925389, step = 4600 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.81\n",
      "INFO:tensorflow:loss = 0.9199798, step = 4700 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.485\n",
      "INFO:tensorflow:loss = 0.94469917, step = 4800 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.363\n",
      "INFO:tensorflow:loss = 0.71888095, step = 4900 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.059\n",
      "INFO:tensorflow:loss = 0.9310282, step = 5000 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.116\n",
      "INFO:tensorflow:loss = 0.720786, step = 5100 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.56\n",
      "INFO:tensorflow:loss = 1.1235368, step = 5200 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.196\n",
      "INFO:tensorflow:loss = 0.9222283, step = 5300 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.139\n",
      "INFO:tensorflow:loss = 0.8783831, step = 5400 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.11\n",
      "INFO:tensorflow:loss = 0.7842911, step = 5500 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.756\n",
      "INFO:tensorflow:loss = 0.8956688, step = 5600 (0.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.493\n",
      "INFO:tensorflow:loss = 0.85700643, step = 5700 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.038\n",
      "INFO:tensorflow:loss = 0.9098345, step = 5800 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.525\n",
      "INFO:tensorflow:loss = 0.9515579, step = 5900 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.763\n",
      "INFO:tensorflow:loss = 0.960791, step = 6000 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.793\n",
      "INFO:tensorflow:loss = 1.068954, step = 6100 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.032\n",
      "INFO:tensorflow:loss = 0.98294127, step = 6200 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.543\n",
      "INFO:tensorflow:loss = 0.8593848, step = 6300 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.367\n",
      "INFO:tensorflow:loss = 1.0397906, step = 6400 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.484\n",
      "INFO:tensorflow:loss = 0.9381981, step = 6500 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.606\n",
      "INFO:tensorflow:loss = 1.030613, step = 6600 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.669\n",
      "INFO:tensorflow:loss = 0.99548197, step = 6700 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.679\n",
      "INFO:tensorflow:loss = 0.9113633, step = 6800 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.229\n",
      "INFO:tensorflow:loss = 0.96387225, step = 6900 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.875\n",
      "INFO:tensorflow:loss = 0.87956315, step = 7000 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.943\n",
      "INFO:tensorflow:loss = 1.0169915, step = 7100 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.785\n",
      "INFO:tensorflow:loss = 0.9996823, step = 7200 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.922\n",
      "INFO:tensorflow:loss = 0.95276785, step = 7300 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.343\n",
      "INFO:tensorflow:loss = 1.0619712, step = 7400 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.516\n",
      "INFO:tensorflow:loss = 1.0762533, step = 7500 (0.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.885\n",
      "INFO:tensorflow:loss = 0.9289282, step = 7600 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.54\n",
      "INFO:tensorflow:loss = 1.0458697, step = 7700 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.274\n",
      "INFO:tensorflow:loss = 0.93249536, step = 7800 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.726\n",
      "INFO:tensorflow:loss = 0.821493, step = 7900 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.943\n",
      "INFO:tensorflow:loss = 0.98210984, step = 8000 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.848\n",
      "INFO:tensorflow:loss = 0.9925418, step = 8100 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.02\n",
      "INFO:tensorflow:loss = 0.93644935, step = 8200 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.699\n",
      "INFO:tensorflow:loss = 1.0503954, step = 8300 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.575\n",
      "INFO:tensorflow:loss = 1.0466498, step = 8400 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.811\n",
      "INFO:tensorflow:loss = 1.1357701, step = 8500 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.84\n",
      "INFO:tensorflow:loss = 0.927688, step = 8600 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.451\n",
      "INFO:tensorflow:loss = 1.0741647, step = 8700 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.168\n",
      "INFO:tensorflow:loss = 0.8999358, step = 8800 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.694\n",
      "INFO:tensorflow:loss = 1.0770683, step = 8900 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.279\n",
      "INFO:tensorflow:loss = 0.9208231, step = 9000 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.123\n",
      "INFO:tensorflow:loss = 1.2568507, step = 9100 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.129\n",
      "INFO:tensorflow:loss = 1.0407605, step = 9200 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.786\n",
      "INFO:tensorflow:loss = 0.96152157, step = 9300 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.832\n",
      "INFO:tensorflow:loss = 0.95566505, step = 9400 (0.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.125\n",
      "INFO:tensorflow:loss = 1.0109394, step = 9500 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.021\n",
      "INFO:tensorflow:loss = 1.3177092, step = 9600 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.426\n",
      "INFO:tensorflow:loss = 1.2634734, step = 9700 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.597\n",
      "INFO:tensorflow:loss = 1.0169425, step = 9800 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.504\n",
      "INFO:tensorflow:loss = 0.8844881, step = 9900 (0.292 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10000...\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10000...\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(None,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(28, 28, 1), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "vanilla_gan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(None, 28, 28, 1) dtype=float32>}\n",
      "vanilla_gan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=int32)\n",
      "vanilla_gan_model: mode = eval\n",
      "vanilla_gan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model', 'train_batch_size': 32, 'train_steps': 56250, 'save_summary_steps': 100, 'save_checkpoints_steps': 10000, 'keep_checkpoint_max': 10, 'input_fn_autotune': False, 'eval_batch_size': 32, 'eval_steps': 100, 'start_delay_secs': 60000, 'throttle_secs': 60000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 512, 'generator_hidden_units': [256, 512, 1024], 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_hidden_units': [1024, 512, 256], 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'label_smoothing': 0.9}\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"Reshape:0\", shape=(None, 784), dtype=float32)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(None, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(None, 512), dtype=float32).\n",
      "\n",
      "get_fake_images: network = Tensor(\"random_normal:0\", shape=(None, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_0/BiasAdd:0\", shape=(None, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(None, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_1/BiasAdd:0\", shape=(None, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(None, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_2/BiasAdd:0\", shape=(None, 1024), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(None, 1024), dtype=float32)\n",
      "get_fake_images: generated_outputs = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(None, 784), dtype=float32)\n",
      "\n",
      "Call discriminator with fake_images = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(None, 784), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(None, 784), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_0/BiasAdd:0\", shape=(None, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_0:0\", shape=(None, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_1/BiasAdd:0\", shape=(None, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_1:0\", shape=(None, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_2/BiasAdd:0\", shape=(None, 256), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_2:0\", shape=(None, 256), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/layers_dense_logits/BiasAdd:0\", shape=(None, 1), dtype=float32)\n",
      "\n",
      "Call discriminator with real_images = Tensor(\"Reshape:0\", shape=(None, 784), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"Reshape:0\", shape=(None, 784), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_0/BiasAdd:0\", shape=(None, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_0:0\", shape=(None, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_1/BiasAdd:0\", shape=(None, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_1:0\", shape=(None, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_2/BiasAdd:0\", shape=(None, 256), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_2:0\", shape=(None, 256), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_1/layers_dense_logits/BiasAdd:0\", shape=(None, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"generator_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_fake_loss = Tensor(\"discriminator_fake_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"Const_4:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_eval_metric_ops: discriminator_logits = Tensor(\"discriminator_concat_logits:0\", shape=(None, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_labels = Tensor(\"discriminator_concat_labels:0\", shape=(None, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_probabilities = Tensor(\"discriminator_probabilities:0\", shape=(None, 1), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-9-71b84ff8f43a>:63: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "get_eval_metric_ops: eval_metric_ops = {'accuracy': (<tf.Tensor 'discriminator_accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_accuracy/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'discriminator_precision/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'discriminator_recall/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_recall/update_op:0' shape=() dtype=float32>), 'auc_roc': (<tf.Tensor 'discriminator_auc_roc/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_roc/update_op:0' shape=() dtype=float32>), 'auc_pr': (<tf.Tensor 'discriminator_auc_pr/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_pr/update_op:0' shape=() dtype=float32>)}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-07-24T00:11:29Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Inference Time : 1.40707s\n",
      "INFO:tensorflow:Finished evaluation at 2020-07-24-00:11:31\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.0, auc_pr = 0.8769913, auc_roc = 0.8615721, global_step = 10000, loss = 1.0742536, precision = 0.5, recall = 1.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-10000\n",
      "\n",
      "serving_input_fn: feature_placeholders = {'Z': <tf.Tensor 'serving_input_placeholder_Z:0' shape=(None, 512) dtype=float32>}\n",
      "serving_input_fn: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(None, 512) dtype=float32>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "vanilla_gan_model: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(None, 512) dtype=float32>}\n",
      "vanilla_gan_model: labels = None\n",
      "vanilla_gan_model: mode = infer\n",
      "vanilla_gan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model', 'train_batch_size': 32, 'train_steps': 56250, 'save_summary_steps': 100, 'save_checkpoints_steps': 10000, 'keep_checkpoint_max': 10, 'input_fn_autotune': False, 'eval_batch_size': 32, 'eval_steps': 100, 'start_delay_secs': 60000, 'throttle_secs': 60000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 512, 'generator_hidden_units': [256, 512, 1024], 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_hidden_units': [1024, 512, 256], 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'label_smoothing': 0.9}\n",
      "\n",
      "get_predictions_and_export_outputs: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(None, 512), dtype=float32)\n",
      "\n",
      "get_fake_images: network = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(None, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_0/BiasAdd:0\", shape=(None, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(None, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_1/BiasAdd:0\", shape=(None, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(None, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_2/BiasAdd:0\", shape=(None, 1024), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(None, 1024), dtype=float32)\n",
      "get_fake_images: generated_outputs = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(None, 784), dtype=float32)\n",
      "get_predictions_and_export_outputs: fake_images = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(None, 784), dtype=float32)\n",
      "get_predictions_and_export_outputs: generated_images = Tensor(\"Reshape:0\", shape=(None, 28, 28, 1), dtype=float32)\n",
      "get_predictions_and_export_outputs: predictions_dict = {'generated_images': <tf.Tensor 'Reshape:0' shape=(None, 28, 28, 1) dtype=float32>}\n",
      "get_predictions_and_export_outputs: export_outputs = {'predict_export_outputs': <tensorflow.python.saved_model.model_utils.export_output.PredictOutput object at 0x7f07d00d92d0>}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-10000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/temp-1595549492/saved_model.pb\n",
      "INFO:tensorflow:global_step/sec: 8.15184\n",
      "INFO:tensorflow:loss = 1.0479531, step = 10000 (12.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.039\n",
      "INFO:tensorflow:loss = 0.98213786, step = 10100 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.532\n",
      "INFO:tensorflow:loss = 1.0675718, step = 10200 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.758\n",
      "INFO:tensorflow:loss = 0.892248, step = 10300 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.836\n",
      "INFO:tensorflow:loss = 1.0174904, step = 10400 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.374\n",
      "INFO:tensorflow:loss = 1.0973763, step = 10500 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.458\n",
      "INFO:tensorflow:loss = 0.99393946, step = 10600 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.195\n",
      "INFO:tensorflow:loss = 1.0264039, step = 10700 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.477\n",
      "INFO:tensorflow:loss = 0.90980774, step = 10800 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.943\n",
      "INFO:tensorflow:loss = 0.9814321, step = 10900 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.485\n",
      "INFO:tensorflow:loss = 1.1479112, step = 11000 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.982\n",
      "INFO:tensorflow:loss = 1.158084, step = 11100 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.913\n",
      "INFO:tensorflow:loss = 0.94809985, step = 11200 (0.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.545\n",
      "INFO:tensorflow:loss = 1.115243, step = 11300 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.777\n",
      "INFO:tensorflow:loss = 1.0971072, step = 11400 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.911\n",
      "INFO:tensorflow:loss = 0.96836376, step = 11500 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.121\n",
      "INFO:tensorflow:loss = 0.90071964, step = 11600 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.234\n",
      "INFO:tensorflow:loss = 1.010527, step = 11700 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.704\n",
      "INFO:tensorflow:loss = 1.1645865, step = 11800 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.439\n",
      "INFO:tensorflow:loss = 1.2000377, step = 11900 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.012\n",
      "INFO:tensorflow:loss = 1.0159081, step = 12000 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.085\n",
      "INFO:tensorflow:loss = 1.0369492, step = 12100 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.497\n",
      "INFO:tensorflow:loss = 1.0337043, step = 12200 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.208\n",
      "INFO:tensorflow:loss = 1.033351, step = 12300 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.358\n",
      "INFO:tensorflow:loss = 1.0280449, step = 12400 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.582\n",
      "INFO:tensorflow:loss = 1.2459284, step = 12500 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.75\n",
      "INFO:tensorflow:loss = 1.215595, step = 12600 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.627\n",
      "INFO:tensorflow:loss = 1.0202229, step = 12700 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.575\n",
      "INFO:tensorflow:loss = 1.2994078, step = 12800 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.439\n",
      "INFO:tensorflow:loss = 0.9924799, step = 12900 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.882\n",
      "INFO:tensorflow:loss = 1.2552774, step = 13000 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.852\n",
      "INFO:tensorflow:loss = 0.9298098, step = 13100 (0.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.159\n",
      "INFO:tensorflow:loss = 1.0249662, step = 13200 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.75\n",
      "INFO:tensorflow:loss = 1.0652672, step = 13300 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.998\n",
      "INFO:tensorflow:loss = 1.076685, step = 13400 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.072\n",
      "INFO:tensorflow:loss = 1.15031, step = 13500 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.148\n",
      "INFO:tensorflow:loss = 1.0625025, step = 13600 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.56\n",
      "INFO:tensorflow:loss = 1.277576, step = 13700 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.363\n",
      "INFO:tensorflow:loss = 1.0658808, step = 13800 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.87\n",
      "INFO:tensorflow:loss = 1.2370113, step = 13900 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.945\n",
      "INFO:tensorflow:loss = 1.1320643, step = 14000 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.945\n",
      "INFO:tensorflow:loss = 1.0675814, step = 14100 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.133\n",
      "INFO:tensorflow:loss = 0.93721235, step = 14200 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.462\n",
      "INFO:tensorflow:loss = 1.147, step = 14300 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.122\n",
      "INFO:tensorflow:loss = 1.0193636, step = 14400 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.744\n",
      "INFO:tensorflow:loss = 0.95166767, step = 14500 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.327\n",
      "INFO:tensorflow:loss = 1.0073727, step = 14600 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.132\n",
      "INFO:tensorflow:loss = 1.0411992, step = 14700 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.643\n",
      "INFO:tensorflow:loss = 1.0756077, step = 14800 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.694\n",
      "INFO:tensorflow:loss = 1.1424799, step = 14900 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.845\n",
      "INFO:tensorflow:loss = 0.985397, step = 15000 (0.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.636\n",
      "INFO:tensorflow:loss = 1.2275574, step = 15100 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.154\n",
      "INFO:tensorflow:loss = 1.0213279, step = 15200 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.936\n",
      "INFO:tensorflow:loss = 1.074875, step = 15300 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.404\n",
      "INFO:tensorflow:loss = 1.0923427, step = 15400 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.644\n",
      "INFO:tensorflow:loss = 1.0628321, step = 15500 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.783\n",
      "INFO:tensorflow:loss = 1.0461942, step = 15600 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.833\n",
      "INFO:tensorflow:loss = 1.1516154, step = 15700 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.609\n",
      "INFO:tensorflow:loss = 1.1167228, step = 15800 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.367\n",
      "INFO:tensorflow:loss = 0.87745494, step = 15900 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.319\n",
      "INFO:tensorflow:loss = 1.031332, step = 16000 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.538\n",
      "INFO:tensorflow:loss = 1.2620256, step = 16100 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.897\n",
      "INFO:tensorflow:loss = 0.9878269, step = 16200 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.002\n",
      "INFO:tensorflow:loss = 0.97543836, step = 16300 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.082\n",
      "INFO:tensorflow:loss = 1.0837225, step = 16400 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.637\n",
      "INFO:tensorflow:loss = 1.0090368, step = 16500 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.233\n",
      "INFO:tensorflow:loss = 0.9897798, step = 16600 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.05\n",
      "INFO:tensorflow:loss = 1.1298048, step = 16700 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.227\n",
      "INFO:tensorflow:loss = 0.9411819, step = 16800 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.976\n",
      "INFO:tensorflow:loss = 0.91928065, step = 16900 (0.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.6\n",
      "INFO:tensorflow:loss = 0.9146326, step = 17000 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.459\n",
      "INFO:tensorflow:loss = 1.0875126, step = 17100 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.93\n",
      "INFO:tensorflow:loss = 1.1640179, step = 17200 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.434\n",
      "INFO:tensorflow:loss = 1.2217764, step = 17300 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.747\n",
      "INFO:tensorflow:loss = 1.0016961, step = 17400 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.769\n",
      "INFO:tensorflow:loss = 1.0767293, step = 17500 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.406\n",
      "INFO:tensorflow:loss = 1.1265266, step = 17600 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.063\n",
      "INFO:tensorflow:loss = 1.1385243, step = 17700 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.397\n",
      "INFO:tensorflow:loss = 1.1245238, step = 17800 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.516\n",
      "INFO:tensorflow:loss = 1.1862565, step = 17900 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.043\n",
      "INFO:tensorflow:loss = 1.2530525, step = 18000 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.718\n",
      "INFO:tensorflow:loss = 1.0786252, step = 18100 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.409\n",
      "INFO:tensorflow:loss = 0.9018778, step = 18200 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.02\n",
      "INFO:tensorflow:loss = 1.2021788, step = 18300 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.151\n",
      "INFO:tensorflow:loss = 1.2201877, step = 18400 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.886\n",
      "INFO:tensorflow:loss = 1.0727044, step = 18500 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.654\n",
      "INFO:tensorflow:loss = 1.1316624, step = 18600 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.362\n",
      "INFO:tensorflow:loss = 0.9946443, step = 18700 (0.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.785\n",
      "INFO:tensorflow:loss = 1.0604126, step = 18800 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.518\n",
      "INFO:tensorflow:loss = 1.1634941, step = 18900 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.704\n",
      "INFO:tensorflow:loss = 0.96396667, step = 19000 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.326\n",
      "INFO:tensorflow:loss = 1.2078096, step = 19100 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.46\n",
      "INFO:tensorflow:loss = 1.2078229, step = 19200 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.254\n",
      "INFO:tensorflow:loss = 1.0995294, step = 19300 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.171\n",
      "INFO:tensorflow:loss = 0.9196749, step = 19400 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.726\n",
      "INFO:tensorflow:loss = 1.0326978, step = 19500 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.175\n",
      "INFO:tensorflow:loss = 1.2680268, step = 19600 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.142\n",
      "INFO:tensorflow:loss = 0.9592879, step = 19700 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.912\n",
      "INFO:tensorflow:loss = 1.0903792, step = 19800 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.824\n",
      "INFO:tensorflow:loss = 0.9953799, step = 19900 (0.294 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 20000...\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 20000...\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (60000 secs).\n",
      "INFO:tensorflow:global_step/sec: 29.8831\n",
      "INFO:tensorflow:loss = 1.2095861, step = 20000 (3.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.697\n",
      "INFO:tensorflow:loss = 1.1185255, step = 20100 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.658\n",
      "INFO:tensorflow:loss = 0.9155216, step = 20200 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.267\n",
      "INFO:tensorflow:loss = 1.1468832, step = 20300 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.833\n",
      "INFO:tensorflow:loss = 1.1518002, step = 20400 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.656\n",
      "INFO:tensorflow:loss = 1.019797, step = 20500 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.822\n",
      "INFO:tensorflow:loss = 1.014814, step = 20600 (0.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.442\n",
      "INFO:tensorflow:loss = 1.0342565, step = 20700 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.971\n",
      "INFO:tensorflow:loss = 1.0329521, step = 20800 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.839\n",
      "INFO:tensorflow:loss = 1.0601107, step = 20900 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.43\n",
      "INFO:tensorflow:loss = 0.9498259, step = 21000 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.077\n",
      "INFO:tensorflow:loss = 0.9240876, step = 21100 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.791\n",
      "INFO:tensorflow:loss = 1.0736605, step = 21200 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.533\n",
      "INFO:tensorflow:loss = 0.95147634, step = 21300 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.654\n",
      "INFO:tensorflow:loss = 1.1640346, step = 21400 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.266\n",
      "INFO:tensorflow:loss = 1.1049736, step = 21500 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.425\n",
      "INFO:tensorflow:loss = 1.1189556, step = 21600 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.534\n",
      "INFO:tensorflow:loss = 1.0988692, step = 21700 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.743\n",
      "INFO:tensorflow:loss = 0.8827927, step = 21800 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.764\n",
      "INFO:tensorflow:loss = 1.0876393, step = 21900 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.162\n",
      "INFO:tensorflow:loss = 1.1097544, step = 22000 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.45\n",
      "INFO:tensorflow:loss = 1.2520988, step = 22100 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.222\n",
      "INFO:tensorflow:loss = 1.0567733, step = 22200 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.124\n",
      "INFO:tensorflow:loss = 0.9549648, step = 22300 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.989\n",
      "INFO:tensorflow:loss = 1.24928, step = 22400 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.394\n",
      "INFO:tensorflow:loss = 1.0122098, step = 22500 (0.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.309\n",
      "INFO:tensorflow:loss = 1.0279343, step = 22600 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.576\n",
      "INFO:tensorflow:loss = 1.1465982, step = 22700 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.931\n",
      "INFO:tensorflow:loss = 1.0049295, step = 22800 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.501\n",
      "INFO:tensorflow:loss = 1.1505655, step = 22900 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.282\n",
      "INFO:tensorflow:loss = 1.1561027, step = 23000 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.802\n",
      "INFO:tensorflow:loss = 1.1104548, step = 23100 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.627\n",
      "INFO:tensorflow:loss = 1.0214257, step = 23200 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.54\n",
      "INFO:tensorflow:loss = 1.1174617, step = 23300 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.042\n",
      "INFO:tensorflow:loss = 1.1508381, step = 23400 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.395\n",
      "INFO:tensorflow:loss = 0.916763, step = 23500 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.432\n",
      "INFO:tensorflow:loss = 1.0897524, step = 23600 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.476\n",
      "INFO:tensorflow:loss = 0.9429777, step = 23700 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.205\n",
      "INFO:tensorflow:loss = 1.0865431, step = 23800 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.745\n",
      "INFO:tensorflow:loss = 1.2693365, step = 23900 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.121\n",
      "INFO:tensorflow:loss = 1.1597139, step = 24000 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.415\n",
      "INFO:tensorflow:loss = 1.2075784, step = 24100 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.347\n",
      "INFO:tensorflow:loss = 1.1012646, step = 24200 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.894\n",
      "INFO:tensorflow:loss = 0.9035676, step = 24300 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.77\n",
      "INFO:tensorflow:loss = 1.0996423, step = 24400 (0.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.61\n",
      "INFO:tensorflow:loss = 1.0685426, step = 24500 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.556\n",
      "INFO:tensorflow:loss = 1.1785536, step = 24600 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.133\n",
      "INFO:tensorflow:loss = 1.067791, step = 24700 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.17\n",
      "INFO:tensorflow:loss = 1.068905, step = 24800 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.371\n",
      "INFO:tensorflow:loss = 1.2307315, step = 24900 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.811\n",
      "INFO:tensorflow:loss = 1.0282319, step = 25000 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.483\n",
      "INFO:tensorflow:loss = 0.98169094, step = 25100 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.496\n",
      "INFO:tensorflow:loss = 1.155837, step = 25200 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.56\n",
      "INFO:tensorflow:loss = 1.0228617, step = 25300 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.42\n",
      "INFO:tensorflow:loss = 1.211204, step = 25400 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.197\n",
      "INFO:tensorflow:loss = 1.1147974, step = 25500 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.729\n",
      "INFO:tensorflow:loss = 1.0767391, step = 25600 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.982\n",
      "INFO:tensorflow:loss = 1.1485176, step = 25700 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.11\n",
      "INFO:tensorflow:loss = 1.1760935, step = 25800 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.013\n",
      "INFO:tensorflow:loss = 1.1312004, step = 25900 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.157\n",
      "INFO:tensorflow:loss = 1.1343367, step = 26000 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.958\n",
      "INFO:tensorflow:loss = 1.0945675, step = 26100 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.227\n",
      "INFO:tensorflow:loss = 1.0671948, step = 26200 (0.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.984\n",
      "INFO:tensorflow:loss = 1.0909472, step = 26300 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.2\n",
      "INFO:tensorflow:loss = 1.0683181, step = 26400 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.896\n",
      "INFO:tensorflow:loss = 1.2220905, step = 26500 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.281\n",
      "INFO:tensorflow:loss = 1.0501812, step = 26600 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.751\n",
      "INFO:tensorflow:loss = 1.2830334, step = 26700 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.435\n",
      "INFO:tensorflow:loss = 1.1820927, step = 26800 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.6\n",
      "INFO:tensorflow:loss = 1.0412974, step = 26900 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.768\n",
      "INFO:tensorflow:loss = 0.89205205, step = 27000 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.685\n",
      "INFO:tensorflow:loss = 1.0662029, step = 27100 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.079\n",
      "INFO:tensorflow:loss = 1.2203815, step = 27200 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.852\n",
      "INFO:tensorflow:loss = 1.1736934, step = 27300 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.475\n",
      "INFO:tensorflow:loss = 1.0458995, step = 27400 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.294\n",
      "INFO:tensorflow:loss = 1.0451627, step = 27500 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.812\n",
      "INFO:tensorflow:loss = 1.1065347, step = 27600 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.133\n",
      "INFO:tensorflow:loss = 1.063629, step = 27700 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.732\n",
      "INFO:tensorflow:loss = 1.0002826, step = 27800 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.16\n",
      "INFO:tensorflow:loss = 1.1134276, step = 27900 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.791\n",
      "INFO:tensorflow:loss = 1.0658729, step = 28000 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.05\n",
      "INFO:tensorflow:loss = 0.9752915, step = 28100 (0.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 341\n",
      "INFO:tensorflow:loss = 1.0684254, step = 28200 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.574\n",
      "INFO:tensorflow:loss = 1.0734992, step = 28300 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.967\n",
      "INFO:tensorflow:loss = 1.0858517, step = 28400 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.002\n",
      "INFO:tensorflow:loss = 1.0033655, step = 28500 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.574\n",
      "INFO:tensorflow:loss = 1.1671939, step = 28600 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.375\n",
      "INFO:tensorflow:loss = 0.99499124, step = 28700 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.835\n",
      "INFO:tensorflow:loss = 0.99299574, step = 28800 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.458\n",
      "INFO:tensorflow:loss = 1.2031922, step = 28900 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.619\n",
      "INFO:tensorflow:loss = 1.0500741, step = 29000 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.759\n",
      "INFO:tensorflow:loss = 1.0177547, step = 29100 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.559\n",
      "INFO:tensorflow:loss = 0.92903847, step = 29200 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.102\n",
      "INFO:tensorflow:loss = 1.0332358, step = 29300 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.279\n",
      "INFO:tensorflow:loss = 1.101382, step = 29400 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.18\n",
      "INFO:tensorflow:loss = 1.0280107, step = 29500 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.791\n",
      "INFO:tensorflow:loss = 1.1035588, step = 29600 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.254\n",
      "INFO:tensorflow:loss = 1.2564795, step = 29700 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.168\n",
      "INFO:tensorflow:loss = 1.0615232, step = 29800 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.787\n",
      "INFO:tensorflow:loss = 0.8842442, step = 29900 (0.288 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 30000...\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 30000...\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (60000 secs).\n",
      "INFO:tensorflow:global_step/sec: 27.9768\n",
      "INFO:tensorflow:loss = 1.1193485, step = 30000 (3.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.136\n",
      "INFO:tensorflow:loss = 1.1473632, step = 30100 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.877\n",
      "INFO:tensorflow:loss = 1.0435296, step = 30200 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.524\n",
      "INFO:tensorflow:loss = 1.0566214, step = 30300 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.22\n",
      "INFO:tensorflow:loss = 1.1068819, step = 30400 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.541\n",
      "INFO:tensorflow:loss = 1.0392063, step = 30500 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.453\n",
      "INFO:tensorflow:loss = 1.1663389, step = 30600 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.82\n",
      "INFO:tensorflow:loss = 1.1058118, step = 30700 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.739\n",
      "INFO:tensorflow:loss = 1.00103, step = 30800 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.53\n",
      "INFO:tensorflow:loss = 1.1379355, step = 30900 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.305\n",
      "INFO:tensorflow:loss = 1.0583435, step = 31000 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.321\n",
      "INFO:tensorflow:loss = 1.0049303, step = 31100 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.977\n",
      "INFO:tensorflow:loss = 1.0395126, step = 31200 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.276\n",
      "INFO:tensorflow:loss = 1.1322054, step = 31300 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.49\n",
      "INFO:tensorflow:loss = 0.9953739, step = 31400 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.068\n",
      "INFO:tensorflow:loss = 1.1938149, step = 31500 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.221\n",
      "INFO:tensorflow:loss = 1.0344702, step = 31600 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.909\n",
      "INFO:tensorflow:loss = 1.1111047, step = 31700 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.745\n",
      "INFO:tensorflow:loss = 1.087033, step = 31800 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.137\n",
      "INFO:tensorflow:loss = 1.2103608, step = 31900 (0.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.046\n",
      "INFO:tensorflow:loss = 1.1073233, step = 32000 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.646\n",
      "INFO:tensorflow:loss = 1.0712032, step = 32100 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.076\n",
      "INFO:tensorflow:loss = 1.22971, step = 32200 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.173\n",
      "INFO:tensorflow:loss = 1.1562189, step = 32300 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.953\n",
      "INFO:tensorflow:loss = 1.1556934, step = 32400 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.442\n",
      "INFO:tensorflow:loss = 1.1015875, step = 32500 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.648\n",
      "INFO:tensorflow:loss = 1.2375529, step = 32600 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.244\n",
      "INFO:tensorflow:loss = 1.065863, step = 32700 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.324\n",
      "INFO:tensorflow:loss = 1.2560565, step = 32800 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.211\n",
      "INFO:tensorflow:loss = 1.0613945, step = 32900 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.682\n",
      "INFO:tensorflow:loss = 1.015824, step = 33000 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.409\n",
      "INFO:tensorflow:loss = 1.046206, step = 33100 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.005\n",
      "INFO:tensorflow:loss = 1.0956609, step = 33200 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.256\n",
      "INFO:tensorflow:loss = 1.1372961, step = 33300 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.899\n",
      "INFO:tensorflow:loss = 1.2318778, step = 33400 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.124\n",
      "INFO:tensorflow:loss = 1.1371951, step = 33500 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.441\n",
      "INFO:tensorflow:loss = 1.0990528, step = 33600 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.111\n",
      "INFO:tensorflow:loss = 1.0226643, step = 33700 (0.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.011\n",
      "INFO:tensorflow:loss = 1.1384839, step = 33800 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.022\n",
      "INFO:tensorflow:loss = 1.0459784, step = 33900 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.587\n",
      "INFO:tensorflow:loss = 1.1106534, step = 34000 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.217\n",
      "INFO:tensorflow:loss = 1.0465572, step = 34100 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.036\n",
      "INFO:tensorflow:loss = 0.9607486, step = 34200 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.362\n",
      "INFO:tensorflow:loss = 0.951609, step = 34300 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.334\n",
      "INFO:tensorflow:loss = 1.0153944, step = 34400 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.002\n",
      "INFO:tensorflow:loss = 0.9575238, step = 34500 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.189\n",
      "INFO:tensorflow:loss = 1.1038914, step = 34600 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.371\n",
      "INFO:tensorflow:loss = 0.961535, step = 34700 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 345\n",
      "INFO:tensorflow:loss = 1.0181007, step = 34800 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.479\n",
      "INFO:tensorflow:loss = 1.2611041, step = 34900 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.403\n",
      "INFO:tensorflow:loss = 0.9899153, step = 35000 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.498\n",
      "INFO:tensorflow:loss = 1.0656755, step = 35100 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.518\n",
      "INFO:tensorflow:loss = 1.0796914, step = 35200 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.988\n",
      "INFO:tensorflow:loss = 0.97306824, step = 35300 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.224\n",
      "INFO:tensorflow:loss = 1.1053491, step = 35400 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.386\n",
      "INFO:tensorflow:loss = 1.1233327, step = 35500 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.748\n",
      "INFO:tensorflow:loss = 0.9686781, step = 35600 (0.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.903\n",
      "INFO:tensorflow:loss = 1.3582169, step = 35700 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.773\n",
      "INFO:tensorflow:loss = 1.0037897, step = 35800 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.716\n",
      "INFO:tensorflow:loss = 1.0814939, step = 35900 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.074\n",
      "INFO:tensorflow:loss = 1.2097222, step = 36000 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.523\n",
      "INFO:tensorflow:loss = 0.98724204, step = 36100 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.928\n",
      "INFO:tensorflow:loss = 1.0833836, step = 36200 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.045\n",
      "INFO:tensorflow:loss = 0.98804444, step = 36300 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.414\n",
      "INFO:tensorflow:loss = 0.976433, step = 36400 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.842\n",
      "INFO:tensorflow:loss = 1.2175274, step = 36500 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.095\n",
      "INFO:tensorflow:loss = 1.1842133, step = 36600 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.092\n",
      "INFO:tensorflow:loss = 0.89120644, step = 36700 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.308\n",
      "INFO:tensorflow:loss = 1.1233673, step = 36800 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.326\n",
      "INFO:tensorflow:loss = 1.0067838, step = 36900 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.651\n",
      "INFO:tensorflow:loss = 1.0484271, step = 37000 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.437\n",
      "INFO:tensorflow:loss = 1.2422557, step = 37100 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.757\n",
      "INFO:tensorflow:loss = 1.1391327, step = 37200 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.012\n",
      "INFO:tensorflow:loss = 0.9281557, step = 37300 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.621\n",
      "INFO:tensorflow:loss = 0.9056669, step = 37400 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.123\n",
      "INFO:tensorflow:loss = 0.95753783, step = 37500 (0.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.321\n",
      "INFO:tensorflow:loss = 1.0757469, step = 37600 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.656\n",
      "INFO:tensorflow:loss = 1.0720007, step = 37700 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.88\n",
      "INFO:tensorflow:loss = 1.1266361, step = 37800 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.805\n",
      "INFO:tensorflow:loss = 1.0245874, step = 37900 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.913\n",
      "INFO:tensorflow:loss = 1.1378975, step = 38000 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.538\n",
      "INFO:tensorflow:loss = 1.1172436, step = 38100 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.027\n",
      "INFO:tensorflow:loss = 1.180836, step = 38200 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.62\n",
      "INFO:tensorflow:loss = 0.9818892, step = 38300 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.613\n",
      "INFO:tensorflow:loss = 1.2129061, step = 38400 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.064\n",
      "INFO:tensorflow:loss = 1.0748774, step = 38500 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.834\n",
      "INFO:tensorflow:loss = 1.03192, step = 38600 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.536\n",
      "INFO:tensorflow:loss = 1.1989402, step = 38700 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.338\n",
      "INFO:tensorflow:loss = 1.1601467, step = 38800 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.029\n",
      "INFO:tensorflow:loss = 1.221862, step = 38900 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.678\n",
      "INFO:tensorflow:loss = 1.0911837, step = 39000 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.067\n",
      "INFO:tensorflow:loss = 1.0675159, step = 39100 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.98\n",
      "INFO:tensorflow:loss = 1.0522077, step = 39200 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.58\n",
      "INFO:tensorflow:loss = 1.1193844, step = 39300 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.951\n",
      "INFO:tensorflow:loss = 1.0520983, step = 39400 (0.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.672\n",
      "INFO:tensorflow:loss = 1.2332582, step = 39500 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.291\n",
      "INFO:tensorflow:loss = 1.2317872, step = 39600 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.982\n",
      "INFO:tensorflow:loss = 1.2166523, step = 39700 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.614\n",
      "INFO:tensorflow:loss = 1.1683915, step = 39800 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.65\n",
      "INFO:tensorflow:loss = 1.2827923, step = 39900 (0.291 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 40000...\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 40000...\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (60000 secs).\n",
      "INFO:tensorflow:global_step/sec: 23.2777\n",
      "INFO:tensorflow:loss = 1.088998, step = 40000 (4.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.794\n",
      "INFO:tensorflow:loss = 1.1167402, step = 40100 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.12\n",
      "INFO:tensorflow:loss = 1.1435668, step = 40200 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.222\n",
      "INFO:tensorflow:loss = 1.1281053, step = 40300 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.019\n",
      "INFO:tensorflow:loss = 1.1748445, step = 40400 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.581\n",
      "INFO:tensorflow:loss = 1.0353835, step = 40500 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.309\n",
      "INFO:tensorflow:loss = 1.2025824, step = 40600 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.598\n",
      "INFO:tensorflow:loss = 0.9991964, step = 40700 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.202\n",
      "INFO:tensorflow:loss = 1.2206808, step = 40800 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.598\n",
      "INFO:tensorflow:loss = 1.1644576, step = 40900 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.732\n",
      "INFO:tensorflow:loss = 1.2040467, step = 41000 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.221\n",
      "INFO:tensorflow:loss = 1.0213187, step = 41100 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.795\n",
      "INFO:tensorflow:loss = 1.2124133, step = 41200 (0.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.827\n",
      "INFO:tensorflow:loss = 1.0791284, step = 41300 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.685\n",
      "INFO:tensorflow:loss = 1.1841204, step = 41400 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.094\n",
      "INFO:tensorflow:loss = 1.0521338, step = 41500 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.029\n",
      "INFO:tensorflow:loss = 1.1498733, step = 41600 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.218\n",
      "INFO:tensorflow:loss = 1.1286198, step = 41700 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.654\n",
      "INFO:tensorflow:loss = 1.183981, step = 41800 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.409\n",
      "INFO:tensorflow:loss = 1.1244378, step = 41900 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.471\n",
      "INFO:tensorflow:loss = 0.932783, step = 42000 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.095\n",
      "INFO:tensorflow:loss = 1.2444737, step = 42100 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.06\n",
      "INFO:tensorflow:loss = 0.9673578, step = 42200 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.403\n",
      "INFO:tensorflow:loss = 0.99728286, step = 42300 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.58\n",
      "INFO:tensorflow:loss = 1.0250247, step = 42400 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.039\n",
      "INFO:tensorflow:loss = 1.0707052, step = 42500 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.245\n",
      "INFO:tensorflow:loss = 1.2774116, step = 42600 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.644\n",
      "INFO:tensorflow:loss = 1.0707562, step = 42700 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.973\n",
      "INFO:tensorflow:loss = 1.197412, step = 42800 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.498\n",
      "INFO:tensorflow:loss = 1.1422148, step = 42900 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.009\n",
      "INFO:tensorflow:loss = 1.1020937, step = 43000 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.389\n",
      "INFO:tensorflow:loss = 1.0058253, step = 43100 (0.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.549\n",
      "INFO:tensorflow:loss = 1.3194963, step = 43200 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.378\n",
      "INFO:tensorflow:loss = 1.0444306, step = 43300 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.443\n",
      "INFO:tensorflow:loss = 0.98150766, step = 43400 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.902\n",
      "INFO:tensorflow:loss = 1.3193485, step = 43500 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.568\n",
      "INFO:tensorflow:loss = 1.0730414, step = 43600 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.074\n",
      "INFO:tensorflow:loss = 1.1102042, step = 43700 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.44\n",
      "INFO:tensorflow:loss = 1.084512, step = 43800 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.181\n",
      "INFO:tensorflow:loss = 1.2366986, step = 43900 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.619\n",
      "INFO:tensorflow:loss = 1.1173992, step = 44000 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.333\n",
      "INFO:tensorflow:loss = 0.91128004, step = 44100 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.942\n",
      "INFO:tensorflow:loss = 1.050028, step = 44200 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.261\n",
      "INFO:tensorflow:loss = 1.1301243, step = 44300 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.539\n",
      "INFO:tensorflow:loss = 1.318706, step = 44400 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.249\n",
      "INFO:tensorflow:loss = 1.0387466, step = 44500 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.899\n",
      "INFO:tensorflow:loss = 1.1280148, step = 44600 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.68\n",
      "INFO:tensorflow:loss = 0.9963414, step = 44700 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.018\n",
      "INFO:tensorflow:loss = 0.9823272, step = 44800 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.348\n",
      "INFO:tensorflow:loss = 1.1039433, step = 44900 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.936\n",
      "INFO:tensorflow:loss = 1.2893485, step = 45000 (0.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.415\n",
      "INFO:tensorflow:loss = 1.0473925, step = 45100 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.889\n",
      "INFO:tensorflow:loss = 1.2806127, step = 45200 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.212\n",
      "INFO:tensorflow:loss = 1.1749237, step = 45300 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.947\n",
      "INFO:tensorflow:loss = 1.0401398, step = 45400 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.516\n",
      "INFO:tensorflow:loss = 1.166014, step = 45500 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.323\n",
      "INFO:tensorflow:loss = 1.0148687, step = 45600 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.704\n",
      "INFO:tensorflow:loss = 1.0965788, step = 45700 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.336\n",
      "INFO:tensorflow:loss = 0.97115713, step = 45800 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.995\n",
      "INFO:tensorflow:loss = 1.0068071, step = 45900 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.894\n",
      "INFO:tensorflow:loss = 1.1256866, step = 46000 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.567\n",
      "INFO:tensorflow:loss = 1.1325053, step = 46100 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.925\n",
      "INFO:tensorflow:loss = 1.1767026, step = 46200 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.366\n",
      "INFO:tensorflow:loss = 0.999475, step = 46300 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.309\n",
      "INFO:tensorflow:loss = 0.9938817, step = 46400 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.171\n",
      "INFO:tensorflow:loss = 1.0111455, step = 46500 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.49\n",
      "INFO:tensorflow:loss = 1.0661242, step = 46600 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.184\n",
      "INFO:tensorflow:loss = 1.1180861, step = 46700 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.549\n",
      "INFO:tensorflow:loss = 1.1348033, step = 46800 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.052\n",
      "INFO:tensorflow:loss = 0.96910524, step = 46900 (0.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.341\n",
      "INFO:tensorflow:loss = 1.1614258, step = 47000 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.575\n",
      "INFO:tensorflow:loss = 1.0673203, step = 47100 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.945\n",
      "INFO:tensorflow:loss = 1.1182046, step = 47200 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.884\n",
      "INFO:tensorflow:loss = 1.0694213, step = 47300 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.938\n",
      "INFO:tensorflow:loss = 0.99380255, step = 47400 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.238\n",
      "INFO:tensorflow:loss = 1.2808595, step = 47500 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.946\n",
      "INFO:tensorflow:loss = 1.222106, step = 47600 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.783\n",
      "INFO:tensorflow:loss = 1.0585419, step = 47700 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.088\n",
      "INFO:tensorflow:loss = 1.1118407, step = 47800 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.58\n",
      "INFO:tensorflow:loss = 1.0781112, step = 47900 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.051\n",
      "INFO:tensorflow:loss = 1.3312261, step = 48000 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.645\n",
      "INFO:tensorflow:loss = 1.0130258, step = 48100 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.616\n",
      "INFO:tensorflow:loss = 1.0572872, step = 48200 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.103\n",
      "INFO:tensorflow:loss = 1.1172012, step = 48300 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.525\n",
      "INFO:tensorflow:loss = 1.2224332, step = 48400 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.002\n",
      "INFO:tensorflow:loss = 1.2341423, step = 48500 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.705\n",
      "INFO:tensorflow:loss = 1.0560459, step = 48600 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.349\n",
      "INFO:tensorflow:loss = 0.9799346, step = 48700 (0.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.964\n",
      "INFO:tensorflow:loss = 1.0709302, step = 48800 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.099\n",
      "INFO:tensorflow:loss = 1.0980372, step = 48900 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.418\n",
      "INFO:tensorflow:loss = 1.161141, step = 49000 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.133\n",
      "INFO:tensorflow:loss = 1.1133852, step = 49100 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.749\n",
      "INFO:tensorflow:loss = 1.0951934, step = 49200 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.31\n",
      "INFO:tensorflow:loss = 1.0972655, step = 49300 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.432\n",
      "INFO:tensorflow:loss = 1.2974272, step = 49400 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.966\n",
      "INFO:tensorflow:loss = 1.2389125, step = 49500 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.067\n",
      "INFO:tensorflow:loss = 1.1128131, step = 49600 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.567\n",
      "INFO:tensorflow:loss = 1.0854824, step = 49700 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.579\n",
      "INFO:tensorflow:loss = 1.0695616, step = 49800 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.352\n",
      "INFO:tensorflow:loss = 1.1879729, step = 49900 (0.283 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 50000...\n",
      "INFO:tensorflow:Saving checkpoints for 50000 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 50000...\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (60000 secs).\n",
      "INFO:tensorflow:global_step/sec: 28.8348\n",
      "INFO:tensorflow:loss = 0.99197626, step = 50000 (3.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.439\n",
      "INFO:tensorflow:loss = 0.97236145, step = 50100 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.74\n",
      "INFO:tensorflow:loss = 1.0635287, step = 50200 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.45\n",
      "INFO:tensorflow:loss = 1.1402745, step = 50300 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.961\n",
      "INFO:tensorflow:loss = 1.1059217, step = 50400 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.599\n",
      "INFO:tensorflow:loss = 1.1500279, step = 50500 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.87\n",
      "INFO:tensorflow:loss = 0.87957287, step = 50600 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.23\n",
      "INFO:tensorflow:loss = 1.0019858, step = 50700 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.162\n",
      "INFO:tensorflow:loss = 1.2761388, step = 50800 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.285\n",
      "INFO:tensorflow:loss = 1.1495982, step = 50900 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.284\n",
      "INFO:tensorflow:loss = 1.1036322, step = 51000 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.256\n",
      "INFO:tensorflow:loss = 1.0683929, step = 51100 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.716\n",
      "INFO:tensorflow:loss = 1.1423435, step = 51200 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.993\n",
      "INFO:tensorflow:loss = 1.190402, step = 51300 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.38\n",
      "INFO:tensorflow:loss = 1.1283497, step = 51400 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.967\n",
      "INFO:tensorflow:loss = 1.1106353, step = 51500 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.548\n",
      "INFO:tensorflow:loss = 1.0037339, step = 51600 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.007\n",
      "INFO:tensorflow:loss = 1.2215939, step = 51700 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.963\n",
      "INFO:tensorflow:loss = 1.2761807, step = 51800 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.035\n",
      "INFO:tensorflow:loss = 0.9973612, step = 51900 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.686\n",
      "INFO:tensorflow:loss = 1.0269008, step = 52000 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.164\n",
      "INFO:tensorflow:loss = 1.0359094, step = 52100 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.583\n",
      "INFO:tensorflow:loss = 1.110756, step = 52200 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.269\n",
      "INFO:tensorflow:loss = 1.1946311, step = 52300 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.294\n",
      "INFO:tensorflow:loss = 1.0684041, step = 52400 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.895\n",
      "INFO:tensorflow:loss = 1.389905, step = 52500 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.571\n",
      "INFO:tensorflow:loss = 1.2885227, step = 52600 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.96\n",
      "INFO:tensorflow:loss = 1.0094182, step = 52700 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.071\n",
      "INFO:tensorflow:loss = 1.2153224, step = 52800 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.427\n",
      "INFO:tensorflow:loss = 1.1167386, step = 52900 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.204\n",
      "INFO:tensorflow:loss = 1.1928575, step = 53000 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.445\n",
      "INFO:tensorflow:loss = 0.9940459, step = 53100 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.227\n",
      "INFO:tensorflow:loss = 1.0345839, step = 53200 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.823\n",
      "INFO:tensorflow:loss = 1.1056504, step = 53300 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.187\n",
      "INFO:tensorflow:loss = 1.1044167, step = 53400 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.865\n",
      "INFO:tensorflow:loss = 1.1544813, step = 53500 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.669\n",
      "INFO:tensorflow:loss = 1.1924697, step = 53600 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.968\n",
      "INFO:tensorflow:loss = 1.0132308, step = 53700 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.072\n",
      "INFO:tensorflow:loss = 1.1149609, step = 53800 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.813\n",
      "INFO:tensorflow:loss = 1.2164471, step = 53900 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.045\n",
      "INFO:tensorflow:loss = 1.0571082, step = 54000 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.075\n",
      "INFO:tensorflow:loss = 1.1205993, step = 54100 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.17\n",
      "INFO:tensorflow:loss = 1.1484734, step = 54200 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.571\n",
      "INFO:tensorflow:loss = 1.0630224, step = 54300 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.775\n",
      "INFO:tensorflow:loss = 1.0974889, step = 54400 (0.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.798\n",
      "INFO:tensorflow:loss = 1.0769842, step = 54500 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.517\n",
      "INFO:tensorflow:loss = 1.0278537, step = 54600 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.435\n",
      "INFO:tensorflow:loss = 1.3574514, step = 54700 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.435\n",
      "INFO:tensorflow:loss = 1.1019528, step = 54800 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.882\n",
      "INFO:tensorflow:loss = 1.0225238, step = 54900 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.561\n",
      "INFO:tensorflow:loss = 0.94367826, step = 55000 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.431\n",
      "INFO:tensorflow:loss = 1.2015088, step = 55100 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.151\n",
      "INFO:tensorflow:loss = 1.3151857, step = 55200 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.357\n",
      "INFO:tensorflow:loss = 0.97069144, step = 55300 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.662\n",
      "INFO:tensorflow:loss = 1.168324, step = 55400 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.637\n",
      "INFO:tensorflow:loss = 1.1230863, step = 55500 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.304\n",
      "INFO:tensorflow:loss = 1.0397905, step = 55600 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.123\n",
      "INFO:tensorflow:loss = 1.037957, step = 55700 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.454\n",
      "INFO:tensorflow:loss = 1.060916, step = 55800 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.834\n",
      "INFO:tensorflow:loss = 1.1651084, step = 55900 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.214\n",
      "INFO:tensorflow:loss = 1.0948739, step = 56000 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.573\n",
      "INFO:tensorflow:loss = 1.2449062, step = 56100 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.847\n",
      "INFO:tensorflow:loss = 1.0496985, step = 56200 (0.614 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 56250...\n",
      "INFO:tensorflow:Saving checkpoints for 56250 into gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 56250...\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (60000 secs).\n",
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(None,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(28, 28, 1), dtype=uint8)\n",
      "preprocess_image: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: image = Tensor(\"sub:0\", shape=(28, 28, 1), dtype=float32)\n",
      "decode_example: label = Tensor(\"Cast_1:0\", shape=(), dtype=int32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "vanilla_gan_model: features = {'image': <tf.Tensor 'IteratorGetNext:0' shape=(None, 28, 28, 1) dtype=float32>}\n",
      "vanilla_gan_model: labels = Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=int32)\n",
      "vanilla_gan_model: mode = eval\n",
      "vanilla_gan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model', 'train_batch_size': 32, 'train_steps': 56250, 'save_summary_steps': 100, 'save_checkpoints_steps': 10000, 'keep_checkpoint_max': 10, 'input_fn_autotune': False, 'eval_batch_size': 32, 'eval_steps': 100, 'start_delay_secs': 60000, 'throttle_secs': 60000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 512, 'generator_hidden_units': [256, 512, 1024], 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_hidden_units': [1024, 512, 256], 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'label_smoothing': 0.9}\n",
      "\n",
      "get_logits_and_losses: real_images = Tensor(\"Reshape:0\", shape=(None, 784), dtype=float32)\n",
      "get_logits_and_losses: Z = Tensor(\"random_normal:0\", shape=(None, 512), dtype=float32)\n",
      "\n",
      "Call generator with Z = Tensor(\"random_normal:0\", shape=(None, 512), dtype=float32).\n",
      "\n",
      "get_fake_images: network = Tensor(\"random_normal:0\", shape=(None, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_0/BiasAdd:0\", shape=(None, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(None, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_1/BiasAdd:0\", shape=(None, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(None, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_2/BiasAdd:0\", shape=(None, 1024), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(None, 1024), dtype=float32)\n",
      "get_fake_images: generated_outputs = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(None, 784), dtype=float32)\n",
      "\n",
      "Call discriminator with fake_images = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(None, 784), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(None, 784), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_0/BiasAdd:0\", shape=(None, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_0:0\", shape=(None, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_1/BiasAdd:0\", shape=(None, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_1:0\", shape=(None, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/layers_dense_2/BiasAdd:0\", shape=(None, 256), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator/leaky_relu_2:0\", shape=(None, 256), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator/layers_dense_logits/BiasAdd:0\", shape=(None, 1), dtype=float32)\n",
      "\n",
      "Call discriminator with real_images = Tensor(\"Reshape:0\", shape=(None, 784), dtype=float32).\n",
      "\n",
      "get_discriminator_logits: network = Tensor(\"Reshape:0\", shape=(None, 784), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_0/BiasAdd:0\", shape=(None, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_0:0\", shape=(None, 1024), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_1/BiasAdd:0\", shape=(None, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_1:0\", shape=(None, 512), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/layers_dense_2/BiasAdd:0\", shape=(None, 256), dtype=float32)\n",
      "get_discriminator_logits: network = Tensor(\"discriminator_1/leaky_relu_2:0\", shape=(None, 256), dtype=float32)\n",
      "get_discriminator_logits: logits = Tensor(\"discriminator_1/layers_dense_logits/BiasAdd:0\", shape=(None, 1), dtype=float32)\n",
      "\n",
      "get_generator_loss: generator_loss = Tensor(\"generator_loss:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_reg_loss = Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
      "get_generator_loss: generator_total_loss = Tensor(\"generator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_discriminator_loss: discriminator_real_loss = Tensor(\"discriminator_real_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_fake_loss = Tensor(\"discriminator_fake_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_loss = Tensor(\"discriminator_loss:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_reg_loss = Tensor(\"Const_4:0\", shape=(), dtype=float32)\n",
      "get_discriminator_loss: discriminator_total_loss = Tensor(\"discriminator_total_loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "get_eval_metric_ops: discriminator_logits = Tensor(\"discriminator_concat_logits:0\", shape=(None, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_labels = Tensor(\"discriminator_concat_labels:0\", shape=(None, 1), dtype=float32)\n",
      "get_eval_metric_ops: discriminator_probabilities = Tensor(\"discriminator_probabilities:0\", shape=(None, 1), dtype=float32)\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "get_eval_metric_ops: eval_metric_ops = {'accuracy': (<tf.Tensor 'discriminator_accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_accuracy/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'discriminator_precision/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'discriminator_recall/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_recall/update_op:0' shape=() dtype=float32>), 'auc_roc': (<tf.Tensor 'discriminator_auc_roc/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_roc/update_op:0' shape=() dtype=float32>), 'auc_pr': (<tf.Tensor 'discriminator_auc_pr/value:0' shape=() dtype=float32>, <tf.Tensor 'discriminator_auc_pr/update_op:0' shape=() dtype=float32>)}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-07-24T00:14:20Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-56250\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Inference Time : 1.36762s\n",
      "INFO:tensorflow:Finished evaluation at 2020-07-24-00:14:21\n",
      "INFO:tensorflow:Saving dict for global step 56250: accuracy = 0.0, auc_pr = 0.70085496, auc_roc = 0.6861256, global_step = 56250, loss = 1.3609688, precision = 0.5, recall = 1.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 56250: gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-56250\n",
      "\n",
      "serving_input_fn: feature_placeholders = {'Z': <tf.Tensor 'serving_input_placeholder_Z:0' shape=(None, 512) dtype=float32>}\n",
      "serving_input_fn: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(None, 512) dtype=float32>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "vanilla_gan_model: features = {'Z': <tf.Tensor 'serving_input_fn_identity_placeholder_Z:0' shape=(None, 512) dtype=float32>}\n",
      "vanilla_gan_model: labels = None\n",
      "vanilla_gan_model: mode = infer\n",
      "vanilla_gan_model: params = {'train_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord', 'eval_file_pattern': 'gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord', 'output_dir': 'gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model', 'train_batch_size': 32, 'train_steps': 56250, 'save_summary_steps': 100, 'save_checkpoints_steps': 10000, 'keep_checkpoint_max': 10, 'input_fn_autotune': False, 'eval_batch_size': 32, 'eval_steps': 100, 'start_delay_secs': 60000, 'throttle_secs': 60000, 'height': 28, 'width': 28, 'depth': 1, 'latent_size': 512, 'generator_hidden_units': [256, 512, 1024], 'generator_leaky_relu_alpha': 0.2, 'generator_final_activation': 'tanh', 'generator_l1_regularization_scale': 0.0, 'generator_l2_regularization_scale': 0.0, 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0002, 'generator_adam_beta1': 0.5, 'generator_adam_beta2': 0.999, 'generator_adam_epsilon': 1e-08, 'generator_clip_gradients': None, 'generator_train_steps': 1, 'discriminator_hidden_units': [1024, 512, 256], 'discriminator_leaky_relu_alpha': 0.2, 'discriminator_l1_regularization_scale': 0.0, 'discriminator_l2_regularization_scale': 0.0, 'discriminator_optimizer': 'Adam', 'discriminator_learning_rate': 0.0002, 'discriminator_adam_beta1': 0.5, 'discriminator_adam_beta2': 0.999, 'discriminator_adam_epsilon': 1e-08, 'discriminator_clip_gradients': None, 'discriminator_train_steps': 1, 'label_smoothing': 0.9}\n",
      "\n",
      "get_predictions_and_export_outputs: Z = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(None, 512), dtype=float32)\n",
      "\n",
      "get_fake_images: network = Tensor(\"serving_input_fn_identity_placeholder_Z:0\", shape=(None, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_0/BiasAdd:0\", shape=(None, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_0:0\", shape=(None, 256), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_1/BiasAdd:0\", shape=(None, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_1:0\", shape=(None, 512), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/layers_dense_2/BiasAdd:0\", shape=(None, 1024), dtype=float32)\n",
      "get_fake_images: network = Tensor(\"generator/leaky_relu_2:0\", shape=(None, 1024), dtype=float32)\n",
      "get_fake_images: generated_outputs = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(None, 784), dtype=float32)\n",
      "get_predictions_and_export_outputs: fake_images = Tensor(\"generator/layers_dense_generated_outputs/Tanh:0\", shape=(None, 784), dtype=float32)\n",
      "get_predictions_and_export_outputs: generated_images = Tensor(\"Reshape:0\", shape=(None, 28, 28, 1), dtype=float32)\n",
      "get_predictions_and_export_outputs: predictions_dict = {'generated_images': <tf.Tensor 'Reshape:0' shape=(None, 28, 28, 1) dtype=float32>}\n",
      "get_predictions_and_export_outputs: export_outputs = {'predict_export_outputs': <tensorflow.python.saved_model.model_utils.export_output.PredictOutput object at 0x7f077447ec50>}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/model.ckpt-56250\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/temp-1595549661/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 1.4244734.\n"
     ]
    }
   ],
   "source": [
    "estimator = train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/\n",
      "gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1595549492/\n",
      "gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter/1595549661/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://machine-learning-1234-bucket/gan/vanilla_gan/trained_model/export/exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['serving_default', 'predict_export_outputs']\n"
     ]
    }
   ],
   "source": [
    "loaded = tf.saved_model.load(\n",
    "    export_dir=os.path.join(\n",
    "        arguments[\"output_dir\"], \"export\", \"exporter\", \"1595549661\"\n",
    "    )\n",
    ")\n",
    "print(list(loaded.signatures.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_images': <tf.Tensor 'Reshape:0' shape=(None, 28, 28, 1) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "infer = loaded.signatures[\"serving_default\"]\n",
    "print(infer.structured_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = tf.random.normal(shape=(10, 512))\n",
    "predictions = infer(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = np.clip(\n",
    "    a=tf.cast(\n",
    "        x=((tf.reshape(\n",
    "            tensor=predictions[\"generated_images\"],\n",
    "            shape=[\n",
    "                -1,\n",
    "                arguments[\"height\"],\n",
    "                arguments[\"width\"],\n",
    "                arguments[\"depth\"]\n",
    "            ]\n",
    "        ) + 1.0) * (255. / 2)),\n",
    "        dtype=tf.int32\n",
    "    ),\n",
    "    a_min=0,\n",
    "    a_max=255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(generated_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "    \"\"\"Plots images.\n",
    "\n",
    "    Args:\n",
    "        images: np.array, array of images of\n",
    "            [num_images, image_size, image_size, num_channels].\n",
    "    \"\"\"\n",
    "    num_images = len(images)\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(num_images):\n",
    "        image = images[i]\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(\n",
    "            tf.reshape(image, image.shape[:-1]),\n",
    "            cmap=\"gray_r\"\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
