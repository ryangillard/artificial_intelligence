{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model module locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {}\n",
    "# File arguments.\n",
    "arguments[\"train_file_pattern\"] = \"gs://machine-learning-1234-bucket/gan/data/mnist/train*.tfrecord\"\n",
    "arguments[\"eval_file_pattern\"] = \"gs://machine-learning-1234-bucket/gan/data/mnist/test*.tfrecord\"\n",
    "arguments[\"output_dir\"] = \"gs://machine-learning-1234-bucket/gan/vanilla_gan/tf2/trained_model\"\n",
    "\n",
    "# Training parameters.\n",
    "arguments[\"tf_version\"] = 2.2\n",
    "arguments[\"num_epochs\"] = 50\n",
    "arguments[\"train_dataset_length\"] = 60000\n",
    "arguments[\"train_batch_size\"] = 32\n",
    "arguments[\"log_step_count_steps\"] = 100\n",
    "arguments[\"save_summary_steps\"] = 100\n",
    "arguments[\"save_checkpoints_steps\"] = 10000\n",
    "arguments[\"keep_checkpoint_max\"] = 10\n",
    "arguments[\"input_fn_autotune\"] = False\n",
    "\n",
    "# Eval parameters.\n",
    "arguments[\"eval_batch_size\"] = 32\n",
    "arguments[\"eval_steps\"] = 100\n",
    "\n",
    "# Image parameters.\n",
    "arguments[\"height\"] = 28\n",
    "arguments[\"width\"] = 28\n",
    "arguments[\"depth\"] = 1\n",
    "\n",
    "# Generator parameters.\n",
    "arguments[\"latent_size\"] = 512\n",
    "arguments[\"generator_hidden_units\"] = [256, 512, 1024]\n",
    "arguments[\"generator_leaky_relu_alpha\"] = 0.2\n",
    "arguments[\"generator_final_activation\"] = \"tanh\"\n",
    "arguments[\"generator_l1_regularization_scale\"] = 0.\n",
    "arguments[\"generator_l2_regularization_scale\"] = 0.\n",
    "arguments[\"generator_optimizer\"] = \"Adam\"\n",
    "arguments[\"generator_learning_rate\"] = 0.0002\n",
    "arguments[\"generator_adam_beta1\"] = 0.5\n",
    "arguments[\"generator_adam_beta2\"] = 0.999\n",
    "arguments[\"generator_adam_epsilon\"] = 1e-8\n",
    "arguments[\"generator_clip_gradients\"] = None\n",
    "arguments[\"generator_train_steps\"] = 1\n",
    "\n",
    "# Discriminator hyperparameters.\n",
    "arguments[\"discriminator_hidden_units\"] = [1024, 512, 256]\n",
    "arguments[\"discriminator_leaky_relu_alpha\"] = 0.2\n",
    "arguments[\"discriminator_l1_regularization_scale\"] = 0.\n",
    "arguments[\"discriminator_l2_regularization_scale\"] = 0.\n",
    "arguments[\"discriminator_optimizer\"] = \"Adam\"\n",
    "arguments[\"discriminator_learning_rate\"] = 0.0002\n",
    "arguments[\"discriminator_adam_beta1\"] = 0.5\n",
    "arguments[\"discriminator_adam_beta2\"] = 0.999\n",
    "arguments[\"discriminator_adam_epsilon\"] = 1e-8\n",
    "arguments[\"discriminator_clip_gradients\"] = None\n",
    "arguments[\"discriminator_train_steps\"] = 1\n",
    "arguments[\"label_smoothing\"] = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Import os environment variables for file hyperparameters.\n",
    "os.environ[\"TRAIN_FILE_PATTERN\"] = arguments[\"train_file_pattern\"]\n",
    "os.environ[\"EVAL_FILE_PATTERN\"] = arguments[\"eval_file_pattern\"]\n",
    "os.environ[\"OUTPUT_DIR\"] = arguments[\"output_dir\"]\n",
    "\n",
    "# Import os environment variables for train hyperparameters.\n",
    "os.environ[\"TF_VERSION\"] = str(arguments[\"tf_version\"])\n",
    "os.environ[\"NUM_EPOCHS\"] = str(arguments[\"num_epochs\"])\n",
    "os.environ[\"TRAIN_DATASET_LENGTH\"] = str(arguments[\"train_dataset_length\"])\n",
    "os.environ[\"TRAIN_BATCH_SIZE\"] = str(arguments[\"train_batch_size\"])\n",
    "os.environ[\"LOG_STEP_COUNT_STEPS\"] = str(arguments[\"log_step_count_steps\"])\n",
    "os.environ[\"SAVE_SUMMARY_STEPS\"] = str(arguments[\"save_summary_steps\"])\n",
    "os.environ[\"SAVE_CHECKPOINTS_STEPS\"] = str(arguments[\"save_checkpoints_steps\"])\n",
    "os.environ[\"KEEP_CHECKPOINT_MAX\"] = str(arguments[\"keep_checkpoint_max\"])\n",
    "os.environ[\"INPUT_FN_AUTOTUNE\"] = str(arguments[\"input_fn_autotune\"])\n",
    "\n",
    "# Import os environment variables for eval hyperparameters.\n",
    "os.environ[\"EVAL_BATCH_SIZE\"] = str(arguments[\"eval_batch_size\"])\n",
    "os.environ[\"EVAL_STEPS\"] = str(arguments[\"eval_steps\"])\n",
    "\n",
    "# Import os environment variables for image hyperparameters.\n",
    "os.environ[\"HEIGHT\"] = str(arguments[\"height\"])\n",
    "os.environ[\"WIDTH\"] = str(arguments[\"width\"])\n",
    "os.environ[\"DEPTH\"] = str(arguments[\"depth\"])\n",
    "\n",
    "# Import os environment variables for generator hyperparameters.\n",
    "os.environ[\"LATENT_SIZE\"] = str(arguments[\"latent_size\"])\n",
    "os.environ[\"GENERATOR_HIDDEN_UNITS\"] = \",\".join(\n",
    "    [str(x) for x in arguments[\"generator_hidden_units\"]]\n",
    ")\n",
    "os.environ[\"GENERATOR_LEAKY_RELU_ALPHA\"] = str(arguments[\"generator_leaky_relu_alpha\"])\n",
    "os.environ[\"GENERATOR_FINAL_ACTIVATION\"] = arguments[\"generator_final_activation\"]\n",
    "os.environ[\"GENERATOR_L1_REGULARIZATION_SCALE\"] = str(arguments[\"generator_l1_regularization_scale\"])\n",
    "os.environ[\"GENERATOR_L2_REGULARIZATION_SCALE\"] = str(arguments[\"generator_l2_regularization_scale\"])\n",
    "os.environ[\"GENERATOR_OPTIMIZER\"] = arguments[\"generator_optimizer\"]\n",
    "os.environ[\"GENERATOR_LEARNING_RATE\"] = str(arguments[\"generator_learning_rate\"])\n",
    "os.environ[\"GENERATOR_ADAM_BETA1\"] = str(arguments[\"generator_adam_beta1\"])\n",
    "os.environ[\"GENERATOR_ADAM_BETA2\"] = str(arguments[\"generator_adam_beta2\"])\n",
    "os.environ[\"GENERATOR_ADAM_EPSILON\"] = str(arguments[\"generator_adam_epsilon\"])\n",
    "os.environ[\"GENERATOR_CLIP_GRADIENTS\"] = str(arguments[\"generator_clip_gradients\"])\n",
    "os.environ[\"GENERATOR_TRAIN_STEPS\"] = str(arguments[\"generator_train_steps\"])\n",
    "\n",
    "# Import os environment variables for discriminator hyperparameters.\n",
    "os.environ[\"DISCRIMINATOR_HIDDEN_UNITS\"] = \",\".join(\n",
    "    [str(x) for x in arguments[\"discriminator_hidden_units\"]]\n",
    ")\n",
    "os.environ[\"DISCRIMINATOR_LEAKY_RELU_ALPHA\"] = str(arguments[\"discriminator_leaky_relu_alpha\"])\n",
    "os.environ[\"DISCRIMINATOR_L1_REGULARIZATION_SCALE\"] = str(arguments[\"discriminator_l1_regularization_scale\"])\n",
    "os.environ[\"DISCRIMINATOR_L2_REGULARIZATION_SCALE\"] = str(arguments[\"discriminator_l2_regularization_scale\"])\n",
    "os.environ[\"DISCRIMINATOR_OPTIMIZER\"] = arguments[\"discriminator_optimizer\"]\n",
    "os.environ[\"DISCRIMINATOR_LEARNING_RATE\"] = str(arguments[\"discriminator_learning_rate\"])\n",
    "os.environ[\"DISCRIMINATOR_ADAM_BETA1\"] = str(arguments[\"discriminator_adam_beta1\"])\n",
    "os.environ[\"DISCRIMINATOR_ADAM_BETA2\"] = str(arguments[\"discriminator_adam_beta2\"])\n",
    "os.environ[\"DISCRIMINATOR_ADAM_EPSILON\"] = str(arguments[\"discriminator_adam_epsilon\"])\n",
    "os.environ[\"DISCRIMINATOR_CLIP_GRADIENTS\"] = str(arguments[\"discriminator_clip_gradients\"])\n",
    "os.environ[\"DISCRIMINATOR_TRAIN_STEPS\"] = str(arguments[\"discriminator_train_steps\"])\n",
    "os.environ[\"LABEL_SMOOTHING\"] = str(arguments[\"label_smoothing\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Vanilla GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices = 1\n",
      "epoch = 0, global_step = 0, epoch_step = 0, loss = 1.437708854675293\n",
      "epoch = 0, global_step = 100, epoch_step = 100, loss = 1.3188461065292358\n",
      "epoch = 0, global_step = 200, epoch_step = 200, loss = 1.3110480308532715\n",
      "epoch = 0, global_step = 300, epoch_step = 300, loss = 1.325720191001892\n",
      "epoch = 0, global_step = 400, epoch_step = 400, loss = 1.078068494796753\n",
      "epoch = 0, global_step = 500, epoch_step = 500, loss = 1.015324354171753\n",
      "epoch = 0, global_step = 600, epoch_step = 600, loss = 1.083125114440918\n",
      "epoch = 0, global_step = 700, epoch_step = 700, loss = 1.081690788269043\n",
      "epoch = 0, global_step = 800, epoch_step = 800, loss = 0.9734196662902832\n",
      "epoch = 0, global_step = 900, epoch_step = 900, loss = 1.0034548044204712\n",
      "epoch = 0, global_step = 1000, epoch_step = 1000, loss = 0.9632654190063477\n",
      "epoch = 0, global_step = 1100, epoch_step = 1100, loss = 1.002490520477295\n",
      "epoch = 0, global_step = 1200, epoch_step = 1200, loss = 0.9389034509658813\n",
      "epoch = 0, global_step = 1300, epoch_step = 1300, loss = 0.967352032661438\n",
      "epoch = 0, global_step = 1400, epoch_step = 1400, loss = 0.9394391775131226\n",
      "epoch = 0, global_step = 1500, epoch_step = 1500, loss = 0.9476230144500732\n",
      "epoch = 0, global_step = 1600, epoch_step = 1600, loss = 0.9232929348945618\n",
      "epoch = 0, global_step = 1700, epoch_step = 1700, loss = 1.0075427293777466\n",
      "epoch = 0, global_step = 1800, epoch_step = 1800, loss = 0.9169418215751648\n",
      "epoch = 1, global_step = 1900, epoch_step = 25, loss = 0.9115000367164612\n",
      "epoch = 1, global_step = 2000, epoch_step = 125, loss = 0.9108113050460815\n",
      "epoch = 1, global_step = 2100, epoch_step = 225, loss = 0.9559242725372314\n",
      "epoch = 1, global_step = 2200, epoch_step = 325, loss = 0.9882175922393799\n",
      "epoch = 1, global_step = 2300, epoch_step = 425, loss = 0.9164524078369141\n",
      "epoch = 1, global_step = 2400, epoch_step = 525, loss = 0.985141396522522\n",
      "epoch = 1, global_step = 2500, epoch_step = 625, loss = 0.9423912763595581\n",
      "epoch = 1, global_step = 2600, epoch_step = 725, loss = 0.90927654504776\n",
      "epoch = 1, global_step = 2700, epoch_step = 825, loss = 0.888254702091217\n",
      "epoch = 1, global_step = 2800, epoch_step = 925, loss = 0.9294224381446838\n",
      "epoch = 1, global_step = 2900, epoch_step = 1025, loss = 0.890533447265625\n",
      "epoch = 1, global_step = 3000, epoch_step = 1125, loss = 0.957792341709137\n",
      "epoch = 1, global_step = 3100, epoch_step = 1225, loss = 0.9166173934936523\n",
      "epoch = 1, global_step = 3200, epoch_step = 1325, loss = 0.9632236957550049\n",
      "epoch = 1, global_step = 3300, epoch_step = 1425, loss = 0.9975020885467529\n",
      "epoch = 1, global_step = 3400, epoch_step = 1525, loss = 0.945941686630249\n",
      "epoch = 1, global_step = 3500, epoch_step = 1625, loss = 0.8927009105682373\n",
      "epoch = 1, global_step = 3600, epoch_step = 1725, loss = 0.9555528163909912\n",
      "epoch = 1, global_step = 3700, epoch_step = 1825, loss = 0.969622790813446\n",
      "epoch = 2, global_step = 3800, epoch_step = 50, loss = 0.9865165948867798\n",
      "epoch = 2, global_step = 3900, epoch_step = 150, loss = 0.9642465710639954\n",
      "epoch = 2, global_step = 4000, epoch_step = 250, loss = 0.905393123626709\n",
      "epoch = 2, global_step = 4100, epoch_step = 350, loss = 0.9486979246139526\n",
      "epoch = 2, global_step = 4200, epoch_step = 450, loss = 0.9658558368682861\n",
      "epoch = 2, global_step = 4300, epoch_step = 550, loss = 1.0221867561340332\n",
      "epoch = 2, global_step = 4400, epoch_step = 650, loss = 0.908245325088501\n",
      "epoch = 2, global_step = 4500, epoch_step = 750, loss = 0.9833647608757019\n",
      "epoch = 2, global_step = 4600, epoch_step = 850, loss = 0.9852479696273804\n",
      "epoch = 2, global_step = 4700, epoch_step = 950, loss = 0.9598951935768127\n",
      "epoch = 2, global_step = 4800, epoch_step = 1050, loss = 0.9785521626472473\n",
      "epoch = 2, global_step = 4900, epoch_step = 1150, loss = 0.9831845164299011\n",
      "epoch = 2, global_step = 5000, epoch_step = 1250, loss = 0.9147666096687317\n",
      "epoch = 2, global_step = 5100, epoch_step = 1350, loss = 0.9958997964859009\n",
      "epoch = 2, global_step = 5200, epoch_step = 1450, loss = 0.9513809084892273\n",
      "epoch = 2, global_step = 5300, epoch_step = 1550, loss = 0.9818329215049744\n",
      "epoch = 2, global_step = 5400, epoch_step = 1650, loss = 0.9922634363174438\n",
      "epoch = 2, global_step = 5500, epoch_step = 1750, loss = 1.0109119415283203\n",
      "epoch = 2, global_step = 5600, epoch_step = 1850, loss = 0.9241881370544434\n",
      "epoch = 3, global_step = 5700, epoch_step = 75, loss = 0.9534789323806763\n",
      "epoch = 3, global_step = 5800, epoch_step = 175, loss = 1.035850167274475\n",
      "epoch = 3, global_step = 5900, epoch_step = 275, loss = 0.9459395408630371\n",
      "epoch = 3, global_step = 6000, epoch_step = 375, loss = 1.0071405172348022\n",
      "epoch = 3, global_step = 6100, epoch_step = 475, loss = 1.0800199508666992\n",
      "epoch = 3, global_step = 6200, epoch_step = 575, loss = 1.012457013130188\n",
      "epoch = 3, global_step = 6300, epoch_step = 675, loss = 1.012885332107544\n",
      "epoch = 3, global_step = 6400, epoch_step = 775, loss = 1.2239266633987427\n",
      "epoch = 3, global_step = 6500, epoch_step = 875, loss = 0.9906793832778931\n",
      "epoch = 3, global_step = 6600, epoch_step = 975, loss = 0.9949241876602173\n",
      "epoch = 3, global_step = 6700, epoch_step = 1075, loss = 1.0077688694000244\n",
      "epoch = 3, global_step = 6800, epoch_step = 1175, loss = 0.984412431716919\n",
      "epoch = 3, global_step = 6900, epoch_step = 1275, loss = 1.0067460536956787\n",
      "epoch = 3, global_step = 7000, epoch_step = 1375, loss = 1.01065993309021\n",
      "epoch = 3, global_step = 7100, epoch_step = 1475, loss = 0.9875893592834473\n",
      "epoch = 3, global_step = 7200, epoch_step = 1575, loss = 1.0050803422927856\n",
      "epoch = 3, global_step = 7300, epoch_step = 1675, loss = 1.031633734703064\n",
      "epoch = 3, global_step = 7400, epoch_step = 1775, loss = 1.0361167192459106\n",
      "epoch = 4, global_step = 7500, epoch_step = 0, loss = 1.0633049011230469\n",
      "epoch = 4, global_step = 7600, epoch_step = 100, loss = 1.043912649154663\n",
      "epoch = 4, global_step = 7700, epoch_step = 200, loss = 1.0094865560531616\n",
      "epoch = 4, global_step = 7800, epoch_step = 300, loss = 1.0792567729949951\n",
      "epoch = 4, global_step = 7900, epoch_step = 400, loss = 1.103256344795227\n",
      "epoch = 4, global_step = 8000, epoch_step = 500, loss = 1.1082682609558105\n",
      "epoch = 4, global_step = 8100, epoch_step = 600, loss = 1.0261166095733643\n",
      "epoch = 4, global_step = 8200, epoch_step = 700, loss = 1.00368070602417\n",
      "epoch = 4, global_step = 8300, epoch_step = 800, loss = 1.0493836402893066\n",
      "epoch = 4, global_step = 8400, epoch_step = 900, loss = 1.0368925333023071\n",
      "epoch = 4, global_step = 8500, epoch_step = 1000, loss = 1.0692367553710938\n",
      "epoch = 4, global_step = 8600, epoch_step = 1100, loss = 0.9768374562263489\n",
      "epoch = 4, global_step = 8700, epoch_step = 1200, loss = 0.986541748046875\n",
      "epoch = 4, global_step = 8800, epoch_step = 1300, loss = 1.085047721862793\n",
      "epoch = 4, global_step = 8900, epoch_step = 1400, loss = 1.0500296354293823\n",
      "epoch = 4, global_step = 9000, epoch_step = 1500, loss = 1.0364351272583008\n",
      "epoch = 4, global_step = 9100, epoch_step = 1600, loss = 1.0185374021530151\n",
      "epoch = 4, global_step = 9200, epoch_step = 1700, loss = 1.0478509664535522\n",
      "epoch = 4, global_step = 9300, epoch_step = 1800, loss = 1.027273178100586\n",
      "epoch = 5, global_step = 9400, epoch_step = 25, loss = 0.98496413230896\n",
      "epoch = 5, global_step = 9500, epoch_step = 125, loss = 0.9928956031799316\n",
      "epoch = 5, global_step = 9600, epoch_step = 225, loss = 1.0858274698257446\n",
      "epoch = 5, global_step = 9700, epoch_step = 325, loss = 1.087185263633728\n",
      "epoch = 5, global_step = 9800, epoch_step = 425, loss = 1.063653588294983\n",
      "epoch = 5, global_step = 9900, epoch_step = 525, loss = 1.0346927642822266\n",
      "epoch = 5, global_step = 10000, epoch_step = 625, loss = 1.067624807357788\n",
      "epoch = 5, global_step = 10100, epoch_step = 725, loss = 0.9907361268997192\n",
      "epoch = 5, global_step = 10200, epoch_step = 825, loss = 1.0070528984069824\n",
      "epoch = 5, global_step = 10300, epoch_step = 925, loss = 1.0841559171676636\n",
      "epoch = 5, global_step = 10400, epoch_step = 1025, loss = 1.0778138637542725\n",
      "epoch = 5, global_step = 10500, epoch_step = 1125, loss = 1.0577218532562256\n",
      "epoch = 5, global_step = 10600, epoch_step = 1225, loss = 0.9866412878036499\n",
      "epoch = 5, global_step = 10700, epoch_step = 1325, loss = 1.0047413110733032\n",
      "epoch = 5, global_step = 10800, epoch_step = 1425, loss = 1.101492166519165\n",
      "epoch = 5, global_step = 10900, epoch_step = 1525, loss = 1.0163791179656982\n",
      "epoch = 5, global_step = 11000, epoch_step = 1625, loss = 1.0664743185043335\n",
      "epoch = 5, global_step = 11100, epoch_step = 1725, loss = 1.028515100479126\n",
      "epoch = 5, global_step = 11200, epoch_step = 1825, loss = 1.0353190898895264\n",
      "epoch = 6, global_step = 11300, epoch_step = 50, loss = 1.015052080154419\n",
      "epoch = 6, global_step = 11400, epoch_step = 150, loss = 1.0283831357955933\n",
      "epoch = 6, global_step = 11500, epoch_step = 250, loss = 1.1506727933883667\n",
      "epoch = 6, global_step = 11600, epoch_step = 350, loss = 1.040435552597046\n",
      "epoch = 6, global_step = 11700, epoch_step = 450, loss = 1.0025893449783325\n",
      "epoch = 6, global_step = 11800, epoch_step = 550, loss = 1.0481820106506348\n",
      "epoch = 6, global_step = 11900, epoch_step = 650, loss = 1.0708831548690796\n",
      "epoch = 6, global_step = 12000, epoch_step = 750, loss = 1.1036123037338257\n",
      "epoch = 6, global_step = 12100, epoch_step = 850, loss = 1.0562399625778198\n",
      "epoch = 6, global_step = 12200, epoch_step = 950, loss = 1.1019940376281738\n",
      "epoch = 6, global_step = 12300, epoch_step = 1050, loss = 0.9790847301483154\n",
      "epoch = 6, global_step = 12400, epoch_step = 1150, loss = 1.034238338470459\n",
      "epoch = 6, global_step = 12500, epoch_step = 1250, loss = 1.0145909786224365\n",
      "epoch = 6, global_step = 12600, epoch_step = 1350, loss = 0.9948892593383789\n",
      "epoch = 6, global_step = 12700, epoch_step = 1450, loss = 1.023916244506836\n",
      "epoch = 6, global_step = 12800, epoch_step = 1550, loss = 1.0551042556762695\n",
      "epoch = 6, global_step = 12900, epoch_step = 1650, loss = 1.0382944345474243\n",
      "epoch = 6, global_step = 13000, epoch_step = 1750, loss = 1.059053659439087\n",
      "epoch = 6, global_step = 13100, epoch_step = 1850, loss = 1.0126845836639404\n",
      "epoch = 7, global_step = 13200, epoch_step = 75, loss = 1.0042177438735962\n",
      "epoch = 7, global_step = 13300, epoch_step = 175, loss = 1.0286390781402588\n",
      "epoch = 7, global_step = 13400, epoch_step = 275, loss = 1.0570783615112305\n",
      "epoch = 7, global_step = 13500, epoch_step = 375, loss = 1.074225664138794\n",
      "epoch = 7, global_step = 13600, epoch_step = 475, loss = 0.9943675398826599\n",
      "epoch = 7, global_step = 13700, epoch_step = 575, loss = 1.035154938697815\n",
      "epoch = 7, global_step = 13800, epoch_step = 675, loss = 1.1428906917572021\n",
      "epoch = 7, global_step = 13900, epoch_step = 775, loss = 1.1108946800231934\n",
      "epoch = 7, global_step = 14000, epoch_step = 875, loss = 1.0649763345718384\n",
      "epoch = 7, global_step = 14100, epoch_step = 975, loss = 1.0669124126434326\n",
      "epoch = 7, global_step = 14200, epoch_step = 1075, loss = 1.024055004119873\n",
      "epoch = 7, global_step = 14300, epoch_step = 1175, loss = 1.058203101158142\n",
      "epoch = 7, global_step = 14400, epoch_step = 1275, loss = 1.0332003831863403\n",
      "epoch = 7, global_step = 14500, epoch_step = 1375, loss = 1.028820276260376\n",
      "epoch = 7, global_step = 14600, epoch_step = 1475, loss = 1.0518370866775513\n",
      "epoch = 7, global_step = 14700, epoch_step = 1575, loss = 1.0461992025375366\n",
      "epoch = 7, global_step = 14800, epoch_step = 1675, loss = 1.0407661199569702\n",
      "epoch = 7, global_step = 14900, epoch_step = 1775, loss = 1.0548889636993408\n",
      "epoch = 8, global_step = 15000, epoch_step = 0, loss = 1.0595399141311646\n",
      "epoch = 8, global_step = 15100, epoch_step = 100, loss = 1.0336120128631592\n",
      "epoch = 8, global_step = 15200, epoch_step = 200, loss = 1.0502314567565918\n",
      "epoch = 8, global_step = 15300, epoch_step = 300, loss = 1.1026335954666138\n",
      "epoch = 8, global_step = 15400, epoch_step = 400, loss = 1.0657317638397217\n",
      "epoch = 8, global_step = 15500, epoch_step = 500, loss = 1.0360591411590576\n",
      "epoch = 8, global_step = 15600, epoch_step = 600, loss = 1.047093152999878\n",
      "epoch = 8, global_step = 15700, epoch_step = 700, loss = 1.0105531215667725\n",
      "epoch = 8, global_step = 15800, epoch_step = 800, loss = 0.9929171800613403\n",
      "epoch = 8, global_step = 15900, epoch_step = 900, loss = 1.1658324003219604\n",
      "epoch = 8, global_step = 16000, epoch_step = 1000, loss = 1.12642502784729\n",
      "epoch = 8, global_step = 16100, epoch_step = 1100, loss = 1.0795634984970093\n",
      "epoch = 8, global_step = 16200, epoch_step = 1200, loss = 1.0242249965667725\n",
      "epoch = 8, global_step = 16300, epoch_step = 1300, loss = 1.0382616519927979\n",
      "epoch = 8, global_step = 16400, epoch_step = 1400, loss = 1.0592143535614014\n",
      "epoch = 8, global_step = 16500, epoch_step = 1500, loss = 1.0814425945281982\n",
      "epoch = 8, global_step = 16600, epoch_step = 1600, loss = 1.0756604671478271\n",
      "epoch = 8, global_step = 16700, epoch_step = 1700, loss = 1.105842113494873\n",
      "epoch = 8, global_step = 16800, epoch_step = 1800, loss = 0.9958652853965759\n",
      "epoch = 9, global_step = 16900, epoch_step = 25, loss = 1.0233967304229736\n",
      "epoch = 9, global_step = 17000, epoch_step = 125, loss = 1.0671907663345337\n",
      "epoch = 9, global_step = 17100, epoch_step = 225, loss = 1.0174909830093384\n",
      "epoch = 9, global_step = 17200, epoch_step = 325, loss = 1.120021104812622\n",
      "epoch = 9, global_step = 17300, epoch_step = 425, loss = 1.1124262809753418\n",
      "epoch = 9, global_step = 17400, epoch_step = 525, loss = 0.9937498569488525\n",
      "epoch = 9, global_step = 17500, epoch_step = 625, loss = 1.173921823501587\n",
      "epoch = 9, global_step = 17600, epoch_step = 725, loss = 1.1080846786499023\n",
      "epoch = 9, global_step = 17700, epoch_step = 825, loss = 1.0439329147338867\n",
      "epoch = 9, global_step = 17800, epoch_step = 925, loss = 1.0756949186325073\n",
      "epoch = 9, global_step = 17900, epoch_step = 1025, loss = 1.0708215236663818\n",
      "epoch = 9, global_step = 18000, epoch_step = 1125, loss = 1.0101604461669922\n",
      "epoch = 9, global_step = 18100, epoch_step = 1225, loss = 1.0555377006530762\n",
      "epoch = 9, global_step = 18200, epoch_step = 1325, loss = 0.9993083477020264\n",
      "epoch = 9, global_step = 18300, epoch_step = 1425, loss = 1.0741488933563232\n",
      "epoch = 9, global_step = 18400, epoch_step = 1525, loss = 1.153414011001587\n",
      "epoch = 9, global_step = 18500, epoch_step = 1625, loss = 1.0714702606201172\n",
      "epoch = 9, global_step = 18600, epoch_step = 1725, loss = 1.0777106285095215\n",
      "epoch = 9, global_step = 18700, epoch_step = 1825, loss = 0.9856740236282349\n",
      "epoch = 10, global_step = 18800, epoch_step = 50, loss = 1.100284218788147\n",
      "epoch = 10, global_step = 18900, epoch_step = 150, loss = 1.0297768115997314\n",
      "epoch = 10, global_step = 19000, epoch_step = 250, loss = 1.0648974180221558\n",
      "epoch = 10, global_step = 19100, epoch_step = 350, loss = 1.1636161804199219\n",
      "epoch = 10, global_step = 19200, epoch_step = 450, loss = 1.0711264610290527\n",
      "epoch = 10, global_step = 19300, epoch_step = 550, loss = 1.0515471696853638\n",
      "epoch = 10, global_step = 19400, epoch_step = 650, loss = 1.038648009300232\n",
      "epoch = 10, global_step = 19500, epoch_step = 750, loss = 1.081391453742981\n",
      "epoch = 10, global_step = 19600, epoch_step = 850, loss = 1.1043552160263062\n",
      "epoch = 10, global_step = 19700, epoch_step = 950, loss = 1.0289576053619385\n",
      "epoch = 10, global_step = 19800, epoch_step = 1050, loss = 0.9538612365722656\n",
      "epoch = 10, global_step = 19900, epoch_step = 1150, loss = 1.0812126398086548\n",
      "epoch = 10, global_step = 20000, epoch_step = 1250, loss = 1.0437431335449219\n",
      "epoch = 10, global_step = 20100, epoch_step = 1350, loss = 1.1439435482025146\n",
      "epoch = 10, global_step = 20200, epoch_step = 1450, loss = 0.9888875484466553\n",
      "epoch = 10, global_step = 20300, epoch_step = 1550, loss = 1.0592944622039795\n",
      "epoch = 10, global_step = 20400, epoch_step = 1650, loss = 1.0676010847091675\n",
      "epoch = 10, global_step = 20500, epoch_step = 1750, loss = 1.0252516269683838\n",
      "epoch = 10, global_step = 20600, epoch_step = 1850, loss = 1.0842106342315674\n",
      "epoch = 11, global_step = 20700, epoch_step = 75, loss = 1.0459942817687988\n",
      "epoch = 11, global_step = 20800, epoch_step = 175, loss = 1.0365009307861328\n",
      "epoch = 11, global_step = 20900, epoch_step = 275, loss = 1.140375018119812\n",
      "epoch = 11, global_step = 21000, epoch_step = 375, loss = 1.0334831476211548\n",
      "epoch = 11, global_step = 21100, epoch_step = 475, loss = 1.130591869354248\n",
      "epoch = 11, global_step = 21200, epoch_step = 575, loss = 1.025666356086731\n",
      "epoch = 11, global_step = 21300, epoch_step = 675, loss = 1.048394799232483\n",
      "epoch = 11, global_step = 21400, epoch_step = 775, loss = 1.067605972290039\n",
      "epoch = 11, global_step = 21500, epoch_step = 875, loss = 1.0750007629394531\n",
      "epoch = 11, global_step = 21600, epoch_step = 975, loss = 1.1345844268798828\n",
      "epoch = 11, global_step = 21700, epoch_step = 1075, loss = 1.1027463674545288\n",
      "epoch = 11, global_step = 21800, epoch_step = 1175, loss = 1.026344895362854\n",
      "epoch = 11, global_step = 21900, epoch_step = 1275, loss = 0.9975835680961609\n",
      "epoch = 11, global_step = 22000, epoch_step = 1375, loss = 1.05370032787323\n",
      "epoch = 11, global_step = 22100, epoch_step = 1475, loss = 1.0096410512924194\n",
      "epoch = 11, global_step = 22200, epoch_step = 1575, loss = 1.0848585367202759\n",
      "epoch = 11, global_step = 22300, epoch_step = 1675, loss = 1.1106317043304443\n",
      "epoch = 11, global_step = 22400, epoch_step = 1775, loss = 1.0455081462860107\n",
      "epoch = 12, global_step = 22500, epoch_step = 0, loss = 1.010328769683838\n",
      "epoch = 12, global_step = 22600, epoch_step = 100, loss = 1.0166627168655396\n",
      "epoch = 12, global_step = 22700, epoch_step = 200, loss = 1.0249665975570679\n",
      "epoch = 12, global_step = 22800, epoch_step = 300, loss = 1.0478919744491577\n",
      "epoch = 12, global_step = 22900, epoch_step = 400, loss = 1.0498859882354736\n",
      "epoch = 12, global_step = 23000, epoch_step = 500, loss = 1.0241512060165405\n",
      "epoch = 12, global_step = 23100, epoch_step = 600, loss = 0.9874294996261597\n",
      "epoch = 12, global_step = 23200, epoch_step = 700, loss = 1.0314240455627441\n",
      "epoch = 12, global_step = 23300, epoch_step = 800, loss = 1.0015968084335327\n",
      "epoch = 12, global_step = 23400, epoch_step = 900, loss = 1.0114281177520752\n",
      "epoch = 12, global_step = 23500, epoch_step = 1000, loss = 1.0790375471115112\n",
      "epoch = 12, global_step = 23600, epoch_step = 1100, loss = 1.043645977973938\n",
      "epoch = 12, global_step = 23700, epoch_step = 1200, loss = 1.139315128326416\n",
      "epoch = 12, global_step = 23800, epoch_step = 1300, loss = 1.0561047792434692\n",
      "epoch = 12, global_step = 23900, epoch_step = 1400, loss = 1.0536079406738281\n",
      "epoch = 12, global_step = 24000, epoch_step = 1500, loss = 0.9857310056686401\n",
      "epoch = 12, global_step = 24100, epoch_step = 1600, loss = 1.0141781568527222\n",
      "epoch = 12, global_step = 24200, epoch_step = 1700, loss = 1.029186725616455\n",
      "epoch = 12, global_step = 24300, epoch_step = 1800, loss = 1.0072903633117676\n",
      "epoch = 13, global_step = 24400, epoch_step = 25, loss = 1.0388550758361816\n",
      "epoch = 13, global_step = 24500, epoch_step = 125, loss = 1.1254096031188965\n",
      "epoch = 13, global_step = 24600, epoch_step = 225, loss = 1.0082389116287231\n",
      "epoch = 13, global_step = 24700, epoch_step = 325, loss = 1.0816900730133057\n",
      "epoch = 13, global_step = 24800, epoch_step = 425, loss = 1.0734527111053467\n",
      "epoch = 13, global_step = 24900, epoch_step = 525, loss = 1.072627067565918\n",
      "epoch = 13, global_step = 25000, epoch_step = 625, loss = 1.0775701999664307\n",
      "epoch = 13, global_step = 25100, epoch_step = 725, loss = 1.097923755645752\n",
      "epoch = 13, global_step = 25200, epoch_step = 825, loss = 1.0288970470428467\n",
      "epoch = 13, global_step = 25300, epoch_step = 925, loss = 1.087135672569275\n",
      "epoch = 13, global_step = 25400, epoch_step = 1025, loss = 1.0334279537200928\n",
      "epoch = 13, global_step = 25500, epoch_step = 1125, loss = 1.0381884574890137\n",
      "epoch = 13, global_step = 25600, epoch_step = 1225, loss = 1.0678694248199463\n",
      "epoch = 13, global_step = 25700, epoch_step = 1325, loss = 1.0543501377105713\n",
      "epoch = 13, global_step = 25800, epoch_step = 1425, loss = 1.0275440216064453\n",
      "epoch = 13, global_step = 25900, epoch_step = 1525, loss = 1.0610945224761963\n",
      "epoch = 13, global_step = 26000, epoch_step = 1625, loss = 1.089560866355896\n",
      "epoch = 13, global_step = 26100, epoch_step = 1725, loss = 1.0824742317199707\n",
      "epoch = 13, global_step = 26200, epoch_step = 1825, loss = 1.0097603797912598\n",
      "epoch = 14, global_step = 26300, epoch_step = 50, loss = 1.0733351707458496\n",
      "epoch = 14, global_step = 26400, epoch_step = 150, loss = 1.0127661228179932\n",
      "epoch = 14, global_step = 26500, epoch_step = 250, loss = 1.041100263595581\n",
      "epoch = 14, global_step = 26600, epoch_step = 350, loss = 1.0631941556930542\n",
      "epoch = 14, global_step = 26700, epoch_step = 450, loss = 1.0885933637619019\n",
      "epoch = 14, global_step = 26800, epoch_step = 550, loss = 1.114436149597168\n",
      "epoch = 14, global_step = 26900, epoch_step = 650, loss = 1.0382626056671143\n",
      "epoch = 14, global_step = 27000, epoch_step = 750, loss = 1.0581586360931396\n",
      "epoch = 14, global_step = 27100, epoch_step = 850, loss = 1.0377588272094727\n",
      "epoch = 14, global_step = 27200, epoch_step = 950, loss = 1.0454869270324707\n",
      "epoch = 14, global_step = 27300, epoch_step = 1050, loss = 1.0583540201187134\n",
      "epoch = 14, global_step = 27400, epoch_step = 1150, loss = 1.0133366584777832\n",
      "epoch = 14, global_step = 27500, epoch_step = 1250, loss = 1.077606439590454\n",
      "epoch = 14, global_step = 27600, epoch_step = 1350, loss = 1.100414514541626\n",
      "epoch = 14, global_step = 27700, epoch_step = 1450, loss = 1.1161221265792847\n",
      "epoch = 14, global_step = 27800, epoch_step = 1550, loss = 1.143572211265564\n",
      "epoch = 14, global_step = 27900, epoch_step = 1650, loss = 1.0769802331924438\n",
      "epoch = 14, global_step = 28000, epoch_step = 1750, loss = 1.0377990007400513\n",
      "epoch = 14, global_step = 28100, epoch_step = 1850, loss = 1.0562162399291992\n",
      "epoch = 15, global_step = 28200, epoch_step = 75, loss = 1.0043396949768066\n",
      "epoch = 15, global_step = 28300, epoch_step = 175, loss = 1.0635794401168823\n",
      "epoch = 15, global_step = 28400, epoch_step = 275, loss = 1.055513858795166\n",
      "epoch = 15, global_step = 28500, epoch_step = 375, loss = 1.1001770496368408\n",
      "epoch = 15, global_step = 28600, epoch_step = 475, loss = 1.0372958183288574\n",
      "epoch = 15, global_step = 28700, epoch_step = 575, loss = 1.0057928562164307\n",
      "epoch = 15, global_step = 28800, epoch_step = 675, loss = 1.0487728118896484\n",
      "epoch = 15, global_step = 28900, epoch_step = 775, loss = 1.069048285484314\n",
      "epoch = 15, global_step = 29000, epoch_step = 875, loss = 1.0761632919311523\n",
      "epoch = 15, global_step = 29100, epoch_step = 975, loss = 1.053344488143921\n",
      "epoch = 15, global_step = 29200, epoch_step = 1075, loss = 1.0400819778442383\n",
      "epoch = 15, global_step = 29300, epoch_step = 1175, loss = 1.0344165563583374\n",
      "epoch = 15, global_step = 29400, epoch_step = 1275, loss = 1.1592426300048828\n",
      "epoch = 15, global_step = 29500, epoch_step = 1375, loss = 1.029163122177124\n",
      "epoch = 15, global_step = 29600, epoch_step = 1475, loss = 1.0974303483963013\n",
      "epoch = 15, global_step = 29700, epoch_step = 1575, loss = 1.0428035259246826\n",
      "epoch = 15, global_step = 29800, epoch_step = 1675, loss = 1.03536057472229\n",
      "epoch = 15, global_step = 29900, epoch_step = 1775, loss = 1.0545978546142578\n",
      "epoch = 16, global_step = 30000, epoch_step = 0, loss = 0.9816895723342896\n",
      "epoch = 16, global_step = 30100, epoch_step = 100, loss = 0.9975699186325073\n",
      "epoch = 16, global_step = 30200, epoch_step = 200, loss = 1.0806301832199097\n",
      "epoch = 16, global_step = 30300, epoch_step = 300, loss = 1.0591458082199097\n",
      "epoch = 16, global_step = 30400, epoch_step = 400, loss = 1.0363692045211792\n",
      "epoch = 16, global_step = 30500, epoch_step = 500, loss = 1.0187218189239502\n",
      "epoch = 16, global_step = 30600, epoch_step = 600, loss = 1.081424593925476\n",
      "epoch = 16, global_step = 30700, epoch_step = 700, loss = 1.0935964584350586\n",
      "epoch = 16, global_step = 30800, epoch_step = 800, loss = 1.081678867340088\n",
      "epoch = 16, global_step = 30900, epoch_step = 900, loss = 1.01200532913208\n",
      "epoch = 16, global_step = 31000, epoch_step = 1000, loss = 1.0131702423095703\n",
      "epoch = 16, global_step = 31100, epoch_step = 1100, loss = 1.0526905059814453\n",
      "epoch = 16, global_step = 31200, epoch_step = 1200, loss = 1.0150794982910156\n",
      "epoch = 16, global_step = 31300, epoch_step = 1300, loss = 1.1318459510803223\n",
      "epoch = 16, global_step = 31400, epoch_step = 1400, loss = 1.0379281044006348\n",
      "epoch = 16, global_step = 31500, epoch_step = 1500, loss = 1.0374938249588013\n",
      "epoch = 16, global_step = 31600, epoch_step = 1600, loss = 1.0839834213256836\n",
      "epoch = 16, global_step = 31700, epoch_step = 1700, loss = 1.0631321668624878\n",
      "epoch = 16, global_step = 31800, epoch_step = 1800, loss = 0.986549973487854\n",
      "epoch = 17, global_step = 31900, epoch_step = 25, loss = 1.1330925226211548\n",
      "epoch = 17, global_step = 32000, epoch_step = 125, loss = 1.0568174123764038\n",
      "epoch = 17, global_step = 32100, epoch_step = 225, loss = 1.0605638027191162\n",
      "epoch = 17, global_step = 32200, epoch_step = 325, loss = 1.1039425134658813\n",
      "epoch = 17, global_step = 32300, epoch_step = 425, loss = 1.0860629081726074\n",
      "epoch = 17, global_step = 32400, epoch_step = 525, loss = 1.044716477394104\n",
      "epoch = 17, global_step = 32500, epoch_step = 625, loss = 0.9971610307693481\n",
      "epoch = 17, global_step = 32600, epoch_step = 725, loss = 1.0783617496490479\n",
      "epoch = 17, global_step = 32700, epoch_step = 825, loss = 1.0352656841278076\n",
      "epoch = 17, global_step = 32800, epoch_step = 925, loss = 1.0574907064437866\n",
      "epoch = 17, global_step = 32900, epoch_step = 1025, loss = 1.0683339834213257\n",
      "epoch = 17, global_step = 33000, epoch_step = 1125, loss = 1.0312236547470093\n",
      "epoch = 17, global_step = 33100, epoch_step = 1225, loss = 1.0372816324234009\n",
      "epoch = 17, global_step = 33200, epoch_step = 1325, loss = 1.0615668296813965\n",
      "epoch = 17, global_step = 33300, epoch_step = 1425, loss = 1.0374727249145508\n",
      "epoch = 17, global_step = 33400, epoch_step = 1525, loss = 1.0594704151153564\n",
      "epoch = 17, global_step = 33500, epoch_step = 1625, loss = 1.0103156566619873\n",
      "epoch = 17, global_step = 33600, epoch_step = 1725, loss = 1.0254234075546265\n",
      "epoch = 17, global_step = 33700, epoch_step = 1825, loss = 1.0325803756713867\n",
      "epoch = 18, global_step = 33800, epoch_step = 50, loss = 1.076600193977356\n",
      "epoch = 18, global_step = 33900, epoch_step = 150, loss = 1.0603468418121338\n",
      "epoch = 18, global_step = 34000, epoch_step = 250, loss = 1.0830252170562744\n",
      "epoch = 18, global_step = 34100, epoch_step = 350, loss = 0.9894050359725952\n",
      "epoch = 18, global_step = 34200, epoch_step = 450, loss = 1.0574690103530884\n",
      "epoch = 18, global_step = 34300, epoch_step = 550, loss = 1.0845390558242798\n",
      "epoch = 18, global_step = 34400, epoch_step = 650, loss = 1.069596290588379\n",
      "epoch = 18, global_step = 34500, epoch_step = 750, loss = 1.0631963014602661\n",
      "epoch = 18, global_step = 34600, epoch_step = 850, loss = 1.0262573957443237\n",
      "epoch = 18, global_step = 34700, epoch_step = 950, loss = 1.0667741298675537\n",
      "epoch = 18, global_step = 34800, epoch_step = 1050, loss = 1.0156502723693848\n",
      "epoch = 18, global_step = 34900, epoch_step = 1150, loss = 1.0851850509643555\n",
      "epoch = 18, global_step = 35000, epoch_step = 1250, loss = 1.0303750038146973\n",
      "epoch = 18, global_step = 35100, epoch_step = 1350, loss = 1.0253548622131348\n",
      "epoch = 18, global_step = 35200, epoch_step = 1450, loss = 1.078739881515503\n",
      "epoch = 18, global_step = 35300, epoch_step = 1550, loss = 1.1595747470855713\n",
      "epoch = 18, global_step = 35400, epoch_step = 1650, loss = 1.037961483001709\n",
      "epoch = 18, global_step = 35500, epoch_step = 1750, loss = 1.131889820098877\n",
      "epoch = 18, global_step = 35600, epoch_step = 1850, loss = 1.0862399339675903\n",
      "epoch = 19, global_step = 35700, epoch_step = 75, loss = 0.969821572303772\n",
      "epoch = 19, global_step = 35800, epoch_step = 175, loss = 1.0630134344100952\n",
      "epoch = 19, global_step = 35900, epoch_step = 275, loss = 1.0656425952911377\n",
      "epoch = 19, global_step = 36000, epoch_step = 375, loss = 1.0157806873321533\n",
      "epoch = 19, global_step = 36100, epoch_step = 475, loss = 1.0588823556900024\n",
      "epoch = 19, global_step = 36200, epoch_step = 575, loss = 1.071335792541504\n",
      "epoch = 19, global_step = 36300, epoch_step = 675, loss = 1.030250072479248\n",
      "epoch = 19, global_step = 36400, epoch_step = 775, loss = 1.0183457136154175\n",
      "epoch = 19, global_step = 36500, epoch_step = 875, loss = 1.0665878057479858\n",
      "epoch = 19, global_step = 36600, epoch_step = 975, loss = 1.060594081878662\n",
      "epoch = 19, global_step = 36700, epoch_step = 1075, loss = 1.1415883302688599\n",
      "epoch = 19, global_step = 36800, epoch_step = 1175, loss = 1.077286720275879\n",
      "epoch = 19, global_step = 36900, epoch_step = 1275, loss = 1.0594724416732788\n",
      "epoch = 19, global_step = 37000, epoch_step = 1375, loss = 1.015883445739746\n",
      "epoch = 19, global_step = 37100, epoch_step = 1475, loss = 1.0558009147644043\n",
      "epoch = 19, global_step = 37200, epoch_step = 1575, loss = 1.1491425037384033\n",
      "epoch = 19, global_step = 37300, epoch_step = 1675, loss = 1.1285626888275146\n",
      "epoch = 19, global_step = 37400, epoch_step = 1775, loss = 1.0233774185180664\n",
      "epoch = 20, global_step = 37500, epoch_step = 0, loss = 1.0688766241073608\n",
      "epoch = 20, global_step = 37600, epoch_step = 100, loss = 1.094649076461792\n",
      "epoch = 20, global_step = 37700, epoch_step = 200, loss = 1.114044427871704\n",
      "epoch = 20, global_step = 37800, epoch_step = 300, loss = 1.0620397329330444\n",
      "epoch = 20, global_step = 37900, epoch_step = 400, loss = 1.0159589052200317\n",
      "epoch = 20, global_step = 38000, epoch_step = 500, loss = 1.116833209991455\n",
      "epoch = 20, global_step = 38100, epoch_step = 600, loss = 1.0361096858978271\n",
      "epoch = 20, global_step = 38200, epoch_step = 700, loss = 1.0304973125457764\n",
      "epoch = 20, global_step = 38300, epoch_step = 800, loss = 1.1403119564056396\n",
      "epoch = 20, global_step = 38400, epoch_step = 900, loss = 1.0538159608840942\n",
      "epoch = 20, global_step = 38500, epoch_step = 1000, loss = 1.0628376007080078\n",
      "epoch = 20, global_step = 38600, epoch_step = 1100, loss = 1.020318865776062\n",
      "epoch = 20, global_step = 38700, epoch_step = 1200, loss = 1.026916265487671\n",
      "epoch = 20, global_step = 38800, epoch_step = 1300, loss = 1.0355340242385864\n",
      "epoch = 20, global_step = 38900, epoch_step = 1400, loss = 1.0971916913986206\n",
      "epoch = 20, global_step = 39000, epoch_step = 1500, loss = 1.0644385814666748\n",
      "epoch = 20, global_step = 39100, epoch_step = 1600, loss = 1.05148446559906\n",
      "epoch = 20, global_step = 39200, epoch_step = 1700, loss = 1.0692317485809326\n",
      "epoch = 20, global_step = 39300, epoch_step = 1800, loss = 1.0269334316253662\n",
      "epoch = 21, global_step = 39400, epoch_step = 25, loss = 1.0710170269012451\n",
      "epoch = 21, global_step = 39500, epoch_step = 125, loss = 1.0573766231536865\n",
      "epoch = 21, global_step = 39600, epoch_step = 225, loss = 1.0307443141937256\n",
      "epoch = 21, global_step = 39700, epoch_step = 325, loss = 1.052412986755371\n",
      "epoch = 21, global_step = 39800, epoch_step = 425, loss = 1.1098341941833496\n",
      "epoch = 21, global_step = 39900, epoch_step = 525, loss = 1.052459716796875\n",
      "epoch = 21, global_step = 40000, epoch_step = 625, loss = 1.0240520238876343\n",
      "epoch = 21, global_step = 40100, epoch_step = 725, loss = 1.0753192901611328\n",
      "epoch = 21, global_step = 40200, epoch_step = 825, loss = 1.0684278011322021\n",
      "epoch = 21, global_step = 40300, epoch_step = 925, loss = 1.029901146888733\n",
      "epoch = 21, global_step = 40400, epoch_step = 1025, loss = 1.0663496255874634\n",
      "epoch = 21, global_step = 40500, epoch_step = 1125, loss = 0.9984033703804016\n",
      "epoch = 21, global_step = 40600, epoch_step = 1225, loss = 1.1127794981002808\n",
      "epoch = 21, global_step = 40700, epoch_step = 1325, loss = 1.0212236642837524\n",
      "epoch = 21, global_step = 40800, epoch_step = 1425, loss = 1.1432013511657715\n",
      "epoch = 21, global_step = 40900, epoch_step = 1525, loss = 1.0654559135437012\n",
      "epoch = 21, global_step = 41000, epoch_step = 1625, loss = 1.0451312065124512\n",
      "epoch = 21, global_step = 41100, epoch_step = 1725, loss = 1.1008827686309814\n",
      "epoch = 21, global_step = 41200, epoch_step = 1825, loss = 1.0430158376693726\n",
      "epoch = 22, global_step = 41300, epoch_step = 50, loss = 1.1208629608154297\n",
      "epoch = 22, global_step = 41400, epoch_step = 150, loss = 1.0420008897781372\n",
      "epoch = 22, global_step = 41500, epoch_step = 250, loss = 1.0754330158233643\n",
      "epoch = 22, global_step = 41600, epoch_step = 350, loss = 1.101327896118164\n",
      "epoch = 22, global_step = 41700, epoch_step = 450, loss = 1.0351897478103638\n",
      "epoch = 22, global_step = 41800, epoch_step = 550, loss = 1.05147123336792\n",
      "epoch = 22, global_step = 41900, epoch_step = 650, loss = 1.111646294593811\n",
      "epoch = 22, global_step = 42000, epoch_step = 750, loss = 1.09812593460083\n",
      "epoch = 22, global_step = 42100, epoch_step = 850, loss = 1.0127434730529785\n",
      "epoch = 22, global_step = 42200, epoch_step = 950, loss = 1.0618823766708374\n",
      "epoch = 22, global_step = 42300, epoch_step = 1050, loss = 1.0648494958877563\n",
      "epoch = 22, global_step = 42400, epoch_step = 1150, loss = 1.084341287612915\n",
      "epoch = 22, global_step = 42500, epoch_step = 1250, loss = 0.9996442794799805\n",
      "epoch = 22, global_step = 42600, epoch_step = 1350, loss = 1.036116361618042\n",
      "epoch = 22, global_step = 42700, epoch_step = 1450, loss = 1.032917857170105\n",
      "epoch = 22, global_step = 42800, epoch_step = 1550, loss = 1.1401734352111816\n",
      "epoch = 22, global_step = 42900, epoch_step = 1650, loss = 1.1633731126785278\n",
      "epoch = 22, global_step = 43000, epoch_step = 1750, loss = 1.0517328977584839\n",
      "epoch = 22, global_step = 43100, epoch_step = 1850, loss = 1.0257898569107056\n",
      "epoch = 23, global_step = 43200, epoch_step = 75, loss = 1.0867161750793457\n",
      "epoch = 23, global_step = 43300, epoch_step = 175, loss = 1.0589790344238281\n",
      "epoch = 23, global_step = 43400, epoch_step = 275, loss = 1.119572401046753\n",
      "epoch = 23, global_step = 43500, epoch_step = 375, loss = 1.0778822898864746\n",
      "epoch = 23, global_step = 43600, epoch_step = 475, loss = 1.0995304584503174\n",
      "epoch = 23, global_step = 43700, epoch_step = 575, loss = 1.1259753704071045\n",
      "epoch = 23, global_step = 43800, epoch_step = 675, loss = 1.0741281509399414\n",
      "epoch = 23, global_step = 43900, epoch_step = 775, loss = 1.059474229812622\n",
      "epoch = 23, global_step = 44000, epoch_step = 875, loss = 1.027779459953308\n",
      "epoch = 23, global_step = 44100, epoch_step = 975, loss = 1.079538106918335\n",
      "epoch = 23, global_step = 44200, epoch_step = 1075, loss = 1.0409759283065796\n",
      "epoch = 23, global_step = 44300, epoch_step = 1175, loss = 1.0330727100372314\n",
      "epoch = 23, global_step = 44400, epoch_step = 1275, loss = 1.0300155878067017\n",
      "epoch = 23, global_step = 44500, epoch_step = 1375, loss = 1.1260077953338623\n",
      "epoch = 23, global_step = 44600, epoch_step = 1475, loss = 1.0442962646484375\n",
      "epoch = 23, global_step = 44700, epoch_step = 1575, loss = 1.0522576570510864\n",
      "epoch = 23, global_step = 44800, epoch_step = 1675, loss = 1.0048670768737793\n",
      "epoch = 23, global_step = 44900, epoch_step = 1775, loss = 1.0268778800964355\n",
      "epoch = 24, global_step = 45000, epoch_step = 0, loss = 1.0736504793167114\n",
      "epoch = 24, global_step = 45100, epoch_step = 100, loss = 1.0612952709197998\n",
      "epoch = 24, global_step = 45200, epoch_step = 200, loss = 1.0588438510894775\n",
      "epoch = 24, global_step = 45300, epoch_step = 300, loss = 1.0811327695846558\n",
      "epoch = 24, global_step = 45400, epoch_step = 400, loss = 1.0337265729904175\n",
      "epoch = 24, global_step = 45500, epoch_step = 500, loss = 1.1383931636810303\n",
      "epoch = 24, global_step = 45600, epoch_step = 600, loss = 1.0318922996520996\n",
      "epoch = 24, global_step = 45700, epoch_step = 700, loss = 1.128089189529419\n",
      "epoch = 24, global_step = 45800, epoch_step = 800, loss = 0.9992185831069946\n",
      "epoch = 24, global_step = 45900, epoch_step = 900, loss = 1.0525833368301392\n",
      "epoch = 24, global_step = 46000, epoch_step = 1000, loss = 1.0482876300811768\n",
      "epoch = 24, global_step = 46100, epoch_step = 1100, loss = 0.9844298362731934\n",
      "epoch = 24, global_step = 46200, epoch_step = 1200, loss = 1.110007882118225\n",
      "epoch = 24, global_step = 46300, epoch_step = 1300, loss = 1.0415960550308228\n",
      "epoch = 24, global_step = 46400, epoch_step = 1400, loss = 1.0491735935211182\n",
      "epoch = 24, global_step = 46500, epoch_step = 1500, loss = 1.0271612405776978\n",
      "epoch = 24, global_step = 46600, epoch_step = 1600, loss = 1.1042832136154175\n",
      "epoch = 24, global_step = 46700, epoch_step = 1700, loss = 1.0736477375030518\n",
      "epoch = 24, global_step = 46800, epoch_step = 1800, loss = 1.0639469623565674\n",
      "epoch = 25, global_step = 46900, epoch_step = 25, loss = 1.0156728029251099\n",
      "epoch = 25, global_step = 47000, epoch_step = 125, loss = 1.0516692399978638\n",
      "epoch = 25, global_step = 47100, epoch_step = 225, loss = 1.1011840105056763\n",
      "epoch = 25, global_step = 47200, epoch_step = 325, loss = 1.0414361953735352\n",
      "epoch = 25, global_step = 47300, epoch_step = 425, loss = 1.0564827919006348\n",
      "epoch = 25, global_step = 47400, epoch_step = 525, loss = 1.0953521728515625\n",
      "epoch = 25, global_step = 47500, epoch_step = 625, loss = 1.0311403274536133\n",
      "epoch = 25, global_step = 47600, epoch_step = 725, loss = 1.1103012561798096\n",
      "epoch = 25, global_step = 47700, epoch_step = 825, loss = 1.0576168298721313\n",
      "epoch = 25, global_step = 47800, epoch_step = 925, loss = 1.0624284744262695\n",
      "epoch = 25, global_step = 47900, epoch_step = 1025, loss = 1.0945768356323242\n",
      "epoch = 25, global_step = 48000, epoch_step = 1125, loss = 1.119961142539978\n",
      "epoch = 25, global_step = 48100, epoch_step = 1225, loss = 1.0923690795898438\n",
      "epoch = 25, global_step = 48200, epoch_step = 1325, loss = 1.0417777299880981\n",
      "epoch = 25, global_step = 48300, epoch_step = 1425, loss = 1.0758298635482788\n",
      "epoch = 25, global_step = 48400, epoch_step = 1525, loss = 1.0820082426071167\n",
      "epoch = 25, global_step = 48500, epoch_step = 1625, loss = 1.029505729675293\n",
      "epoch = 25, global_step = 48600, epoch_step = 1725, loss = 1.087101697921753\n",
      "epoch = 25, global_step = 48700, epoch_step = 1825, loss = 1.025582194328308\n",
      "epoch = 26, global_step = 48800, epoch_step = 50, loss = 1.0501633882522583\n",
      "epoch = 26, global_step = 48900, epoch_step = 150, loss = 1.1264989376068115\n",
      "epoch = 26, global_step = 49000, epoch_step = 250, loss = 1.0151078701019287\n",
      "epoch = 26, global_step = 49100, epoch_step = 350, loss = 1.02816641330719\n",
      "epoch = 26, global_step = 49200, epoch_step = 450, loss = 1.0330519676208496\n",
      "epoch = 26, global_step = 49300, epoch_step = 550, loss = 1.0929181575775146\n",
      "epoch = 26, global_step = 49400, epoch_step = 650, loss = 1.0159142017364502\n",
      "epoch = 26, global_step = 49500, epoch_step = 750, loss = 1.0821151733398438\n",
      "epoch = 26, global_step = 49600, epoch_step = 850, loss = 1.0748522281646729\n",
      "epoch = 26, global_step = 49700, epoch_step = 950, loss = 1.121820092201233\n",
      "epoch = 26, global_step = 49800, epoch_step = 1050, loss = 0.9969803690910339\n",
      "epoch = 26, global_step = 49900, epoch_step = 1150, loss = 1.153427004814148\n",
      "epoch = 26, global_step = 50000, epoch_step = 1250, loss = 1.0598564147949219\n",
      "epoch = 26, global_step = 50100, epoch_step = 1350, loss = 1.0574142932891846\n",
      "epoch = 26, global_step = 50200, epoch_step = 1450, loss = 1.0548412799835205\n",
      "epoch = 26, global_step = 50300, epoch_step = 1550, loss = 1.0423064231872559\n",
      "epoch = 26, global_step = 50400, epoch_step = 1650, loss = 1.0870106220245361\n",
      "epoch = 26, global_step = 50500, epoch_step = 1750, loss = 1.0654983520507812\n",
      "epoch = 26, global_step = 50600, epoch_step = 1850, loss = 1.1322232484817505\n",
      "epoch = 27, global_step = 50700, epoch_step = 75, loss = 1.0258569717407227\n",
      "epoch = 27, global_step = 50800, epoch_step = 175, loss = 1.0363757610321045\n",
      "epoch = 27, global_step = 50900, epoch_step = 275, loss = 1.0873115062713623\n",
      "epoch = 27, global_step = 51000, epoch_step = 375, loss = 1.0624868869781494\n",
      "epoch = 27, global_step = 51100, epoch_step = 475, loss = 1.0759776830673218\n",
      "epoch = 27, global_step = 51200, epoch_step = 575, loss = 1.0683056116104126\n",
      "epoch = 27, global_step = 51300, epoch_step = 675, loss = 1.0109970569610596\n",
      "epoch = 27, global_step = 51400, epoch_step = 775, loss = 1.0486938953399658\n",
      "epoch = 27, global_step = 51500, epoch_step = 875, loss = 1.1065342426300049\n",
      "epoch = 27, global_step = 51600, epoch_step = 975, loss = 1.073479175567627\n",
      "epoch = 27, global_step = 51700, epoch_step = 1075, loss = 1.0561673641204834\n",
      "epoch = 27, global_step = 51800, epoch_step = 1175, loss = 1.0897815227508545\n",
      "epoch = 27, global_step = 51900, epoch_step = 1275, loss = 1.0818685293197632\n",
      "epoch = 27, global_step = 52000, epoch_step = 1375, loss = 1.009028434753418\n",
      "epoch = 27, global_step = 52100, epoch_step = 1475, loss = 1.1576036214828491\n",
      "epoch = 27, global_step = 52200, epoch_step = 1575, loss = 1.0088552236557007\n",
      "epoch = 27, global_step = 52300, epoch_step = 1675, loss = 1.0761005878448486\n",
      "epoch = 27, global_step = 52400, epoch_step = 1775, loss = 1.0830601453781128\n",
      "epoch = 28, global_step = 52500, epoch_step = 0, loss = 1.1019421815872192\n",
      "epoch = 28, global_step = 52600, epoch_step = 100, loss = 1.1421184539794922\n",
      "epoch = 28, global_step = 52700, epoch_step = 200, loss = 1.0099892616271973\n",
      "epoch = 28, global_step = 52800, epoch_step = 300, loss = 1.0393989086151123\n",
      "epoch = 28, global_step = 52900, epoch_step = 400, loss = 0.9952602386474609\n",
      "epoch = 28, global_step = 53000, epoch_step = 500, loss = 0.9822003841400146\n",
      "epoch = 28, global_step = 53100, epoch_step = 600, loss = 1.0285204648971558\n",
      "epoch = 28, global_step = 53200, epoch_step = 700, loss = 1.035446047782898\n",
      "epoch = 28, global_step = 53300, epoch_step = 800, loss = 1.053064227104187\n",
      "epoch = 28, global_step = 53400, epoch_step = 900, loss = 1.0877357721328735\n",
      "epoch = 28, global_step = 53500, epoch_step = 1000, loss = 1.0729504823684692\n",
      "epoch = 28, global_step = 53600, epoch_step = 1100, loss = 1.0746381282806396\n",
      "epoch = 28, global_step = 53700, epoch_step = 1200, loss = 1.090004801750183\n",
      "epoch = 28, global_step = 53800, epoch_step = 1300, loss = 1.1095564365386963\n",
      "epoch = 28, global_step = 53900, epoch_step = 1400, loss = 1.117014765739441\n",
      "epoch = 28, global_step = 54000, epoch_step = 1500, loss = 1.0234017372131348\n",
      "epoch = 28, global_step = 54100, epoch_step = 1600, loss = 1.0303337574005127\n",
      "epoch = 28, global_step = 54200, epoch_step = 1700, loss = 1.0626800060272217\n",
      "epoch = 28, global_step = 54300, epoch_step = 1800, loss = 1.0829952955245972\n",
      "epoch = 29, global_step = 54400, epoch_step = 25, loss = 0.9883543252944946\n",
      "epoch = 29, global_step = 54500, epoch_step = 125, loss = 0.9891865849494934\n",
      "epoch = 29, global_step = 54600, epoch_step = 225, loss = 1.0953586101531982\n",
      "epoch = 29, global_step = 54700, epoch_step = 325, loss = 1.0338655710220337\n",
      "epoch = 29, global_step = 54800, epoch_step = 425, loss = 1.1370389461517334\n",
      "epoch = 29, global_step = 54900, epoch_step = 525, loss = 1.0837020874023438\n",
      "epoch = 29, global_step = 55000, epoch_step = 625, loss = 1.0760186910629272\n",
      "epoch = 29, global_step = 55100, epoch_step = 725, loss = 1.0776435136795044\n",
      "epoch = 29, global_step = 55200, epoch_step = 825, loss = 0.9947758913040161\n",
      "epoch = 29, global_step = 55300, epoch_step = 925, loss = 1.0412535667419434\n",
      "epoch = 29, global_step = 55400, epoch_step = 1025, loss = 1.0602490901947021\n",
      "epoch = 29, global_step = 55500, epoch_step = 1125, loss = 1.1150466203689575\n",
      "epoch = 29, global_step = 55600, epoch_step = 1225, loss = 1.0825772285461426\n",
      "epoch = 29, global_step = 55700, epoch_step = 1325, loss = 1.0818408727645874\n",
      "epoch = 29, global_step = 55800, epoch_step = 1425, loss = 1.0362333059310913\n",
      "epoch = 29, global_step = 55900, epoch_step = 1525, loss = 0.9776546955108643\n",
      "epoch = 29, global_step = 56000, epoch_step = 1625, loss = 1.0845767259597778\n",
      "epoch = 29, global_step = 56100, epoch_step = 1725, loss = 1.054490327835083\n",
      "epoch = 29, global_step = 56200, epoch_step = 1825, loss = 1.0471456050872803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/tf2/trained_model/#1594268083658844...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/tf2/trained_model/summaries/#1594268083930543...\n",
      "Removing gs://machine-learning-1234-bucket/gan/vanilla_gan/tf2/trained_model/summaries/events.out.tfevents.1594268083.tensorflow-2-2-20200707-090436.27409.518.v2#1594268084181023...\n",
      "/ [3/3 objects] 100% Done                                                       \n",
      "Operation completed over 3 objects.                                              \n",
      "2020-07-09 04:14:54.300123: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-09 04:14:55.983621: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-07-09 04:14:55.989850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-09 04:14:55.990237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2020-07-09 04:14:55.990268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-09 04:14:55.992141: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-07-09 04:14:55.993883: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-07-09 04:14:55.994178: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-07-09 04:14:55.995995: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-07-09 04:14:55.997131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-07-09 04:14:56.001438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-07-09 04:14:56.001611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-09 04:14:56.002033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-09 04:14:56.002338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2020-07-09 04:14:56.013269: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz\n",
      "2020-07-09 04:14:56.014267: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ceb9a75d30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-07-09 04:14:56.014302: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-07-09 04:14:56.126173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-09 04:14:56.126701: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ceb9adfa90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-07-09 04:14:56.126740: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2020-07-09 04:14:56.126946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-09 04:14:56.127297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2020-07-09 04:14:56.127334: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-09 04:14:56.127362: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-07-09 04:14:56.127379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-07-09 04:14:56.127390: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-07-09 04:14:56.127403: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-07-09 04:14:56.127415: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-07-09 04:14:56.127429: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-07-09 04:14:56.127484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-09 04:14:56.127829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-09 04:14:56.128158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2020-07-09 04:14:56.128230: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-09 04:14:56.705235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-07-09 04:14:56.705305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2020-07-09 04:14:56.705315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2020-07-09 04:14:56.705606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-09 04:14:56.706028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-09 04:14:56.706374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 391 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf2_vanilla_gan/vanilla_gan_module/trainer/input.py:108: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/gan/vanilla_gan/tf2_vanilla_gan/vanilla_gan_module/trainer/input.py:123: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "2020-07-09 04:14:58.721997: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "2020-07-09 05:06:52.589110: W tensorflow/python/util/util.cc:329] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil -m rm -rf ${OUTPUT_DIR}\n",
    "export PYTHONPATH=$PYTHONPATH:$PWD/vanilla_gan_module\n",
    "python3 -m trainer.task \\\n",
    "    --train_file_pattern=${TRAIN_FILE_PATTERN} \\\n",
    "    --eval_file_pattern=${EVAL_FILE_PATTERN} \\\n",
    "    --output_dir=${OUTPUT_DIR} \\\n",
    "    --job-dir=./tmp \\\n",
    "    \\\n",
    "    --tf_version=${TF_VERSION} \\\n",
    "    --num_epochs=${NUM_EPOCHS} \\\n",
    "    --train_dataset_length=${TRAIN_DATASET_LENGTH} \\\n",
    "    --train_batch_size=${TRAIN_BATCH_SIZE} \\\n",
    "    --log_step_count_steps=${LOG_STEP_COUNT_STEPS} \\\n",
    "    --save_summary_steps=${SAVE_SUMMARY_STEPS} \\\n",
    "    --save_checkpoints_steps=${SAVE_CHECKPOINTS_STEPS} \\\n",
    "    --keep_checkpoint_max=${KEEP_CHECKPOINT_MAX} \\\n",
    "    --input_fn_autotune=${INPUT_FN_AUTOTUNE} \\\n",
    "    \\\n",
    "    --eval_batch_size=${EVAL_BATCH_SIZE} \\\n",
    "    --eval_steps=${EVAL_STEPS} \\\n",
    "    \\\n",
    "    --height=${HEIGHT} \\\n",
    "    --width=${WIDTH} \\\n",
    "    --depth=${DEPTH} \\\n",
    "    \\\n",
    "    --latent_size=${LATENT_SIZE} \\\n",
    "    --generator_hidden_units=${GENERATOR_HIDDEN_UNITS} \\\n",
    "    --generator_leaky_relu_alpha=${GENERATOR_LEAKY_RELU_ALPHA} \\\n",
    "    --generator_final_activation=${GENERATOR_FINAL_ACTIVATION} \\\n",
    "    --generator_l1_regularization_scale=${GENERATOR_L1_REGULARIZATION_SCALE} \\\n",
    "    --generator_l2_regularization_scale=${GENERATOR_L2_REGULARIZATION_SCALE} \\\n",
    "    --generator_optimizer=${GENERATOR_OPTIMIZER} \\\n",
    "    --generator_learning_rate=${GENERATOR_LEARNING_RATE} \\\n",
    "    --generator_adam_beta1=${GENERATOR_ADAM_BETA1} \\\n",
    "    --generator_adam_beta2=${GENERATOR_ADAM_BETA2} \\\n",
    "    --generator_adam_epsilon=${GENERATOR_ADAM_EPSILON} \\\n",
    "    --generator_clip_gradients=${GENERATOR_CLIP_GRADIENTS} \\\n",
    "    --generator_train_steps=${GENERATOR_TRAIN_STEPS} \\\n",
    "    \\\n",
    "    --discriminator_hidden_units=${DISCRIMINATOR_HIDDEN_UNITS} \\\n",
    "    --discriminator_leaky_relu_alpha=${DISCRIMINATOR_LEAKY_RELU_ALPHA} \\\n",
    "    --discriminator_l1_regularization_scale=${DISCRIMINATOR_L1_REGULARIZATION_SCALE} \\\n",
    "    --discriminator_l2_regularization_scale=${DISCRIMINATOR_L2_REGULARIZATION_SCALE} \\\n",
    "    --discriminator_optimizer=${DISCRIMINATOR_OPTIMIZER} \\\n",
    "    --discriminator_learning_rate=${DISCRIMINATOR_LEARNING_RATE} \\\n",
    "    --discriminator_adam_beta1=${DISCRIMINATOR_ADAM_BETA1} \\\n",
    "    --discriminator_adam_beta2=${DISCRIMINATOR_ADAM_BETA2} \\\n",
    "    --discriminator_adam_epsilon=${DISCRIMINATOR_ADAM_EPSILON} \\\n",
    "    --discriminator_clip_gradients=${DISCRIMINATOR_CLIP_GRADIENTS} \\\n",
    "    --discriminator_train_steps=${DISCRIMINATOR_TRAIN_STEPS} \\\n",
    "    --label_smoothing=${LABEL_SMOOTHING}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://machine-learning-1234-bucket/gan/vanilla_gan/tf2/trained_model/export/\n",
      "gs://machine-learning-1234-bucket/gan/vanilla_gan/tf2/trained_model/export/20200709050652/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls ${OUTPUT_DIR}/export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['serving_default']\n"
     ]
    }
   ],
   "source": [
    "loaded = tf.saved_model.load(\n",
    "    export_dir=os.path.join(\n",
    "        arguments[\"output_dir\"], \"export\", \"20200709050652\"\n",
    "    )\n",
    ")\n",
    "print(list(loaded.signatures.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generator_layers_dense_generated_outputs': TensorSpec(shape=(None, 784), dtype=tf.float32, name='generator_layers_dense_generated_outputs')}\n"
     ]
    }
   ],
   "source": [
    "infer = loaded.signatures[\"serving_default\"]\n",
    "print(infer.structured_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = tf.random.normal(shape=(10, 512))\n",
    "predictions = infer(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = np.clip(\n",
    "    a=tf.cast(\n",
    "        x=((tf.reshape(\n",
    "            tensor=predictions[\"generator_layers_dense_generated_outputs\"],\n",
    "            shape=[\n",
    "                -1,\n",
    "                arguments[\"height\"],\n",
    "                arguments[\"width\"],\n",
    "                arguments[\"depth\"]\n",
    "            ]\n",
    "        ) + 1.0) * (255. / 2)),\n",
    "        dtype=tf.int32\n",
    "    ),\n",
    "    a_min=0,\n",
    "    a_max=255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(generated_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "    \"\"\"Plots images.\n",
    "\n",
    "    Args:\n",
    "        images: np.array, array of images of\n",
    "            [num_images, image_size, image_size, num_channels].\n",
    "    \"\"\"\n",
    "    num_images = len(images)\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(num_images):\n",
    "        image = images[i]\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(\n",
    "            tf.reshape(image, image.shape[:-1]),\n",
    "            cmap=\"gray_r\"\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
