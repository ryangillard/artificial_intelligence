{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (50000, 32, 32, 3)\n",
      "y_train.shape = (50000, 1)\n",
      "x_test.shape = (10000, 32, 32, 3)\n",
      "y_test.shape = (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train.shape = {}\".format(x_train.shape))\n",
    "print(\"y_train.shape = {}\".format(y_train.shape))\n",
    "print(\"x_test.shape = {}\".format(x_test.shape))\n",
    "print(\"y_test.shape = {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {}\n",
    "# Image parameters\n",
    "arguments[\"height\"] = 32\n",
    "arguments[\"width\"] = 32\n",
    "arguments[\"depth\"] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tf_record(filepath, data):\n",
    "    with tf.python_io.TFRecordWriter(filepath) as ofp:\n",
    "        for i in range(len(data[\"image_raw\"])):\n",
    "            example = tf.train.Example(\n",
    "                features=tf.train.Features(\n",
    "                    feature={\n",
    "                        \"image_raw\": tf.train.Feature(\n",
    "                            bytes_list=tf.train.BytesList(\n",
    "                                value=[data[\"image_raw\"][i].tostring()]\n",
    "                            )\n",
    "                        ),\n",
    "                        \"label\": tf.train.Feature(\n",
    "                            int64_list=tf.train.Int64List(\n",
    "                                value=[data[\"label\"][i]]\n",
    "                            )\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "            ofp.write(example.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tf_record(\n",
    "    \"data/train.tfrecord\", {\"image_raw\": x_train, \"label\": y_train}\n",
    ")\n",
    "write_tf_record(\"data/test.tfrecord\", {\"image_raw\": x_test, \"label\": y_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_obj(function_name, object_name, object_value):\n",
    "    \"\"\"Prints enclosing function, object name, and object value.\n",
    "\n",
    "    Args:\n",
    "        function_name: str, name of function.\n",
    "        object_name: str, name of object.\n",
    "        object_value: object, value of passed object.\n",
    "    \"\"\"\n",
    "#     pass\n",
    "    print(\"{}: {} = {}\".format(function_name, object_name, object_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_example(protos, params):\n",
    "    \"\"\"Decodes TFRecord file into tensors.\n",
    "\n",
    "    Given protobufs, decode into image and label tensors.\n",
    "\n",
    "    Args:\n",
    "        protos: protobufs from TFRecord file.\n",
    "        params: dict, user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        Image and label tensors.\n",
    "    \"\"\"\n",
    "    # Create feature schema map for protos.\n",
    "    features = {\n",
    "        \"image_raw\": tf.FixedLenFeature(shape=[], dtype=tf.string),\n",
    "        \"label\": tf.FixedLenFeature(shape=[], dtype=tf.int64)\n",
    "    }\n",
    "\n",
    "    # Parse features from tf.Example.\n",
    "    parsed_features = tf.parse_single_example(\n",
    "        serialized=protos, features=features\n",
    "    )\n",
    "    print_obj(\"\\ndecode_example\", \"features\", features)\n",
    "\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length height * width * depth) to a uint8 tensor with shape\n",
    "    # [height * width * depth].\n",
    "    image = tf.decode_raw(\n",
    "        input_bytes=parsed_features[\"image_raw\"], out_type=tf.uint8\n",
    "    )\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Reshape flattened image back into normal dimensions.\n",
    "    image = tf.reshape(\n",
    "        tensor=image,\n",
    "        shape=[params[\"height\"], params[\"width\"], params[\"depth\"]]\n",
    "    )\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Convert from [0, 255] -> [-1.0, 1.0] floats.\n",
    "    image = tf.cast(x=image, dtype=tf.float32) * (2. / 255) - 1.0\n",
    "    print_obj(\"decode_example\", \"image\", image)\n",
    "\n",
    "    # Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "    label = tf.cast(x=parsed_features[\"label\"], dtype=tf.int32)\n",
    "    print_obj(\"decode_example\", \"label\", label)\n",
    "\n",
    "    return {\"image\": image}, label\n",
    "\n",
    "\n",
    "def read_dataset(filename, mode, batch_size, params):\n",
    "    \"\"\"Reads CSV time series data using tf.data, doing necessary preprocessing.\n",
    "\n",
    "    Given filename, mode, batch size, and other parameters, read CSV dataset\n",
    "    using Dataset API, apply necessary preprocessing, and return an input\n",
    "    function to the Estimator API.\n",
    "\n",
    "    Args:\n",
    "        filename: str, file pattern that to read into our tf.data dataset.\n",
    "        mode: The estimator ModeKeys. Can be TRAIN or EVAL.\n",
    "        batch_size: int, number of examples per batch.\n",
    "        params: dict, dictionary of user passed parameters.\n",
    "\n",
    "    Returns:\n",
    "        An input function.\n",
    "    \"\"\"\n",
    "    def _input_fn():\n",
    "        \"\"\"Wrapper input function used by Estimator API to get data tensors.\n",
    "\n",
    "        Returns:\n",
    "            Batched dataset object of dictionary of feature tensors and label\n",
    "                tensor.\n",
    "        \"\"\"\n",
    "        # Create list of files that match pattern.\n",
    "        file_list = tf.gfile.Glob(filename=filename)\n",
    "\n",
    "        # Create dataset from file list.\n",
    "        dataset = tf.data.TFRecordDataset(\n",
    "            filenames=file_list, num_parallel_reads=40\n",
    "        )\n",
    "\n",
    "        # Shuffle and repeat if training with fused op.\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            dataset = dataset.apply(\n",
    "                tf.contrib.data.shuffle_and_repeat(\n",
    "                    buffer_size=50 * batch_size,\n",
    "                    count=None  # indefinitely\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Decode CSV file into a features dictionary of tensors, then batch.\n",
    "        dataset = dataset.apply(\n",
    "            tf.contrib.data.map_and_batch(\n",
    "                map_func=lambda x: decode_example(\n",
    "                    protos=x,\n",
    "                    params=params\n",
    "                ),\n",
    "                batch_size=batch_size,\n",
    "                num_parallel_calls=4\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Prefetch data to improve latency.\n",
    "        dataset = dataset.prefetch(buffer_size=2)\n",
    "\n",
    "        # Create a iterator, then get batch of features from example queue.\n",
    "        batched_dataset = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        return batched_dataset\n",
    "    return _input_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_out_input_function(arguments):\n",
    "    \"\"\"Trys out input function for testing purposes.\n",
    "\n",
    "    Args:\n",
    "        arguments: dict, user passed parameters.\n",
    "    \"\"\"\n",
    "    filename = \"data/train.tfrecord\"\n",
    "    with tf.Session() as sess:\n",
    "        fn = read_dataset(\n",
    "            filename=filename,\n",
    "            mode=tf.estimator.ModeKeys.EVAL,\n",
    "            batch_size=3,\n",
    "            params=arguments\n",
    "        )\n",
    "\n",
    "        features, labels = sess.run(fn())\n",
    "        print(\"features[image].shape = {}\".format(features[\"image\"].shape))\n",
    "        print(\"labels.shape = {}\".format(labels.shape))\n",
    "        print(\"features = \\n{}\".format(features))\n",
    "        print(\"labels = \\n{}\".format(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "decode_example: features = {'image_raw': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "decode_example: image = Tensor(\"DecodeRaw:0\", shape=(?,), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "decode_example: image = Tensor(\"Reshape:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "decode_example: label = Tensor(\"Cast:0\", shape=(), dtype=int32)\n",
      "features[image].shape = (3, 32, 32, 3)\n",
      "labels.shape = (3,)\n",
      "features = \n",
      "{'image': array([[[[ 59,  62,  63],\n",
      "         [ 43,  46,  45],\n",
      "         [ 50,  48,  43],\n",
      "         ...,\n",
      "         [158, 132, 108],\n",
      "         [152, 125, 102],\n",
      "         [148, 124, 103]],\n",
      "\n",
      "        [[ 16,  20,  20],\n",
      "         [  0,   0,   0],\n",
      "         [ 18,   8,   0],\n",
      "         ...,\n",
      "         [123,  88,  55],\n",
      "         [119,  83,  50],\n",
      "         [122,  87,  57]],\n",
      "\n",
      "        [[ 25,  24,  21],\n",
      "         [ 16,   7,   0],\n",
      "         [ 49,  27,   8],\n",
      "         ...,\n",
      "         [118,  84,  50],\n",
      "         [120,  84,  50],\n",
      "         [109,  73,  42]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[208, 170,  96],\n",
      "         [201, 153,  34],\n",
      "         [198, 161,  26],\n",
      "         ...,\n",
      "         [160, 133,  70],\n",
      "         [ 56,  31,   7],\n",
      "         [ 53,  34,  20]],\n",
      "\n",
      "        [[180, 139,  96],\n",
      "         [173, 123,  42],\n",
      "         [186, 144,  30],\n",
      "         ...,\n",
      "         [184, 148,  94],\n",
      "         [ 97,  62,  34],\n",
      "         [ 83,  53,  34]],\n",
      "\n",
      "        [[177, 144, 116],\n",
      "         [168, 129,  94],\n",
      "         [179, 142,  87],\n",
      "         ...,\n",
      "         [216, 184, 140],\n",
      "         [151, 118,  84],\n",
      "         [123,  92,  72]]],\n",
      "\n",
      "\n",
      "       [[[154, 177, 187],\n",
      "         [126, 137, 136],\n",
      "         [105, 104,  95],\n",
      "         ...,\n",
      "         [ 91,  95,  71],\n",
      "         [ 87,  90,  71],\n",
      "         [ 79,  81,  70]],\n",
      "\n",
      "        [[140, 160, 169],\n",
      "         [145, 153, 154],\n",
      "         [125, 125, 118],\n",
      "         ...,\n",
      "         [ 96,  99,  78],\n",
      "         [ 77,  80,  62],\n",
      "         [ 71,  73,  61]],\n",
      "\n",
      "        [[140, 155, 164],\n",
      "         [139, 146, 149],\n",
      "         [115, 115, 112],\n",
      "         ...,\n",
      "         [ 79,  82,  64],\n",
      "         [ 68,  70,  55],\n",
      "         [ 67,  69,  55]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[175, 167, 166],\n",
      "         [156, 154, 160],\n",
      "         [154, 160, 170],\n",
      "         ...,\n",
      "         [ 42,  34,  36],\n",
      "         [ 61,  53,  57],\n",
      "         [ 93,  83,  91]],\n",
      "\n",
      "        [[165, 154, 128],\n",
      "         [156, 152, 130],\n",
      "         [159, 161, 142],\n",
      "         ...,\n",
      "         [103,  93,  96],\n",
      "         [123, 114, 120],\n",
      "         [131, 121, 131]],\n",
      "\n",
      "        [[163, 148, 120],\n",
      "         [158, 148, 122],\n",
      "         [163, 156, 133],\n",
      "         ...,\n",
      "         [143, 133, 139],\n",
      "         [143, 134, 142],\n",
      "         [143, 133, 144]]],\n",
      "\n",
      "\n",
      "       [[[255, 255, 255],\n",
      "         [253, 253, 253],\n",
      "         [253, 253, 253],\n",
      "         ...,\n",
      "         [253, 253, 253],\n",
      "         [253, 253, 253],\n",
      "         [253, 253, 253]],\n",
      "\n",
      "        [[255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         ...,\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255]],\n",
      "\n",
      "        [[255, 255, 255],\n",
      "         [254, 254, 254],\n",
      "         [254, 254, 254],\n",
      "         ...,\n",
      "         [254, 254, 254],\n",
      "         [254, 254, 254],\n",
      "         [254, 254, 254]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[113, 120, 112],\n",
      "         [111, 118, 111],\n",
      "         [105, 112, 106],\n",
      "         ...,\n",
      "         [ 72,  81,  80],\n",
      "         [ 72,  80,  79],\n",
      "         [ 72,  80,  79]],\n",
      "\n",
      "        [[111, 118, 110],\n",
      "         [104, 111, 104],\n",
      "         [ 99, 106,  98],\n",
      "         ...,\n",
      "         [ 68,  75,  73],\n",
      "         [ 70,  76,  75],\n",
      "         [ 78,  84,  82]],\n",
      "\n",
      "        [[106, 113, 105],\n",
      "         [ 99, 106,  98],\n",
      "         [ 95, 102,  94],\n",
      "         ...,\n",
      "         [ 78,  85,  83],\n",
      "         [ 79,  85,  83],\n",
      "         [ 80,  86,  84]]]], dtype=uint8)}\n",
      "labels = \n",
      "[6 9 9]\n"
     ]
    }
   ],
   "source": [
    "try_out_input_function(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
