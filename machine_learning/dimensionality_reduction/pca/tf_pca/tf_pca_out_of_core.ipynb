{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA(object):\n",
    "    \"\"\"Class that performs PCA projection and reconstruction.\n",
    "\n",
    "    Attributes:\n",
    "        num_examples: int, number of data instances.\n",
    "        num_cols: int, number of dimensions for each data instance.\n",
    "        use_sample_covariance: bool, whether using sample or population\n",
    "            covariance.\n",
    "        top_k_pc: int, number of top principal components to keep.\n",
    "        seen_example_count: tensor, rank 0 tensor of shape () containing\n",
    "            the count of the number of examples seen so far.\n",
    "        col_means_vector: tensor, rank 1 tensor of shape (num_cols,) containing\n",
    "            column means.\n",
    "        covariance_matrix: tensor, rank 2 tensor of shape (num_cols, num_cols)\n",
    "            containing covariance matrix.\n",
    "        rollover_singleton_example: tensor, rank 2 tensor of shape\n",
    "            (1, num_cols) containing a rollover singleton example in case the\n",
    "            data batch size begins at 1. This avoids NaN covariances.\n",
    "        self.top_k_eigenvectors: tensor, rank 2 tensor of shape\n",
    "            (num_cols, top_k_pc) containing the eigenvectors associated with\n",
    "            the top_k_pc eigenvalues.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_cols, use_sample_covariance, top_k_pc):\n",
    "        \"\"\"Initializes `PCA` class instance.\n",
    "\n",
    "        Args:\n",
    "            num_cols: int, number of dimensions for each data instance.\n",
    "            use_sample_covariance: bool, whether using sample or population\n",
    "                covariance.\n",
    "            top_k_pc: int, number of top principal components to keep.\n",
    "        \"\"\"\n",
    "        self.num_cols = num_cols\n",
    "        self.use_sample_covariance = use_sample_covariance\n",
    "        self.top_k_pc = top_k_pc\n",
    "\n",
    "        self.seen_example_count = tf.zeros(shape=(), dtype=tf.int64)\n",
    "        self.col_means_vector = tf.zeros(\n",
    "            shape=(self.num_cols,), dtype=tf.float32\n",
    "        )\n",
    "        self.covariance_matrix = tf.zeros(\n",
    "            shape=(self.num_cols, self.num_cols), dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        self.rollover_singleton_example = None\n",
    "\n",
    "        self.top_k_eigenvectors = tf.zeros(\n",
    "            shape=(self.num_cols, self.top_k_pc)\n",
    "        )\n",
    "\n",
    "    def update_example_count(self, count_a, count_b):\n",
    "        \"\"\"Updates the running number of examples processed.\n",
    "\n",
    "        Given previous running total and current batch size, return new running\n",
    "        total.\n",
    "\n",
    "        Args:\n",
    "            count_a: tensor, tf.int64 rank 0 tensor of previous running total\n",
    "                of examples.\n",
    "            count_b: tensor, tf.int64 rank 0 tensor of current batch size.\n",
    "\n",
    "        Returns:\n",
    "            A tf.int64 rank 0 tensor of new running total of examples.\n",
    "        \"\"\"\n",
    "        return count_a + count_b\n",
    "\n",
    "    def update_mean_incremental(self, count_a, mean_a, value_b):\n",
    "        \"\"\"Updates the running mean vector incrementally.\n",
    "\n",
    "        Given previous running total, running column means, and single\n",
    "            example's column values, return new running column means.\n",
    "\n",
    "        Args:\n",
    "            count_a: tensor, tf.int64 rank 0 tensor of previous running total\n",
    "                of examples.\n",
    "            mean_a: tensor, tf.float32 rank 1 tensor of previous running column\n",
    "                means.\n",
    "            value_b: tensor, tf.float32 rank 1 tensor of single example's\n",
    "                column values.\n",
    "\n",
    "        Returns:\n",
    "            A tf.float32 rank 1 tensor of new running column means.\n",
    "        \"\"\"\n",
    "        umean_a = mean_a * tf.cast(x=count_a, dtype=tf.float32)\n",
    "        mean_ab_num = umean_a + tf.squeeze(input=value_b, axis=0)\n",
    "        mean_ab = mean_ab_num / tf.cast(x=count_a + 1, dtype=tf.float32)\n",
    "\n",
    "        return mean_ab\n",
    "\n",
    "    def update_covariance_incremental(\n",
    "        self, count_a, mean_a, cov_a, value_b, mean_ab, use_sample_covariance\n",
    "    ):\n",
    "        \"\"\"Updates the running covariance matrix incrementally.\n",
    "\n",
    "        Given previous running total, running column means, running covariance\n",
    "        matrix, single example's column values, new running column means, and\n",
    "        whether to use sample covariance or not, return new running covariance\n",
    "        matrix.\n",
    "\n",
    "        Args:\n",
    "            count_a: tensor, tf.int64 rank 0 tensor of previous running total\n",
    "                of examples.\n",
    "            mean_a: tensor, tf.float32 rank 1 tensor of previous running column\n",
    "                means.\n",
    "            cov_a: tensor, tf.float32 rank 2 tensor of previous running\n",
    "                covariance matrix.\n",
    "            value_b: tensor, tf.float32 rank 1 tensor of single example's\n",
    "                column values.\n",
    "            mean_ab: tensor, tf.float32 rank 1 tensor of new running column\n",
    "                means.\n",
    "            use_sample_covariance: bool, flag on whether sample or population\n",
    "                covariance is used.\n",
    "\n",
    "        Returns:\n",
    "            A tf.float32 rank 2 tensor of new covariance matrix.\n",
    "        \"\"\"\n",
    "        mean_diff = tf.matmul(\n",
    "                a=value_b - mean_a, b=value_b - mean_ab, transpose_a=True\n",
    "        )\n",
    "\n",
    "        if use_sample_covariance:\n",
    "            ucov_a = cov_a * tf.cast(x=count_a - 1, dtype=tf.float32)\n",
    "            cov_ab_denominator = tf.cast(x=count_a, dtype=tf.float32)\n",
    "        else:\n",
    "            ucov_a = cov_a * tf.cast(x=count_a, dtype=tf.float32)\n",
    "            cov_ab_denominator = tf.cast(x=count_a + 1, dtype=tf.float32)\n",
    "        cov_ab_numerator = ucov_a + mean_diff\n",
    "        cov_ab = cov_ab_numerator / cov_ab_denominator\n",
    "\n",
    "        return cov_ab\n",
    "\n",
    "    def singleton_batch_update(\n",
    "        self,\n",
    "        X,\n",
    "        running_count,\n",
    "        running_mean,\n",
    "        running_covariance,\n",
    "        use_sample_covariance\n",
    "    ):\n",
    "        \"\"\"Updates running tensors incrementally when batch_size equals 1.\n",
    "\n",
    "        Given the the data vector X, the tensor tracking running example\n",
    "        counts, the tensor tracking running column means, and the tensor\n",
    "        tracking running covariance matrix, returns updated running example\n",
    "        count tensor, column means tensor, and covariance matrix tensor.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, tf.float32 rank 2 tensor of input data.\n",
    "            running_count: tensor, tf.int64 rank 0 tensor tracking running\n",
    "                example counts.\n",
    "            running_mean: tensor, tf.float32 rank 1 tensor tracking running\n",
    "                column means.\n",
    "            running_covariance: tensor, tf.float32 rank 2 tensor tracking\n",
    "                running covariance matrix.\n",
    "            use_sample_covariance: bool, flag on whether sample or population\n",
    "                covariance is used.\n",
    "\n",
    "        Returns:\n",
    "            Updated updated running example count tensor, column means tensor,\n",
    "                and covariance matrix tensor.\n",
    "        \"\"\"\n",
    "        # shape = (num_cols, num_cols)\n",
    "        if running_count == 0:\n",
    "            # Would produce NaNs, so rollover example for next iteration.\n",
    "            self.rollover_singleton_example = X\n",
    "\n",
    "            # Update count though so that we don't end up in this block again.\n",
    "            count = self.update_example_count(\n",
    "                count_a=running_count, count_b=1\n",
    "            )\n",
    "\n",
    "            # No need to update mean or covariance this iteration\n",
    "            mean = running_mean\n",
    "            covariance = running_covariance\n",
    "        elif running_count == 1:\n",
    "            # Batch update since we're combining previous & current batches.\n",
    "            count, mean, covariance = self.non_singleton_batch_update(\n",
    "                batch_size=2,\n",
    "                X=tf.concat(\n",
    "                    values=[self.rollover_singleton_example, X], axis=0\n",
    "                ),\n",
    "                running_count=0,\n",
    "                running_mean=running_mean,\n",
    "                running_covariance=running_covariance,\n",
    "                use_sample_covariance=use_sample_covariance\n",
    "            )\n",
    "        else:\n",
    "            # Calculate new combined mean for incremental covariance matrix.\n",
    "            # shape = (num_cols,)\n",
    "            mean = self.update_mean_incremental(\n",
    "                count_a=running_count, mean_a=running_mean, value_b=X\n",
    "            )\n",
    "\n",
    "            # Update running tensors from single example\n",
    "            # shape = ()\n",
    "            count = self.update_example_count(\n",
    "                count_a=running_count, count_b=1\n",
    "            )\n",
    "\n",
    "            # shape = (num_cols, num_cols)\n",
    "            covariance = self.update_covariance_incremental(\n",
    "                count_a=running_count,\n",
    "                mean_a=running_mean,\n",
    "                cov_a=running_covariance,\n",
    "                value_b=X,\n",
    "                mean_ab=mean,\n",
    "                use_sample_covariance=use_sample_covariance\n",
    "            )\n",
    "\n",
    "        return count, mean, covariance\n",
    "\n",
    "    def update_mean_batch(self, count_a, mean_a, count_b, mean_b):\n",
    "        \"\"\"Updates the running mean vector with a batch of data.\n",
    "\n",
    "        Given previous running example count, running column means, current\n",
    "        batch size, and batch's column means, return new running column means.\n",
    "\n",
    "        Args:\n",
    "            count_a: tensor, tf.int64 rank 0 tensor of previous running total\n",
    "                of examples.\n",
    "            mean_a: tensor, tf.float32 rank 1 tensor of previous running column\n",
    "                means.\n",
    "            count_b: tensor, tf.int64 rank 0 tensor of current batch size.\n",
    "            mean_b: tensor, tf.float32 rank 1 tensor of batch's column means.\n",
    "\n",
    "        Returns:\n",
    "            A tf.float32 rank 1 tensor of new running column means.\n",
    "        \"\"\"\n",
    "        sum_a = mean_a * tf.cast(x=count_a, dtype=tf.float32)\n",
    "        sum_b = mean_b * tf.cast(x=count_b, dtype=tf.float32)\n",
    "        mean_ab_denominator = tf.cast(x=count_a + count_b, dtype=tf.float32)\n",
    "        mean_ab = (sum_a + sum_b) / mean_ab_denominator\n",
    "\n",
    "        return mean_ab\n",
    "\n",
    "    def update_covariance_batch(\n",
    "        self,\n",
    "        count_a,\n",
    "        mean_a,\n",
    "        cov_a,\n",
    "        count_b,\n",
    "        mean_b,\n",
    "        cov_b,\n",
    "        use_sample_covariance\n",
    "    ):\n",
    "        \"\"\"Updates the running covariance matrix with batch of data.\n",
    "\n",
    "        Given previous running example count, column means, and\n",
    "        covariance matrix, current batch size, column means, and covariance\n",
    "        matrix, and whether to use sample covariance or not, return new running\n",
    "        covariance matrix.\n",
    "\n",
    "        Args:\n",
    "            count_a: tensor, tf.int64 rank 0 tensor of previous running total\n",
    "                of examples.\n",
    "            mean_a: tensor, tf.float32 rank 1 tensor of previous running column\n",
    "                means.\n",
    "            cov_a: tensor, tf.float32 rank 2 tensor of previous running\n",
    "                covariance matrix.\n",
    "            count_b: tensor, tf.int64 rank 0 tensor of current batch size.\n",
    "            mean_b: tensor, tf.float32 rank 1 tensor of batch's column means.\n",
    "            cov_b: tensor, tf.float32 rank 2 tensor of batch's covariance\n",
    "                matrix.\n",
    "            use_sample_covariance: bool, flag on whether sample or population\n",
    "                covariance is used.\n",
    "\n",
    "        Returns:\n",
    "            A tf.float32 rank 2 tensor of new running covariance matrix.\n",
    "        \"\"\"\n",
    "        mean_diff = tf.expand_dims(input=mean_a - mean_b, axis=0)\n",
    "\n",
    "        if use_sample_covariance:\n",
    "            ucov_a = cov_a * tf.cast(x=count_a - 1, dtype=tf.float32)\n",
    "            ucov_b = cov_b * tf.cast(x=count_b - 1, dtype=tf.float32)\n",
    "            den = tf.cast(x=count_a + count_b - 1, dtype=tf.float32)\n",
    "        else:\n",
    "            ucov_a = cov_a * tf.cast(x=count_a, dtype=tf.float32)\n",
    "            ucov_b = cov_b * tf.cast(x=count_b, dtype=tf.float32)\n",
    "            den = tf.cast(x=count_a + count_b, dtype=tf.float32)\n",
    "\n",
    "        mean_diff = tf.matmul(a=mean_diff, b=mean_diff, transpose_a=True)\n",
    "        mean_scaling_num = tf.cast(x=count_a * count_b, dtype=tf.float32)\n",
    "        mean_scaling_den = tf.cast(x=count_a + count_b, dtype=tf.float32)\n",
    "        mean_scaling = mean_scaling_num / mean_scaling_den\n",
    "        cov_ab = (ucov_a + ucov_b + mean_diff * mean_scaling) / den\n",
    "\n",
    "        return cov_ab\n",
    "\n",
    "    def non_singleton_batch_update(\n",
    "        self,\n",
    "        batch_size,\n",
    "        X,\n",
    "        running_count,\n",
    "        running_mean,\n",
    "        running_covariance,\n",
    "        use_sample_covariance\n",
    "    ):\n",
    "        \"\"\"Updates running tensors when batch_size does NOT equal 1.\n",
    "\n",
    "        Given the current batch size, the data matrix X, the tensor tracking\n",
    "        running example counts, the tensor tracking running column means, and\n",
    "        the tensor tracking running covariance matrix, returns updated running\n",
    "        example count tensor, column means tensor, and covariance matrix\n",
    "        tensor.\n",
    "\n",
    "        Args:\n",
    "            batch_size: int, number of examples in current batch (could be\n",
    "                partial).\n",
    "            X: tensor, tf.float32 rank 2 tensor of input data.\n",
    "            running_count: tensor, tf.int64 rank 0 tensor tracking running\n",
    "                example counts.\n",
    "            running_mean: tensor, tf.float32 rank 1 tensor tracking running\n",
    "                column means.\n",
    "            running_covariance: tensor, tf.float32 rank 2 tensor tracking\n",
    "                running covariance matrix.\n",
    "            use_sample_covariance: bool, flag on whether sample or population\n",
    "                covariance is used.\n",
    "\n",
    "        Returns:\n",
    "            Updated updated running example count tensor, column means tensor,\n",
    "                and covariance matrix tensor.\n",
    "        \"\"\"\n",
    "        # shape = (num_cols,)\n",
    "        X_mean = tf.reduce_mean(input_tensor=X, axis=0)\n",
    "\n",
    "        # shape = (batch_size, num_cols)\n",
    "        X_centered = X - X_mean\n",
    "\n",
    "        # shape = (num_cols, num_cols)\n",
    "        X_cov = tf.matmul(\n",
    "                a=X_centered,\n",
    "                b=X_centered,\n",
    "                transpose_a=True\n",
    "        )\n",
    "        X_cov /= tf.cast(x=batch_size - 1, dtype=tf.float32)\n",
    "\n",
    "        # Update running tensors from batch statistics.\n",
    "        # shape = ()\n",
    "        count = self.update_example_count(\n",
    "            count_a=running_count, count_b=batch_size\n",
    "        )\n",
    "\n",
    "        # shape = (num_cols,)\n",
    "        mean = self.update_mean_batch(\n",
    "            count_a=running_count,\n",
    "            mean_a=running_mean,\n",
    "            count_b=batch_size,\n",
    "            mean_b=X_mean\n",
    "        )\n",
    "\n",
    "        # shape = (num_cols, num_cols)\n",
    "        covariance = self.update_covariance_batch(\n",
    "            count_a=running_count,\n",
    "            mean_a=running_mean,\n",
    "            cov_a=running_covariance,\n",
    "            count_b=batch_size,\n",
    "            mean_b=X_mean,\n",
    "            cov_b=X_cov,\n",
    "            use_sample_covariance=use_sample_covariance\n",
    "        )\n",
    "\n",
    "        return count, mean, covariance\n",
    "\n",
    "    def calculate_data_stats(self, data):\n",
    "        \"\"\"Calculates statistics of data.\n",
    "\n",
    "        Args:\n",
    "            data: tensor, rank 2 tensor of shape\n",
    "                (current_batch_size, num_cols) containing batch of input data.\n",
    "        \"\"\"\n",
    "        current_batch_size = data.shape[0]\n",
    "\n",
    "        if current_batch_size == 1:\n",
    "            (self.seen_example_count,\n",
    "             self.col_means_vector,\n",
    "             self.covariance_matrix) = self.singleton_batch_update(\n",
    "                X=data,\n",
    "                running_count=self.seen_example_count,\n",
    "                running_mean=self.col_means_vector,\n",
    "                running_covariance=self.covariance_matrix,\n",
    "                use_sample_covariance=self.use_sample_covariance\n",
    "            )\n",
    "        else:\n",
    "            (self.seen_example_count,\n",
    "             self.col_means_vector,\n",
    "             self.covariance_matrix) = self.non_singleton_batch_update(\n",
    "                batch_size=current_batch_size,\n",
    "                X=data,\n",
    "                running_count=self.seen_example_count,\n",
    "                running_mean=self.col_means_vector,\n",
    "                running_covariance=self.covariance_matrix,\n",
    "                use_sample_covariance=self.use_sample_covariance\n",
    "            )\n",
    "\n",
    "    def calculate_eigenvalues_and_eigenvectors(self, dataset):\n",
    "        \"\"\"Calculates eigenvalues and eigenvectors of data.\n",
    "\n",
    "        Args:\n",
    "            dataset: tf.data.Dataset, batched dataset that contains example\n",
    "                data points each of shape (batch_size, num_cols).\n",
    "        \"\"\"\n",
    "        for batch in dataset:\n",
    "            self.calculate_data_stats(data=batch)\n",
    "\n",
    "        # shape = (num_cols,) & (num_cols, num_cols)\n",
    "        self.eigenvalues, self.eigenvectors = tf.linalg.eigh(\n",
    "            tensor=self.covariance_matrix\n",
    "        )\n",
    "\n",
    "    def pca_projection_to_top_k_pc(self, data):\n",
    "        \"\"\"Projects data down to top_k principal components.\n",
    "\n",
    "        Args:\n",
    "            data: tensor, rank 2 tensor of shape (num_examples, num_cols)\n",
    "                containing batch of input data.\n",
    "\n",
    "        Returns:\n",
    "            Rank 2 tensor of shape (num_examples, top_k_pc) containing\n",
    "                projected centered data.\n",
    "        \"\"\"\n",
    "        # shape = (num_cols, top_k_pc)\n",
    "        self.top_k_eigenvectors = self.eigenvectors[:, -self.top_k_pc:]\n",
    "\n",
    "        # shape = (num_examples, num_cols)\n",
    "        centered_data = data - self.col_means_vector\n",
    "\n",
    "        # shape = (num_examples, top_k_pc)\n",
    "        projected_centered_data = tf.matmul(\n",
    "            a=centered_data,\n",
    "            b=self.top_k_eigenvectors\n",
    "        )\n",
    "\n",
    "        return projected_centered_data\n",
    "\n",
    "    def pca_reconstruction_from_top_k_pc(self, data):\n",
    "        \"\"\"Reconstructs data up from top_k principal components.\n",
    "\n",
    "        Args:\n",
    "            data: tensor, rank 2 tensor of shape (num_examples, num_cols)\n",
    "                containing batch of input data.\n",
    "\n",
    "        Returns:\n",
    "            Rank 2 tensor of shape (num_examples, num_cols) containing\n",
    "                lossy, reconstructed input data.\n",
    "        \"\"\"\n",
    "        # shape = (num_examples, top_k_pc)\n",
    "        projected_centered_data = self.pca_projection_to_top_k_pc(data=data)\n",
    "\n",
    "        # shape = (num_examples, num_cols)\n",
    "        unprojected_centered_data = tf.matmul(\n",
    "            a=projected_centered_data,\n",
    "            b=self.top_k_eigenvectors,\n",
    "            transpose_b=True\n",
    "        )\n",
    "\n",
    "        # shape = (num_examples, num_cols)\n",
    "        data_reconstructed = unprojected_centered_data + self.col_means_vector\n",
    "\n",
    "        return data_reconstructed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(data, batch_size):\n",
    "    \"\"\"Gets tf.data.Dataset containing point data to cluster.\n",
    "\n",
    "    Args:\n",
    "        data: tensor, rank 2 tensor of shape (num_examples, num_dims) that\n",
    "            contains the coordinates of each point in dataset of examples.\n",
    "        batch_size: int, number of data examples within a batch.\n",
    "\n",
    "    Returns:\n",
    "        Batched `Dataset` object.\n",
    "    \"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(tensors=data)\n",
    "    dataset = dataset.batch(\n",
    "        batch_size=batch_size, drop_remainder=False\n",
    "    )\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(\n",
    "    [\n",
    "        [7.0, 4.0, 3.0],\n",
    "        [4.0, 1.0, 8.0],\n",
    "        [6.0, 3.0, 5.0],\n",
    "        [8.0, 6.0, 1.0],\n",
    "        [8.0, 5.0, 7.0],\n",
    "        [7.0, 2.0, 9.0],\n",
    "        [5.0, 3.0, 3.0],\n",
    "        [9.0, 5.0, 8.0],\n",
    "        [7.0, 4.0, 5.0],\n",
    "        [8.0, 2.0, 2.0],\n",
    "    ]\n",
    ").astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_examples = 10, num_cols = 3\n"
     ]
    }
   ],
   "source": [
    "print(\"num_examples = {}, num_cols = {}\".format(data.shape[0], data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(data=data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[7. 4. 3.]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([[4. 1. 8.]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([[6. 3. 5.]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([[8. 6. 1.]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([[8. 5. 7.]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([[7. 2. 9.]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([[5. 3. 3.]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([[9. 5. 8.]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([[7. 4. 5.]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([[8. 2. 2.]], shape=(1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for batch in dataset:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(num_cols=3, use_sample_covariance=True, top_k_pc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate data statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.calculate_eigenvalues_and_eigenvectors(dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.seen_example_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([6.9, 3.5, 5.1], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.col_means_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[ 2.3222225 ,  1.6111112 , -0.43333337],\n",
       "       [ 1.6111112 ,  2.5       , -1.2777777 ],\n",
       "       [-0.43333322, -1.2777777 ,  7.877778  ]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.7499283, 3.6761296, 8.273943 ], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[ 0.70172733,  0.69903713, -0.13757075],\n",
       "       [-0.70745707,  0.6608891 , -0.2504596 ],\n",
       "       [-0.08416158,  0.2730798 ,  0.95830274]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
       "array([[-0.17311937, -2.1514225 ],\n",
       "       [-2.8874989 ,  3.8041823 ],\n",
       "       [-0.98688596,  0.15321332],\n",
       "       [ 1.3015363 , -4.706518  ],\n",
       "       [ 2.2791262 ,  1.293758  ],\n",
       "       [ 0.14358133,  4.0993133 ],\n",
       "       [-2.2320828 , -1.6258214 ],\n",
       "       [ 3.251243  ,  2.11449   ],\n",
       "       [ 0.37304023, -0.23481706],\n",
       "       [-1.0689402 , -2.7463768 ]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.pca_projection_to_top_k_pc(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 0.69903713, -0.13757075],\n",
       "       [ 0.6608891 , -0.2504596 ],\n",
       "       [ 0.2730798 ,  0.95830274]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.top_k_eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 3), dtype=float32, numpy=\n",
       "array([[7.074956  , 3.9244318 , 2.9910104 ],\n",
       "       [4.3581867 , 0.63888955, 7.957041  ],\n",
       "       [6.1890526 , 2.8094041 , 4.977326  ],\n",
       "       [8.457302  , 5.538964  , 0.9451542 ],\n",
       "       [8.31521   , 4.6822157 , 6.9621954 ],\n",
       "       [6.4364233 , 2.568179  , 9.067593  ],\n",
       "       [5.563357  , 2.4320436 , 2.932434  ],\n",
       "       [8.881847  , 5.119117  , 8.014171  ],\n",
       "       [7.1930733 , 3.8053503 , 4.976844  ],\n",
       "       [6.5305924 , 3.4814055 , 2.1762338 ]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon = pca.pca_reconstruction_from_top_k_pc(data=data)\n",
    "recon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7499280505710179"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.sum((data - recon)**2) / data.shape[0]) * (data.shape[0] / (data.shape[0] - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
