{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CovarianceMatrix(object):\n",
    "    \"\"\"Class that batch updates covariance matrix.\n",
    "\n",
    "    Attributes:\n",
    "        params: dict, user passed parameters.\n",
    "        seen_example_count: tf.Variable, rank 0 of shape () containing\n",
    "            the count of the number of examples seen so far.\n",
    "        col_means_vector: tf.Variable, rank 1 of shape (num_cols,) containing\n",
    "            column means.\n",
    "        covariance_matrix: tf.Variable, rank 2 of shape (num_cols, num_cols)\n",
    "            containing covariance matrix.\n",
    "    \"\"\"\n",
    "    def __init__(self, params):\n",
    "        \"\"\"Initializes `CovarianceMatrix` class instance.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "        \"\"\"\n",
    "        self.params = params\n",
    "\n",
    "        self.seen_example_count = tf.Variable(\n",
    "            initial_value=tf.zeros(shape=(), dtype=tf.int64), trainable=False\n",
    "        )\n",
    "        self.col_means_vector = tf.Variable(\n",
    "            initial_value=tf.zeros(\n",
    "                shape=(self.params[\"num_cols\"],), dtype=tf.float32\n",
    "            ),\n",
    "            trainable=False\n",
    "        )\n",
    "        self.covariance_matrix = tf.Variable(\n",
    "            initial_value=tf.zeros(\n",
    "                shape=(self.params[\"num_cols\"], self.params[\"num_cols\"]),\n",
    "                dtype=tf.float32\n",
    "            ),\n",
    "            trainable=False\n",
    "        )\n",
    "\n",
    "    @tf.function\n",
    "    def assign_seen_example_count(self, seen_example_count):\n",
    "        \"\"\"Assigns seen example count tf.Variable.\n",
    "\n",
    "        Args:\n",
    "            seen_example_count: tensor, rank 0 of shape () containing\n",
    "            the count of the number of examples seen so far.\n",
    "        \"\"\"\n",
    "        self.seen_example_count.assign(value=seen_example_count)\n",
    "\n",
    "    @tf.function\n",
    "    def assign_col_means_vector(self, col_means_vector):\n",
    "        \"\"\"Assigns column means vector tf.Variable.\n",
    "\n",
    "        Args:\n",
    "            col_means_vector: tensor, rank 1 of shape (num_cols,) containing\n",
    "            column means.\n",
    "        \"\"\"\n",
    "        self.col_means_vector.assign(value=col_means_vector)\n",
    "\n",
    "    @tf.function\n",
    "    def assign_covariance_matrix(self, covariance_matrix):\n",
    "        \"\"\"Assigns covariance matrix tf.Variable.\n",
    "\n",
    "        Args:\n",
    "            covariance_matrix: tensor, rank 2 of shape (num_cols, num_cols)\n",
    "            containing covariance matrix.\n",
    "        \"\"\"\n",
    "        self.covariance_matrix.assign(value=covariance_matrix)\n",
    "\n",
    "    def update_example_count(self, count_a, count_b):\n",
    "        \"\"\"Updates the running number of examples processed.\n",
    "\n",
    "        Given previous running total and current batch size, return new\n",
    "        running total.\n",
    "\n",
    "        Args:\n",
    "            count_a: tensor, tf.int64 rank 0 tensor of previous running total\n",
    "                of examples.\n",
    "            count_b: tensor, tf.int64 rank 0 tensor of current batch size.\n",
    "\n",
    "        Returns:\n",
    "            A tf.int64 rank 0 tensor of new running total of examples.\n",
    "        \"\"\"\n",
    "        return count_a + count_b\n",
    "\n",
    "    def update_mean_incremental(self, count_a, mean_a, value_b):\n",
    "        \"\"\"Updates the running mean vector incrementally.\n",
    "\n",
    "        Given previous running total, running column means, and single\n",
    "            example's column values, return new running column means.\n",
    "\n",
    "        Args:\n",
    "            count_a: tensor, tf.int64 rank 0 tensor of previous running total\n",
    "                of examples.\n",
    "            mean_a: tensor, tf.float32 rank 1 tensor of previous running column\n",
    "                means.\n",
    "            value_b: tensor, tf.float32 rank 1 tensor of single example's\n",
    "                column values.\n",
    "\n",
    "        Returns:\n",
    "            A tf.float32 rank 1 tensor of new running column means.\n",
    "        \"\"\"\n",
    "        umean_a = mean_a * tf.cast(x=count_a, dtype=tf.float32)\n",
    "        mean_ab_num = umean_a + tf.squeeze(input=value_b, axis=0)\n",
    "        mean_ab = mean_ab_num / tf.cast(x=count_a + 1, dtype=tf.float32)\n",
    "\n",
    "        return mean_ab\n",
    "\n",
    "    def update_covariance_incremental(\n",
    "        self, count_a, mean_a, cov_a, value_b, mean_ab, use_sample_covariance\n",
    "    ):\n",
    "        \"\"\"Updates the running covariance matrix incrementally.\n",
    "\n",
    "        Given previous running total, running column means, running covariance\n",
    "        matrix, single example's column values, new running column means, and\n",
    "        whether to use sample covariance or not, return new running covariance\n",
    "        matrix.\n",
    "\n",
    "        Args:\n",
    "            count_a: tensor, tf.int64 rank 0 tensor of previous running total\n",
    "                of examples.\n",
    "            mean_a: tensor, tf.float32 rank 1 tensor of previous running column\n",
    "                means.\n",
    "            cov_a: tensor, tf.float32 rank 2 tensor of previous running\n",
    "                covariance matrix.\n",
    "            value_b: tensor, tf.float32 rank 1 tensor of single example's\n",
    "                column values.\n",
    "            mean_ab: tensor, tf.float32 rank 1 tensor of new running column\n",
    "                means.\n",
    "            use_sample_covariance: bool, flag on whether sample or population\n",
    "                covariance is used.\n",
    "\n",
    "        Returns:\n",
    "            A tf.float32 rank 2 tensor of new covariance matrix.\n",
    "        \"\"\"\n",
    "        mean_diff = tf.matmul(\n",
    "                a=value_b - mean_a, b=value_b - mean_ab, transpose_a=True\n",
    "        )\n",
    "\n",
    "        if use_sample_covariance:\n",
    "            ucov_a = cov_a * tf.cast(x=count_a - 1, dtype=tf.float32)\n",
    "            cov_ab_denominator = tf.cast(x=count_a, dtype=tf.float32)\n",
    "        else:\n",
    "            ucov_a = cov_a * tf.cast(x=count_a, dtype=tf.float32)\n",
    "            cov_ab_denominator = tf.cast(x=count_a + 1, dtype=tf.float32)\n",
    "        cov_ab_numerator = ucov_a + mean_diff\n",
    "        cov_ab = cov_ab_numerator / cov_ab_denominator\n",
    "\n",
    "        return cov_ab\n",
    "\n",
    "    def singleton_batch_update(\n",
    "        self,\n",
    "        X,\n",
    "        running_count,\n",
    "        running_mean,\n",
    "        running_covariance,\n",
    "        use_sample_covariance\n",
    "    ):\n",
    "        \"\"\"Updates running tensors incrementally when batch_size equals 1.\n",
    "\n",
    "        Given the the data vector X, the tensor tracking running example\n",
    "        counts, the tensor tracking running column means, and the tensor\n",
    "        tracking running covariance matrix, returns updated running example\n",
    "        count tensor, column means tensor, and covariance matrix tensor.\n",
    "\n",
    "        Args:\n",
    "            X: tensor, tf.float32 rank 2 tensor of input data.\n",
    "            running_count: tensor, tf.int64 rank 0 tensor tracking running\n",
    "                example counts.\n",
    "            running_mean: tensor, tf.float32 rank 1 tensor tracking running\n",
    "                column means.\n",
    "            running_covariance: tensor, tf.float32 rank 2 tensor tracking\n",
    "                running covariance matrix.\n",
    "            use_sample_covariance: bool, flag on whether sample or population\n",
    "                covariance is used.\n",
    "\n",
    "        Returns:\n",
    "            Updated updated running example count tensor, column means tensor,\n",
    "                and covariance matrix tensor.\n",
    "        \"\"\"\n",
    "        # shape = (num_cols, num_cols)\n",
    "        if running_count == 0:\n",
    "            # Would produce NaNs, so rollover example for next iteration.\n",
    "            self.rollover_singleton_example = X\n",
    "\n",
    "            # Update count though so that we don't end up in this block again.\n",
    "            count = self.update_example_count(\n",
    "                count_a=running_count, count_b=1\n",
    "            )\n",
    "\n",
    "            # No need to update mean or covariance this iteration\n",
    "            mean = running_mean\n",
    "            covariance = running_covariance\n",
    "        elif running_count == 1:\n",
    "            # Batch update since we're combining previous & current batches.\n",
    "            count, mean, covariance = self.non_singleton_batch_update(\n",
    "                batch_size=2,\n",
    "                X=tf.concat(\n",
    "                    values=[self.rollover_singleton_example, X], axis=0\n",
    "                ),\n",
    "                running_count=0,\n",
    "                running_mean=running_mean,\n",
    "                running_covariance=running_covariance,\n",
    "                use_sample_covariance=use_sample_covariance\n",
    "            )\n",
    "        else:\n",
    "            # Calculate new combined mean for incremental covariance matrix.\n",
    "            # shape = (num_cols,)\n",
    "            mean = self.update_mean_incremental(\n",
    "                count_a=running_count, mean_a=running_mean, value_b=X\n",
    "            )\n",
    "\n",
    "            # Update running tensors from single example\n",
    "            # shape = ()\n",
    "            count = self.update_example_count(\n",
    "                count_a=running_count, count_b=1\n",
    "            )\n",
    "\n",
    "            # shape = (num_cols, num_cols)\n",
    "            covariance = self.update_covariance_incremental(\n",
    "                count_a=running_count,\n",
    "                mean_a=running_mean,\n",
    "                cov_a=running_covariance,\n",
    "                value_b=X,\n",
    "                mean_ab=mean,\n",
    "                use_sample_covariance=use_sample_covariance\n",
    "            )\n",
    "\n",
    "        return count, mean, covariance\n",
    "\n",
    "    def update_mean_batch(self, count_a, mean_a, count_b, mean_b):\n",
    "        \"\"\"Updates the running mean vector with a batch of data.\n",
    "\n",
    "        Given previous running example count, running column means, current\n",
    "        batch size, and batch's column means, return new running column means.\n",
    "\n",
    "        Args:\n",
    "            count_a: tensor, tf.int64 rank 0 tensor of previous running total\n",
    "                of examples.\n",
    "            mean_a: tensor, tf.float32 rank 1 tensor of previous running column\n",
    "                means.\n",
    "            count_b: tensor, tf.int64 rank 0 tensor of current batch size.\n",
    "            mean_b: tensor, tf.float32 rank 1 tensor of batch's column means.\n",
    "\n",
    "        Returns:\n",
    "            A tf.float32 rank 1 tensor of new running column means.\n",
    "        \"\"\"\n",
    "        sum_a = mean_a * tf.cast(x=count_a, dtype=tf.float32)\n",
    "        sum_b = mean_b * tf.cast(x=count_b, dtype=tf.float32)\n",
    "        mean_ab_denominator = tf.cast(x=count_a + count_b, dtype=tf.float32)\n",
    "        mean_ab = (sum_a + sum_b) / mean_ab_denominator\n",
    "\n",
    "        return mean_ab\n",
    "\n",
    "    def update_covariance_batch(\n",
    "        self,\n",
    "        count_a,\n",
    "        mean_a,\n",
    "        cov_a,\n",
    "        count_b,\n",
    "        mean_b,\n",
    "        cov_b,\n",
    "        use_sample_covariance\n",
    "    ):\n",
    "        \"\"\"Updates the running covariance matrix with batch of data.\n",
    "\n",
    "        Given previous running example count, column means, and\n",
    "        covariance matrix, current batch size, column means, and covariance\n",
    "        matrix, and whether to use sample covariance or not, return new running\n",
    "        covariance matrix.\n",
    "\n",
    "        Args:\n",
    "            count_a: tensor, tf.int64 rank 0 tensor of previous running total\n",
    "                of examples.\n",
    "            mean_a: tensor, tf.float32 rank 1 tensor of previous running column\n",
    "                means.\n",
    "            cov_a: tensor, tf.float32 rank 2 tensor of previous running\n",
    "                covariance matrix.\n",
    "            count_b: tensor, tf.int64 rank 0 tensor of current batch size.\n",
    "            mean_b: tensor, tf.float32 rank 1 tensor of batch's column means.\n",
    "            cov_b: tensor, tf.float32 rank 2 tensor of batch's covariance\n",
    "                matrix.\n",
    "            use_sample_covariance: bool, flag on whether sample or population\n",
    "                covariance is used.\n",
    "\n",
    "        Returns:\n",
    "            A tf.float32 rank 2 tensor of new running covariance matrix.\n",
    "        \"\"\"\n",
    "        mean_diff = tf.expand_dims(input=mean_a - mean_b, axis=0)\n",
    "\n",
    "        if use_sample_covariance:\n",
    "            ucov_a = cov_a * tf.cast(x=count_a - 1, dtype=tf.float32)\n",
    "            ucov_b = cov_b * tf.cast(x=count_b - 1, dtype=tf.float32)\n",
    "            den = tf.cast(x=count_a + count_b - 1, dtype=tf.float32)\n",
    "        else:\n",
    "            ucov_a = cov_a * tf.cast(x=count_a, dtype=tf.float32)\n",
    "            ucov_b = cov_b * tf.cast(x=count_b, dtype=tf.float32)\n",
    "            den = tf.cast(x=count_a + count_b, dtype=tf.float32)\n",
    "\n",
    "        mean_diff = tf.matmul(a=mean_diff, b=mean_diff, transpose_a=True)\n",
    "        mean_scaling_num = tf.cast(x=count_a * count_b, dtype=tf.float32)\n",
    "        mean_scaling_den = tf.cast(x=count_a + count_b, dtype=tf.float32)\n",
    "        mean_scaling = mean_scaling_num / mean_scaling_den\n",
    "        cov_ab = (ucov_a + ucov_b + mean_diff * mean_scaling) / den\n",
    "\n",
    "        return cov_ab\n",
    "\n",
    "    def non_singleton_batch_update(\n",
    "        self,\n",
    "        batch_size,\n",
    "        X,\n",
    "        running_count,\n",
    "        running_mean,\n",
    "        running_covariance,\n",
    "        use_sample_covariance\n",
    "    ):\n",
    "        \"\"\"Updates running tensors when batch_size does NOT equal 1.\n",
    "\n",
    "        Given the current batch size, the data matrix X, the tensor tracking\n",
    "        running example counts, the tensor tracking running column means, and\n",
    "        the tensor tracking running covariance matrix, returns updated running\n",
    "        example count tensor, column means tensor, and covariance matrix\n",
    "        tensor.\n",
    "\n",
    "        Args:\n",
    "            batch_size: int, number of examples in current batch (could be\n",
    "                partial).\n",
    "            X: tensor, tf.float32 rank 2 tensor of input data.\n",
    "            running_count: tensor, tf.int64 rank 0 tensor tracking running\n",
    "                example counts.\n",
    "            running_mean: tensor, tf.float32 rank 1 tensor tracking running\n",
    "                column means.\n",
    "            running_covariance: tensor, tf.float32 rank 2 tensor tracking\n",
    "                running covariance matrix.\n",
    "            use_sample_covariance: bool, flag on whether sample or population\n",
    "                covariance is used.\n",
    "\n",
    "        Returns:\n",
    "            Updated updated running example count tensor, column means tensor,\n",
    "                and covariance matrix tensor.\n",
    "        \"\"\"\n",
    "        # shape = (num_cols,)\n",
    "        X_mean = tf.reduce_mean(input_tensor=X, axis=0)\n",
    "\n",
    "        # shape = (batch_size, num_cols)\n",
    "        X_centered = X - X_mean\n",
    "\n",
    "        # shape = (num_cols, num_cols)\n",
    "        X_cov = tf.matmul(\n",
    "                a=X_centered,\n",
    "                b=X_centered,\n",
    "                transpose_a=True\n",
    "        )\n",
    "        X_cov /= tf.cast(x=batch_size - 1, dtype=tf.float32)\n",
    "\n",
    "        # Update running tensors from batch statistics.\n",
    "        # shape = ()\n",
    "        count = self.update_example_count(\n",
    "            count_a=running_count, count_b=batch_size\n",
    "        )\n",
    "\n",
    "        # shape = (num_cols,)\n",
    "        mean = self.update_mean_batch(\n",
    "            count_a=running_count,\n",
    "            mean_a=running_mean,\n",
    "            count_b=batch_size,\n",
    "            mean_b=X_mean\n",
    "        )\n",
    "\n",
    "        # shape = (num_cols, num_cols)\n",
    "        covariance = self.update_covariance_batch(\n",
    "            count_a=running_count,\n",
    "            mean_a=running_mean,\n",
    "            cov_a=running_covariance,\n",
    "            count_b=batch_size,\n",
    "            mean_b=X_mean,\n",
    "            cov_b=X_cov,\n",
    "            use_sample_covariance=use_sample_covariance\n",
    "        )\n",
    "\n",
    "        return count, mean, covariance\n",
    "\n",
    "    def calculate_data_stats(self, data):\n",
    "        \"\"\"Calculates statistics of data.\n",
    "\n",
    "        Args:\n",
    "            data: tensor, rank 2 tensor of shape\n",
    "                (current_batch_size, num_cols) containing batch of input data.\n",
    "        \"\"\"\n",
    "        current_batch_size = data.shape[0]\n",
    "\n",
    "        if current_batch_size == 1:\n",
    "            (seen_example_count,\n",
    "             col_means_vector,\n",
    "             covariance_matrix) = self.singleton_batch_update(\n",
    "                X=data,\n",
    "                running_count=self.seen_example_count,\n",
    "                running_mean=self.col_means_vector,\n",
    "                running_covariance=self.covariance_matrix,\n",
    "                use_sample_covariance=self.params[\"use_sample_covariance\"]\n",
    "            )\n",
    "        else:\n",
    "            (seen_example_count,\n",
    "             col_means_vector,\n",
    "             covariance_matrix) = self.non_singleton_batch_update(\n",
    "                batch_size=current_batch_size,\n",
    "                X=data,\n",
    "                running_count=self.seen_example_count,\n",
    "                running_mean=self.col_means_vector,\n",
    "                running_covariance=self.covariance_matrix,\n",
    "                use_sample_covariance=self.params[\"use_sample_covariance\"]\n",
    "            )\n",
    "\n",
    "        self.assign_seen_example_count(seen_example_count=seen_example_count)\n",
    "        self.assign_col_means_vector(col_means_vector=col_means_vector)\n",
    "        self.assign_covariance_matrix(covariance_matrix=covariance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA(CovarianceMatrix):\n",
    "    \"\"\"Class that performs PCA projection and reconstruction.\n",
    "\n",
    "    Attributes:\n",
    "        rollover_singleton_example: tensor, rank 2 tensor of shape\n",
    "            (1, num_cols) containing a rollover singleton example in case the\n",
    "            data batch size begins at 1. This avoids NaN covariances.\n",
    "        eigenvalues: tf.Variable, rank 1 of shape (num_cols,) containing the\n",
    "            eigenvalues of the covariance matrix.\n",
    "        eigenvectors: tf.Variable, rank 2 of shape (num_cols, num_cols)\n",
    "            containing the eigenvectors of the covariance matrix.\n",
    "        top_k_eigenvectors: tensor, rank 2 tensor of shape\n",
    "            (num_cols, top_k_pc) containing the eigenvectors associated with\n",
    "            the top_k_pc eigenvalues.\n",
    "    \"\"\"\n",
    "    def __init__(self, params):\n",
    "        \"\"\"Initializes `PCA` class instance.\n",
    "\n",
    "        Args:\n",
    "            params: dict, user passed parameters.\n",
    "        \"\"\"\n",
    "        super().__init__(params=params)\n",
    "        self.params = params\n",
    "\n",
    "        self.rollover_singleton_example = None\n",
    "\n",
    "        self.eigenvalues = tf.Variable(\n",
    "            initial_value=tf.zeros(\n",
    "                shape=(self.params[\"num_cols\"],), dtype=tf.float32\n",
    "            ),\n",
    "            trainable=False\n",
    "        )\n",
    "\n",
    "        self.eigenvectors = tf.Variable(\n",
    "            initial_value=tf.zeros(\n",
    "                shape=(self.params[\"num_cols\"], self.params[\"num_cols\"]),\n",
    "                dtype=tf.float32\n",
    "            ),\n",
    "            trainable=False\n",
    "        )\n",
    "\n",
    "        self.top_k_eigenvectors = tf.zeros(\n",
    "            shape=(self.params[\"num_cols\"], self.params[\"top_k_pc\"])\n",
    "        )\n",
    "\n",
    "    @tf.function\n",
    "    def assign_eigenvalues(self, eigenvalues):\n",
    "        \"\"\"Assigns covariance matrix eigenvalues tf.Variable.\n",
    "\n",
    "        Args:\n",
    "            eigenvalues: tensor, rank 1 of shape (num_cols,) containing the\n",
    "            eigenvalues of the covariance matrix.\n",
    "        \"\"\"\n",
    "        self.eigenvalues.assign(value=eigenvalues)\n",
    "\n",
    "    @tf.function\n",
    "    def assign_eigenvectors(self, eigenvectors):\n",
    "        \"\"\"Assigns covariance matrix eigenvectors tf.Variable.\n",
    "\n",
    "        Args:\n",
    "            eigenvectors: tensor, rank 2 of shape (num_cols, num_cols)\n",
    "            containing the eigenvectors of the covariance matrix.\n",
    "        \"\"\"\n",
    "        self.eigenvectors.assign(value=eigenvectors)\n",
    "\n",
    "    def calculate_eigenvalues_and_eigenvectors(self, dataset):\n",
    "        \"\"\"Calculates eigenvalues and eigenvectors of data.\n",
    "\n",
    "        Args:\n",
    "            dataset: tf.data.Dataset, batched dataset that contains example\n",
    "                data points each of shape (batch_size, num_cols).\n",
    "        \"\"\"\n",
    "        for batch in dataset:\n",
    "            self.calculate_data_stats(data=batch)\n",
    "\n",
    "        # shape = (num_cols,) & (num_cols, num_cols)\n",
    "        eigenvalues, eigenvectors = tf.linalg.eigh(\n",
    "            tensor=self.covariance_matrix\n",
    "        )\n",
    "\n",
    "        self.assign_eigenvalues(eigenvalues=eigenvalues)\n",
    "        self.assign_eigenvectors(eigenvectors=eigenvectors)\n",
    "\n",
    "    def pca_projection_to_top_k_pc(self, data):\n",
    "        \"\"\"Projects data down to top_k principal components.\n",
    "\n",
    "        Args:\n",
    "            data: tensor, rank 2 tensor of shape (num_examples, num_cols)\n",
    "                containing batch of input data.\n",
    "\n",
    "        Returns:\n",
    "            Rank 2 tensor of shape (num_examples, top_k_pc) containing\n",
    "                projected centered data.\n",
    "        \"\"\"\n",
    "        # shape = (num_cols, top_k_pc)\n",
    "        self.top_k_eigenvectors = (\n",
    "            self.eigenvectors[:, -self.params[\"top_k_pc\"]:]\n",
    "        )\n",
    "\n",
    "        # shape = (num_examples, num_cols)\n",
    "        centered_data = data - self.col_means_vector\n",
    "\n",
    "        # shape = (num_examples, top_k_pc)\n",
    "        projected_centered_data = tf.matmul(\n",
    "            a=centered_data,\n",
    "            b=self.top_k_eigenvectors\n",
    "        )\n",
    "\n",
    "        return projected_centered_data\n",
    "\n",
    "    def pca_reconstruction_from_top_k_pc(self, data):\n",
    "        \"\"\"Reconstructs data up from top_k principal components.\n",
    "\n",
    "        Args:\n",
    "            data: tensor, rank 2 tensor of shape (num_examples, num_cols)\n",
    "                containing batch of input data.\n",
    "\n",
    "        Returns:\n",
    "            Rank 2 tensor of shape (num_examples, num_cols) containing\n",
    "                lossy, reconstructed input data.\n",
    "        \"\"\"\n",
    "        # shape = (num_examples, top_k_pc)\n",
    "        projected_centered_data = self.pca_projection_to_top_k_pc(data=data)\n",
    "\n",
    "        # shape = (num_examples, num_cols)\n",
    "        unprojected_centered_data = tf.matmul(\n",
    "            a=projected_centered_data,\n",
    "            b=self.top_k_eigenvectors,\n",
    "            transpose_b=True\n",
    "        )\n",
    "\n",
    "        # shape = (num_examples, num_cols)\n",
    "        data_reconstructed = unprojected_centered_data + self.col_means_vector\n",
    "\n",
    "        return data_reconstructed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(data, batch_size):\n",
    "    \"\"\"Gets tf.data.Dataset containing point data to cluster.\n",
    "\n",
    "    Args:\n",
    "        data: tensor, rank 2 tensor of shape (num_examples, num_dims) that\n",
    "            contains the coordinates of each point in dataset of examples.\n",
    "        batch_size: int, number of data examples within a batch.\n",
    "\n",
    "    Returns:\n",
    "        Batched `Dataset` object.\n",
    "    \"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(tensors=data)\n",
    "    dataset = dataset.batch(\n",
    "        batch_size=batch_size, drop_remainder=False\n",
    "    )\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(\n",
    "    [\n",
    "        [7.0, 4.0, 3.0],\n",
    "        [4.0, 1.0, 8.0],\n",
    "        [6.0, 3.0, 5.0],\n",
    "        [8.0, 6.0, 1.0],\n",
    "        [8.0, 5.0, 7.0],\n",
    "        [7.0, 2.0, 9.0],\n",
    "        [5.0, 3.0, 3.0],\n",
    "        [9.0, 5.0, 8.0],\n",
    "        [7.0, 4.0, 5.0],\n",
    "        [8.0, 2.0, 2.0],\n",
    "    ]\n",
    ").astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_examples = 10, num_cols = 3\n"
     ]
    }
   ],
   "source": [
    "print(\"num_examples = {}, num_cols = {}\".format(data.shape[0], data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(data=data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[7. 4. 3.]\n",
      " [4. 1. 8.]\n",
      " [6. 3. 5.]\n",
      " [8. 6. 1.]\n",
      " [8. 5. 7.]\n",
      " [7. 2. 9.]\n",
      " [5. 3. 3.]\n",
      " [9. 5. 8.]], shape=(8, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[7. 4. 5.]\n",
      " [8. 2. 2.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for batch in dataset:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(\n",
    "    params={\n",
    "        \"num_cols\": 3,\n",
    "        \"use_sample_covariance\": True,\n",
    "        \"top_k_pc\": 2\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate data statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.calculate_eigenvalues_and_eigenvectors(dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int64, numpy=10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.seen_example_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([6.9, 3.5, 5.1], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.col_means_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=\n",
       "array([[ 2.3222222 ,  1.6111112 , -0.43333334],\n",
       "       [ 1.6111112 ,  2.5       , -1.2777778 ],\n",
       "       [-0.43333334, -1.2777778 ,  7.877778  ]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0.74992794, 3.6761296 , 8.273943  ], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=\n",
       "array([[ 0.7017274 ,  0.6990372 , -0.13757078],\n",
       "       [-0.70745707,  0.66088915, -0.2504597 ],\n",
       "       [-0.08416159,  0.2730798 ,  0.95830274]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
       "array([[-0.17311934, -2.1514225 ],\n",
       "       [-2.8874993 ,  3.8041825 ],\n",
       "       [-0.986886  ,  0.15321338],\n",
       "       [ 1.3015366 , -4.706518  ],\n",
       "       [ 2.2791264 ,  1.2937579 ],\n",
       "       [ 0.14358121,  4.0993133 ],\n",
       "       [-2.2320828 , -1.6258214 ],\n",
       "       [ 3.251243  ,  2.1144898 ],\n",
       "       [ 0.37304026, -0.23481709],\n",
       "       [-1.0689402 , -2.7463768 ]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.pca_projection_to_top_k_pc(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 0.6990372 , -0.13757078],\n",
       "       [ 0.66088915, -0.2504597 ],\n",
       "       [ 0.2730798 ,  0.95830274]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.top_k_eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 3), dtype=float32, numpy=\n",
       "array([[7.074956 , 3.924432 , 2.9910104],\n",
       "       [4.3581862, 0.6388886, 7.957041 ],\n",
       "       [6.1890526, 2.809404 , 4.977326 ],\n",
       "       [8.457302 , 5.5389643, 0.9451542],\n",
       "       [8.315211 , 4.6822157, 6.9621954],\n",
       "       [6.436423 , 2.5681784, 9.067593 ],\n",
       "       [5.5633564, 2.4320436, 2.932434 ],\n",
       "       [8.881848 , 5.119117 , 8.01417  ],\n",
       "       [7.1930733, 3.8053505, 4.976844 ],\n",
       "       [6.5305924, 3.4814057, 2.1762338]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon = pca.pca_reconstruction_from_top_k_pc(data=data)\n",
    "recon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7499281565348308"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.sum((data - recon)**2) / data.shape[0]) * (data.shape[0] / (data.shape[0] - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
