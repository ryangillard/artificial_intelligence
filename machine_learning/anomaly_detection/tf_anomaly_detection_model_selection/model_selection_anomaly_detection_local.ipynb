{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "1.16.4\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and modules\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.enable_eager_execution()\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_data_gen = False\n",
    "\n",
    "pct_seq_before_anom = 70.0\n",
    "pct_seq_after_anom = 0.0\n",
    "\n",
    "\n",
    "def create_time_series_norm_params(simple_data_gen):\n",
    "  \"\"\"Creates \"normal\" time series sine parameters.\n",
    "\n",
    "  Returns multiple \"normal\" sequences.\n",
    "\n",
    "  Args:\n",
    "    simple_data_gen: Bool that determines if we are making simple data\n",
    "      or more complex.\n",
    "\n",
    "  Returns:\n",
    "    np.array of shape = (num_seq, seq_len) of \"normal\" sequences.\n",
    "  \"\"\"\n",
    "  norm_freq_scale = 1.0\n",
    "  norm_freq_shift = 1.0\n",
    "\n",
    "  norm_ampl_scale = 1.0\n",
    "  norm_ampl_shift = 1.0\n",
    "\n",
    "  norm_noise = 1.0\n",
    "\n",
    "  if simple_data_gen:\n",
    "    norm_freq = 1.0\n",
    "    norm_ampl = 1.0\n",
    "  else:\n",
    "    norm_freq = np.random.random() * norm_freq_scale + norm_freq_shift\n",
    "    norm_ampl = np.random.random() * norm_ampl_scale + norm_ampl_shift\n",
    "\n",
    "  return {\"norm_freq\": norm_freq,\n",
    "          \"norm_ampl\": norm_ampl,\n",
    "          \"norm_noise\": norm_noise}\n",
    "\n",
    "\n",
    "def create_time_series_normal(\n",
    "    simple_data_gen,\n",
    "    num_seq,\n",
    "    seq_len,\n",
    "    norm_freq,\n",
    "    norm_ampl,\n",
    "    norm_noise):\n",
    "  \"\"\"Creates normal time series data.\n",
    "\n",
    "  Given the number of sequences to create, the sequence length, and \"normal\"\n",
    "  parameters for sine, returns multiple \"normal\" sequences.\n",
    "\n",
    "  Args:\n",
    "    simple_data_gen: Bool that determines if we are making simple data\n",
    "      or more complex.\n",
    "    num_seq: Number of sequences we want to create.\n",
    "    seq_len: Number of timesteps to create for each sequence.\n",
    "    norm_freq: Sine frequency for \"normal\" sequences.\n",
    "    norm_ampl: Sine amplitude for \"normal\" sequences.\n",
    "    norm_noise: Noise level for \"normal\" sequences.\n",
    "\n",
    "  Returns:\n",
    "    np.array of shape = (num_seq, seq_len) of \"normal\" sequences\n",
    "  \"\"\"\n",
    "  if simple_data_gen:\n",
    "    sequence = np.stack(\n",
    "        arrays=[np.sin(np.arange(seq_len) * norm_freq) * norm_ampl\n",
    "                for _ in range(num_seq)],\n",
    "        axis=0)\n",
    "  else:\n",
    "    sequence = np.stack(\n",
    "        arrays=[np.sin(np.arange(seq_len) * norm_freq) * norm_ampl + \\\n",
    "                  [np.random.random() * norm_noise\n",
    "                   for _ in range(seq_len)] for _ in range(num_seq)],\n",
    "        axis=0)\n",
    "\n",
    "  return sequence\n",
    "\n",
    "\n",
    "def create_time_series_with_anomaly(\n",
    "    simple_data_gen,\n",
    "    num_seq,\n",
    "    seq_len,\n",
    "    pct_seq_before_anom,\n",
    "    pct_seq_after_anom,\n",
    "    norm_freq,\n",
    "    norm_ampl,\n",
    "    norm_noise):\n",
    "  \"\"\"Creates anomalous time series data.\n",
    "\n",
    "  Given the number of sequences to create, the sequence length, and \"normal\"\n",
    "  parameters for sine, returns multiple \"normal\" sequences.\n",
    "\n",
    "  Args:\n",
    "    simple_data_gen: Bool that determines if we are making simple data\n",
    "      or more complex.\n",
    "    num_seq: Number of sequences we want to create.\n",
    "    seq_len: Number of timesteps to create for each sequence.\n",
    "    pct_seq_before_anom: Percent of sequence that will be \"normal\" before\n",
    "      anomaly section.\n",
    "    pct_seq_after_anom: Percent of sequence that will be \"normal\" after\n",
    "      anomaly section.\n",
    "    norm_freq: Sine frequency for \"normal\" sequences.\n",
    "    norm_ampl: Sine amplitude for \"normal\" sequences.\n",
    "    norm_noise: Noise level for \"normal\" sequences.\n",
    "\n",
    "  Returns:\n",
    "    np.array of shape = (num_seq, seq_len) of \"normal\" sequences\n",
    "  \"\"\"\n",
    "  seq_len_bf_anom = int(seq_len * pct_seq_before_anom / 100.0)\n",
    "  seq_len_af_anom = int(seq_len * pct_seq_after_anom / 100.0)\n",
    "  seq_len_anom = seq_len - seq_len_bf_anom - seq_len_af_anom\n",
    "\n",
    "  # Extra anomalous parameters\n",
    "  anom_ampl_multi_min = 8.0\n",
    "  anom_ampl_multi_max = 20.0\n",
    "\n",
    "  if simple_data_gen:\n",
    "    sequence_with_anomaly = np.stack(\n",
    "        arrays=[np.sin(np.arange(seq_len) * norm_freq) * norm_ampl\n",
    "                for _ in range(num_seq)],\n",
    "        axis=0)\n",
    "  else:\n",
    "    sequence_with_anomaly = create_time_series_normal(\n",
    "        simple_data_gen, num_seq, seq_len, norm_freq, norm_ampl, norm_noise)\n",
    "\n",
    "  sequence_with_anomaly[:, seq_len_bf_anom:seq_len_bf_anom + seq_len_anom] *= \\\n",
    "    ((anom_ampl_multi_max - anom_ampl_multi_min) * \\\n",
    "     np.random.random_sample([num_seq, seq_len_anom]) + anom_ampl_multi_min) * \\\n",
    "    (np.random.randint(2, size=[num_seq, seq_len_anom]) * -2 + 1)\n",
    "\n",
    "  return sequence_with_anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_norm_params = create_time_series_norm_params(\n",
    "    simple_data_gen=simple_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/seaborn/timeseries.py:183: UserWarning: The `tsplot` function is deprecated and will be removed in a future release. Please update your code to use the new `lineplot` function.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "flatui = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\n",
    "for i in range(0, 5):\n",
    "  data = create_time_series_normal(\n",
    "      simple_data_gen=simple_data_gen,\n",
    "      num_seq=1,\n",
    "      seq_len=10,\n",
    "      norm_freq=test_norm_params[\"norm_freq\"],\n",
    "      norm_ampl=test_norm_params[\"norm_ampl\"],\n",
    "      norm_noise=test_norm_params[\"norm_noise\"])\n",
    "\n",
    "  sns.tsplot(data=data.reshape(-1), color=flatui[i%len(flatui)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "flatui = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\n",
    "for i in range(0, 5):\n",
    "  data = create_time_series_with_anomaly(\n",
    "      simple_data_gen=simple_data_gen,\n",
    "      num_seq=1,\n",
    "      seq_len=10,\n",
    "      pct_seq_before_anom=pct_seq_before_anom,\n",
    "      pct_seq_after_anom=pct_seq_after_anom,\n",
    "      norm_freq=test_norm_params[\"norm_freq\"],\n",
    "      norm_ampl=test_norm_params[\"norm_ampl\"],\n",
    "      norm_noise=test_norm_params[\"norm_noise\"])\n",
    "\n",
    "  sns.tsplot(data=data.reshape(-1), color=flatui[i%len(flatui)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_norm_seq = 64000\n",
    "\n",
    "num_val_norm_1_seq = 6400\n",
    "num_val_norm_2_seq = 6400\n",
    "num_val_anom_seq = 6400\n",
    "\n",
    "num_test_norm_seq = 6400\n",
    "num_test_anom_seq = 6400\n",
    "\n",
    "seq_len = 30\n",
    "num_tags = 5\n",
    "tag_columns = [\"tag_{0}\".format(tag) for tag in range(0, num_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag_data_list = \n",
      "[{'norm_noise': 1.0, 'norm_freq': 1.3504756824426942, 'norm_ampl': 1.8178921577262472}, {'norm_noise': 1.0, 'norm_freq': 1.9908552901233687, 'norm_ampl': 1.2507221017278454}, {'norm_noise': 1.0, 'norm_freq': 1.117756758794882, 'norm_ampl': 1.3994681608728563}, {'norm_noise': 1.0, 'norm_freq': 1.7997871819782745, 'norm_ampl': 1.4316305648215053}, {'norm_noise': 1.0, 'norm_freq': 1.302486350766258, 'norm_ampl': 1.1331132144686396}]\n"
     ]
    }
   ],
   "source": [
    "tag_data_list = [create_time_series_norm_params(\n",
    "    simple_data_gen=simple_data_gen)\n",
    "                 for tag in range(num_tags)]\n",
    "print(\"tag_data_list = \\n{}\".format(tag_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_norm_seq_array.shape = \n",
      "(64000, 5)\n"
     ]
    }
   ],
   "source": [
    "# Create training set using normal sequences\n",
    "train_norm_seq_list = [create_time_series_normal(\n",
    "    simple_data_gen=simple_data_gen,\n",
    "    num_seq=num_train_norm_seq,\n",
    "    seq_len=seq_len,\n",
    "    norm_freq=tag[\"norm_freq\"],\n",
    "    norm_ampl=tag[\"norm_ampl\"],\n",
    "    norm_noise=tag[\"norm_noise\"])\n",
    "                       for tag in tag_data_list]\n",
    "\n",
    "train_norm_seq_array = np.stack(\n",
    "  arrays=[np.stack(\n",
    "        arrays=[\n",
    "            np.array2string(\n",
    "                a=train_norm_seq_list[i][j], separator=\";\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "            for j in range(num_train_norm_seq)],\n",
    "        axis=0)\n",
    "          for i in range(num_tags)],\n",
    "    axis=1)\n",
    "\n",
    "np.random.shuffle(train_norm_seq_array)\n",
    "print(\"train_norm_seq_array.shape = \\n{}\".format(train_norm_seq_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_norm_1_seq_array.shape = \n",
      "(6400, 5)\n",
      "val_norm_2_seq_array.shape = \n",
      "(6400, 5)\n",
      "val_anom_seq_array.shape = \n",
      "(6400, 5)\n"
     ]
    }
   ],
   "source": [
    "# Create validation sets\n",
    "\n",
    "# Create set vn1 of normal sequences which will be used for early stopping\n",
    "# during training as well as using the error vectors to learn mu and sigma\n",
    "# for mahalanobis distance\n",
    "val_norm_1_seq_list = [create_time_series_normal(\n",
    "    simple_data_gen=simple_data_gen,\n",
    "    num_seq=num_val_norm_1_seq,\n",
    "    seq_len=seq_len,\n",
    "    norm_freq=tag[\"norm_freq\"],\n",
    "    norm_ampl=tag[\"norm_ampl\"],\n",
    "    norm_noise=tag[\"norm_noise\"])\n",
    "                       for tag in tag_data_list]\n",
    "\n",
    "val_norm_1_seq_array = np.stack(\n",
    "    arrays=[np.stack(\n",
    "        arrays=[\n",
    "            np.array2string(\n",
    "                a=val_norm_1_seq_list[i][j], separator=\";\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "            for j in range(num_val_norm_1_seq)],\n",
    "        axis=0)\n",
    "            for i in range(num_tags)],\n",
    "    axis=1)\n",
    "np.random.shuffle(val_norm_1_seq_array)\n",
    "print(\"val_norm_1_seq_array.shape = \\n{}\".format(val_norm_1_seq_array.shape))\n",
    "\n",
    "# Create set vn2 of normal sequences which will be used for tuning the\n",
    "# anomaly thresholds\n",
    "val_norm_2_seq_list = [create_time_series_normal(\n",
    "    simple_data_gen=simple_data_gen,\n",
    "    num_seq=num_val_norm_2_seq,\n",
    "    seq_len=seq_len,\n",
    "    norm_freq=tag[\"norm_freq\"],\n",
    "    norm_ampl=tag[\"norm_ampl\"],\n",
    "    norm_noise=tag[\"norm_noise\"])\n",
    "                       for tag in tag_data_list]\n",
    "\n",
    "val_norm_2_seq_array = np.stack(\n",
    "    arrays=[np.stack(\n",
    "        arrays=[\n",
    "            np.array2string(\n",
    "                a=val_norm_2_seq_list[i][j], separator=\";\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "            for j in range(num_val_norm_2_seq)],\n",
    "        axis=0)\n",
    "            for i in range(num_tags)],\n",
    "    axis=1)\n",
    "np.random.shuffle(val_norm_2_seq_array)\n",
    "print(\"val_norm_2_seq_array.shape = \\n{}\".format(val_norm_2_seq_array.shape))\n",
    "\n",
    "# Create set va of anomalous sequences which will be used for tuning the\n",
    "# anomaly thresholds\n",
    "val_anom_seq_list = [create_time_series_with_anomaly(\n",
    "    simple_data_gen=simple_data_gen,\n",
    "    num_seq=num_val_anom_seq,\n",
    "    seq_len=seq_len,\n",
    "    pct_seq_before_anom=pct_seq_before_anom,\n",
    "    pct_seq_after_anom=pct_seq_after_anom,\n",
    "    norm_freq=tag[\"norm_freq\"],\n",
    "    norm_ampl=tag[\"norm_ampl\"],\n",
    "    norm_noise=tag[\"norm_noise\"])\n",
    "                       for tag in tag_data_list]\n",
    "\n",
    "val_anom_seq_array = np.stack(\n",
    "    arrays=[np.stack(\n",
    "        arrays=[\n",
    "            np.array2string(\n",
    "                a=val_anom_seq_list[i][j], separator=\";\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "            for j in range(num_val_anom_seq)],\n",
    "        axis=0)\n",
    "            for i in range(num_tags)],\n",
    "    axis=1)\n",
    "np.random.shuffle(val_anom_seq_array)\n",
    "print(\"val_anom_seq_array.shape = \\n{}\".format(val_anom_seq_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_norm_seq_array.shape = \n",
      "(6400, 5)\n",
      "test_anom_seq_array.shape = \n",
      "(6400, 5)\n"
     ]
    }
   ],
   "source": [
    "# Create test sets\n",
    "\n",
    "# Create set tn of normal sequences which will be used for testing model\n",
    "test_norm_seq_list = [create_time_series_normal(\n",
    "    simple_data_gen=simple_data_gen,\n",
    "    num_seq=num_test_norm_seq,\n",
    "    seq_len=seq_len,\n",
    "    norm_freq=tag[\"norm_freq\"],\n",
    "    norm_ampl=tag[\"norm_ampl\"],\n",
    "    norm_noise=tag[\"norm_noise\"])\n",
    "                       for tag in tag_data_list]\n",
    "\n",
    "test_norm_seq_array = np.stack(\n",
    "    arrays=[np.stack(\n",
    "        arrays=[\n",
    "            np.array2string(\n",
    "                a=test_norm_seq_list[i][j], separator=\";\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "            for j in range(num_test_norm_seq)],\n",
    "        axis=0)\n",
    "            for i in range(num_tags)],\n",
    "    axis=1)\n",
    "np.random.shuffle(test_norm_seq_array)\n",
    "print(\"test_norm_seq_array.shape = \\n{}\".format(test_norm_seq_array.shape))\n",
    "\n",
    "# Create set ta of anomalous sequences which will be used for testing model\n",
    "test_anom_seq_list = [create_time_series_with_anomaly(\n",
    "    simple_data_gen=simple_data_gen,\n",
    "    num_seq=num_test_anom_seq,\n",
    "    seq_len=seq_len,\n",
    "    pct_seq_before_anom=pct_seq_before_anom,\n",
    "    pct_seq_after_anom=pct_seq_after_anom,\n",
    "    norm_freq=tag[\"norm_freq\"],\n",
    "    norm_ampl=tag[\"norm_ampl\"],\n",
    "    norm_noise=tag[\"norm_noise\"])\n",
    "                      for tag in tag_data_list]\n",
    "\n",
    "test_anom_seq_array = np.stack(\n",
    "    arrays=[np.stack(\n",
    "        arrays=[\n",
    "            np.array2string(\n",
    "                a=test_anom_seq_list[i][j], separator=\";\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "            for j in range(num_test_anom_seq)],\n",
    "        axis=0)\n",
    "            for i in range(num_tags)],\n",
    "    axis=1)\n",
    "np.random.shuffle(test_anom_seq_array)\n",
    "print(\"test_anom_seq_array.shape = \\n{}\".format(test_anom_seq_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled_val_mixed_seq_array.shape = \n",
      "(12800, 6)\n",
      "unlabeled_val_mixed_seq_array.shape = \n",
      "(12800, 5)\n",
      "labeled_test_mixed_seq_array.shape = \n",
      "(12800, 6)\n",
      "unlabeled_test_mixed_seq_array.shape = \n",
      "(12800, 5)\n"
     ]
    }
   ],
   "source": [
    "# Combine vn2 and va sets for tuning anomaly thresholds\n",
    "# Labeled\n",
    "labeled_val_norm_2_seq_array = np.concatenate(\n",
    "    seq=[val_norm_2_seq_array,\n",
    "         np.zeros(shape=[val_norm_2_seq_array.shape[0], 1],\n",
    "                  dtype=np.int64)],\n",
    "    axis=1)\n",
    "\n",
    "labeled_val_anom_seq_array = np.concatenate(\n",
    "    seq=[val_anom_seq_array,\n",
    "         np.ones(shape=[val_anom_seq_array.shape[0], 1],\n",
    "                 dtype=np.int64)],\n",
    "    axis=1)\n",
    "\n",
    "labeled_val_mixed_seq_array = np.concatenate(\n",
    "    seq=[labeled_val_norm_2_seq_array,\n",
    "         labeled_val_anom_seq_array],\n",
    "    axis=0)\n",
    "\n",
    "np.random.shuffle(labeled_val_mixed_seq_array)\n",
    "print(\"labeled_val_mixed_seq_array.shape = \\n{}\".format(\n",
    "    labeled_val_mixed_seq_array.shape))\n",
    "\n",
    "# Unlabeled\n",
    "unlabeled_val_mixed_seq_array = np.concatenate(\n",
    "    seq=[val_norm_2_seq_array,\n",
    "         val_anom_seq_array],\n",
    "    axis=0)\n",
    "\n",
    "np.random.shuffle(unlabeled_val_mixed_seq_array)\n",
    "print(\"unlabeled_val_mixed_seq_array.shape = \\n{}\".format(\n",
    "    unlabeled_val_mixed_seq_array.shape))\n",
    "\n",
    "# Combine tn and ta sets for testing model\n",
    "# Labeled\n",
    "labeled_test_norm_seq_array = np.concatenate(\n",
    "    seq=[test_norm_seq_array,\n",
    "         np.zeros(shape=[test_norm_seq_array.shape[0], 1],\n",
    "                  dtype=np.int64)],\n",
    "    axis=1)\n",
    "\n",
    "labeled_test_anom_seq_array = np.concatenate(\n",
    "    seq=[test_anom_seq_array,\n",
    "         np.ones(shape=[test_anom_seq_array.shape[0], 1],\n",
    "                 dtype=np.int64)],\n",
    "    axis=1)\n",
    "\n",
    "labeled_test_mixed_seq_array = np.concatenate(\n",
    "    seq=[labeled_test_norm_seq_array,\n",
    "         labeled_test_anom_seq_array],\n",
    "    axis=0)\n",
    "\n",
    "np.random.shuffle(labeled_test_mixed_seq_array)\n",
    "print(\"labeled_test_mixed_seq_array.shape = \\n{}\".format(\n",
    "    labeled_test_mixed_seq_array.shape))\n",
    "\n",
    "# Unlabeled\n",
    "unlabeled_test_mixed_seq_array = np.concatenate(\n",
    "    seq=[test_norm_seq_array,\n",
    "         test_anom_seq_array],\n",
    "    axis=0)\n",
    "\n",
    "np.random.shuffle(unlabeled_test_mixed_seq_array)\n",
    "print(\"unlabeled_test_mixed_seq_array.shape = \\n{}\".format(\n",
    "    unlabeled_test_mixed_seq_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save out the errays to csv files\n",
    "np.savetxt(\n",
    "    fname=\"data/train_norm_seq.csv\",\n",
    "    X=train_norm_seq_array,\n",
    "    fmt=\"%s\",\n",
    "    delimiter=\",\")\n",
    "\n",
    "np.savetxt(\n",
    "    fname=\"data/val_norm_1_seq.csv\",\n",
    "    X=val_norm_1_seq_array,\n",
    "    fmt=\"%s\",\n",
    "    delimiter=\",\")\n",
    "\n",
    "np.savetxt(\n",
    "    fname=\"data/labeled_val_mixed_seq.csv\",\n",
    "    X=labeled_val_mixed_seq_array,\n",
    "    fmt=\"%s\",\n",
    "    delimiter=\",\")\n",
    "\n",
    "np.savetxt(\n",
    "    fname=\"data/unlabeled_val_mixed_seq.csv\",\n",
    "    X=unlabeled_val_mixed_seq_array,\n",
    "    fmt=\"%s\",\n",
    "    delimiter=\",\")\n",
    "\n",
    "np.savetxt(\n",
    "    fname=\"data/labeled_test_mixed_seq.csv\",\n",
    "    X=labeled_test_mixed_seq_array,\n",
    "    fmt=\"%s\",\n",
    "    delimiter=\",\")\n",
    "\n",
    "np.savetxt(\n",
    "    fname=\"data/unlabeled_test_mixed_seq.csv\",\n",
    "    X=unlabeled_test_mixed_seq_array,\n",
    "    fmt=\"%s\",\n",
    "    delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64156794;2.0570719;1.51023622;-1.03397408;-0.42711516;1.6938142;1.88987423;0.02357005;-1.68075479;-0.61226294;1.90485724;1.73309454;-0.30766133;-1.69887823;0.82745535;1.99242293;1.20513292;-1.087819;-0.62724112;1.19874695;1.92223101;0.77941634;-0.94882886;0.09533837;1.81874162;1.31984766;-0.53678953;-1.17570662;0.59605331;2.00667448,0.96114844;1.42130137;-0.38870902;-0.3660921;1.48991917;-0.28572381;-0.27272745;2.09968912;0.4984339;-0.82107063;1.32707951;0.6326064;-0.4108803;1.18057756;0.57918092;-0.47154053;1.01114214;0.97182383;-0.96864169;0.55540506;1.06932072;-0.12265277;0.32035001;1.3176848;-0.65685844;-0.12720884;1.68291058;0.47105551;-0.57871738;1.96425389,0.76168924;2.02606293;1.42143557;-0.21082963;-0.54019798;-0.09016458;0.57824257;1.83808034;1.01730961;-0.46044262;-0.86933959;-0.00706518;1.43399518;2.22073197;0.44029561;-1.13000127;-1.05810157;0.82726691;2.08218557;1.10121079;0.12454809;-1.1199253;0.11282269;1.31789684;2.01539561;0.71110604;-0.76391041;-0.74176747;0.51794894;1.25462339,0.487012;1.86829394;-0.29465473;-0.26837393;1.64254204;1.259899;-0.64510813;0.29044762;1.78796205;0.18854064;-0.1121283;1.93534838;1.48404052;-0.46785007;0.65057684;1.41684771;-0.60332207;-0.33526617;1.97856475;0.94441903;-0.49105487;0.57667716;1.46477477;-0.10656934;-0.84089378;2.05258499;0.73444352;-0.65300757;1.05089406;2.30812531,0.554202;1.11438699;1.28779904;0.01139299;-0.30814284;1.03426114;1.53566225;0.98277634;-0.13967597;-0.58975605;1.39709536;2.07658331;0.74937631;-0.39737965;-0.17150691;1.05716722;1.89938069;0.29613774;-0.27067785;0.38321161;1.46177153;1.17781404;0.40065642;-0.74544952;0.13641675;2.00707234;1.50000135;-0.52466968;-0.40973051;0.80793772\n",
      "0.24081571;1.97914591;0.90042224;-1.20645613;-0.7566253;1.46627315;2.72147848;0.75109683;-1.58077988;0.22057862;1.7776985;2.28285898;-0.00851754;-1.45231996;0.39066182;2.04996427;1.15193599;-1.34154339;-0.3935035;1.57360562;2.68724277;-0.04019962;-1.53867318;0.24117609;1.57343339;2.26874574;-0.03248161;-1.27609482;0.60878781;2.7917361,0.48692234;1.8432961;-0.35419027;0.42107673;1.54870703;0.17361979;-0.71824907;1.46519251;0.39426845;-0.20050871;1.24525399;0.50238463;-0.53897037;1.29422849;0.93013115;-0.49384014;1.05274172;0.83210391;-0.97718329;1.01758066;1.07951133;-0.1614682;0.43586288;2.13494617;-0.40618322;-0.28694501;1.92679989;-0.20389976;-0.89897316;1.32042907,0.55763208;1.99581058;1.67586377;-0.24152767;-1.27643406;-0.1592866;1.0935106;2.01919204;0.65188233;-0.56537098;-1.14345903;-0.12188234;1.97874411;1.78880958;0.25331358;-1.07133264;-0.69663186;1.13502629;2.20718238;1.81268906;-0.45681834;-1.03155258;-0.10988422;1.01968961;2.16287134;0.57937528;-0.75317058;-0.51203919;0.21621948;2.03704123,0.80867109;2.22653828;-0.1514525;-0.39015431;1.91240462;1.37955237;-0.50722239;0.97296325;2.15754413;-0.52875156;-0.29448704;1.78517704;0.72230107;-0.43682081;0.51498694;2.35127226;-0.05678958;-0.76616866;1.68137158;1.06245224;-0.87237289;0.23632314;1.71030013;-0.43435614;-0.84529647;2.15259764;0.90546797;-0.8713074;1.03162815;1.79700002,0.50212282;1.9306303;0.74620412;-0.30698093;-0.49521313;0.25795515;1.88305831;1.18152957;-0.07501472;-0.2964922;1.07517508;2.09121994;0.60659407;-0.429123;-0.59403968;1.22953748;1.57071915;0.11425354;-0.12742297;0.24050534;1.19754476;1.50152659;0.53065037;-0.85520618;0.48489956;1.56458448;1.53106756;-0.30020969;-0.56215247;0.89107244\n",
      "0.26501667;2.6452136;1.32079782;-1.1881545;-0.86643505;1.24471537;2.4718358;0.14584429;-1.57212464;0.25494063;1.69310951;1.69978864;-0.42240722;-1.38226219;0.71135277;2.49075393;1.19491725;-0.91599767;-0.36945719;1.11228542;2.26134061;-0.07249476;-1.29029676;-0.57787916;2.26095005;1.89371571;-0.20255739;-0.92597836;0.66086993;2.78029272,0.37514351;1.32586785;-0.4450229;0.44717224;1.34493357;-0.12491906;-0.51118102;2.21826061;0.67680195;-0.99440525;1.35771641;0.66372054;-0.22939893;1.42996225;1.27534782;-1.15387689;0.91051269;0.8716024;-1.10997002;0.34914726;1.79479253;-0.20958002;0.6520451;1.54514198;0.03449102;-0.46188375;2.06345803;0.4324685;-0.89969995;1.92559202,0.36824605;1.60646089;1.98731151;0.44566984;-0.85672975;-0.83246523;0.86810533;2.03356899;1.00714918;-0.51604992;-0.65332769;-0.35972947;1.59491477;1.93543625;0.97537415;-0.26256016;-0.58232163;0.96994232;1.76872631;1.11302859;0.09026546;-1.06874656;0.19224833;1.40664349;2.21124881;0.89098614;-0.14906419;-0.74814713;0.62145747;1.91293353,0.49789932;1.54993419;-0.44030866;-0.45600796;1.49483506;0.73309072;-1.36952761;0.55204514;1.53321465;0.12758071;-0.29308515;1.2155309;1.44059234;-0.97617845;1.02309559;1.46615105;-0.146098;-0.34850257;1.43942422;1.27677646;-0.75120343;0.5410478;2.04096456;-0.38568662;-0.3955403;2.04103327;1.01572362;-0.72674489;0.25855549;2.09033791,0.16899239;1.37519836;0.62171451;0.16067332;-0.43777752;1.24094549;1.96892351;0.75090359;-0.42155379;-0.43046247;0.77217686;1.57879332;0.23874046;-0.41065224;0.23624748;1.3374793;1.80223448;0.03661254;-0.63393737;0.54945667;1.76313823;1.87233117;-0.08760877;-0.81133097;0.47074172;1.27506246;1.40384253;0.1493438;-0.15852;0.74877347\n"
     ]
    }
   ],
   "source": [
    "!head -3 data/train_norm_seq.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76402585;2.42152038;1.14593988;-0.88644568;-0.6483749;1.06603041;2.0237842;0.27951256;-0.79509449;0.27127016;2.0381305;1.82648078;-0.50394311;-0.80689189;0.22631745;2.09392572;0.95331054;-0.79060213;-1.26582263;1.57399303;1.90060234;0.26606981;-0.93520413;-0.01964698;1.806543;1.84041263;-0.62095057;-1.7085484;0.26046187;2.64069475,0.24404553;1.8273648;-0.12105245;0.12207419;1.52096039;-0.45907848;-0.32404064;2.15135704;-0.08485969;-0.92801799;1.95789577;0.80835046;-0.20972729;1.07410484;0.59525686;-1.07563073;1.18458934;1.44619882;-0.92605927;0.44739472;1.1028633;-0.75940521;0.05402271;2.17462478;-0.6049857;0.01624913;1.89584065;0.06568979;-0.05604155;1.29117435,0.93885815;1.33504723;1.83923091;0.67218879;-0.50799734;-0.37644997;1.2645081;2.00520055;1.16131615;-0.47798966;-1.36501431;-0.09694735;1.31533516;1.68573807;0.19278911;-0.40825779;-0.22981406;0.36810041;1.97780061;1.28883003;-0.28790778;-0.84465206;0.18409692;1.14590469;1.59976562;1.42434866;-0.69603601;-1.02472914;0.65940562;2.13866815,0.61746283;2.34656667;-0.13637288;-0.72843643;2.078887;0.72357628;-0.55907456;0.20015322;2.36179099;-0.19901745;-0.17010587;1.9933536;0.66284162;-1.01545868;0.12654102;2.00888387;-0.22778614;-0.72399788;2.18086577;1.09287104;-1.08993723;0.19276791;2.12316539;0.02280805;-0.25570246;2.09405193;1.24520491;-0.55543861;0.4752952;1.42178551,0.25087403;1.21243565;0.77734504;-0.52959982;-0.11113117;0.43645653;1.92288923;0.36411087;-0.70481182;-0.22815495;1.42875051;1.52539462;0.25054418;-0.48838606;-0.45378423;0.98574412;1.25203089;-0.17006186;-0.56519286;-0.42091423;0.94239243;1.58033142;0.02391847;-0.52193731;0.1075199;1.21676833;1.22562926;-0.56271111;-0.69341226;0.15768409\n",
      "0.10625781;1.99490014;1.15838956;-0.83550352;-1.04179376;1.71105763;2.74063409;0.86009115;-1.24960348;-0.373623;2.33616823;2.22104161;-0.42776705;-1.08104985;0.72477031;2.47060401;0.85065549;-0.92475762;-1.28972107;1.70378197;1.97515806;0.45492759;-1.23104979;0.09946397;2.18497456;1.87255488;-0.81364615;-1.30795642;1.02862771;2.14426638,0.22762073;1.48145477;-0.2355394;0.07513493;1.3030686;-0.3053647;-0.05392279;1.42417436;0.57841742;-0.17486947;1.67108931;0.93481701;-1.01231401;1.69174765;0.8432469;-0.76132672;0.96627316;1.79983695;-0.48864427;0.33498116;1.79417353;-0.79340567;-0.0635166;2.18233225;-0.63199397;-0.36129848;1.53996524;0.09690243;-0.24758771;1.7953232,0.04002003;1.74565535;1.32447301;0.06786369;-0.75643757;-0.06866617;1.09614258;1.62858464;1.38556598;-0.22096134;-1.25473779;0.56343753;1.42731952;1.7358309;0.64558229;-0.43235779;-0.64400699;0.63782565;1.40576423;1.502321;0.00386107;-1.2747909;-0.21706231;1.48355622;1.62072678;1.24818981;-0.14481187;-1.01105113;0.46397256;1.21590931,0.44057811;1.6483639;-0.48923915;-0.41509731;1.67577555;1.21601278;-0.7065705;1.00740847;1.84248607;-0.65333654;-0.70049351;1.25442001;1.29021777;-1.09344518;0.83785232;1.74317569;-0.04423243;-0.15682328;1.25390929;1.26609002;-1.39568959;0.66065082;1.7844513;-0.18229929;-0.99957923;2.14143665;0.87817984;-1.24879683;0.29343966;1.66050115,0.62805043;1.69675047;1.35371676;-0.69710223;-0.68656313;1.14513722;1.42511953;0.86214671;0.04929974;-0.26933835;0.71776201;1.77732553;0.96481651;-0.64181922;-0.33786109;1.65962413;1.05121707;0.24948713;-1.08314479;0.1466389;1.60704569;1.59642331;0.29079896;-0.81374764;0.05615185;1.72188736;0.74563859;-0.45139668;-0.76739188;0.59584529\n",
      "0.53019063;2.43876635;1.74242346;-1.32439468;-1.32146408;1.15156366;2.08283126;0.1871002;-0.99766434;-0.06860379;1.84096134;1.55029599;-0.76849158;-0.88312865;0.54958919;1.97948382;0.98187514;-1.43356803;-0.81146759;0.9548939;1.89141979;0.60860416;-0.87962028;0.33963029;2.30287261;1.29974481;-0.19488604;-1.11244757;0.97368549;2.29952102,0.49666277;1.53665571;-0.73925519;0.19258966;1.34478174;-0.06772388;0.26146484;1.56104665;0.62039177;-0.88257126;1.78617589;0.22098281;-1.06423331;1.20797683;1.27356948;-0.27521056;0.85013187;1.28600487;-0.61615115;0.35469401;1.48500558;-0.55460014;0.33971077;1.64670562;-0.48476337;-0.19051443;2.0636896;0.57526363;-0.14536439;1.18151044,0.8892859;1.63935513;1.18898055;0.19968242;-0.93002925;-0.76896665;1.01091491;1.71406016;0.85947683;-0.4513059;-0.66240155;-0.12204674;1.59500148;1.70974573;0.90999264;-1.19384893;-0.75925306;0.98721263;1.63525851;1.58396915;-0.31836945;-1.32342119;-0.47891133;1.60359801;2.22903763;0.90326756;-0.31642844;-0.8933134;0.1308447;1.38336968,0.94369599;2.04201558;0.30791425;-0.11965966;1.76144926;0.93115001;-0.70977351;0.12045347;1.64588185;-0.23327054;-0.34614873;1.95121789;1.31687414;-1.33794796;0.56079235;2.24960673;-0.69604306;-1.02889337;1.8558126;1.21716045;-0.49108299;0.9014301;2.22193331;-0.20446521;-0.39127256;1.60191665;0.64123424;-1.13630716;0.47028793;1.65102214,0.661793;2.00426522;1.3150844;-0.16243192;-0.70148544;0.84811619;1.55540006;1.10220082;-0.89167661;-0.60022526;0.64277059;1.78781916;0.31615991;-0.88732691;-0.55981443;0.98492601;1.82981878;0.57847727;-0.19311501;-0.40231433;1.58643339;1.11072612;-0.05733217;-0.80974824;0.39300027;1.08730047;1.05820418;-0.12599379;-0.74763897;0.89348943\n"
     ]
    }
   ],
   "source": [
    "!head -3 data/val_norm_1_seq.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61610045;1.84579277;1.44185565;-0.84710761;-0.98807746;1.21512715;2.72435928;0.89446418;-1.46679858;-0.37549074;1.89270695;2.18771418;-0.65528436;-1.69140947;0.75758368;2.16389282;1.44755904;-0.5112777;-1.1593997;1.26075746;2.42985866;4.32190231;22.38921568;3.20988361;36.5649403;21.88334438;16.10679525;12.46886483;5.48433992;47.32669551,0.52705329;1.90216168;-0.04663588;-0.20231357;2.11926194;-0.14649253;0.08658961;1.40186632;0.34819497;-0.27847899;1.31022801;0.13867491;-0.76381087;1.76275833;0.60055566;-0.36032459;0.77349132;1.46120441;-1.00448103;0.81109283;1.69533212;-10.29366951;-4.44034229;25.17631087;-1.74089224;-1.40257017;-18.6920417;2.82792523;-2.80478604;-15.81491252,0.78038034;1.49359417;1.70171075;0.07156558;-0.69681128;-0.78798171;1.0052512;1.9034441;0.69974691;-0.05766501;-1.34861971;0.54989616;1.37757272;1.38602159;0.22806682;-0.44662711;-0.95602641;0.42401389;1.60726334;0.96821479;-0.41129208;8.75587378;-1.23128291;-11.66433188;13.94254318;-7.84447864;-3.33240616;6.16643319;-0.81889069;-17.05891921,0.55432054;1.62894816;0.2862261;-1.09656603;1.97333889;0.66145773;-0.85218862;0.29957011;2.12284666;0.23217441;-0.10408096;1.68159997;1.41213911;-0.71900963;0.17669748;2.23513452;-0.27805675;-0.56960993;1.57042084;0.89057733;-1.15009563;13.81778567;-40.95403074;-12.01823635;-12.35389111;20.25191531;-18.83242973;12.813148;10.85134718;-25.95414623,7.48287224e-01;2.01429992e+00;1.08598180e+00;1.77889961e-01;-5.67471034e-01;3.68003438e-01;1.95663851e+00;9.49666498e-01;-6.46620015e-01;-7.97592495e-01;1.49205164e+00;1.76284401e+00;4.01750772e-01;-9.60718191e-01;2.22500774e-02;1.61029474e+00;1.31307987e+00;5.17805258e-01;-2.93392904e-01;-1.94882740e-01;9.51051561e-01;2.35259500e+01;5.07926736e+00;-2.76884494e+00;-2.13756093e+00;-2.09616004e+01;-2.57460739e+01;-3.52784695e+00;1.67371020e+01;-7.62767039e-01,1\n",
      "0.7115601;2.3819851;1.33477067;-0.64987297;-1.28958207;0.83786623;2.67732383;0.05980916;-1.31039454;-0.65549192;2.32592735;2.16065695;-0.7930286;-1.09521185;0.94557412;2.02622317;0.90422563;-0.7788494;-0.95859785;1.52489876;2.42729666;-0.09877423;-1.3626717;0.05107381;2.22366095;2.00925192;-0.67181435;-1.3590159;0.23206769;2.00202021,0.03999939;1.62449507;-0.28671191;0.09992518;1.39749047;-0.44177402;0.17813733;2.20001693;-0.24865366;-0.21615325;1.81859736;0.66044099;-0.67856662;1.59135587;1.10004669;-1.09629451;0.71747402;1.30057515;-0.51565586;1.09556132;1.1998089;-0.32624562;0.37143536;1.30963507;-0.09157916;-0.49062145;1.87609923;0.09770495;0.08602866;1.27780014,0.53715702;1.67036452;1.39408236;0.60541275;-1.00924707;-0.84888695;1.4990157;1.71992612;0.6807682;-0.19659772;-1.31788552;-0.08404402;1.44689085;1.34309843;0.10436342;-0.6222895;-0.54971944;0.86558892;1.91919055;1.1153202;-0.40109602;-0.43449762;-0.40992847;0.79603643;1.76541736;1.35407325;-0.20649726;-1.1754844;-0.12578751;1.58946647,0.4372151;2.01279671;-0.544061;-0.15411322;1.37659933;1.04391136;-0.99040826;0.9723634;1.41929401;0.19285206;-0.2976951;2.07802382;1.14222815;-1.25635237;0.79579254;1.55843035;-0.20797359;-0.71534033;1.24672191;1.03997264;-0.77112534;1.08623957;2.20534931;0.06179618;-0.64936271;1.53196513;1.1031467;-1.19802868;0.6104724;1.6114705,0.647025;1.90410283;1.57711036;-0.09043956;-0.95190004;0.86121706;1.27700258;0.39840517;-0.17670012;-0.69182305;0.60796634;1.65885085;0.76276173;-0.3334834;0.04279173;1.35958752;1.92850786;-0.04470804;-0.63679977;0.55012297;0.91933295;1.49407198;0.17007492;-1.0144738;-0.07036646;1.51363272;1.25716417;-0.10281436;-0.82851839;0.27949452,0\n",
      "0.24554077;2.46759394;1.27729045;-0.75007794;-1.07792142;0.96329659;2.61213503;0.42940509;-1.32317364;-0.04633849;2.24063192;1.3966495;-0.61778034;-0.80241737;0.28957254;2.33551941;1.58756408;-1.38141673;-1.15084997;1.79331138;2.54636908;0.04890068;-1.61201543;-0.40634878;2.26810083;1.93880328;0.00626554;-1.39525947;0.64307937;2.03023546,0.30541383;1.15315054;-0.37030048;-0.30113048;1.993643;-0.04538442;0.26832625;1.57661731;0.13390912;-0.72767934;2.08033261;0.44017553;-0.34361963;1.00307646;0.70068895;-1.13559101;1.37586734;1.51387267;-0.87130181;0.60978877;1.5975394;-0.7704954;0.59146068;1.77626853;0.19217311;-0.38003818;1.79921865;0.36112894;-0.1260961;2.01884219,0.62586665;1.3234417;1.21354906;0.14739435;-0.72226869;0.09036815;1.47216646;1.52216251;0.98255838;0.0274565;-0.62566129;0.38819782;1.6923251;1.52490747;0.21964798;-0.66362215;-0.47787364;0.21427754;1.40334344;1.02197935;-0.14507836;-1.36938255;-0.36698078;1.23163568;2.06121587;1.02992652;-0.03841833;-0.74826517;0.30479761;1.63269327,0.62953676;1.78583111;-0.34866159;-0.45359061;1.2827004;0.85696265;-0.94679439;0.32860969;1.71388324;-0.29487345;-0.58748427;1.68654303;1.37582882;-1.00643526;0.47171991;1.76873702;-0.40130837;-0.67780121;1.19122094;1.27599953;-0.96739169;0.41585485;1.40690512;-0.68989637;-0.55116074;1.23565536;0.7453346;-1.36476015;0.69951383;2.27610748,0.72225972;1.98162168;0.98328837;-0.7133426;-0.1271781;0.75998463;1.18706158;1.34102118;-0.65332928;-0.3342288;1.49139799;1.44469836;0.67608097;-0.85310808;0.05882848;0.93446092;1.10590327;-0.12701557;-0.37599329;0.25232348;1.18332146;1.81709526;0.3311935;-0.3135522;0.59690654;1.44458685;1.28093441;0.12167247;-0.50736803;0.60127424,0\n"
     ]
    }
   ],
   "source": [
    "!head -3 data/labeled_val_mixed_seq.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4079424;2.26187744;0.84983534;-0.93005702;-0.87851025;1.24989225;2.00073326;0.12340413;-1.10718824;-0.40564753;1.76203483;1.53018086;-0.75647635;-0.90718394;0.47547539;2.42662813;0.94016111;-0.54022713;-0.54632202;1.04116146;2.49591603;0.4639748;-1.60644465;0.33127074;1.67994135;2.06961218;-0.55240869;-0.95800864;0.35556699;1.95173137,0.03158174;1.14590559;-0.75326098;-0.01658641;1.8351998;0.10721897;-0.45577732;1.34250495;0.41842831;-0.6868769;1.31327183;0.16677593;-0.34996307;1.84814746;0.93442044;-0.53579625;0.62423046;1.39473298;-0.59123631;1.1384;1.67110564;-0.66012458;0.73028124;1.8991457;-0.62406406;0.28001612;1.7657872;-0.11495727;-0.33890438;1.31243179,0.41782968;2.21762179;1.70452712;0.46184405;-0.75356086;-0.8112679;1.24335936;1.56111374;1.49205869;-0.71174399;-1.04784973;0.52509478;1.67214686;1.96801298;0.26097005;-0.48054963;-0.21111277;0.68997241;2.08116904;1.15546219;0.361879;-1.18533623;-0.25120581;0.82771703;1.87104874;0.46304588;-0.56755381;-0.3428621;0.01742238;2.13261232,0.18517633;1.62742981;-0.62309097;-0.93964758;2.070436;1.53264496;-1.05200327;0.33255254;2.20829894;-0.44935877;-0.77817961;1.59512843;0.60134163;-1.31119335;0.61143269;2.01743068;0.07281072;-0.44438489;2.11999601;0.67277849;-0.46130513;0.68296785;2.10142975;-0.15487296;-0.93464397;1.86957089;0.87020614;-1.29773436;0.95398211;2.23265211,0.39330134;2.05590619;1.34225628;-0.30380414;-0.90677624;0.42149815;1.94338366;1.21108588;-0.87601161;-0.3224513;0.63113829;1.21868875;0.55056719;-0.81373969;-0.25848485;1.04846057;1.43847897;0.26462844;-0.81208641;0.10746012;1.33185094;1.29654111;0.55791161;-0.73385328;0.24496603;1.29367233;1.05056523;-0.36954;-0.68537046;0.26721797\n",
      "0.9443666;2.58026194;0.83590784;-0.65400751;-1.32532122;1.25987568;2.09595013;0.58319106;-0.84209404;-0.23269929;1.8278447;1.42106478;-0.54403533;-1.39924964;0.6003171;2.33340223;0.78402012;-0.95352462;-0.41560928;0.94979048;2.24482918;0.83223042;-1.77659372;-0.62914598;1.94966898;1.50541704;-0.66336174;-1.35841283;0.87133051;1.93175427,0.59018691;1.94392146;-0.48707333;-0.25034644;1.88744361;-0.34470524;-0.69649291;1.98324316;-0.2427122;-0.77352446;1.11602736;0.86439176;-0.89700118;1.31102753;0.72307434;-0.35449997;0.55331128;0.85316758;-0.47559339;0.16735505;1.27677608;-0.92025951;0.32810726;1.60221842;0.06111335;0.26534365;1.27883293;0.43138156;-0.44115304;2.08300357,0.34593967;1.56587213;1.10668036;-0.23978297;-1.23871392;0.08171049;1.46711141;1.60811927;1.32486289;-0.23442205;-1.27696569;-0.23332686;1.20982507;1.4835117;0.20539738;-0.65100615;-0.86248849;0.95613581;1.75749365;1.30356606;-0.04083545;-1.01986359;-0.13149781;1.20483698;2.06490951;1.37533415;-0.22093832;-0.4215716;0.13127939;1.18237014,0.8453314;2.33676645;-0.26560077;-0.98849093;2.06692536;1.21716543;-1.10904999;0.44740828;2.22822905;-0.17740308;-0.71970282;1.64154357;1.38340445;-1.03607608;0.86326097;2.0113637;0.06923137;-0.14147913;2.18032475;1.48239747;-0.43102686;0.16066171;2.12382383;0.00996105;-0.23369389;1.80712861;0.83957856;-1.35477719;0.79768205;1.69866491,4.24273945e-01;1.80674072e+00;7.54115156e-01;2.49133606e-02;-7.08055295e-01;9.94863027e-01;1.32507450e+00;9.89478280e-01;-7.60437995e-01;1.28331909e-01;1.39314970e+00;2.05542465e+00;6.24431069e-01;-9.35489851e-01;3.18663186e-01;9.33013821e-01;1.65203584e+00;7.88721394e-01;-5.13701564e-01;-3.46103097e-01;1.77111826e+00;1.00043016e+00;-1.84866034e-01;-3.70410175e-01;9.35226584e-05;1.35372900e+00;9.05093003e-01;-3.12687050e-01;-1.54044210e-01;1.46801928e-01\n",
      "1.90879845e-01;2.70157293e+00;1.56446600e+00;-4.51049887e-01;-6.38629831e-01;9.33601758e-01;2.17392197e+00;5.77967833e-01;-1.17341741e+00;2.42651464e-01;2.08534906e+00;1.93553317e+00;2.75964847e-02;-1.28393384e+00;6.25878668e-01;2.32233404e+00;8.88759172e-01;-6.90924280e-01;-1.09946354e+00;1.30979329e+00;2.36835436e+00;2.64114324e+00;9.50001829e+00;3.17060079e+00;-3.44322106e+01;-2.30707523e+01;5.21500895e+00;1.29265434e+01;-4.71074313e+00;1.94451536e+01,0.37048241;1.19698193;-0.25717526;0.38171475;1.90656091;-0.52655408;-0.18468122;2.0762593;0.13255792;-0.71135099;1.39075772;0.42478604;-0.58922162;1.48329791;0.53439931;-0.94851227;0.80382122;1.60731598;-0.8774776;0.85702804;1.19719611;4.16354631;-6.5267263;20.16509175;-2.10850062;1.51135797;29.21985267;-0.52309693;-0.68889016;21.20535405,0.55317858;1.55546538;1.40841139;0.30409385;-1.17528357;-0.60446325;1.29967845;1.87095569;1.32350896;-0.2505098;-0.8557127;-0.18529516;2.0119903;1.63900893;0.73683623;-1.13458904;-0.63445655;1.07355338;1.40025361;1.60584762;0.28925908;13.9854216;13.29333009;-22.61060269;-20.68492311;14.02359123;9.31878805;-11.30789993;-1.66643871;17.84152459,2.36859974e-03;1.94734515e+00;-2.61156060e-01;-6.31698258e-01;1.84484615e+00;7.42528939e-01;-1.39461471e+00;6.73128497e-01;2.33998712e+00;-4.16143286e-01;-8.19578891e-01;1.47695577e+00;8.15941315e-01;-7.91138152e-01;1.86016346e-01;1.69696912e+00;1.04880507e-01;-4.23123578e-01;1.51732910e+00;8.08358753e-01;-7.35881312e-01;-1.30078469e+01;-2.95437753e+01;8.45887932e+00;5.19446911e+00;3.46319167e+01;2.52096585e+01;-1.36985767e+01;1.83938720e+01;-3.36687842e+01,0.79862903;1.30490811;0.78199316;0.21230976;-0.82504529;1.05818601;2.01754232;1.22513458;-0.05568771;-0.6802758;0.50864959;2.01903207;0.60887676;-0.78663882;0.08990596;1.71363755;1.60623953;0.40877251;-0.73660647;-0.12200678;1.37715877;-16.06434332;4.23178199;-4.29314096;1.44835926;9.05504969;-21.02777146;-1.75560483;10.39751185;-3.26635103\n"
     ]
    }
   ],
   "source": [
    "!head -3 data/unlabeled_val_mixed_seq.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66491856;1.9145195;1.75234653;-0.78400576;-0.75609776;0.84197907;2.33069302;0.67758695;-1.60418555;-0.16573821;1.65752209;1.38322258;-0.65379731;-0.98907577;0.85974301;2.28947191;1.30827902;-1.28121539;-0.84517686;1.16128253;2.54710653;-0.07715313;-0.99222116;-0.14657169;2.05595855;1.51383899;-0.53623582;-0.75514892;0.48173323;2.3100255,0.14611996;1.91715205;-0.37882894;0.21415584;2.12791802;-0.0619942;0.11572278;1.93012199;0.6541758;-0.68204207;1.56716207;0.75419849;-0.37778253;1.57716806;1.37025903;-1.14077495;1.15195495;1.68996712;-0.81952461;0.85177925;1.21750258;-0.15392611;-0.18813038;2.1498899;0.22421678;-0.30835851;1.58292183;-0.08034281;-0.51606627;2.0111497,0.93582327;1.42382616;2.07416534;0.66961254;-0.45530108;-0.33779627;1.29564858;1.57718875;1.62194094;-0.50371325;-0.68795334;-0.21823157;1.67758936;1.87901361;0.89202323;-1.15923235;-0.39328089;1.03425895;1.62499189;1.47040884;0.40736898;-1.1339056;-0.29514493;1.74666228;2.22234859;0.66564559;-0.7699364;-0.64337751;0.32518635;1.48844008,0.55496827;1.63017531;-0.17487062;-0.14967874;2.12154598;0.98646297;-0.89614069;0.16462197;1.48088977;-0.2009814;-0.7492661;1.41074009;1.49459742;-0.78390433;0.96362317;2.35191643;0.01970021;-0.30345158;1.84212884;0.63518639;-1.26010881;0.84082203;2.33136081;-0.67124369;-0.70904769;1.48210016;0.858758;-1.31116881;0.49555797;1.40730677,0.09135211;2.01834776;0.97056041;-0.1594919;-0.62361487;0.47084415;1.44724272;1.15545605;-0.64437793;-0.18398029;1.1087019;2.06215052;0.45822295;-0.61682919;-0.29801659;0.82097915;1.61374037;0.41494366;-1.0210058;-0.21951907;1.65998406;1.83563618;-0.25813724;-0.13240912;0.38837674;1.99312546;1.22683365;-0.4224495;-0.18025518;0.08359485,0\n",
      "0.17719106;2.36471116;1.33668375;-0.4400062;-1.25963378;1.73031706;2.58521375;0.11354567;-1.11310486;-0.32198926;1.51152682;2.13049867;-0.35512449;-1.27345835;0.54471967;2.6967149;0.86732941;-1.24531881;-0.42520021;1.44453372;1.94324334;0.40487656;-1.015864;0.25622177;1.77878128;1.57045202;-0.79358892;-1.3590808;0.73755601;2.62965859,0.71030153;1.8669475;-0.09171495;-0.17981998;2.22558183;-0.14653793;-0.40682499;1.55818913;0.34023437;-0.21518259;1.86580895;0.86045721;-0.6714036;1.13412677;0.8525273;-0.48981632;1.17631327;1.59408396;-0.78513187;1.1368699;1.7272055;-0.03057556;0.53859453;1.69313548;0.226495;-0.10393593;1.44571603;-0.07160673;-0.73000503;1.86491928,0.09367139;1.33746674;1.9004417;-0.21943487;-1.31156289;0.09949706;1.15835086;1.53605551;1.30479204;0.15526542;-0.41549426;0.04660619;1.80027446;2.14560549;1.0622532;-0.38149954;-0.43315075;0.65333784;1.4824436;0.97490262;-0.36708224;-1.01950586;0.18231947;1.00474388;2.17614239;0.85310003;-0.94154304;-0.97572663;0.2814986;2.11980224,0.43296269;2.23009529;-0.48612455;-0.36227708;1.45665627;0.75931715;-1.18570904;0.44684432;1.794074;0.12783238;-0.99541007;2.04215917;1.53342289;-0.48745935;0.91976961;2.02896366;0.07280475;-0.82926737;1.65608629;0.57029549;-0.96460788;0.66030174;1.88675877;-0.30225988;-0.12357446;2.07062348;0.66685794;-0.56192636;0.92809804;1.80654295,0.587145;1.35353767;0.9576224;0.12748192;-0.56293386;0.94937899;1.53220376;1.18329597;-0.02936159;0.10863562;0.63922954;1.49684617;0.98793307;-0.64285446;-0.54617024;1.54162035;1.61626536;0.67105137;-0.38921715;0.48454694;0.97877305;1.24861088;0.1069746;-0.6347279;-0.04215181;1.26183669;1.56819848;0.32655155;-0.10546471;0.3429311,0\n",
      "0.56407532;2.21735549;1.48425456;-0.4582741;-0.74001439;1.17780382;2.51229789;0.81291222;-0.89756718;-0.04710926;2.26889544;2.08856754;-0.34440918;-1.26350166;0.82788279;2.41310829;0.8713713;-0.77068466;-1.29778275;1.51732726;2.08484064;0.11026772;-0.93499246;0.31454002;2.03869059;2.17338;0.02256827;-0.76568536;0.223173;2.41177806,0.99841597;1.8766039;-0.67996731;-0.36469926;2.02594307;-0.40838761;-0.70422727;1.60641465;0.30621662;-0.59939678;1.82428969;0.74964436;-0.19356367;1.11676055;1.45679273;-0.30363095;0.88551093;1.61644233;-0.86644429;0.64232134;1.86929387;-0.56763947;0.28351136;1.2989801;0.07792312;0.20716147;1.3108805;-0.35569196;-0.83411026;2.03297332,0.79596068;1.78534899;1.18440192;0.6851619;-0.51180857;-0.64516618;0.859677;1.81742657;1.00894047;-0.02323468;-1.32522709;0.59765354;1.22555665;2.10937369;0.93312951;-0.93750619;-0.21586528;1.09578856;1.76662781;1.33824507;0.38463941;-0.40313816;-0.51195442;1.69684109;2.37203636;1.17955189;-0.94215326;-0.77441587;0.14614711;1.85351877,0.56405834;2.3395669;0.01928487;-0.88295555;1.38164722;0.93342287;-0.98667119;0.69532375;2.16844925;-0.19033075;-0.12080565;1.47695624;1.2454856;-0.64102547;0.60170497;2.33863214;0.07862161;-0.53523123;1.59156042;1.40543765;-1.21651573;0.86007653;2.3446296;0.14265097;-0.55523953;1.66811979;0.8424894;-0.59742515;1.12757917;2.20907267,0.94153508;1.9210392;1.23240201;0.19354849;-0.02721869;0.32052958;1.2136126;0.35832705;-0.82980208;-0.09731961;1.41645797;1.97141205;0.18904187;-0.98276332;-0.59979095;1.61790449;1.22859036;0.19796442;-1.08586748;0.10717925;1.10829904;1.60354724;0.37362338;-0.61213502;-0.10515549;1.70933596;0.97441548;0.11367894;-0.55315244;0.41229579,0\n"
     ]
    }
   ],
   "source": [
    "!head -3 data/labeled_test_mixed_seq.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08630851;2.37045866;1.20743555;-1.14710842;-0.48609804;1.50719389;2.19601683;0.10701992;-1.24018965;-0.19057113;1.8352755;1.752288;-0.68841143;-1.25716387;0.38385502;2.6536265;0.79187743;-1.04243811;-0.52800537;1.76135306;2.42560225;0.47596221;-0.93880634;0.34620397;1.77331762;1.74868177;-0.03435227;-0.88146609;0.34844452;2.28759207,0.01710703;1.43010645;-0.40862645;0.54163604;2.06510263;-0.00407659;-0.12560559;1.91115068;0.08341453;-0.99214653;1.59915954;0.90426161;-1.14516381;0.92210796;0.52287498;-0.74294574;0.70845168;1.03833225;-0.4001544;0.95978758;1.08263277;-0.31584913;0.00862613;1.30877146;-0.22048323;-0.24728125;1.4809888;-0.20183649;-0.16185678;1.24482918,0.94729535;2.04044194;1.47843099;0.16625841;-0.75320741;-0.41766578;1.258229;1.52247393;0.72566737;-0.61741024;-0.55178713;0.43867216;1.09453834;1.59920523;0.34086948;-0.8572519;-0.9924474;0.89896643;1.69688929;1.0605381;-0.45109315;-0.96045705;-0.59540668;1.24977148;2.10291277;0.88623454;-0.87614424;-0.54596172;0.32117828;1.82773091,0.39874107;2.00116413;0.31937228;-0.16407445;1.40468418;0.85744544;-0.96783301;0.09800176;1.56246727;0.24066002;-0.20638952;1.49479056;0.8453935;-0.65794037;0.81768388;1.53697035;-0.60762906;-0.41178175;1.97426229;1.27885467;-0.99065918;0.75421874;2.28180555;-0.0776754;-0.52754049;2.00615088;0.92636092;-1.06403935;0.65159031;2.25599744,0.10912429;1.21779374;1.52916082;-0.177806;-0.54337799;0.44055714;1.27923318;1.18207574;-0.84995686;0.08906497;0.65940998;1.61871863;0.81842511;-0.96566587;-0.60382206;1.69003285;1.66798859;0.31696774;-0.408903;-0.25624363;1.39733346;1.38432466;-0.19920215;-0.79272972;0.38229627;1.13707338;1.69781059;0.19309917;-0.97771496;0.44386982\n",
      "0.33326098;1.85213809;0.9367061;-0.70338119;-1.04182581;1.76439127;2.36971889;0.02464679;-1.33960764;0.03777979;2.43879841;2.07333333;-0.63452483;-0.80411878;0.68186144;2.09670113;0.71299439;-1.27104652;-0.93329058;1.77084673;1.75081246;-0.12435358;-1.22616821;-0.14038669;1.9363168;1.57056515;-0.93900226;-1.15834962;1.15378587;1.90757666,0.69319743;1.99742394;-0.34534823;-0.18763758;1.98480288;0.04597313;-0.60822359;2.07220695;0.58939806;-0.50059845;1.30255595;0.29817767;-0.66609921;1.75415711;1.18993307;-0.82581176;0.65695489;1.58478922;-1.12820328;0.37838228;1.41823725;-0.80229066;-0.10926555;1.55461754;-0.40455603;-0.35484316;1.67598159;0.20869392;-0.4338172;1.67318093,0.01836919;2.10079674;1.45575831;0.4292372;-1.18797205;-0.80021461;0.8894862;1.75786206;1.46853713;-0.02519642;-0.9383983;0.12175777;1.4568485;1.43912591;0.9491389;-1.20018373;-0.35509279;0.95545257;2.21985516;1.78304166;-0.13381787;-0.64774564;-0.23528506;1.2975945;2.208059;0.63649609;-0.68651097;-0.76814667;0.51465272;1.5418206,0.34392828;2.22022254;-0.62486174;-0.64590716;1.6803571;0.75811967;-1.26129641;0.88613567;1.55815841;-0.2753162;-0.69940586;1.89796118;1.53808388;-1.39588061;0.46195093;2.09925021;-0.23745644;-0.79142007;1.28753278;0.76307192;-0.45385005;0.92661575;1.42590031;-0.69073748;-0.85690587;1.28799933;0.49766533;-0.98356903;0.32941458;1.87212755,0.14320316;1.29770315;1.07947085;-0.1310581;-0.3940327;1.23110166;1.25224647;0.83662982;-0.94877962;-0.00280088;0.60816257;1.16871775;0.67355164;-0.33326375;-0.16736942;0.78481252;1.17160361;0.34967432;-0.97550557;0.52889076;1.63690058;1.67796765;-0.1170558;-0.95527216;0.50201129;1.89823695;1.12541774;0.27771255;-0.11889077;0.54388248\n",
      "0.73445717;2.72353904;0.88211537;-1.32664507;-0.5210361;1.29496037;1.90929892;0.4232938;-0.80236621;-0.70083891;1.52373953;1.83750916;-0.3666452;-1.5214794;0.98290438;2.48461036;0.96254537;-1.21225544;-0.93638252;1.11062498;2.34966482;-0.35560748;23.20449342;3.8036013;-25.57941473;-15.92919286;-15.76944922;-14.0063463;5.42956756;19.74947804,0.19593637;1.76879507;-0.83715153;0.59350303;1.63039714;0.18211453;0.17978823;2.12240027;0.19751445;-0.36542212;1.57107445;0.9932112;-0.53727715;0.91906189;0.53024939;-0.77351041;0.6343829;1.34788263;-0.53486089;0.99252583;1.70572377;5.34229905;-1.93771172;24.33740572;3.09886769;5.4089372;22.0932672;-5.37011838;11.2843526;15.25303853,0.75526572;1.66106826;2.08408904;0.52117267;-0.46353711;-0.66013605;1.15982625;1.64075277;1.28945757;-0.19133592;-0.65200834;0.4360381;1.88170736;2.01106892;1.0584947;-0.78742361;-0.76440265;0.74252922;1.94999506;1.95534266;-0.42487493;11.34676376;-8.75499856;13.73333075;30.43334572;16.02409734;-12.42682254;-17.83573912;3.73843064;17.66327856,0.10518585;1.97269593;0.05511016;-0.36149535;1.3647047;1.4665965;-0.98610863;0.72499472;2.19375337;-0.48821122;-0.56973544;1.2726906;0.59708671;-1.14598304;0.17213327;1.78199422;0.17972115;-0.81727977;2.15765594;1.30375861;-0.76766416;-4.5207422;-38.77923254;-0.25832894;12.26882665;19.72439461;16.23403127;7.62880641;4.28571629;-17.2711947,0.92380376;1.1275517;0.68680086;-0.65989216;-0.65966357;1.13504582;1.71752066;1.16837965;-0.71586137;-0.13441075;1.14169827;1.99655389;0.69922314;-0.6801096;0.29903466;1.68053185;1.2336307;0.32646373;-1.03204426;-0.33344275;1.11825307;26.42256512;-7.4768817;6.55099231;-1.56550118;23.40616989;-12.96872267;0.5533737;3.96783856;3.01739029\n"
     ]
    }
   ],
   "source": [
    "!head -3 data/unlabeled_test_mixed_seq.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging to be level of INFO\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## globals.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine CSV and label columns\n",
    "UNLABELED_CSV_COLUMNS = tag_columns\n",
    "\n",
    "LABEL_COLUMN = \"anomalous_sequence_flag\"\n",
    "LABELED_CSV_COLUMNS = UNLABELED_CSV_COLUMNS + [LABEL_COLUMN]\n",
    "\n",
    "# Set default values for each CSV column\n",
    "UNLABELED_DEFAULTS = [[\"\"] for _ in UNLABELED_CSV_COLUMNS]\n",
    "\n",
    "LABELED_DEFAULTS = UNLABELED_DEFAULTS + [[0.0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input function functions\n",
    "def split_and_convert_string(string_tensor):\n",
    "  \"\"\"Splits and converts string tensor into dense float tensor.\n",
    "\n",
    "  Given string tensor, splits string by delimiter, converts to and returns\n",
    "  dense float tensor.\n",
    "\n",
    "  Args:\n",
    "    string_tensor: tf.string tensor.\n",
    "\n",
    "  Returns:\n",
    "    tf.float64 tensor split along delimiter.\n",
    "  \"\"\"\n",
    "  # Split string tensor into a sparse tensor based on delimiter\n",
    "  split_string = tf.string_split(source=tf.expand_dims(\n",
    "      input=string_tensor, axis=0), delimiter=\";\")\n",
    "\n",
    "  # Converts the values of the sparse tensor to floats\n",
    "  converted_tensor = tf.string_to_number(\n",
    "      string_tensor=split_string.values,\n",
    "      out_type=tf.float64)\n",
    "\n",
    "  # Create a new sparse tensor with the new converted values,\n",
    "  # because the original sparse tensor values are immutable\n",
    "  new_sparse_tensor = tf.SparseTensor(\n",
    "      indices=split_string.indices,\n",
    "      values=converted_tensor,\n",
    "      dense_shape=split_string.dense_shape)\n",
    "\n",
    "  # Create a dense tensor of the float values that were converted from text csv\n",
    "  dense_floats = tf.sparse_tensor_to_dense(\n",
    "      sp_input=new_sparse_tensor, default_value=0.0)\n",
    "\n",
    "  dense_floats_vector = tf.squeeze(input=dense_floats, axis=0)\n",
    "\n",
    "  return dense_floats_vector\n",
    "\n",
    "\n",
    "def convert_sequences_from_strings_to_floats(features, column_list, seq_len):\n",
    "  \"\"\"Converts sequences from single strings to a sequence of floats.\n",
    "\n",
    "  Given features dictionary and feature column names list, convert features\n",
    "  from strings to a sequence of floats.\n",
    "\n",
    "  Args:\n",
    "    features: Dictionary of tensors of our features as tf.strings.\n",
    "    column_list: List of column names of our features.\n",
    "    seq_len: Number of timesteps in sequence.\n",
    "\n",
    "  Returns:\n",
    "    Dictionary of tensors of our features as tf.float64s.\n",
    "  \"\"\"\n",
    "  for column in column_list:\n",
    "    features[column] = split_and_convert_string(features[column])\n",
    "    # Since we know the sequence length, set the shape to remove the ambiguity\n",
    "    features[column].set_shape([seq_len])\n",
    "\n",
    "  return features\n",
    "\n",
    "\n",
    "def decode_csv(value_column, mode, seq_len, training_mode, labeled_tune_thresh):\n",
    "  \"\"\"Decodes CSV file into tensors.\n",
    "\n",
    "  Given single string tensor and sequence length, returns features dictionary\n",
    "  of tensors and labels tensor.\n",
    "\n",
    "  Args:\n",
    "    value_column: tf.string tensor of shape () compromising entire line of\n",
    "      CSV file.\n",
    "    mode: The estimator ModeKeys. Can be TRAIN or EVAL.\n",
    "    seq_len: Number of timesteps in sequence.\n",
    "    training_mode: Which training mode we're in. Values are \"reconstruction\",\n",
    "      \"calculate_error_distribution_statistics\", and \"tune_anomaly_thresholds\".\n",
    "    labeled_tune_thresh: If tune anomaly thresholds dataset is labeled or not.\n",
    "\n",
    "  Returns:\n",
    "    Features dictionary of tensors and labels tensor.\n",
    "  \"\"\"\n",
    "  if (mode == tf.estimator.ModeKeys.TRAIN or\n",
    "      (mode == tf.estimator.ModeKeys.EVAL and\n",
    "       (training_mode != \"tune_anomaly_thresholds\" or\n",
    "        (training_mode == \"tune_anomaly_thresholds\" and\n",
    "         not labeled_tune_thresh)))):\n",
    "    # For subset of CSV files that do NOT have labels\n",
    "    columns = tf.decode_csv(\n",
    "        records=value_column,\n",
    "        record_defaults=UNLABELED_DEFAULTS,\n",
    "        field_delim=\",\")\n",
    "\n",
    "    features = dict(zip(UNLABELED_CSV_COLUMNS, columns))\n",
    "    features = convert_sequences_from_strings_to_floats(\n",
    "        features=features,\n",
    "        column_list=UNLABELED_CSV_COLUMNS,\n",
    "        seq_len=seq_len)\n",
    "    return features\n",
    "  else:\n",
    "    # For subset of CSV files that DO have labels\n",
    "    columns = tf.decode_csv(\n",
    "        records=value_column,\n",
    "        record_defaults=LABELED_DEFAULTS,\n",
    "        field_delim=\",\")\n",
    "\n",
    "    features = dict(zip(LABELED_CSV_COLUMNS, columns))\n",
    "\n",
    "    labels = tf.cast(x=features.pop(LABEL_COLUMN), dtype=tf.float64)\n",
    "\n",
    "    features = convert_sequences_from_strings_to_floats(\n",
    "        features=features,\n",
    "        column_list=UNLABELED_CSV_COLUMNS,\n",
    "        seq_len=seq_len)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def read_dataset(filename, mode, batch_size, params):\n",
    "  \"\"\"Reads CSV time series dataset using tf.data, doing necessary preprocessing.\n",
    "\n",
    "  Given filename, mode, batch size and other parameters, read CSV dataset using\n",
    "  Dataset API, apply necessary preprocessing, and return an input function to\n",
    "  the Estimator API.\n",
    "\n",
    "  Args:\n",
    "    filename: The file pattern that we want to read into our tf.data dataset.\n",
    "    mode: The estimator ModeKeys. Can be TRAIN or EVAL.\n",
    "    batch_size: Number of examples to read and combine into a single tensor.\n",
    "    params: Additional parameters.\n",
    "\n",
    "  Returns:\n",
    "    An input function.\n",
    "  \"\"\"\n",
    "  def _input_fn():\n",
    "    \"\"\"Wrapper input function to be used by Estimator API to get data tensors.\n",
    "\n",
    "    Returns:\n",
    "      Batched dataset object of dictionary of feature tensors and label tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create list of files that match pattern\n",
    "    file_list = tf.gfile.Glob(filename=filename)\n",
    "\n",
    "    # Create dataset from file list\n",
    "    dataset = tf.data.TextLineDataset(filenames=file_list)  # Read text file\n",
    "\n",
    "    # Decode the CSV file into a features dictionary of tensors\n",
    "    dataset = dataset.map(\n",
    "        map_func=lambda x: decode_csv(\n",
    "            value_column=x,\n",
    "            mode=mode,\n",
    "            seq_len=params[\"seq_len\"],\n",
    "            training_mode=params[\"training_mode\"],\n",
    "            labeled_tune_thresh=params[\"labeled_tune_thresh\"]))\n",
    "\n",
    "    # Determine amount of times to repeat file if we are training or evaluating\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      num_epochs = None  # indefinitely\n",
    "    else:\n",
    "      num_epochs = 1  # end-of-input after this\n",
    "\n",
    "    # Repeat files num_epoch times\n",
    "    dataset = dataset.repeat(count=num_epochs)\n",
    "\n",
    "    # Group the data into batches\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "\n",
    "    # Determine if we should shuffle based on if we are training or evaluating\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      dataset = dataset.shuffle(buffer_size=10 * batch_size)\n",
    "\n",
    "    # Create a iterator, then pull batch of features from the example queue\n",
    "    batched_dataset = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "    return batched_dataset\n",
    "\n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_out_input_function():\n",
    "  \"\"\"Trys out input function for testing purposes.\"\"\"\n",
    "  filename = \"data/labeled_val_mixed_seq.csv\"\n",
    "  training_mode = \"tune_anomaly_thresholds\"\n",
    "  labeled_tune_thresh = True\n",
    "  with tf.Session() as sess:\n",
    "    fn = read_dataset(\n",
    "        filename=filename,\n",
    "        mode=tf.estimator.ModeKeys.EVAL,\n",
    "        batch_size=8,\n",
    "        params={\n",
    "            \"seq_len\": seq_len,\n",
    "            \"training_mode\": training_mode,\n",
    "            \"labeled_tune_thresh\": labeled_tune_thresh})\n",
    "\n",
    "    if training_mode == \"tune_anomaly_thresholds\" and labeled_tune_thresh:\n",
    "      features, labels = sess.run(fn())\n",
    "      print(\"features[tag_0].shape = {}\".format(features[\"tag_0\"].shape))\n",
    "      print(\"labels.shape = {}\".format(labels.shape))\n",
    "      print(\"features = \\n{}\".format(features))\n",
    "      print(\"labels = \\n{}\".format(labels))\n",
    "    else:\n",
    "      features = sess.run(fn())\n",
    "      print(\"features[tag_0].shape = {}\".format(features[\"tag_0\"].shape))\n",
    "      print(\"features = \\n{}\".format(features))\n",
    "\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try_out_input_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoencoder_dense.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense autoencoder model functions\n",
    "def dense_encoder(X, params):\n",
    "  \"\"\"Dense model encoder subgraph that produces latent matrix.\n",
    "\n",
    "  Given data matrix tensor X and dictionary of parameters, process through dense\n",
    "  model encoder subgraph and return encoder latent vector for each example in\n",
    "  batch.\n",
    "\n",
    "  Args:\n",
    "    X: tf.float64 matrix tensor of input data.\n",
    "    params: Dictionary of parameters.\n",
    "\n",
    "  Returns:\n",
    "    tf.float64 matrix tensor encoder latent vector for each example in batch.\n",
    "  \"\"\"\n",
    "  # Create the input layer to our DNN\n",
    "  network = X\n",
    "\n",
    "  # Add hidden layers with the given number of units/neurons per layer\n",
    "  for units in params[\"enc_dnn_hidden_units\"]:\n",
    "    network = tf.layers.dense(\n",
    "        inputs=network,\n",
    "        units=units,\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "  latent_matrix = tf.layers.dense(\n",
    "      inputs=network,\n",
    "      units=params[\"latent_vector_size\"],\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  return latent_matrix\n",
    "\n",
    "\n",
    "def dense_decoder(latent_matrix, orig_dims, params):\n",
    "  \"\"\"Dense model decoder subgraph that produces output matrix.\n",
    "\n",
    "  Given encoder latent matrix tensor, the original dimensions of the input, and\n",
    "  dictionary of parameters, process through dense model decoder subgraph and\n",
    "  return decoder output matrix.\n",
    "\n",
    "  Args:\n",
    "    latent_matrix: tf.float64 matrix tensor of encoder latent matrix.\n",
    "    orig_dims: Original dimensions of input data.\n",
    "    params: Dictionary of parameters.\n",
    "\n",
    "  Returns:\n",
    "    tf.float64 matrix tensor decoder output vector for each example in batch.\n",
    "  \"\"\"\n",
    "  # Create the input layer to our DNN\n",
    "  network = latent_matrix\n",
    "\n",
    "  # Add hidden layers with the given number of units/neurons per layer\n",
    "  for units in params[\"dec_dnn_hidden_units\"][::-1]:\n",
    "    network = tf.layers.dense(\n",
    "        inputs=network,\n",
    "        units=units,\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "  output_matrix = tf.layers.dense(\n",
    "      inputs=network,\n",
    "      units=orig_dims,\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  return output_matrix\n",
    "\n",
    "\n",
    "def dense_autoencoder(X, orig_dims, params):\n",
    "  \"\"\"Dense model autoencoder using dense encoder and decoder networks.\n",
    "\n",
    "  Given data matrix tensor X, the original dimensions of the input, and\n",
    "  dictionary of parameters, process through dense model encoder and decoder\n",
    "  subgraphs and return reconstructed inputs as output.\n",
    "\n",
    "  Args:\n",
    "    X: tf.float64 matrix tensor of input data.\n",
    "    orig_dims: Original dimensions of input data.\n",
    "    params: Dictionary of parameters.\n",
    "\n",
    "  Returns:\n",
    "    tf.float64 matrix tensor decoder output vector for each example in batch\n",
    "    that is the reconstructed inputs.\n",
    "  \"\"\"\n",
    "  latent_matrix = dense_encoder(X, params)\n",
    "  output_matrix = dense_decoder(latent_matrix, orig_dims, params)\n",
    "\n",
    "  return output_matrix\n",
    "\n",
    "\n",
    "def dense_autoencoder_model(\n",
    "    X, mode, params, cur_batch_size, dummy_var):\n",
    "  \"\"\"Dense autoencoder to reconstruct inputs and minimize reconstruction error.\n",
    "\n",
    "  Given data matrix tensor X, the current Estimator mode, the dictionary of\n",
    "  parameters, and the current batch size, process through dense model encoder\n",
    "  and decoder subgraphs and return reconstructed inputs as output.\n",
    "\n",
    "  Args:\n",
    "    X: tf.float64 matrix tensor of input data.\n",
    "    mode: Estimator ModeKeys. Can take values of TRAIN, EVAL, and PREDICT.\n",
    "    params: Dictionary of parameters.\n",
    "    cur_batch_size: Current batch size, could be partially filled.\n",
    "    dummy_var: Dummy variable used to allow training mode to happen since it\n",
    "      requires a gradient to tie back to the graph dependency.\n",
    "\n",
    "  Returns:\n",
    "    loss: Reconstruction loss.\n",
    "    train_op: Train operation so that Estimator can correctly add to dependency\n",
    "      graph.\n",
    "    X_time: 2D tensor representation of time major input data.\n",
    "    X_time_recon: 2D tensor representation of time major input data.\n",
    "    X_feat: 2D tensor representation of feature major input data.\n",
    "    X_feat_recon: 2D tensor representation of feature major input data.\n",
    "  \"\"\"\n",
    "  # Reshape into 2-D tensors\n",
    "  # Time based\n",
    "  # shape = (cur_batch_size * seq_len, num_feat)\n",
    "  X_time = tf.reshape(\n",
    "      tensor=X,\n",
    "      shape=[cur_batch_size * params[\"seq_len\"], params[\"num_feat\"]])\n",
    "\n",
    "  # shape = (cur_batch_size * seq_len, num_feat)\n",
    "  X_time_recon = dense_autoencoder(X_time, params[\"num_feat\"], params)\n",
    "\n",
    "  # Features based\n",
    "  # shape = (cur_batch_size, num_feat, seq_len)\n",
    "  X_transposed = tf.transpose(a=X, perm=[0, 2, 1])\n",
    "\n",
    "  # shape = (cur_batch_size * num_feat, seq_len)\n",
    "  X_feat = tf.reshape(\n",
    "      tensor=X_transposed,\n",
    "      shape=[cur_batch_size * params[\"num_feat\"], params[\"seq_len\"]])\n",
    "\n",
    "  # shape = (cur_batch_size * num_feat, seq_len)\n",
    "  X_feat_recon = dense_autoencoder(X_feat, params[\"seq_len\"], params)\n",
    "\n",
    "  if (mode == tf.estimator.ModeKeys.TRAIN and\n",
    "      params[\"training_mode\"] == \"reconstruction\"):\n",
    "    X_time_recon_3d = tf.reshape(\n",
    "        tensor=X_time_recon,\n",
    "        shape=[cur_batch_size, params[\"seq_len\"], params[\"num_feat\"]])\n",
    "    X_feat_recon_3d = tf.transpose(\n",
    "        a=tf.reshape(\n",
    "            tensor=X_feat_recon,\n",
    "            shape=[cur_batch_size, params[\"num_feat\"], params[\"seq_len\"]]),\n",
    "        perm=[0, 2, 1])\n",
    "\n",
    "    X_time_recon_3d_weighted = X_time_recon_3d * params[\"time_loss_weight\"]\n",
    "    X_feat_recon_3d_weighted = X_feat_recon_3d * params[\"feat_loss_weight\"]\n",
    "\n",
    "    predictions = (X_time_recon_3d_weighted + X_feat_recon_3d_weighted) \\\n",
    "      / (params[\"time_loss_weight\"] + params[\"feat_loss_weight\"])\n",
    "\n",
    "    loss = tf.losses.mean_squared_error(labels=X, predictions=predictions)\n",
    "\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step(),\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        optimizer=\"Adam\")\n",
    "\n",
    "    return loss, train_op, None, None, None, None\n",
    "  else:\n",
    "    return None, None, X_time, X_time_recon, X_feat, X_feat_recon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoencoder_lstm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Encoder-decoder Autoencoder model functions\n",
    "def create_LSTM_stack(lstm_hidden_units, lstm_dropout_output_keep_probs):\n",
    "  \"\"\"Create LSTM stacked cells.\n",
    "\n",
    "  Given list of LSTM hidden units and list of LSTM dropout output keep\n",
    "  probabilities.\n",
    "\n",
    "  Args:\n",
    "    lstm_hidden_units: List of integers for the number of hidden units in each\n",
    "      layer.\n",
    "    lstm_dropout_output_keep_probs: List of floats for the dropout output keep\n",
    "      probabilities for each layer.\n",
    "\n",
    "  Returns:\n",
    "    MultiRNNCell object of stacked LSTM layers.\n",
    "  \"\"\"\n",
    "  # First create a list of LSTM cell objects using our list of lstm hidden\n",
    "  # unit sizes\n",
    "  lstm_cells = [tf.contrib.rnn.BasicLSTMCell(\n",
    "      num_units=units,\n",
    "      forget_bias=1.0,\n",
    "      state_is_tuple=True)\n",
    "                for units in lstm_hidden_units]\n",
    "\n",
    "  # Next apply a dropout wrapper to our stack of LSTM cells,\n",
    "  # in this case just on the outputs\n",
    "  dropout_lstm_cells = [tf.nn.rnn_cell.DropoutWrapper(\n",
    "      cell=lstm_cells[cell_index],\n",
    "      input_keep_prob=1.0,\n",
    "      output_keep_prob=lstm_dropout_output_keep_probs[cell_index],\n",
    "      state_keep_prob=1.0)\n",
    "                        for cell_index in range(len(lstm_cells))]\n",
    "\n",
    "  # Create a stack of layers of LSTM cells\n",
    "  # Combines list into MultiRNNCell object\n",
    "  stacked_lstm_cells = tf.contrib.rnn.MultiRNNCell(\n",
    "      cells=dropout_lstm_cells,\n",
    "      state_is_tuple=True)\n",
    "\n",
    "  return stacked_lstm_cells\n",
    "\n",
    "\n",
    "# The rnn_decoder function takes labels during TRAIN/EVAL\n",
    "# and a start token followed by its previous predictions during PREDICT\n",
    "# Starts with an initial state of the final encoder states\n",
    "def rnn_decoder(dec_input, init_state, cell, infer, dnn_hidden_units, num_feat):\n",
    "  \"\"\"Decoder for RNN cell.\n",
    "\n",
    "  Given list of LSTM hidden units and list of LSTM dropout output keep\n",
    "  probabilities.\n",
    "\n",
    "  Args:\n",
    "    dec_input: List of tf.float64 current batch size by number of features\n",
    "      matrix tensors input to the decoder.\n",
    "    init_state: Initial state of the decoder cell. Final state from the\n",
    "      encoder cell.\n",
    "    cell: RNN Cell object.\n",
    "    infer: Boolean whether in inference mode or not.\n",
    "    dnn_hidden_units: Python list of integers of number of units per DNN layer.\n",
    "    num_feat: Python integer of the number of features.\n",
    "\n",
    "  Returns:\n",
    "    outputs: List of decoder outputs of length number of timesteps of tf.float64\n",
    "      current batch size by number of features matrix tensors.\n",
    "    state: Final cell state of the decoder.\n",
    "  \"\"\"\n",
    "  # Create the decoder variable scope\n",
    "  with tf.variable_scope(\"decoder\"):\n",
    "    # Load in our initial state from our encoder\n",
    "    # Tuple of final encoder c_state and h_state of final encoder layer\n",
    "    state = init_state\n",
    "\n",
    "    # Create an empty list to store our hidden state output for every timestep\n",
    "    outputs = []\n",
    "\n",
    "    # Begin with no previous output\n",
    "    previous_output = None\n",
    "\n",
    "    # Loop over all of our dec_input which will be seq_len long\n",
    "    for index, decoder_input in enumerate(dec_input):\n",
    "      # If there has been a previous output, we will determine the next input\n",
    "      if previous_output is not None:\n",
    "        # Create the input layer to our DNN\n",
    "        # shape = (cur_batch_size, lstm_hidden_units[-1])\n",
    "        network = previous_output\n",
    "\n",
    "        # Create our dnn variable scope\n",
    "        with tf.variable_scope(name_or_scope=\"dnn\", reuse=tf.AUTO_REUSE):\n",
    "          # Add hidden layers with the given number of units/neurons per layer\n",
    "          # shape = (cur_batch_size, dnn_hidden_units[i])\n",
    "          for units in dnn_hidden_units:\n",
    "            network = tf.layers.dense(\n",
    "                inputs=network,\n",
    "                units=units,\n",
    "                activation=tf.nn.relu)\n",
    "\n",
    "          # Connect final hidden layer to linear layer to get the logits\n",
    "          # shape = (cur_batch_size, num_feat)\n",
    "          logits = tf.layers.dense(\n",
    "              inputs=network,\n",
    "              units=num_feat,\n",
    "              activation=None)\n",
    "\n",
    "        # If we are in inference then we will overwrite our next decoder_input\n",
    "        # with the logits we just calculated. Otherwise, we leave the decoder\n",
    "        # input input as it was from the enumerated list. We have to calculate\n",
    "        # the logits even when not using them so that the correct DNN subgraph\n",
    "        # will be generated here and after the encoder-decoder for both\n",
    "        # training and inference\n",
    "        if infer:\n",
    "          # shape = (cur_batch_size, num_feat)\n",
    "          decoder_input = logits\n",
    "\n",
    "      # If this isn\"t our first time through the loop, just reuse(share) the\n",
    "      # same variables for each iteration within the current variable scope\n",
    "      if index > 0:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "      # Run the decoder input through the decoder stack picking up from the\n",
    "      # previous state\n",
    "      # output_shape = (cur_batch_size, lstm_hidden_units[-1])\n",
    "      # state_shape = # tuple of final decoder c_state and h_state\n",
    "      output, state = cell(decoder_input, state)\n",
    "\n",
    "      # Append the current decoder hidden state output to the outputs list\n",
    "      # List seq_len long of shape = (cur_batch_size, lstm_hidden_units[-1])\n",
    "      outputs.append(output)\n",
    "\n",
    "      # Set the previous output to the output just calculated\n",
    "      # shape = (cur_batch_size, lstm_hidden_units[-1])\n",
    "      previous_output = output\n",
    "  return outputs, state\n",
    "\n",
    "\n",
    "def lstm_enc_dec_autoencoder_model(\n",
    "    X, mode, params, cur_batch_size, dummy_var):\n",
    "  \"\"\"LSTM autoencoder to reconstruct inputs and minimize reconstruction error.\n",
    "\n",
    "  Given data matrix tensor X, the current Estimator mode, the dictionary of\n",
    "  parameters, current batch size, and the number of features, process through\n",
    "  LSTM model encoder, decoder, and DNN subgraphs and return reconstructed inputs\n",
    "  as output.\n",
    "\n",
    "  Args:\n",
    "    X: tf.float64 matrix tensor of input data.\n",
    "    mode: Estimator ModeKeys. Can take values of TRAIN, EVAL, and PREDICT.\n",
    "    params: Dictionary of parameters.\n",
    "    cur_batch_size: Current batch size, could be partially filled.\n",
    "    dummy_var: Dummy variable used to allow training mode to happen since it\n",
    "      requires a gradient to tie back to the graph dependency.\n",
    "\n",
    "  Returns:\n",
    "    loss: Reconstruction loss.\n",
    "    train_op: Train operation so that Estimator can correctly add to dependency\n",
    "      graph.\n",
    "    X_time: 2D tensor representation of time major input data.\n",
    "    X_time_recon: 2D tensor representation of time major input data.\n",
    "    X_feat: 2D tensor representation of feature major input data.\n",
    "    X_feat_recon: 2D tensor representation of feature major input data.\n",
    "  \"\"\"\n",
    "  # Unstack 3-D features tensor into a sequence(list) of 2-D tensors\n",
    "  # shape = (cur_batch_size, num_feat)\n",
    "  X_sequence = tf.unstack(value=X, num=params[\"seq_len\"], axis=1)\n",
    "\n",
    "  # Since this is an autoencoder, the features are the labels.\n",
    "  # It often works better though to have the labels in reverse order\n",
    "  # shape = (cur_batch_size, seq_len, num_feat)\n",
    "  if params[\"reverse_labels_sequence\"]:\n",
    "    Y = tf.reverse_sequence(\n",
    "        input=X,\n",
    "        seq_lengths=tf.tile(\n",
    "            input=tf.constant(value=[params[\"seq_len\"]], dtype=tf.int64),\n",
    "            multiples=tf.expand_dims(input=cur_batch_size, axis=0)),\n",
    "        seq_axis=1,\n",
    "        batch_axis=0)\n",
    "  else:\n",
    "    Y = X  # shape = (cur_batch_size, seq_len, num_feat)\n",
    "\n",
    "  ##############################################################################\n",
    "\n",
    "  # Create encoder of encoder-decoder LSTM stacks\n",
    "\n",
    "  # Create our decoder now\n",
    "  dec_stacked_lstm_cells = create_LSTM_stack(\n",
    "      params[\"dec_lstm_hidden_units\"],\n",
    "      params[\"lstm_dropout_output_keep_probs\"])\n",
    "\n",
    "  # Create the encoder variable scope\n",
    "  with tf.variable_scope(\"encoder\"):\n",
    "    # Create separate encoder cells with their own weights separate from decoder\n",
    "    enc_stacked_lstm_cells = create_LSTM_stack(\n",
    "        params[\"enc_lstm_hidden_units\"],\n",
    "        params[\"lstm_dropout_output_keep_probs\"])\n",
    "\n",
    "    # Encode the input sequence using our encoder stack of LSTMs\n",
    "    # enc_outputs = seq_len long of shape = (cur_batch_size, enc_lstm_hidden_units[-1])\n",
    "    # enc_states = tuple of final encoder c_state and h_state for each layer\n",
    "    _, enc_states = tf.nn.static_rnn(\n",
    "        cell=enc_stacked_lstm_cells,\n",
    "        inputs=X_sequence,\n",
    "        initial_state=enc_stacked_lstm_cells.zero_state(\n",
    "            batch_size=tf.cast(x=cur_batch_size, dtype=tf.int32),\n",
    "            dtype=tf.float64),\n",
    "        dtype=tf.float64)\n",
    "\n",
    "    # We just pass on the final c and h states of the encoder\"s last layer,\n",
    "    # so extract that and drop the others\n",
    "    # LSTMStateTuple shape = (cur_batch_size, lstm_hidden_units[-1])\n",
    "    enc_final_states = enc_states[-1]\n",
    "\n",
    "    # Extract the c and h states from the tuple\n",
    "    # both have shape = (cur_batch_size, lstm_hidden_units[-1])\n",
    "    enc_final_c, enc_final_h = enc_final_states\n",
    "\n",
    "    # In case the decoder\"s first layer's number of units is different than\n",
    "    # encoder's last layer's number of units, use a dense layer to map to the\n",
    "    # correct shape\n",
    "    # shape = (cur_batch_size, dec_lstm_hidden_units[0])\n",
    "    enc_final_c_dense = tf.layers.dense(\n",
    "        inputs=enc_final_c,\n",
    "        units=params[\"dec_lstm_hidden_units\"][0],\n",
    "        activation=None)\n",
    "\n",
    "    # shape = (cur_batch_size, dec_lstm_hidden_units[0])\n",
    "    enc_final_h_dense = tf.layers.dense(\n",
    "        inputs=enc_final_h,\n",
    "        units=params[\"dec_lstm_hidden_units\"][0],\n",
    "        activation=None)\n",
    "\n",
    "    # The decoder\"s first layer\"s state comes from the encoder,\n",
    "    # the rest of the layers\" initial states are zero\n",
    "    dec_init_states = tuple(\n",
    "        [tf.contrib.rnn.LSTMStateTuple(c=enc_final_c_dense,\n",
    "                                       h=enc_final_h_dense)] + \\\n",
    "        [tf.contrib.rnn.LSTMStateTuple(\n",
    "            c=tf.zeros(shape=[cur_batch_size, units], dtype=tf.float64),\n",
    "            h=tf.zeros(shape=[cur_batch_size, units], dtype=tf.float64))\n",
    "         for units in params[\"dec_lstm_hidden_units\"][1:]])\n",
    "\n",
    "  ##############################################################################\n",
    "\n",
    "  # Create decoder of encoder-decoder LSTM stacks\n",
    "\n",
    "  # Train our decoder now\n",
    "\n",
    "  # Encoder-decoders work differently during training, evaluation, and inference\n",
    "  # so we will have two separate subgraphs for each\n",
    "  if (mode == tf.estimator.ModeKeys.TRAIN and\n",
    "      params[\"training_mode\"] == \"reconstruction\"):\n",
    "    # Break 3-D labels tensor into a list of 2-D tensors\n",
    "    # shape = (cur_batch_size, num_feat)\n",
    "    unstacked_labels = tf.unstack(value=Y, num=params[\"seq_len\"], axis=1)\n",
    "\n",
    "    # Call our decoder using the labels as our inputs, the encoder final state\n",
    "    # as our initial state, our other LSTM stack as our cells, and inference\n",
    "    # set to false\n",
    "    dec_outputs, _ = rnn_decoder(\n",
    "        dec_input=unstacked_labels,\n",
    "        init_state=dec_init_states,\n",
    "        cell=dec_stacked_lstm_cells,\n",
    "        infer=False,\n",
    "        dnn_hidden_units=params[\"dnn_hidden_units\"],\n",
    "        num_feat=params[\"num_feat\"])\n",
    "  else:\n",
    "    # Since this is inference create fake labels. The list length needs to be\n",
    "    # the output sequence length even though only the first element is the only\n",
    "    # one actually used (as our go signal)\n",
    "    fake_labels = [tf.zeros(shape=[cur_batch_size, params[\"num_feat\"]],\n",
    "                            dtype=tf.float64)\n",
    "                   for _ in range(params[\"seq_len\"])]\n",
    "\n",
    "    # Call our decoder using fake labels as our inputs, the encoder final state\n",
    "    # as our initial state, our other LSTM stack as our cells, and inference\n",
    "    # set to true\n",
    "    # dec_outputs = seq_len long of shape = (cur_batch_size, dec_lstm_hidden_units[-1])\n",
    "    # decoder_states = tuple of final decoder c_state and h_state for each layer\n",
    "    dec_outputs, _ = rnn_decoder(\n",
    "        dec_input=fake_labels,\n",
    "        init_state=dec_init_states,\n",
    "        cell=dec_stacked_lstm_cells,\n",
    "        infer=True,\n",
    "        dnn_hidden_units=params[\"dnn_hidden_units\"],\n",
    "        num_feat=params[\"num_feat\"])\n",
    "\n",
    "  # Stack together list of rank 2 decoder output tensors into one rank 3 tensor\n",
    "  # shape = (cur_batch_size, seq_len, lstm_hidden_units[-1])\n",
    "  stacked_dec_outputs = tf.stack(values=dec_outputs, axis=1)\n",
    "\n",
    "  # Reshape rank 3 decoder outputs into rank 2 by folding sequence length into\n",
    "  # batch size\n",
    "  # shape = (cur_batch_size * seq_len, lstm_hidden_units[-1])\n",
    "  reshaped_stacked_dec_outputs = tf.reshape(\n",
    "      tensor=stacked_dec_outputs,\n",
    "      shape=[cur_batch_size * params[\"seq_len\"],\n",
    "             params[\"dec_lstm_hidden_units\"][-1]])\n",
    "\n",
    "  ##############################################################################\n",
    "\n",
    "  # Create the DNN structure now after the encoder-decoder LSTM stack\n",
    "  # Create the input layer to our DNN\n",
    "  # shape = (cur_batch_size * seq_len, lstm_hidden_units[-1])\n",
    "  network = reshaped_stacked_dec_outputs\n",
    "\n",
    "  # Reuse the same variable scope as we used within our decoder (for inference)\n",
    "  with tf.variable_scope(name_or_scope=\"dnn\", reuse=tf.AUTO_REUSE):\n",
    "    # Add hidden layers with the given number of units/neurons per layer\n",
    "    for units in params[\"dnn_hidden_units\"]:\n",
    "      # shape = (cur_batch_size * seq_len, dnn_hidden_units[i])\n",
    "      network = tf.layers.dense(\n",
    "          inputs=network,\n",
    "          units=units,\n",
    "          activation=tf.nn.relu)\n",
    "\n",
    "    # Connect the final hidden layer to a dense layer with no activation to\n",
    "    # get the logits\n",
    "    # shape = (cur_batch_size * seq_len, num_feat)\n",
    "    logits = tf.layers.dense(\n",
    "        inputs=network,\n",
    "        units=params[\"num_feat\"],\n",
    "        activation=None)\n",
    "\n",
    "  # Now that we are through the final DNN for each sequence element for\n",
    "  # each example in the batch, reshape the predictions to match our labels.\n",
    "  # shape = (cur_batch_size, seq_len, num_feat)\n",
    "  predictions = tf.reshape(\n",
    "      tensor=logits,\n",
    "      shape=[cur_batch_size, params[\"seq_len\"], params[\"num_feat\"]])\n",
    "\n",
    "  if (mode == tf.estimator.ModeKeys.TRAIN and\n",
    "      params[\"training_mode\"] == \"reconstruction\"):\n",
    "    loss = tf.losses.mean_squared_error(labels=Y, predictions=predictions)\n",
    "\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step(),\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        optimizer=\"Adam\")\n",
    "\n",
    "    return loss, train_op, None, None, None, None\n",
    "  else:\n",
    "    if params[\"reverse_labels_sequence\"]:\n",
    "      # shape=(cur_batch_size, seq_len, num_feat)\n",
    "      predictions = tf.reverse_sequence(\n",
    "          input=predictions,\n",
    "          seq_lengths=tf.tile(\n",
    "              input=tf.constant(value=[params[\"seq_len\"]], dtype=tf.int64),\n",
    "              multiples=tf.expand_dims(input=cur_batch_size, axis=0)),\n",
    "          seq_axis=1,\n",
    "          batch_axis=0)\n",
    "\n",
    "    # Reshape into 2-D tensors\n",
    "    # Time based\n",
    "    # shape = (cur_batch_size * seq_len, num_feat)\n",
    "    X_time = tf.reshape(\n",
    "        tensor=X,\n",
    "        shape=[cur_batch_size * params[\"seq_len\"], params[\"num_feat\"]])\n",
    "\n",
    "    X_time_recon = tf.reshape(\n",
    "        tensor=predictions,\n",
    "        shape=[cur_batch_size * params[\"seq_len\"], params[\"num_feat\"]])\n",
    "\n",
    "    # Features based\n",
    "    # shape = (cur_batch_size, num_feat, seq_len)\n",
    "    X_transposed = tf.transpose(a=X, perm=[0, 2, 1])\n",
    "\n",
    "    # shape = (cur_batch_size * num_feat, seq_len)\n",
    "    X_feat = tf.reshape(\n",
    "        tensor=X_transposed,\n",
    "        shape=[cur_batch_size * params[\"num_feat\"], params[\"seq_len\"]])\n",
    "\n",
    "    # shape = (cur_batch_size, num_feat, seq_len)\n",
    "    predictions_transposed = tf.transpose(a=predictions, perm=[0, 2, 1])\n",
    "\n",
    "    # shape = (cur_batch_size * num_feat, seq_len)\n",
    "    X_feat_recon = tf.reshape(\n",
    "        tensor=predictions_transposed,\n",
    "        shape=[cur_batch_size * params[\"num_feat\"], params[\"seq_len\"]])\n",
    "\n",
    "    return None, None, X_time, X_time_recon, X_feat, X_feat_recon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoencoder_pca.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA model functions\n",
    "def create_pca_vars(var_name, size):\n",
    "  \"\"\"Creates PCA variables.\n",
    "\n",
    "  Given variable name and size, create and return PCA variables for count,\n",
    "  mean, covariance, eigenvalues, eignvectors, and k principal components.\n",
    "\n",
    "  Args:\n",
    "    var_name: String denoting which set of variables to create. Values are\n",
    "      \"time\" and \"feat\".\n",
    "    size: The size of the variable, either sequence length or number of\n",
    "      features.\n",
    "\n",
    "  Returns:\n",
    "    PCA variables for count, mean, covariance, eigenvalues,\n",
    "    eigenvectors, and k principal components.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=\"pca_vars\", reuse=tf.AUTO_REUSE):\n",
    "    count_var = tf.get_variable(\n",
    "        name=\"pca_{}_count_var\".format(var_name),\n",
    "        dtype=tf.int64,\n",
    "        initializer=tf.zeros(shape=[], dtype=tf.int64),\n",
    "        trainable=False)\n",
    "\n",
    "    mean_var = tf.get_variable(\n",
    "        name=\"pca_{}_mean_var\".format(var_name),\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(shape=[size], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "    cov_var = tf.get_variable(\n",
    "        name=\"pca_{}_cov_var\".format(var_name),\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(shape=[size, size], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "    eigval_var = tf.get_variable(\n",
    "        name=\"pca_{}_eigval_var\".format(var_name),\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(shape=[size], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "    eigvec_var = tf.get_variable(\n",
    "        name=\"pca_{}_eigvec_var\".format(var_name),\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(shape=[size, size], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "    k_pc_var = tf.get_variable(\n",
    "        name=\"pca_{}_k_principal_components_var\".format(var_name),\n",
    "        dtype=tf.int64,\n",
    "        initializer=tf.ones(shape=[], dtype=tf.int64),\n",
    "        trainable=False)\n",
    "\n",
    "  return count_var, mean_var, cov_var, eigval_var, eigvec_var, k_pc_var\n",
    "\n",
    "\n",
    "def create_both_pca_vars(seq_len, num_feat):\n",
    "  \"\"\"Creates both time & feature major PCA variables.\n",
    "\n",
    "  Given dimensions of inputs, create and return PCA variables for count,\n",
    "  mean, covariance, eigenvalues, eigenvectors, and k principal components\n",
    "  for both time and feature major representations.\n",
    "\n",
    "  Args:\n",
    "    seq_len: Number of timesteps in sequence.\n",
    "    num_feat: Number of features.\n",
    "\n",
    "  Returns:\n",
    "    PCA variables for count, mean, covariance, eigenvalues,\n",
    "    eigenvectors, and k principal components for both time and feature\n",
    "    major representations.\n",
    "  \"\"\"\n",
    "  # Time based\n",
    "  (pca_time_count_var,\n",
    "   pca_time_mean_var,\n",
    "   pca_time_cov_var,\n",
    "   pca_time_eigval_var,\n",
    "   pca_time_eigvec_var,\n",
    "   pca_time_k_pc_var) = create_pca_vars(\n",
    "       var_name=\"time\", size=num_feat)\n",
    "\n",
    "  # Features based\n",
    "  (pca_feat_count_var,\n",
    "   pca_feat_mean_var,\n",
    "   pca_feat_cov_var,\n",
    "   pca_feat_eigval_var,\n",
    "   pca_feat_eigvec_var,\n",
    "   pca_feat_k_pc_var) = create_pca_vars(\n",
    "       var_name=\"feat\", size=seq_len)\n",
    "\n",
    "  return (pca_time_count_var,\n",
    "          pca_time_mean_var,\n",
    "          pca_time_cov_var,\n",
    "          pca_time_eigval_var,\n",
    "          pca_time_eigvec_var,\n",
    "          pca_time_k_pc_var,\n",
    "          pca_feat_count_var,\n",
    "          pca_feat_mean_var,\n",
    "          pca_feat_cov_var,\n",
    "          pca_feat_eigval_var,\n",
    "          pca_feat_eigvec_var,\n",
    "          pca_feat_k_pc_var)\n",
    "\n",
    "\n",
    "def pca_reconstruction_k_pc(X_cen, pca_eigvec_var, k_pc):\n",
    "  \"\"\"PCA reconstruction with k principal components.\n",
    "\n",
    "  Given centered data matrix tensor X, variables for the column means\n",
    "  and eigenvectors, and the number of principal components, returns\n",
    "  the reconstruction of X centered.\n",
    "\n",
    "  Args:\n",
    "    X_cen: tf.float64 matrix tensor of centered input data.\n",
    "    pca_eigvec_var: tf.float64 matrix variable storing eigenvectors.\n",
    "    k_pc: Number of principal components to keep.\n",
    "\n",
    "  Returns:\n",
    "    X_cen_recon: 2D input data tensor reconstructed.\n",
    "  \"\"\"\n",
    "  # time_shape = (num_feat, num_feat)\n",
    "  # feat_shape = (seq_len, seq_len)\n",
    "  projection_matrix = tf.matmul(\n",
    "      a=pca_eigvec_var[:, -k_pc:],\n",
    "      b=pca_eigvec_var[:, -k_pc:],\n",
    "      transpose_b=True)\n",
    "\n",
    "  # time_shape = (cur_batch_size * seq_len, num_feat)\n",
    "  # feat_shape = (cur_batch_size * num_feat, seq_len)\n",
    "  X_cen_recon = tf.matmul(\n",
    "      a=X_cen,\n",
    "      b=projection_matrix)\n",
    "\n",
    "  return X_cen_recon\n",
    "\n",
    "\n",
    "def pca_reconstruction_k_pc_mse(X_cen, pca_eigvec_var, k_pc):\n",
    "  \"\"\"PCA reconstruction with k principal components.\n",
    "\n",
    "  Given centered data matrix tensor X, variables for the column means\n",
    "  and eigenvectors, and the number of principal components, returns\n",
    "  reconstruction MSE.\n",
    "\n",
    "  Args:\n",
    "    X_cen: tf.float64 matrix tensor of centered input data.\n",
    "    pca_eigvec_var: tf.float64 matrix variable storing eigenvectors.\n",
    "    k_pc: Number of principal components to keep.\n",
    "\n",
    "  Returns:\n",
    "    mse: Reconstruction mean squared error.\n",
    "  \"\"\"\n",
    "  # time_shape = (cur_batch_size * seq_len, num_feat)\n",
    "  # feat_shape = (cur_batch_size * num_feat, seq_len)\n",
    "  X_cen_recon = pca_reconstruction_k_pc(\n",
    "      X_cen, pca_eigvec_var, k_pc)\n",
    "\n",
    "  # time_shape = (cur_batch_size * seq_len, num_feat)\n",
    "  # feat_shape = (cur_batch_size * num_feat, seq_len)\n",
    "  error = X_cen - X_cen_recon\n",
    "\n",
    "  # shape = ()\n",
    "  mse = tf.reduce_mean(\n",
    "      input_tensor=tf.reduce_sum(\n",
    "          input_tensor=tf.square(x=error), axis=-1))\n",
    "\n",
    "  return mse\n",
    "\n",
    "\n",
    "def find_best_k_principal_components(X_recon_mse, pca_k_pc_var):\n",
    "  \"\"\"Find best k principal components from reconstruction MSE.\n",
    "\n",
    "  Given reconstruction MSE, return number of principal components\n",
    "  with lowest MSE in varible.\n",
    "\n",
    "  Args:\n",
    "    X_recon_mse: tf.float64 vector tensor of reconstruction mean\n",
    "      squared error.\n",
    "    pca_k_pc_var: tf.int64 scalar variable to hold best number of\n",
    "      principal components.\n",
    "\n",
    "  Returns:\n",
    "    pca_k_pc_var: Updated scalar variable now with best number of\n",
    "      principal components.\n",
    "  \"\"\"\n",
    "  best_pca_k_pc = tf.argmin(input=X_recon_mse) + 1\n",
    "\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[tf.assign(ref=pca_k_pc_var,\n",
    "                                value=best_pca_k_pc)]):\n",
    "\n",
    "    return tf.identity(input=pca_k_pc_var)\n",
    "\n",
    "\n",
    "def set_k_principal_components(user_k_pc, pca_k_pc_var):\n",
    "  \"\"\"Set k principal components from user-defined value.\n",
    "\n",
    "  Given user-defined number of principal components, return\n",
    "  variable set to this value.\n",
    "\n",
    "  Args:\n",
    "    user_k_pc: User-defined python integer for number of principal\n",
    "      components.\n",
    "    pca_k_pc_var: tf.int64 scalar variable to hold chosen number of\n",
    "      principal components.\n",
    "\n",
    "  Returns:\n",
    "    pca_k_pc_var: Updated scalar variable now with chosen number of\n",
    "      principal components.\n",
    "  \"\"\"\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[tf.assign(ref=pca_k_pc_var,\n",
    "                                value=user_k_pc)]):\n",
    "\n",
    "    return tf.identity(input=pca_k_pc_var)\n",
    "\n",
    "\n",
    "def pca_model(X, mode, params, cur_batch_size, dummy_var):\n",
    "  \"\"\"PCA to reconstruct inputs and minimize reconstruction error.\n",
    "\n",
    "  Given data matrix tensor X, the current Estimator mode, the dictionary of\n",
    "  parameters, current batch size, and the number of features, process through\n",
    "  PCA model subgraph and return reconstructed inputs as output.\n",
    "\n",
    "  Args:\n",
    "    X: tf.float64 matrix tensor of input data.\n",
    "    mode: Estimator ModeKeys. Can take values of TRAIN, EVAL, and PREDICT.\n",
    "    params: Dictionary of parameters.\n",
    "    cur_batch_size: Current batch size, could be partially filled.\n",
    "    dummy_var: Dummy variable used to allow training mode to happen since it\n",
    "      requires a gradient to tie back to the graph dependency.\n",
    "\n",
    "  Returns:\n",
    "    loss: Reconstruction loss.\n",
    "    train_op: Train operation so that Estimator can correctly add to dependency\n",
    "      graph.\n",
    "    X_time: 2D tensor representation of time major input data.\n",
    "    X_time_recon: 2D tensor representation of time major input data.\n",
    "    X_feat: 2D tensor representation of feature major input data.\n",
    "    X_feat_recon: 2D tensor representation of feature major input data.\n",
    "  \"\"\"\n",
    "  # Reshape into 2-D tensors\n",
    "  # Time based\n",
    "  # shape = (cur_batch_size * seq_len, num_feat)\n",
    "  X_time = tf.reshape(\n",
    "      tensor=X,\n",
    "      shape=[cur_batch_size * params[\"seq_len\"], params[\"num_feat\"]])\n",
    "\n",
    "  # Features based\n",
    "  # shape = (cur_batch_size, num_feat, seq_len)\n",
    "  X_transposed = tf.transpose(a=X, perm=[0, 2, 1])\n",
    "\n",
    "  # shape = (cur_batch_size * num_feat, seq_len)\n",
    "  X_feat = tf.reshape(\n",
    "      tensor=X_transposed,\n",
    "      shape=[cur_batch_size * params[\"num_feat\"], params[\"seq_len\"]])\n",
    "\n",
    "  ##############################################################################\n",
    "\n",
    "  # Variables for calculating error distribution statistics\n",
    "  (pca_time_count_var,\n",
    "   pca_time_mean_var,\n",
    "   pca_time_cov_var,\n",
    "   pca_time_eigval_var,\n",
    "   pca_time_eigvec_var,\n",
    "   pca_time_k_pc_var,\n",
    "   pca_feat_count_var,\n",
    "   pca_feat_mean_var,\n",
    "   pca_feat_cov_var,\n",
    "   pca_feat_eigval_var,\n",
    "   pca_feat_eigvec_var,\n",
    "   pca_feat_k_pc_var) = create_both_pca_vars(\n",
    "      params[\"seq_len\"], params[\"num_feat\"])\n",
    "\n",
    "  # 3. Loss function, training/eval ops\n",
    "  if (mode == tf.estimator.ModeKeys.TRAIN and\n",
    "      params[\"training_mode\"] == \"reconstruction\"):\n",
    "    if not params[\"autotune_principal_components\"]:\n",
    "      with tf.variable_scope(name_or_scope=\"pca_vars\", reuse=tf.AUTO_REUSE):\n",
    "        # Check if batch is a singleton, very important for covariance math\n",
    "\n",
    "        # Time based\n",
    "        # shape = ()\n",
    "        singleton_condition = tf.equal(\n",
    "            x=cur_batch_size * params[\"seq_len\"], y=1)\n",
    "\n",
    "        pca_time_cov_var, pca_time_mean_var, pca_time_count_var = tf.cond(\n",
    "            pred=singleton_condition,\n",
    "            true_fn=lambda: singleton_batch_cov_variable_updating(\n",
    "                params[\"seq_len\"],\n",
    "                X_time,\n",
    "                pca_time_count_var,\n",
    "                pca_time_mean_var,\n",
    "                pca_time_cov_var),\n",
    "            false_fn=lambda: non_singleton_batch_cov_variable_updating(\n",
    "                cur_batch_size,\n",
    "                params[\"seq_len\"],\n",
    "                X_time,\n",
    "                pca_time_count_var,\n",
    "                pca_time_mean_var,\n",
    "                pca_time_cov_var))\n",
    "\n",
    "        # shape = (num_feat,) & (num_feat, num_feat)\n",
    "        pca_time_eigval_tensor, pca_time_eigvec_tensor = tf.linalg.eigh(\n",
    "            tensor=pca_time_cov_var)\n",
    "\n",
    "        if params[\"k_principal_components_time\"] is not None:\n",
    "          pca_time_k_pc = set_k_principal_components(\n",
    "              params[\"k_principal_components_time\"], pca_time_k_pc_var)\n",
    "        else:\n",
    "          pca_time_k_pc = tf.zeros(shape=(), dtype=tf.float64)\n",
    "\n",
    "        # Features based\n",
    "        # shape = ()\n",
    "        singleton_features_condition = tf.equal(\n",
    "            x=cur_batch_size * params[\"num_feat\"], y=1)\n",
    "\n",
    "        pca_feat_cov_var, pca_feat_mean_var, pca_feat_count_var = tf.cond(\n",
    "            pred=singleton_features_condition,\n",
    "            true_fn=lambda: singleton_batch_cov_variable_updating(\n",
    "                params[\"num_feat\"],\n",
    "                X_feat,\n",
    "                pca_feat_count_var, pca_feat_mean_var,\n",
    "                pca_feat_cov_var),\n",
    "            false_fn=lambda: non_singleton_batch_cov_variable_updating(\n",
    "                cur_batch_size,\n",
    "                params[\"num_feat\"],\n",
    "                X_feat,\n",
    "                pca_feat_count_var,\n",
    "                pca_feat_mean_var,\n",
    "                pca_feat_cov_var))\n",
    "\n",
    "        # shape = (seq_len,) & (seq_len, seq_len)\n",
    "        pca_feat_eigval_tensor, pca_feat_eigvec_tensor = tf.linalg.eigh(\n",
    "            tensor=pca_feat_cov_var)\n",
    "\n",
    "        if params[\"k_principal_components_feat\"] is not None:\n",
    "          pca_feat_k_pc = set_k_principal_components(\n",
    "              params[\"k_principal_components_feat\"], pca_feat_k_pc_var)\n",
    "        else:\n",
    "          pca_feat_k_pc = tf.zeros(shape=(), dtype=tf.float64)\n",
    "\n",
    "      # Lastly use control dependencies around loss to enforce the mahalanobis\n",
    "      # variables to be assigned, the control order matters, hence the separate\n",
    "      # contexts\n",
    "      with tf.control_dependencies(\n",
    "          control_inputs=[pca_time_cov_var, pca_feat_cov_var]):\n",
    "        with tf.control_dependencies(\n",
    "            control_inputs=[pca_time_mean_var, pca_feat_mean_var]):\n",
    "          with tf.control_dependencies(\n",
    "              control_inputs=[pca_time_count_var, pca_feat_count_var]):\n",
    "            with tf.control_dependencies(\n",
    "                control_inputs=[tf.assign(ref=pca_time_eigval_var,\n",
    "                                          value=pca_time_eigval_tensor),\n",
    "                                tf.assign(ref=pca_time_eigvec_var,\n",
    "                                          value=pca_time_eigvec_tensor),\n",
    "                                tf.assign(ref=pca_feat_eigval_var,\n",
    "                                          value=pca_feat_eigval_tensor),\n",
    "                                tf.assign(ref=pca_feat_eigvec_var,\n",
    "                                          value=pca_feat_eigvec_tensor),\n",
    "                                pca_time_k_pc,\n",
    "                                pca_feat_k_pc]):\n",
    "\n",
    "\n",
    "              loss = tf.reduce_sum(\n",
    "                  input_tensor=tf.zeros(\n",
    "                      shape=(), dtype=tf.float64) * dummy_var)\n",
    "\n",
    "              train_op = tf.contrib.layers.optimize_loss(\n",
    "                  loss=loss,\n",
    "                  global_step=tf.train.get_global_step(),\n",
    "                  learning_rate=params[\"learning_rate\"],\n",
    "                  optimizer=\"SGD\")\n",
    "\n",
    "              return loss, train_op, None, None, None, None\n",
    "    else:\n",
    "      # Time based\n",
    "      if params[\"k_principal_components_time\"] is None:\n",
    "        # shape = (cur_batch_size * seq_len, num_feat)\n",
    "        X_time_cen = X_time - pca_time_mean_var\n",
    "\n",
    "        # shape = (num_feat - 1,)\n",
    "        X_time_recon_mse = tf.map_fn(\n",
    "            fn=lambda x: pca_reconstruction_k_pc_mse(\n",
    "                X_time_cen, pca_time_eigvec_var, x),\n",
    "            elems=tf.range(start=1,\n",
    "                           limit=params[\"num_feat\"],\n",
    "                           dtype=tf.int64),\n",
    "            dtype=tf.float64)\n",
    "\n",
    "        pca_time_k_pc = find_best_k_principal_components(\n",
    "            X_time_recon_mse, pca_time_k_pc_var)\n",
    "      else:\n",
    "        pca_time_k_pc = set_k_principal_components(\n",
    "            params[\"k_principal_components_time\"], pca_time_k_pc_var)\n",
    "\n",
    "      if params[\"k_principal_components_feat\"] is None:\n",
    "        # Features based\n",
    "        # shape = (cur_batch_size * num_feat, seq_len)\n",
    "        X_feat_cen = X_feat - pca_feat_mean_var\n",
    "\n",
    "        # shape = (seq_len - 1,)\n",
    "        X_feat_recon_mse = tf.map_fn(\n",
    "            fn=lambda x: pca_reconstruction_k_pc_mse(\n",
    "                X_feat_cen, pca_feat_eigvec_var, x),\n",
    "            elems=tf.range(start=1,\n",
    "                           limit=params[\"seq_len\"],\n",
    "                           dtype=tf.int64),\n",
    "            dtype=tf.float64)\n",
    "\n",
    "        pca_feat_k_pc = find_best_k_principal_components(\n",
    "            X_feat_recon_mse, pca_feat_k_pc_var)\n",
    "      else:\n",
    "        pca_feat_k_pc = set_k_principal_components(\n",
    "            params[\"k_principal_components_feat\"], pca_feat_k_pc_var)\n",
    "\n",
    "      with tf.control_dependencies(\n",
    "          control_inputs=[pca_time_k_pc, pca_feat_k_pc]):\n",
    "        loss = tf.reduce_sum(\n",
    "            input_tensor=tf.zeros(\n",
    "                shape=(), dtype=tf.float64) * dummy_var)\n",
    "\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step(),\n",
    "            learning_rate=params[\"learning_rate\"],\n",
    "            optimizer=\"SGD\")\n",
    "\n",
    "        return loss, train_op, None, None, None, None\n",
    "\n",
    "  else:\n",
    "    # Time based\n",
    "    # shape = (cur_batch_size * seq_len, num_feat)\n",
    "    X_time_cen = X_time - pca_time_mean_var\n",
    "\n",
    "    # shape = (cur_batch_size * seq_len, num_feat)\n",
    "    if params[\"k_principal_components_time\"] is None:\n",
    "      X_time_recon = pca_reconstruction_k_pc(\n",
    "          X_time_cen,\n",
    "          pca_time_eigvec_var,\n",
    "          pca_time_k_pc_var)\n",
    "    else:\n",
    "      X_time_recon = pca_reconstruction_k_pc(\n",
    "          X_time_cen,\n",
    "          pca_time_eigvec_var,\n",
    "          params[\"k_principal_components_time\"])\n",
    "\n",
    "    # Features based\n",
    "    # shape = (cur_batch_size * num_feat, seq_len)\n",
    "    X_feat_cen = X_feat - pca_feat_mean_var\n",
    "\n",
    "    # shape = (cur_batch_size * num_feat, seq_len)\n",
    "    if params[\"k_principal_components_feat\"] is None:\n",
    "      X_feat_recon = pca_reconstruction_k_pc(\n",
    "          X_feat_cen,\n",
    "          pca_feat_eigvec_var,\n",
    "          pca_feat_k_pc_var)\n",
    "    else:\n",
    "      X_feat_recon = pca_reconstruction_k_pc(\n",
    "          X_feat_cen,\n",
    "          pca_feat_eigvec_var,\n",
    "          params[\"k_principal_components_feat\"])\n",
    "\n",
    "    return None, None, X_time_cen, X_time_recon, X_feat_cen, X_feat_recon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reconstruction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_evaluation(X_time_orig, X_time_recon, training_mode):\n",
    "  \"\"\"Reconstruction loss on evaluation set.\n",
    "\n",
    "  Given time major original and reconstructed features data and the training\n",
    "  mode, return loss and eval_metrics_ops.\n",
    "\n",
    "  Args:\n",
    "    X_time_orig: Time major original features data.\n",
    "    X_time_recon: Time major reconstructed features data.\n",
    "    training_mode: Current training mode.\n",
    "\n",
    "  Returns:\n",
    "    loss: Scalar reconstruction loss.\n",
    "    eval_metric_ops: Evaluation metrics of reconstruction.\n",
    "  \"\"\"\n",
    "  loss = tf.losses.mean_squared_error(\n",
    "      labels=X_time_orig, predictions=X_time_recon)\n",
    "\n",
    "  eval_metric_ops = None\n",
    "\n",
    "  if training_mode == \"reconstruction\":\n",
    "    # Reconstruction eval metrics\n",
    "    eval_metric_ops = {\n",
    "        \"rmse\": tf.metrics.root_mean_squared_error(\n",
    "            labels=X_time_orig, predictions=X_time_recon),\n",
    "        \"mae\": tf.metrics.mean_absolute_error(\n",
    "            labels=X_time_orig, predictions=X_time_recon)\n",
    "    }\n",
    "\n",
    "  return loss, eval_metric_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## error_distribution_vars.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mahalanobis_dist_vars(var_name, size):\n",
    "  \"\"\"Creates mahalanobis distance variables.\n",
    "\n",
    "  Given variable name and size, create and return mahalanobis distance variables\n",
    "  for count, mean, covariance, and inverse covariance.\n",
    "\n",
    "  Args:\n",
    "    var_name: String denoting which set of variables to create. Values are\n",
    "      \"time\" and \"feat\".\n",
    "    size: The size of the variable, either sequence length or number of\n",
    "      features.\n",
    "\n",
    "  Returns:\n",
    "    Mahalanobis distance variables for count, mean, covariance, and inverse\n",
    "    covariance.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=\"mahalanobis_dist_vars\", reuse=tf.AUTO_REUSE):\n",
    "    count_var = tf.get_variable(\n",
    "        name=\"abs_err_count_{0}_var\".format(var_name),\n",
    "        dtype=tf.int64,\n",
    "        initializer=tf.zeros(shape=[], dtype=tf.int64),\n",
    "        trainable=False)\n",
    "\n",
    "    mean_var = tf.get_variable(\n",
    "        name=\"abs_err_mean_{0}_var\".format(var_name),\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(shape=[size], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "    cov_var = tf.get_variable(\n",
    "        name=\"abs_err_cov_{0}_var\".format(var_name),\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(shape=[size, size], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "    inv_cov_var = tf.get_variable(\n",
    "        name=\"abs_err_inv_cov_{0}_var\".format(var_name),\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(shape=[size, size], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "  return count_var, mean_var, cov_var, inv_cov_var\n",
    "\n",
    "\n",
    "def create_both_mahalanobis_dist_vars(seq_len, num_feat):\n",
    "  \"\"\"Creates both time & feature major mahalanobis distance variables.\n",
    "\n",
    "  Given dimensions of inputs, create and return mahalanobis distance variables\n",
    "  for count, mean, covariance, and inverse covariance for both time and\n",
    "  feature major representations.\n",
    "\n",
    "  Args:\n",
    "    seq_len: Number of timesteps in sequence.\n",
    "    num_feat: Number of features.\n",
    "\n",
    "  Returns:\n",
    "    Mahalanobis distance variables for count, mean, covariance, and inverse\n",
    "    covariance for both time and feature major representations.\n",
    "  \"\"\"\n",
    "  # Time based\n",
    "  (abs_err_count_time_var,\n",
    "   abs_err_mean_time_var,\n",
    "   abs_err_cov_time_var,\n",
    "   abs_err_inv_cov_time_var) = create_mahalanobis_dist_vars(\n",
    "       var_name=\"time\", size=num_feat)\n",
    "\n",
    "  # Features based\n",
    "  (abs_err_count_feat_var,\n",
    "   abs_err_mean_feat_var,\n",
    "   abs_err_cov_feat_var,\n",
    "   abs_err_inv_cov_feat_var) = create_mahalanobis_dist_vars(\n",
    "       var_name=\"feat\", size=seq_len)\n",
    "\n",
    "  return (abs_err_count_time_var,\n",
    "          abs_err_mean_time_var,\n",
    "          abs_err_cov_time_var,\n",
    "          abs_err_inv_cov_time_var,\n",
    "          abs_err_count_feat_var,\n",
    "          abs_err_mean_feat_var,\n",
    "          abs_err_cov_feat_var,\n",
    "          abs_err_inv_cov_feat_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate_error_distribution_statistics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running covariance updating functions for mahalanobis distance variables\n",
    "def update_record_count(count_a, count_b):\n",
    "  \"\"\"Updates the running number of records processed.\n",
    "\n",
    "  Given previous running total and current batch size, return new running total.\n",
    "\n",
    "  Args:\n",
    "    count_a: tf.int64 scalar tensor of previous running total of records.\n",
    "    count_b: tf.int64 scalar tensor of current batch size.\n",
    "\n",
    "  Returns:\n",
    "    A tf.int64 scalar tensor of new running total of records.\n",
    "  \"\"\"\n",
    "  return count_a + count_b\n",
    "\n",
    "\n",
    "# Incremental covariance updating functions for mahalanobis distance variables\n",
    "\n",
    "\n",
    "def update_mean_incremental(count_a, mean_a, value_b):\n",
    "  \"\"\"Updates the running mean vector incrementally.\n",
    "\n",
    "  Given previous running total, running column means, and single example's\n",
    "  column values, return new running column means.\n",
    "\n",
    "  Args:\n",
    "    count_a: tf.int64 scalar tensor of previous running total of records.\n",
    "    mean_a: tf.float64 vector tensor of previous running column means.\n",
    "    value_b: tf.float64 vector tensor of single example's column values.\n",
    "\n",
    "  Returns:\n",
    "    A tf.float64 vector tensor of new running column means.\n",
    "  \"\"\"\n",
    "  umean_a = mean_a * tf.cast(x=count_a, dtype=tf.float64)\n",
    "  mean_ab_num = umean_a + tf.squeeze(input=value_b, axis=0)\n",
    "  mean_ab = mean_ab_num / tf.cast(x=count_a + 1, dtype=tf.float64)\n",
    "\n",
    "  return mean_ab\n",
    "\n",
    "\n",
    "# This function updates the covariance matrix incrementally\n",
    "def update_cov_incremental(\n",
    "    count_a, mean_a, cov_a, value_b, mean_ab, sample_cov):\n",
    "  \"\"\"Updates the running covariance matrix incrementally.\n",
    "\n",
    "  Given previous running total, running column means, running covariance matrix,\n",
    "  single example's column values, new running column means, and whether to use\n",
    "  sample covariance or not, return new running covariance matrix.\n",
    "\n",
    "  Args:\n",
    "    count_a: tf.int64 scalar tensor of previous running total of records.\n",
    "    mean_a: tf.float64 vector tensor of previous running column means.\n",
    "    cov_a: tf.float64 matrix tensor of previous running covariance matrix.\n",
    "    value_b: tf.float64 vector tensor of single example's column values.\n",
    "    mean_ab: tf.float64 vector tensor of new running column means.\n",
    "    sample_cov: Bool flag on whether sample or population covariance is used.\n",
    "\n",
    "  Returns:\n",
    "    A tf.float64 matrix tensor of new covariance matrix.\n",
    "  \"\"\"\n",
    "  print(\"value_b = \\n{}\".format(value_b))\n",
    "  print(\"mean_a = \\n{}\".format(mean_a))\n",
    "  print(\"mean_ab = \\n{}\".format(mean_ab))\n",
    "  mean_diff = tf.matmul(\n",
    "      a=value_b - mean_a, b=value_b - mean_ab, transpose_a=True)\n",
    "  if sample_cov:\n",
    "    ucov_a = cov_a * tf.cast(x=count_a - 1, dtype=tf.float64)\n",
    "    cov_ab = (ucov_a + mean_diff) / tf.cast(x=count_a, dtype=tf.float64)\n",
    "  else:\n",
    "    ucov_a = cov_a * tf.cast(x=count_a, dtype=tf.float64)\n",
    "    cov_ab = (ucov_a + mean_diff) / tf.cast(x=count_a + 1, dtype=tf.float64)\n",
    "\n",
    "  return cov_ab\n",
    "\n",
    "\n",
    "def singleton_batch_cov_variable_updating(\n",
    "    inner_size, X, count_variable, mean_variable, cov_variable):\n",
    "  \"\"\"Updates mahalanobis variables incrementally when number_of_rows equals 1.\n",
    "\n",
    "  Given the inner size of the matrix, the data vector X, the variable tracking\n",
    "  running record counts, the variable tracking running column means, and the\n",
    "  variable tracking running covariance matrix, returns updated running\n",
    "  covariance matrix, running column means, and running record count variables.\n",
    "\n",
    "  Args:\n",
    "    inner_size: Inner size of matrix X.\n",
    "    X: tf.float64 matrix tensor of input data.\n",
    "    count_variable: tf.int64 scalar variable tracking running record counts.\n",
    "    mean_variable: tf.float64 vector variable tracking running column means.\n",
    "    cov_variable: tf.float64 matrix variable tracking running covariance matrix.\n",
    "\n",
    "  Returns:\n",
    "    Updated running covariance matrix, running column means, and running record\n",
    "      count variables.\n",
    "  \"\"\"\n",
    "  # Calculate new combined mean for incremental covariance matrix calculation\n",
    "  # time_shape = (num_feat,), features_shape = (seq_len,)\n",
    "  mean_ab = update_mean_incremental(\n",
    "      count_a=count_variable, mean_a=mean_variable, value_b=X)\n",
    "\n",
    "  # Update running variables from single example\n",
    "  # time_shape = (), features_shape = ()\n",
    "  count_tensor = update_record_count(count_a=count_variable, count_b=1)\n",
    "\n",
    "  # time_shape = (num_feat,), features_shape = (seq_len,)\n",
    "  mean_tensor = mean_ab\n",
    "\n",
    "  # Check if inner dimension is greater than 1 to calculate covariance matrix\n",
    "  if inner_size == 1:\n",
    "    cov_tensor = tf.zeros_like(tensor=cov_variable, dtype=tf.float64)\n",
    "  else:\n",
    "    # time_shape = (num_feat, num_feat)\n",
    "    # features_shape = (seq_len, seq_len)\n",
    "    cov_tensor = update_cov_incremental(\n",
    "        count_a=count_variable,\n",
    "        mean_a=mean_variable,\n",
    "        cov_a=cov_variable,\n",
    "        value_b=X,\n",
    "        mean_ab=mean_ab,\n",
    "        sample_cov=True)\n",
    "\n",
    "  # Assign values to variables, use control dependencies around return to\n",
    "  # enforce the mahalanobis variables to be assigned, the control order matters,\n",
    "  # hence the separate contexts.\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[tf.assign(ref=cov_variable, value=cov_tensor)]):\n",
    "    with tf.control_dependencies(\n",
    "        control_inputs=[tf.assign(ref=mean_variable, value=mean_tensor)]):\n",
    "      with tf.control_dependencies(\n",
    "          control_inputs=[tf.assign(ref=count_variable, value=count_tensor)]):\n",
    "\n",
    "        return (tf.identity(input=cov_variable),\n",
    "                tf.identity(input=mean_variable),\n",
    "                tf.identity(input=count_variable))\n",
    "\n",
    "\n",
    "def singleton_batch_var_variable_updating(\n",
    "    inner_size, x, count_variable, mean_variable, var_variable):\n",
    "  \"\"\"Updates mahalanobis thresh vars incrementally when number_of_rows equals 1.\n",
    "\n",
    "  Given the inner size of the matrix, the data scalar x, the variable tracking\n",
    "  running record counts, the variable tracking the running mean, and the\n",
    "  variable tracking the running variance, returns updated running variance,\n",
    "  running mean, and running record count variables.\n",
    "\n",
    "  Args:\n",
    "    inner_size: Inner size of matrix X.\n",
    "    x: tf.float64 scalar tensor of input data.\n",
    "    count_variable: tf.int64 scalar variable tracking running record counts.\n",
    "    mean_variable: tf.float64 scalar variable tracking running mean.\n",
    "    var_variable: tf.float64 scalar variable tracking running variance.\n",
    "\n",
    "  Returns:\n",
    "    Updated running variance, running mean, and running record count variables.\n",
    "  \"\"\"\n",
    "  # Calculate new combined mean for incremental covariance matrix calculation\n",
    "  # time_shape = (), features_shape = ()\n",
    "  mean_ab = update_mean_incremental(\n",
    "      count_a=count_variable, mean_a=mean_variable, value_b=x)\n",
    "\n",
    "  # Update running variables from single example\n",
    "  # time_shape = (), features_shape = ()\n",
    "  count_tensor = update_record_count(count_a=count_variable, count_b=1)\n",
    "\n",
    "  # time_shape = (), features_shape = ()\n",
    "  mean_tensor = mean_ab\n",
    "\n",
    "  # Check if inner dimension is greater than 1 to calculate covariance matrix\n",
    "  if inner_size == 1:\n",
    "    var_tensor = tf.zeros_like(tensor=var_variable, dtype=tf.float64)\n",
    "  else:\n",
    "    # time_shape = (), features_shape = ()\n",
    "    var_tensor = update_cov_incremental(\n",
    "        count_a=count_variable,\n",
    "        mean_a=tf.reshape(tensor=mean_variable, shape=[1]),\n",
    "        cov_a=tf.reshape(tensor=var_variable, shape=[1, 1]),\n",
    "        value_b=tf.reshape(tensor=x, shape=[1, 1]),\n",
    "        mean_ab=tf.reshape(tensor=mean_ab, shape=[1]),\n",
    "        sample_cov=True)\n",
    "\n",
    "    var_tensor = tf.squeeze(input=var_tensor)\n",
    "\n",
    "  # Assign values to variables, use control dependencies around return to\n",
    "  # enforce the mahalanobis variables to be assigned, the control order matters,\n",
    "  # hence the separate contexts.\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[tf.assign(ref=var_variable, value=var_tensor)]):\n",
    "    with tf.control_dependencies(\n",
    "        control_inputs=[tf.assign(ref=mean_variable, value=mean_tensor)]):\n",
    "      with tf.control_dependencies(\n",
    "          control_inputs=[tf.assign(ref=count_variable, value=count_tensor)]):\n",
    "\n",
    "        return (tf.identity(input=var_variable),\n",
    "                tf.identity(input=mean_variable),\n",
    "                tf.identity(input=count_variable))\n",
    "\n",
    "\n",
    "# Batch covariance updating functions for mahalanobis distance variables\n",
    "\n",
    "\n",
    "def update_mean_batch(count_a, mean_a, count_b, mean_b):\n",
    "  \"\"\"Updates the running mean vector with a batch of data.\n",
    "\n",
    "  Given previous running total, running column means, current batch size, and\n",
    "  batch's column means, return new running column means.\n",
    "\n",
    "  Args:\n",
    "    count_a: tf.int64 scalar tensor of previous running total of records.\n",
    "    mean_a: tf.float64 vector tensor of previous running column means.\n",
    "    count_b: tf.int64 scalar tensor of current batch size.\n",
    "    mean_b: tf.float64 vector tensor of batch's column means.\n",
    "\n",
    "  Returns:\n",
    "    A tf.float64 vector tensor of new running column means.\n",
    "  \"\"\"\n",
    "  sum_a = mean_a * tf.cast(x=count_a, dtype=tf.float64)\n",
    "  sum_b = mean_b * tf.cast(x=count_b, dtype=tf.float64)\n",
    "  mean_ab = (sum_a + sum_b) / tf.cast(x=count_a + count_b, dtype=tf.float64)\n",
    "\n",
    "  return mean_ab\n",
    "\n",
    "\n",
    "def update_cov_batch(\n",
    "    count_a, mean_a, cov_a, count_b, mean_b, cov_b, sample_cov):\n",
    "  \"\"\"Updates the running covariance matrix with batch of data.\n",
    "\n",
    "  Given previous running total, running column means, running covariance matrix,\n",
    "  current batch size, batch's column means, batch's covariance matrix, and\n",
    "  whether to use sample covariance or not, return new running covariance matrix.\n",
    "\n",
    "  Args:\n",
    "    count_a: tf.int64 scalar tensor of previous running total of records.\n",
    "    mean_a: tf.float64 vector tensor of previous running column means.\n",
    "    cov_a: tf.float64 matrix tensor of previous running covariance matrix.\n",
    "    count_b: tf.int64 scalar tensor of current batch size.\n",
    "    mean_b: tf.float64 vector tensor of batch's column means.\n",
    "    cov_b: tf.float64 matrix tensor of batch's covariance matrix.\n",
    "    sample_cov: Bool flag on whether sample or population covariance is used.\n",
    "\n",
    "  Returns:\n",
    "    A tf.float64 matrix tensor of new running covariance matrix.\n",
    "  \"\"\"\n",
    "  mean_diff = tf.expand_dims(input=mean_a - mean_b, axis=0)\n",
    "\n",
    "  if sample_cov:\n",
    "    ucov_a = cov_a * tf.cast(x=count_a - 1, dtype=tf.float64)\n",
    "    ucov_b = cov_b * tf.cast(x=count_b - 1, dtype=tf.float64)\n",
    "    den = tf.cast(x=count_a + count_b - 1, dtype=tf.float64)\n",
    "  else:\n",
    "    ucov_a = cov_a * tf.cast(x=count_a, dtype=tf.float64)\n",
    "    ucov_b = cov_b * tf.cast(x=count_b, dtype=tf.float64)\n",
    "    den = tf.cast(x=count_a + count_b, dtype=tf.float64)\n",
    "\n",
    "  mean_diff = tf.matmul(a=mean_diff, b=mean_diff, transpose_a=True)\n",
    "  mean_scaling_num = tf.cast(x=count_a * count_b, dtype=tf.float64)\n",
    "  mean_scaling_den = tf.cast(x=count_a + count_b, dtype=tf.float64)\n",
    "  mean_scaling = mean_scaling_num / mean_scaling_den\n",
    "  cov_ab = (ucov_a + ucov_b + mean_diff * mean_scaling) / den\n",
    "\n",
    "  return cov_ab\n",
    "\n",
    "\n",
    "def non_singleton_batch_cov_variable_updating(\n",
    "    cur_batch_size, inner_size, X, count_variable, mean_variable, cov_variable):\n",
    "  \"\"\"Updates mahalanobis variables when number_of_rows does NOT equal 1.\n",
    "\n",
    "  Given the current batch size, inner size of the matrix, the data matrix X,\n",
    "  the variable tracking running record counts, the variable tracking running\n",
    "  column means, and the variable tracking running covariance matrix, returns\n",
    "  updated running covariance matrix, running column means, and running record\n",
    "  count variables.\n",
    "\n",
    "  Args:\n",
    "    cur_batch_size: Number of examples in current batch (could be partial).\n",
    "    inner_size: Inner size of matrix X.\n",
    "    X: tf.float64 matrix tensor of input data.\n",
    "    count_variable: tf.int64 scalar variable tracking running record counts.\n",
    "    mean_variable: tf.float64 vector variable tracking running column means.\n",
    "    cov_variable: tf.float64 matrix variable tracking running covariance matrix.\n",
    "\n",
    "  Returns:\n",
    "    Updated running covariance matrix, running column means, and running record\n",
    "      count variables.\n",
    "  \"\"\"\n",
    "  # Find statistics of batch\n",
    "  number_of_rows = cur_batch_size * inner_size\n",
    "\n",
    "  # time_shape = (num_feat,), features_shape = (seq_len,)\n",
    "  X_mean = tf.reduce_mean(input_tensor=X, axis=0)\n",
    "\n",
    "  # time_shape = (cur_batch_size * seq_len, num_feat)\n",
    "  # features_shape = (cur_batch_size * num_feat, seq_len)\n",
    "  X_centered = X - X_mean\n",
    "\n",
    "  if inner_size > 1:\n",
    "    # time_shape = (num_feat, num_feat)\n",
    "    # features_shape = (seq_len, seq_len)\n",
    "    X_cov = tf.matmul(\n",
    "        a=X_centered,\n",
    "        b=X_centered,\n",
    "        transpose_a=True) / tf.cast(x=number_of_rows - 1, dtype=tf.float64)\n",
    "\n",
    "  # Update running variables from batch statistics\n",
    "  # time_shape = (), features_shape = ()\n",
    "  count_tensor = update_record_count(\n",
    "      count_a=count_variable, count_b=number_of_rows)\n",
    "\n",
    "  # time_shape = (num_feat,), features_shape = (seq_len,)\n",
    "  mean_tensor = update_mean_batch(\n",
    "      count_a=count_variable,\n",
    "      mean_a=mean_variable,\n",
    "      count_b=number_of_rows,\n",
    "      mean_b=X_mean)\n",
    "\n",
    "  # Check if inner dimension is greater than 1 to calculate covariance matrix\n",
    "  if inner_size == 1:\n",
    "    cov_tensor = tf.zeros_like(tensor=cov_variable, dtype=tf.float64)\n",
    "  else:\n",
    "    # time_shape = (num_feat, num_feat)\n",
    "    # features_shape = (seq_len, seq_len)\n",
    "    cov_tensor = update_cov_batch(\n",
    "        count_a=count_variable,\n",
    "        mean_a=mean_variable,\n",
    "        cov_a=cov_variable,\n",
    "        count_b=number_of_rows,\n",
    "        mean_b=X_mean,\n",
    "        cov_b=X_cov,\n",
    "        sample_cov=True)\n",
    "\n",
    "  # Assign values to variables, use control dependencies around return to\n",
    "  # enforce the mahalanobis variables to be assigned, the control order matters,\n",
    "  # hence the separate contexts.\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[tf.assign(ref=cov_variable, value=cov_tensor)]):\n",
    "    with tf.control_dependencies(\n",
    "        control_inputs=[tf.assign(ref=mean_variable, value=mean_tensor)]):\n",
    "      with tf.control_dependencies(\n",
    "          control_inputs=[tf.assign(ref=count_variable, value=count_tensor)]):\n",
    "\n",
    "        return (tf.identity(input=cov_variable),\n",
    "                tf.identity(input=mean_variable),\n",
    "                tf.identity(input=count_variable))\n",
    "\n",
    "\n",
    "def non_singleton_batch_var_variable_updating(\n",
    "    cur_batch_size, inner_size, x, count_variable, mean_variable, var_variable):\n",
    "  \"\"\"Updates mahalanobis thresh variables when number_of_rows does NOT equal 1.\n",
    "\n",
    "  Given the current batch size, inner size of the matrix, the data vector x,\n",
    "  the variable tracking the running record count, the variable tracking the\n",
    "  running mean, and the variable tracking the running variance, returns\n",
    "  updated running variance, running mean, and running record count variables.\n",
    "\n",
    "  Args:\n",
    "    cur_batch_size: Number of examples in current batch (could be partial).\n",
    "    inner_size: Inner size of matrix X.\n",
    "    x: tf.float64 vector tensor of mahalanobis distance.\n",
    "    count_variable: tf.int64 scalar variable tracking running record count.\n",
    "    mean_variable: tf.float64 scalar variable tracking running mean.\n",
    "    var_variable: tf.float64 scalar variable tracking running variance.\n",
    "\n",
    "  Returns:\n",
    "    Updated running variance, running mean, and running record count variables.\n",
    "  \"\"\"\n",
    "  # Find statistics of batch\n",
    "  number_of_rows = cur_batch_size * inner_size\n",
    "\n",
    "  # time_shape = (), features_shape = ()\n",
    "  x_mean = tf.reduce_mean(input_tensor=x)\n",
    "\n",
    "  # time_shape = (cur_batch_size * seq_len,)\n",
    "  # features_shape = (cur_batch_size * num_feat,)\n",
    "  x_centered = x - x_mean\n",
    "\n",
    "  if inner_size > 1:\n",
    "    # time_shape = (), features_shape = ()\n",
    "    x_var = tf.reduce_sum(input_tensor=tf.square(x=x_centered))\n",
    "    x_var /= tf.cast(x=number_of_rows - 1, dtype=tf.float64)\n",
    "\n",
    "  # Update running variables from batch statistics\n",
    "  # time_shape = (), features_shape = ()\n",
    "  count_tensor = update_record_count(\n",
    "      count_a=count_variable, count_b=number_of_rows)\n",
    "\n",
    "  # time_shape = (), features_shape = ()\n",
    "  mean_tensor = update_mean_batch(\n",
    "      count_a=count_variable,\n",
    "      mean_a=mean_variable,\n",
    "      count_b=number_of_rows,\n",
    "      mean_b=x_mean)\n",
    "\n",
    "  # Check if inner dimension is greater than 1 to calculate covariance matrix\n",
    "  if inner_size == 1:\n",
    "    var_tensor = tf.zeros_like(tensor=var_variable, dtype=tf.float64)\n",
    "  else:\n",
    "    # time_shape = (num_feat, num_feat)\n",
    "    # features_shape = (seq_len, seq_len)\n",
    "    var_tensor = update_cov_batch(\n",
    "        count_a=count_variable,\n",
    "        mean_a=mean_variable,\n",
    "        cov_a=var_variable,\n",
    "        count_b=number_of_rows,\n",
    "        mean_b=tf.expand_dims(input=x_mean, axis=0),\n",
    "        cov_b=tf.reshape(tensor=x_var, shape=[1, 1]),\n",
    "        sample_cov=True)\n",
    "\n",
    "    var_tensor = tf.squeeze(input=var_tensor)\n",
    "\n",
    "  # Assign values to variables, use control dependencies around return to\n",
    "  # enforce the mahalanobis thresh variables to be assigned, the control order\n",
    "  # matters, hence the separate contexts.\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[tf.assign(ref=var_variable, value=var_tensor)]):\n",
    "    with tf.control_dependencies(\n",
    "        control_inputs=[tf.assign(ref=mean_variable, value=mean_tensor)]):\n",
    "      with tf.control_dependencies(\n",
    "          control_inputs=[tf.assign(ref=count_variable, value=count_tensor)]):\n",
    "\n",
    "        return (tf.identity(input=var_variable),\n",
    "                tf.identity(input=mean_variable),\n",
    "                tf.identity(input=count_variable))\n",
    "\n",
    "\n",
    "def mahalanobis_dist(err_vec, mean_vec, inv_cov, final_shape):\n",
    "  \"\"\"Calculates mahalanobis distance from MLE.\n",
    "\n",
    "  Given reconstruction error vector, mean reconstruction error vector, inverse\n",
    "  covariance of reconstruction error, and mahalanobis distance tensor's final\n",
    "  shape, return mahalanobis distance.\n",
    "\n",
    "  Args:\n",
    "    err_vec: tf.float64 matrix tensor of reconstruction errors.\n",
    "    mean_vec: tf.float64 vector variable tracking running column means of\n",
    "      reconstruction errors.\n",
    "    inv_cov: tf.float64 matrix variable tracking running covariance matrix of\n",
    "      reconstruction errors.\n",
    "    final_shape: Final shape of mahalanobis distance tensor.\n",
    "\n",
    "  Returns:\n",
    "    tf.float64 matrix tensor of mahalanobis distance.\n",
    "  \"\"\"\n",
    "  # time_shape = (cur_batch_size * seq_len, num_feat)\n",
    "  # features_shape = (cur_batch_size * num_feat, seq_len)\n",
    "  err_vec_cen = err_vec - mean_vec\n",
    "\n",
    "  # time_shape = (num_feat, cur_batch_size * seq_len)\n",
    "  # features_shape = (seq_len, cur_batch_size * num_feat)\n",
    "  mahalanobis_right_product = tf.matmul(\n",
    "      a=inv_cov, b=err_vec_cen, transpose_b=True)\n",
    "\n",
    "  # time_shape = (cur_batch_size * seq_len, cur_batch_size * seq_len)\n",
    "  # features_shape = (cur_batch_size * num_feat, cur_batch_size * num_feat)\n",
    "  mahalanobis_dist_vectorized = tf.matmul(\n",
    "      a=err_vec_cen, b=mahalanobis_right_product)\n",
    "\n",
    "  # time_shape = (cur_batch_size * seq_len,)\n",
    "  # features_shape = (cur_batch_size * num_feat,)\n",
    "  mahalanobis_dist_flat = tf.diag_part(input=mahalanobis_dist_vectorized)\n",
    "\n",
    "  # time_shape = (cur_batch_size, seq_len)\n",
    "  # features_shape = (cur_batch_size, num_feat)\n",
    "  mahalanobis_dist_final_shaped = tf.reshape(\n",
    "      tensor=mahalanobis_dist_flat, shape=[-1, final_shape])\n",
    "\n",
    "  # time_shape = (cur_batch_size, seq_len)\n",
    "  # features_shape = (cur_batch_size, num_feat)\n",
    "  mahalanobis_dist_final_shaped_sqrt = tf.sqrt(x=mahalanobis_dist_final_shaped)\n",
    "\n",
    "  return mahalanobis_dist_final_shaped_sqrt\n",
    "\n",
    "\n",
    "def calculate_error_distribution_statistics_training(\n",
    "    cur_batch_size,\n",
    "    X_time_abs_recon_err,\n",
    "    abs_err_count_time_var,\n",
    "    abs_err_mean_time_var,\n",
    "    abs_err_cov_time_var,\n",
    "    abs_err_inv_cov_time_var,\n",
    "    X_feat_abs_recon_err,\n",
    "    abs_err_count_feat_var,\n",
    "    abs_err_mean_feat_var,\n",
    "    abs_err_cov_feat_var,\n",
    "    abs_err_inv_cov_feat_var,\n",
    "    params,\n",
    "    dummy_var):\n",
    "  \"\"\"Calculates error distribution statistics during training mode.\n",
    "\n",
    "  Given dimensions of inputs, reconstructed inputs' absolute errors, and\n",
    "  variables tracking counts, means, and covariances of error distribution,\n",
    "  returns loss and train_op.\n",
    "\n",
    "  Args:\n",
    "    cur_batch_size: Current batch size, could be partially filled.\n",
    "    X_time_abs_recon_err: Time major reconstructed input data's absolute\n",
    "      reconstruction error.\n",
    "    abs_err_count_time_var: Time major running count of number of records.\n",
    "    abs_err_mean_time_var: Time major running column means of absolute error.\n",
    "    abs_err_cov_time_var: Time major running covariance matrix of absolute\n",
    "      error.\n",
    "    abs_err_inv_cov_time_var: Time major running inverse covariance matrix of\n",
    "    absolute error.\n",
    "    X_feat_abs_recon_err: Feature major reconstructed input data's absolute\n",
    "      reconstruction error.\n",
    "    abs_err_count_feat_var: Feature major running count of number of records.\n",
    "    abs_err_mean_feat_var: Feature major running column means of absolute error.\n",
    "    abs_err_cov_feat_var: Feature major running covariance matrix of absolute\n",
    "      error.\n",
    "    abs_err_inv_cov_feat_var: Feature major running inverse covariance matrix of\n",
    "    absolute error.\n",
    "    params: Dictionary of parameters.\n",
    "    dummy_var: Dummy variable used to allow training mode to happen since it\n",
    "      requires a gradient to tie back to the graph dependency.\n",
    "\n",
    "  Returns:\n",
    "    loss: The scalar loss to tie our updates back to Estimator graph.\n",
    "    train_op: The train operation to tie our updates back to Estimator graph.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=\"mahalanobis_dist_vars\", reuse=tf.AUTO_REUSE):\n",
    "    # Time based\n",
    "    singleton_time_condition = tf.equal(\n",
    "        x=cur_batch_size * params[\"seq_len\"], y=1)\n",
    "\n",
    "    cov_time_var, mean_time_var, count_time_var = tf.cond(\n",
    "        pred=singleton_time_condition,\n",
    "        true_fn=lambda: singleton_batch_cov_variable_updating(\n",
    "            params[\"seq_len\"],\n",
    "            X_time_abs_recon_err,\n",
    "            abs_err_count_time_var,\n",
    "            abs_err_mean_time_var,\n",
    "            abs_err_cov_time_var),\n",
    "        false_fn=lambda: non_singleton_batch_cov_variable_updating(\n",
    "            cur_batch_size,\n",
    "            params[\"seq_len\"],\n",
    "            X_time_abs_recon_err,\n",
    "            abs_err_count_time_var,\n",
    "            abs_err_mean_time_var,\n",
    "            abs_err_cov_time_var))\n",
    "\n",
    "    # Features based\n",
    "    singleton_feat_condition = tf.equal(\n",
    "        x=cur_batch_size * params[\"num_feat\"], y=1)\n",
    "\n",
    "    cov_feat_var, mean_feat_var, count_feat_var = tf.cond(\n",
    "        pred=singleton_feat_condition,\n",
    "        true_fn=lambda: singleton_batch_cov_variable_updating(\n",
    "            params[\"num_feat\"],\n",
    "            X_feat_abs_recon_err,\n",
    "            abs_err_count_feat_var,\n",
    "            abs_err_mean_feat_var,\n",
    "            abs_err_cov_feat_var),\n",
    "        false_fn=lambda: non_singleton_batch_cov_variable_updating(\n",
    "            cur_batch_size,\n",
    "            params[\"num_feat\"],\n",
    "            X_feat_abs_recon_err,\n",
    "            abs_err_count_feat_var,\n",
    "            abs_err_mean_feat_var,\n",
    "            abs_err_cov_feat_var))\n",
    "\n",
    "  # Lastly use control dependencies around loss to enforce the mahalanobis\n",
    "  # variables to be assigned, the control order matters, hence the separate\n",
    "  # contexts\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[cov_time_var, cov_feat_var]):\n",
    "    with tf.control_dependencies(\n",
    "        control_inputs=[mean_time_var, mean_feat_var]):\n",
    "      with tf.control_dependencies(\n",
    "          control_inputs=[count_time_var, count_feat_var]):\n",
    "        # Time based\n",
    "        # shape = (num_feat, num_feat)\n",
    "        abs_err_inv_cov_time_tensor = \\\n",
    "          tf.matrix_inverse(input=cov_time_var + \\\n",
    "            tf.eye(num_rows=tf.shape(input=cov_time_var)[0],\n",
    "                   dtype=tf.float64) * params[\"eps\"])\n",
    "        # Features based\n",
    "        # shape = (seq_len, seq_len)\n",
    "        abs_err_inv_cov_feat_tensor = \\\n",
    "          tf.matrix_inverse(input=cov_feat_var + \\\n",
    "            tf.eye(num_rows=tf.shape(input=cov_feat_var)[0],\n",
    "                   dtype=tf.float64) * params[\"eps\"])\n",
    "\n",
    "        with tf.control_dependencies(\n",
    "            control_inputs=[tf.assign(ref=abs_err_inv_cov_time_var,\n",
    "                                      value=abs_err_inv_cov_time_tensor),\n",
    "                            tf.assign(ref=abs_err_inv_cov_feat_var,\n",
    "                                      value=abs_err_inv_cov_feat_tensor)]):\n",
    "          loss = tf.reduce_sum(\n",
    "              input_tensor=tf.zeros(shape=(), dtype=tf.float64) * dummy_var)\n",
    "\n",
    "          train_op = tf.contrib.layers.optimize_loss(\n",
    "              loss=loss,\n",
    "              global_step=tf.train.get_global_step(),\n",
    "              learning_rate=params[\"learning_rate\"],\n",
    "              optimizer=\"SGD\")\n",
    "\n",
    "  return loss, train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tune_anomaly_threshold_vars.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix_thresh_vars(scope, var_name, size):\n",
    "  \"\"\"Creates confusion matrix threshold variables.\n",
    "\n",
    "  Given variable scope, name, and size, create and return confusion matrix\n",
    "  threshold variables for true positives, false negatives, false positives,\n",
    "  true negatives.\n",
    "\n",
    "  Args:\n",
    "    scope: String of variable scope name.\n",
    "    var_name: String denoting which set of variables to create. Values are\n",
    "      \"time\" and \"feat\".\n",
    "    size: The size of the variable, number of time/feature thresholds.\n",
    "\n",
    "  Returns:\n",
    "    Confusion matrix threshold variables for true positives, false negatives,\n",
    "    false positives, true negatives.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=scope, reuse=tf.AUTO_REUSE):\n",
    "    tp_thresh_var = tf.get_variable(\n",
    "        name=\"tp_thresh_{0}_var\".format(var_name),\n",
    "        dtype=tf.int64,\n",
    "        initializer=tf.zeros(\n",
    "            shape=size, dtype=tf.int64),\n",
    "        trainable=False)\n",
    "\n",
    "    fn_thresh_var = tf.get_variable(\n",
    "        name=\"fn_thresh_{0}_var\".format(var_name),\n",
    "        dtype=tf.int64,\n",
    "        initializer=tf.zeros(\n",
    "            shape=size, dtype=tf.int64),\n",
    "        trainable=False)\n",
    "\n",
    "    fp_thresh_var = tf.get_variable(\n",
    "        name=\"fp_thresh_{0}_var\".format(var_name),\n",
    "        dtype=tf.int64,\n",
    "        initializer=tf.zeros(\n",
    "            shape=size, dtype=tf.int64),\n",
    "        trainable=False)\n",
    "\n",
    "    tn_thresh_var = tf.get_variable(\n",
    "        name=\"tn_thresh_{0}_var\".format(var_name),\n",
    "        dtype=tf.int64,\n",
    "        initializer=tf.zeros(\n",
    "            shape=size, dtype=tf.int64),\n",
    "        trainable=False)\n",
    "\n",
    "    return (tp_thresh_var,\n",
    "            fn_thresh_var,\n",
    "            fp_thresh_var,\n",
    "            tn_thresh_var)\n",
    "\n",
    "\n",
    "def create_both_confusion_matrix_thresh_vars(\n",
    "    scope, time_thresh_size, feat_thresh_size):\n",
    "  \"\"\"Creates both time & feature major confusion matrix threshold variables.\n",
    "\n",
    "  Given variable scope and sizes, create and return confusion\n",
    "  matrix threshold variables for true positives, false negatives, false\n",
    "  positives, and true negatives for both time and feature major\n",
    "  representations.\n",
    "\n",
    "  Args:\n",
    "    scope: String of variable scope name.\n",
    "    time_thresh_size: Variable size of number of time major thresholds.\n",
    "    feat_thresh_size: Variable size of number of feature major thresholds.\n",
    "\n",
    "  Returns:\n",
    "    Confusion matrix threshold variables for true positives, false negatives,\n",
    "    false positives, true negatives for both time and feature major\n",
    "    representations.\n",
    "  \"\"\"\n",
    "  # Time based\n",
    "  (tp_thresh_time_var,\n",
    "   fn_thresh_time_var,\n",
    "   fp_thresh_time_var,\n",
    "   tn_thresh_time_var) = create_confusion_matrix_thresh_vars(\n",
    "       scope=scope, var_name=\"time\", size=time_thresh_size)\n",
    "\n",
    "  # Features based\n",
    "  (tp_thresh_feat_var,\n",
    "   fn_thresh_feat_var,\n",
    "   fp_thresh_feat_var,\n",
    "   tn_thresh_feat_var) = create_confusion_matrix_thresh_vars(\n",
    "       scope=scope, var_name=\"feat\", size=feat_thresh_size)\n",
    "\n",
    "  return (tp_thresh_time_var,\n",
    "          fn_thresh_time_var,\n",
    "          fp_thresh_time_var,\n",
    "          tn_thresh_time_var,\n",
    "          tp_thresh_feat_var,\n",
    "          fn_thresh_feat_var,\n",
    "          fp_thresh_feat_var,\n",
    "          tn_thresh_feat_var)\n",
    "\n",
    "\n",
    "def create_mahalanobis_unsupervised_thresh_vars(scope, var_name):\n",
    "  \"\"\"Creates mahalanobis unsupervised threshold variables.\n",
    "\n",
    "  Given variable scope and name, create and return mahalanobis unsupervised\n",
    "  threshold variables of mean and standard deviation.\n",
    "\n",
    "  Args:\n",
    "    scope: String of variable scope name.\n",
    "    var_name: String denoting which set of variables to create. Values are\n",
    "      \"time\" and \"feat\".\n",
    "\n",
    "  Returns:\n",
    "    Mahalanobis unsupervised threshold variables of count, mean, and standard\n",
    "    deviation.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=scope, reuse=tf.AUTO_REUSE):\n",
    "    count_thresh_var = tf.get_variable(\n",
    "        name=\"count_thresh_{0}_var\".format(var_name),\n",
    "        dtype=tf.int64,\n",
    "        initializer=tf.zeros(\n",
    "            shape=[], dtype=tf.int64),\n",
    "        trainable=False)\n",
    "\n",
    "    mean_thresh_var = tf.get_variable(\n",
    "        name=\"mean_thresh_{0}_var\".format(var_name),\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(\n",
    "            shape=[], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "    var_thresh_var = tf.get_variable(\n",
    "        name=\"var_thresh_{0}_var\".format(var_name),\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(\n",
    "            shape=[], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "    return (count_thresh_var,\n",
    "            mean_thresh_var,\n",
    "            var_thresh_var)\n",
    "\n",
    "\n",
    "def create_both_mahalanobis_unsupervised_thresh_vars(scope):\n",
    "  \"\"\"Creates time & feature mahalanobis unsupervised threshold variables.\n",
    "\n",
    "  Given variable scope, create and return mahalanobis unsupervised\n",
    "  threshold variables of mean and standard deviation for both time and\n",
    "  feature major representations.\n",
    "\n",
    "  Args:\n",
    "    scope: String of variable scope name.\n",
    "\n",
    "  Returns:\n",
    "    Mahalanobis unsupervised threshold variables of mean and standard\n",
    "    deviation for both time and feature major representations.\n",
    "  \"\"\"\n",
    "  # Time based\n",
    "  (count_thresh_time_var,\n",
    "   mean_thresh_time_var,\n",
    "   var_thresh_time_var) = create_mahalanobis_unsupervised_thresh_vars(\n",
    "       scope=scope, var_name=\"time\")\n",
    "\n",
    "  # Features based\n",
    "  (count_thresh_feat_var,\n",
    "   mean_thresh_feat_var,\n",
    "   var_thresh_feat_var) = create_mahalanobis_unsupervised_thresh_vars(\n",
    "       scope=scope, var_name=\"feat\")\n",
    "\n",
    "  return (count_thresh_time_var,\n",
    "          mean_thresh_time_var,\n",
    "          var_thresh_time_var,\n",
    "          count_thresh_feat_var,\n",
    "          mean_thresh_feat_var,\n",
    "          var_thresh_feat_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tune_anomaly_thresholds_supervised.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_threshold_confusion_matrix(labels_mask, preds, num_thresh):\n",
    "  \"\"\"Calculates confusion matrix based on thresholds.\n",
    "\n",
    "  Given labels mask, predictions, and number of thresholds, returns count\n",
    "  for cell in confusion matrix.\n",
    "\n",
    "  Args:\n",
    "    labels_mask: tf.bool vector tensor when label was normal or\n",
    "      anomalous.\n",
    "    preds: Predicted anomaly labels.\n",
    "    num_thresh: Number of anomaly thresholds to try in parallel grid search.\n",
    "\n",
    "  Returns:\n",
    "    Count for cell in confusion matrix.\n",
    "  \"\"\"\n",
    "  count = tf.reduce_sum(\n",
    "      input_tensor=tf.cast(\n",
    "          x=tf.map_fn(\n",
    "              fn=lambda threshold: tf.logical_and(\n",
    "                  x=labels_mask,\n",
    "                  y=preds[threshold, :]),\n",
    "              elems=tf.range(start=0, limit=num_thresh, dtype=tf.int64),\n",
    "              dtype=tf.bool),\n",
    "          dtype=tf.int64),\n",
    "      axis=1)\n",
    "\n",
    "  return count\n",
    "\n",
    "\n",
    "def update_anom_thresh_vars(\n",
    "    labels_norm_mask,\n",
    "    labels_anom_mask,\n",
    "    num_thresh,\n",
    "    anom_thresh,\n",
    "    mahalanobis_dist,\n",
    "    tp_at_thresh_var,\n",
    "    fn_at_thresh_var,\n",
    "    fp_at_thresh_var,\n",
    "    tn_at_thresh_var,\n",
    "    mode):\n",
    "  \"\"\"Updates anomaly threshold variables.\n",
    "\n",
    "  Given masks for when labels are normal and anomalous, the number of anomaly\n",
    "  thresholds and the thresholds themselves, the mahalanobis distance, variables\n",
    "  for the confusion matrix, and the current Estimator mode, returns the updated\n",
    "  variables for the confusion matrix.\n",
    "\n",
    "  Args:\n",
    "    labels_norm_mask: tf.bool vector tensor that is true when label was normal.\n",
    "    labels_anom_mask: tf.bool vector tensor that is true when label was\n",
    "      anomalous.\n",
    "    num_thresh: Number of anomaly thresholds to try in parallel grid search.\n",
    "    anom_thresh: tf.float64 vector tensor of grid of anomaly thresholds to try.\n",
    "    mahalanobis_dist: tf.float64 matrix tensor of mahalanobis distances across\n",
    "      batch.\n",
    "    tp_at_thresh_var: tf.int64 variable tracking number of true positives at\n",
    "      each possible anomaly threshold.\n",
    "    fn_at_thresh_var: tf.int64 variable tracking number of false negatives at\n",
    "      each possible anomaly threshold.\n",
    "    fp_at_thresh_var: tf.int64 variable tracking number of false positives at\n",
    "      each possible anomaly threshold.\n",
    "    tn_at_thresh_var: tf.int64 variable tracking number of true negatives at\n",
    "      each possible anomaly threshold.\n",
    "    mode: Estimator ModeKeys, can take values of TRAIN and EVAL.\n",
    "\n",
    "  Returns:\n",
    "    Updated confusion matrix variables.\n",
    "  \"\"\"\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    # time_shape = (num_time_anom_thresh, cur_batch_size, seq_len)\n",
    "    # feat_shape = (num_feat_anom_thresh, cur_batch_size, num_feat)\n",
    "    mahalanobis_dist_over_thresh = tf.map_fn(\n",
    "        fn=lambda anom_threshold: mahalanobis_dist > anom_threshold,\n",
    "        elems=anom_thresh,\n",
    "        dtype=tf.bool)\n",
    "  else:\n",
    "    # time_shape = (cur_batch_size, seq_len)\n",
    "    # feat_shape = (cur_batch_size, num_feat)\n",
    "    mahalanobis_dist_over_thresh = mahalanobis_dist > anom_thresh\n",
    "\n",
    "  # time_shape = (num_time_anom_thresh, cur_batch_size)\n",
    "  # feat_shape = (num_feat_anom_thresh, cur_batch_size)\n",
    "  mahalanobis_dist_any_over_thresh = tf.reduce_any(\n",
    "      input_tensor=mahalanobis_dist_over_thresh, axis=-1)\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.EVAL:\n",
    "    # time_shape = (1, cur_batch_size)\n",
    "    # feat_shape = (1, cur_batch_size)\n",
    "    mahalanobis_dist_any_over_thresh = tf.expand_dims(\n",
    "        input=mahalanobis_dist_any_over_thresh, axis=0)\n",
    "\n",
    "  # time_shape = (num_time_anom_thresh, cur_batch_size)\n",
    "  # feat_shape = (num_feat_anom_thresh, cur_batch_size)\n",
    "  predicted_normals = tf.equal(\n",
    "      x=mahalanobis_dist_any_over_thresh, y=False)\n",
    "\n",
    "  # time_shape = (num_time_anom_thresh, cur_batch_size)\n",
    "  # feat_shape = (num_feat_anom_thresh, cur_batch_size)\n",
    "  predicted_anomalies = tf.equal(\n",
    "      x=mahalanobis_dist_any_over_thresh, y=True)\n",
    "\n",
    "  # Calculate confusion matrix of current batch\n",
    "  # time_shape = (num_time_anom_thresh,)\n",
    "  # feat_shape = (num_feat_anom_thresh,)\n",
    "  tp = calculate_threshold_confusion_matrix(\n",
    "      labels_anom_mask, predicted_anomalies, num_thresh)\n",
    "\n",
    "  fn = calculate_threshold_confusion_matrix(\n",
    "      labels_anom_mask, predicted_normals, num_thresh)\n",
    "\n",
    "  fp = calculate_threshold_confusion_matrix(\n",
    "      labels_norm_mask, predicted_anomalies, num_thresh)\n",
    "\n",
    "  tn = calculate_threshold_confusion_matrix(\n",
    "      labels_norm_mask, predicted_normals, num_thresh)\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.EVAL:\n",
    "    # shape = ()\n",
    "    tp = tf.squeeze(input=tp)\n",
    "    fn = tf.squeeze(input=fn)\n",
    "    fp = tf.squeeze(input=fp)\n",
    "    tn = tf.squeeze(input=tn)\n",
    "\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[tf.assign_add(ref=tp_at_thresh_var, value=tp),\n",
    "                      tf.assign_add(ref=fn_at_thresh_var, value=fn),\n",
    "                      tf.assign_add(ref=fp_at_thresh_var, value=fp),\n",
    "                      tf.assign_add(ref=tn_at_thresh_var, value=tn)]):\n",
    "\n",
    "    return (tf.identity(input=tp_at_thresh_var),\n",
    "            tf.identity(input=fn_at_thresh_var),\n",
    "            tf.identity(input=fp_at_thresh_var),\n",
    "            tf.identity(input=tn_at_thresh_var))\n",
    "\n",
    "\n",
    "def calculate_composite_classification_metrics(tp, fn, fp, tn, f_score_beta):\n",
    "  \"\"\"Calculates compositive classification metrics from the confusion matrix.\n",
    "\n",
    "  Given variables for the confusion matrix and the value of beta for f-beta\n",
    "  score, returns accuracy, precision, recall, and f-beta score composite\n",
    "  metrics.\n",
    "\n",
    "  Args:\n",
    "    tp: tf.int64 variable tracking number of true positives at\n",
    "      each possible anomaly threshold.\n",
    "    fn: tf.int64 variable tracking number of false negatives at\n",
    "      each possible anomaly threshold.\n",
    "    fp: tf.int64 variable tracking number of false positives at\n",
    "      each possible anomaly threshold.\n",
    "    tn: tf.int64 variable tracking number of true negatives at\n",
    "      each possible anomaly threshold.\n",
    "    f_score_beta: Value of beta for f-beta score.\n",
    "\n",
    "  Returns:\n",
    "    Accuracy, precision, recall, and f-beta score composite metric tensors.\n",
    "  \"\"\"\n",
    "  # time_shape = (num_time_anom_thresh,)\n",
    "  # feat_shape = (num_feat_anom_thresh,)\n",
    "  acc = tf.cast(x=tp + tn, dtype=tf.float64) \\\n",
    "    / tf.cast(x=tp + fn + fp + tn, dtype=tf.float64)\n",
    "  tp_float64 = tf.cast(x=tp, dtype=tf.float64)\n",
    "  pre = tp_float64 / tf.cast(x=tp + fp, dtype=tf.float64)\n",
    "  rec = tp_float64 / tf.cast(x=tp + fn, dtype=tf.float64)\n",
    "  f_beta_numerator = (1.0 + f_score_beta ** 2) * (pre * rec)\n",
    "  f_beta_score = f_beta_numerator / (f_score_beta ** 2 * pre + rec)\n",
    "\n",
    "  return acc, pre, rec, f_beta_score\n",
    "\n",
    "\n",
    "def find_best_anom_thresh(\n",
    "    anom_threshs, f_beta_score, anom_thresh_var):\n",
    "  \"\"\"Find best anomaly threshold to use for anomaly classification.\n",
    "\n",
    "  Given vector of anomaly thresholds and the value of beta for f-beta score,\n",
    "  returns updated variable that stores the best anomaly threshold value.\n",
    "\n",
    "  Args:\n",
    "    anom_threshs: tf.float64 vector tensor of grid of anomaly thresholds to try.\n",
    "    f_beta_score: tf.float64 vector tensor of f-beta scores for each anomaly\n",
    "      threshold.\n",
    "    anom_thresh_var: tf.float64 variable that stores anomaly threshold value.\n",
    "\n",
    "  Returns:\n",
    "    Updated variable that stores the anomaly threshold value.\n",
    "  \"\"\"\n",
    "  # shape = ()\n",
    "  best_anom_thresh = tf.gather(\n",
    "      params=anom_threshs, indices=tf.argmax(input=f_beta_score, axis=0))\n",
    "\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[tf.assign(\n",
    "          ref=anom_thresh_var, value=best_anom_thresh)]):\n",
    "\n",
    "    return tf.identity(input=anom_thresh_var)\n",
    "\n",
    "\n",
    "def optimize_anomaly_theshold(\n",
    "    var_name,\n",
    "    labels_norm_mask,\n",
    "    labels_anom_mask,\n",
    "    mahalanobis_dist,\n",
    "    tp_thresh_var,\n",
    "    fn_thresh_var,\n",
    "    fp_thresh_var,\n",
    "    tn_thresh_var,\n",
    "    params,\n",
    "    mode,\n",
    "    anom_thresh_var):\n",
    "  \"\"\"Optimizes anomaly threshold for anomaly classification.\n",
    "\n",
    "  Given variable name, label masks, mahalanobis distance, variables for\n",
    "  confusion matrix, and dictionary of parameters, returns accuracy, precision,\n",
    "  recall, and f-beta score composite metrics.\n",
    "\n",
    "  Args:\n",
    "    var_name: String denoting which set of variables to use. Values are\n",
    "      \"time\" and \"feat\".\n",
    "    labels_norm_mask: tf.bool vector mask of labels for normals.\n",
    "    labels_anom_mask: tf.bool vector mask of labels for anomalies.\n",
    "    mahalanobis_dist: Mahalanobis distance of reconstruction error.\n",
    "    tp_thresh_var: tf.int64 variable to track number of true positives wrt\n",
    "      thresholds.\n",
    "    fn_thresh_var: tf.int64 variable to track number of false negatives wrt\n",
    "      thresholds.\n",
    "    fp_thresh_var: tf.int64 variable to track number of false positives wrt\n",
    "      thresholds.\n",
    "    tn_thresh_var: tf.int64 variable to track number of true negatives wrt\n",
    "      thresholds.\n",
    "    params: Dictionary of parameters.\n",
    "    mode: Estimator ModeKeys, can take values of TRAIN and EVAL.\n",
    "    anom_thresh_var: tf.float64 variable that stores anomaly threshold value.\n",
    "\n",
    "  Returns:\n",
    "    Updated variable that stores the anomaly threshold value\n",
    "  \"\"\"\n",
    "  # shape = (num_anom_thresh,)\n",
    "  anom_threshs = tf.linspace(\n",
    "      start=tf.constant(\n",
    "          value=params[\"min_{}_anom_thresh\".format(var_name)],\n",
    "          dtype=tf.float64),\n",
    "      stop=tf.constant(\n",
    "          value=params[\"max_{}_anom_thresh\".format(var_name)],\n",
    "          dtype=tf.float64),\n",
    "      num=params[\"num_{}_anom_thresh\".format(var_name)])\n",
    "\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=\"mahalanobis_dist_thresh_vars\",\n",
    "      reuse=tf.AUTO_REUSE):\n",
    "    (tp_update_op,\n",
    "     fn_update_op,\n",
    "     fp_update_op,\n",
    "     tn_update_op) = \\\n",
    "      update_anom_thresh_vars(\n",
    "          labels_norm_mask,\n",
    "          labels_anom_mask,\n",
    "          params[\"num_{}_anom_thresh\".format(var_name)],\n",
    "          anom_threshs,\n",
    "          mahalanobis_dist,\n",
    "          tp_thresh_var,\n",
    "          fn_thresh_var,\n",
    "          fp_thresh_var,\n",
    "          tn_thresh_var,\n",
    "          mode)\n",
    "\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[\n",
    "          tp_update_op,\n",
    "          fn_update_op,\n",
    "          fp_update_op,\n",
    "          tn_update_op]):\n",
    "    _, pre, rec, f_beta = \\\n",
    "      calculate_composite_classification_metrics(\n",
    "          tp_thresh_var,\n",
    "          fn_thresh_var,\n",
    "          fp_thresh_var,\n",
    "          tn_thresh_var,\n",
    "          params[\"f_score_beta\"])\n",
    "\n",
    "    with tf.control_dependencies(control_inputs=[pre, rec]):\n",
    "      with tf.control_dependencies(control_inputs=[f_beta]):\n",
    "        best_anom_thresh = find_best_anom_thresh(\n",
    "            anom_threshs,\n",
    "            f_beta,\n",
    "            anom_thresh_var)\n",
    "        with tf.control_dependencies(control_inputs=[best_anom_thresh]):\n",
    "          return tf.identity(input=anom_thresh_var)\n",
    "\n",
    "\n",
    "def set_anom_thresh(user_passed_anom_thresh, anom_thresh_var):\n",
    "  \"\"\"Set anomaly threshold to use for anomaly classification from user input.\n",
    "\n",
    "  Given user passed anomaly threshold returns updated variable that stores\n",
    "  the anomaly threshold value.\n",
    "\n",
    "  Args:\n",
    "    user_passed_anom_thresh: User passed anomaly threshold that overrides\n",
    "      the threshold optimization.\n",
    "    anom_thresh_var: tf.float64 variable that stores anomaly threshold value.\n",
    "\n",
    "  Returns:\n",
    "    Updated variable that stores the anomaly threshold value.\n",
    "  \"\"\"\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[tf.assign(\n",
    "          ref=anom_thresh_var, value=user_passed_anom_thresh)]):\n",
    "\n",
    "    return tf.identity(input=anom_thresh_var)\n",
    "\n",
    "\n",
    "def tune_anomaly_thresholds_supervised_training(\n",
    "    labels_norm_mask,\n",
    "    labels_anom_mask,\n",
    "    mahalanobis_dist_time,\n",
    "    tp_thresh_time_var,\n",
    "    fn_thresh_time_var,\n",
    "    fp_thresh_time_var,\n",
    "    tn_thresh_time_var,\n",
    "    time_anom_thresh_var,\n",
    "    mahalanobis_dist_feat,\n",
    "    tp_thresh_feat_var,\n",
    "    fn_thresh_feat_var,\n",
    "    fp_thresh_feat_var,\n",
    "    tn_thresh_feat_var,\n",
    "    feat_anom_thresh_var,\n",
    "    params,\n",
    "    mode,\n",
    "    dummy_var):\n",
    "  \"\"\"Tunes anomaly thresholds during supervised training mode.\n",
    "\n",
    "  Given label masks, mahalanobis distances, confusion matrices, and anomaly\n",
    "  thresholds, returns loss and train_op.\n",
    "\n",
    "  Args:\n",
    "    labels_norm_mask: tf.bool vector mask of labels for normals.\n",
    "    labels_anom_mask: tf.bool vector mask of labels for anomalies.\n",
    "    mahalanobis_dist_time: Mahalanobis distance, time major.\n",
    "    tp_thresh_time_var: tf.int64 variable to track number of true positives wrt\n",
    "      thresholds for time major case.\n",
    "    fn_thresh_time_var: tf.int64 variable to track number of false negatives wrt\n",
    "      thresholds for time major case.\n",
    "    fp_thresh_time_var: tf.int64 variable to track number of false positives wrt\n",
    "      thresholds for time major case.\n",
    "    tn_thresh_time_var: tf.int64 variable to track number of true negatives wrt\n",
    "      thresholds for time major case.\n",
    "    time_anom_thresh_var: tf.float64 variable to hold the set time anomaly\n",
    "      threshold.\n",
    "    mahalanobis_dist_feat: Mahalanobis distance, features major.\n",
    "    tp_thresh_feat_var: tf.int64 variable to track number of true positives wrt\n",
    "      thresholds for feat major case.\n",
    "    fn_thresh_feat_var: tf.int64 variable to track number of false negatives wrt\n",
    "      thresholds for feat major case.\n",
    "    fp_thresh_feat_var: tf.int64 variable to track number of false positives wrt\n",
    "      thresholds for feat major case.\n",
    "    tn_thresh_feat_var: tf.int64 variable to track number of true negatives wrt\n",
    "      thresholds for feat major case.\n",
    "    feat_anom_thresh_var: tf.float64 variable to hold the set feat anomaly\n",
    "      threshold.\n",
    "    params: Dictionary of parameters.\n",
    "    mode: Estimator ModeKeys. Can take value of only TRAIN.\n",
    "    dummy_var: Dummy variable used to allow training mode to happen since it\n",
    "      requires a gradient to tie back to the graph dependency.\n",
    "\n",
    "  Returns:\n",
    "    loss: The scalar loss to tie our updates back to Estimator graph.\n",
    "    train_op: The train operation to tie our updates back to Estimator graph.\n",
    "  \"\"\"\n",
    "  # Time based\n",
    "  if params[\"time_anom_thresh\"] is None:\n",
    "    best_anom_thresh_time = optimize_anomaly_theshold(\n",
    "        \"time\",\n",
    "        labels_norm_mask,\n",
    "        labels_anom_mask,\n",
    "        mahalanobis_dist_time,\n",
    "        tp_thresh_time_var,\n",
    "        fn_thresh_time_var,\n",
    "        fp_thresh_time_var,\n",
    "        tn_thresh_time_var,\n",
    "        params,\n",
    "        mode,\n",
    "        time_anom_thresh_var)\n",
    "  else:\n",
    "    best_anom_thresh_time = set_anom_thresh(\n",
    "        params[\"time_anom_thresh\"], time_anom_thresh_var)\n",
    "\n",
    "  # Features based\n",
    "  if params[\"feat_anom_thresh\"] is None:\n",
    "    best_anom_thresh_feat = optimize_anomaly_theshold(\n",
    "        \"feat\",\n",
    "        labels_norm_mask,\n",
    "        labels_anom_mask,\n",
    "        mahalanobis_dist_feat,\n",
    "        tp_thresh_feat_var,\n",
    "        fn_thresh_feat_var,\n",
    "        fp_thresh_feat_var,\n",
    "        tn_thresh_feat_var,\n",
    "        params,\n",
    "        mode,\n",
    "        feat_anom_thresh_var)\n",
    "  else:\n",
    "    best_anom_thresh_feat = set_anom_thresh(\n",
    "        params[\"feat_anom_thresh\"], feat_anom_thresh_var)\n",
    "\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[best_anom_thresh_time,\n",
    "                      best_anom_thresh_feat]):\n",
    "    loss = tf.reduce_sum(\n",
    "        input_tensor=tf.zeros(\n",
    "            shape=(), dtype=tf.float64) * dummy_var)\n",
    "\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step(),\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        optimizer=\"SGD\")\n",
    "\n",
    "    return loss, train_op\n",
    "\n",
    "\n",
    "def tune_anomaly_thresholds_supervised_eval(\n",
    "    labels_norm_mask,\n",
    "    labels_anom_mask,\n",
    "    time_anom_thresh_var,\n",
    "    mahalanobis_dist_time,\n",
    "    tp_thresh_eval_time_var,\n",
    "    fn_thresh_eval_time_var,\n",
    "    fp_thresh_eval_time_var,\n",
    "    tn_thresh_eval_time_var,\n",
    "    feat_anom_thresh_var,\n",
    "    mahalanobis_dist_feat,\n",
    "    tp_thresh_eval_feat_var,\n",
    "    fn_thresh_eval_feat_var,\n",
    "    fp_thresh_eval_feat_var,\n",
    "    tn_thresh_eval_feat_var,\n",
    "    params,\n",
    "    mode):\n",
    "  \"\"\"Checks tuned anomaly thresholds during supervised evaluation mode.\n",
    "\n",
    "  Given label masks, mahalanobis distances, confusion matrices, and anomaly\n",
    "  thresholds, returns loss and eval_metric_ops.\n",
    "\n",
    "  Args:\n",
    "    labels_norm_mask: tf.bool vector mask of labels for normals.\n",
    "    labels_anom_mask: tf.bool vector mask of labels for anomalies.\n",
    "    time_anom_thresh_var: tf.float64 scalar time anomaly threshold value.\n",
    "    mahalanobis_dist_time: Mahalanobis distance, time major.\n",
    "    tp_thresh_eval_time_var: tf.int64 variable to track number of true\n",
    "      positives wrt thresholds for time major case for evaluation.\n",
    "    fn_thresh_eval_time_var: tf.int64 variable to track number of false\n",
    "      negatives wrt thresholds for time major case for evaluation.\n",
    "    fp_thresh_eval_time_var: tf.int64 variable to track number of false\n",
    "      positives wrt thresholds for time major case for evaluation.\n",
    "    tn_thresh_eval_time_var: tf.int64 variable to track number of true\n",
    "      negatives wrt thresholds for time major case for evaluation.\n",
    "    feat_anom_thresh_var: tf.float64 scalar feature anomaly threshold value.\n",
    "    mahalanobis_dist_feat: Mahalanobis distance, features major.\n",
    "    tp_thresh_eval_feat_var: tf.int64 variable to track number of true\n",
    "      positives wrt thresholds for feat major case for evaluation.\n",
    "    fn_thresh_eval_feat_var: tf.int64 variable to track number of false\n",
    "      negatives wrt thresholds for feat major case for evaluation.\n",
    "    fp_thresh_eval_feat_var: tf.int64 variable to track number of false\n",
    "      positives wrt thresholds for feat major case for evaluation.\n",
    "    tn_thresh_eval_feat_var: tf.int64 variable to track number of true\n",
    "      negatives wrt thresholds for feat major case for evaluation.\n",
    "    params: Dictionary of parameters.\n",
    "    mode: Estimator ModeKeys. Can take value of only EVAL.\n",
    "\n",
    "  Returns:\n",
    "    loss: Scalar reconstruction loss.\n",
    "    eval_metric_ops: Evaluation metrics of threshold tuning.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=\"anom_thresh_eval_vars\", reuse=tf.AUTO_REUSE):\n",
    "    # Time based\n",
    "    (tp_time_update_op,\n",
    "     fn_time_update_op,\n",
    "     fp_time_update_op,\n",
    "     tn_time_update_op) = \\\n",
    "      update_anom_thresh_vars(\n",
    "          labels_norm_mask,\n",
    "          labels_anom_mask,\n",
    "          1,\n",
    "          time_anom_thresh_var,\n",
    "          mahalanobis_dist_time,\n",
    "          tp_thresh_eval_time_var,\n",
    "          fn_thresh_eval_time_var,\n",
    "          fp_thresh_eval_time_var,\n",
    "          tn_thresh_eval_time_var,\n",
    "          mode)\n",
    "\n",
    "    # Features based\n",
    "    (tp_feat_update_op,\n",
    "     fn_feat_update_op,\n",
    "     fp_feat_update_op,\n",
    "     tn_feat_update_op) = \\\n",
    "      update_anom_thresh_vars(\n",
    "          labels_norm_mask,\n",
    "          labels_anom_mask,\n",
    "          1,\n",
    "          feat_anom_thresh_var,\n",
    "          mahalanobis_dist_feat,\n",
    "          tp_thresh_eval_feat_var,\n",
    "          fn_thresh_eval_feat_var,\n",
    "          fp_thresh_eval_feat_var,\n",
    "          tn_thresh_eval_feat_var,\n",
    "          mode)\n",
    "\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=\"anom_thresh_eval_vars\", reuse=tf.AUTO_REUSE):\n",
    "    # Time based\n",
    "    (acc_time_update_op,\n",
    "     pre_time_update_op,\n",
    "     rec_time_update_op,\n",
    "     f_beta_time_update_op) = \\\n",
    "      calculate_composite_classification_metrics(\n",
    "          tp_thresh_eval_time_var,\n",
    "          fn_thresh_eval_time_var,\n",
    "          fp_thresh_eval_time_var,\n",
    "          tn_thresh_eval_time_var,\n",
    "          params[\"f_score_beta\"])\n",
    "\n",
    "    # Features based\n",
    "    (acc_feat_update_op,\n",
    "     pre_feat_update_op,\n",
    "     rec_feat_update_op,\n",
    "     f_beta_feat_update_op) = \\\n",
    "      calculate_composite_classification_metrics(\n",
    "          tp_thresh_eval_feat_var,\n",
    "          fn_thresh_eval_feat_var,\n",
    "          fp_thresh_eval_feat_var,\n",
    "          tn_thresh_eval_feat_var,\n",
    "          params[\"f_score_beta\"])\n",
    "\n",
    "  loss = tf.zeros(shape=[], dtype=tf.float64)\n",
    "\n",
    "  # Time based\n",
    "  acc_trues = tf.cast(\n",
    "      x=tp_thresh_eval_time_var + tn_thresh_eval_time_var,\n",
    "      dtype=tf.float64)\n",
    "  acc_falses = tf.cast(\n",
    "      x=fp_thresh_eval_time_var + fn_thresh_eval_time_var,\n",
    "      dtype=tf.float64)\n",
    "  acc_thresh_eval_time_var = acc_trues / (acc_trues + acc_falses)\n",
    "\n",
    "  tp_float = tf.cast(x=tp_thresh_eval_time_var, dtype=tf.float64)\n",
    "\n",
    "  pre_denominator = tf.cast(\n",
    "      x=tp_thresh_eval_time_var + fp_thresh_eval_time_var,\n",
    "      dtype=tf.float64)\n",
    "  pre_thresh_eval_time_var = tp_float / pre_denominator\n",
    "\n",
    "  rec_denominator = tf.cast(\n",
    "      x=tp_thresh_eval_time_var + fn_thresh_eval_time_var,\n",
    "      dtype=tf.float64)\n",
    "  rec_thresh_eval_time_var = tp_float / rec_denominator\n",
    "\n",
    "  f_beta_numerator = (1.0 + params[\"f_score_beta\"] ** 2)\n",
    "  f_beta_numerator *= pre_thresh_eval_time_var\n",
    "  f_beta_numerator *= rec_thresh_eval_time_var\n",
    "  f_beta_denominator = params[\"f_score_beta\"] ** 2\n",
    "  f_beta_denominator *= pre_thresh_eval_time_var\n",
    "  f_beta_denominator += rec_thresh_eval_time_var\n",
    "  f_beta_thresh_eval_time_var = f_beta_numerator / f_beta_denominator\n",
    "\n",
    "  # Features based\n",
    "  acc_trues = tf.cast(\n",
    "      x=tp_thresh_eval_feat_var + tn_thresh_eval_feat_var,\n",
    "      dtype=tf.float64)\n",
    "  acc_falses = tf.cast(\n",
    "      x=fp_thresh_eval_feat_var + fn_thresh_eval_feat_var,\n",
    "      dtype=tf.float64)\n",
    "  acc_thresh_eval_feat_var = acc_trues / (acc_trues + acc_falses)\n",
    "\n",
    "  tp_float = tf.cast(x=tp_thresh_eval_feat_var, dtype=tf.float64)\n",
    "\n",
    "  pre_denominator = tf.cast(\n",
    "      x=tp_thresh_eval_feat_var + fp_thresh_eval_feat_var,\n",
    "      dtype=tf.float64)\n",
    "  pre_thresh_eval_feat_var = tp_float / pre_denominator\n",
    "\n",
    "  rec_denominator = tf.cast(\n",
    "      x=tp_thresh_eval_feat_var + fn_thresh_eval_feat_var,\n",
    "      dtype=tf.float64)\n",
    "  rec_thresh_eval_feat_var = tp_float / rec_denominator\n",
    "\n",
    "  f_beta_numerator = (1.0 + params[\"f_score_beta\"] ** 2)\n",
    "  f_beta_numerator *= pre_thresh_eval_feat_var\n",
    "  f_beta_numerator *= rec_thresh_eval_feat_var\n",
    "  f_beta_denominator = params[\"f_score_beta\"] ** 2\n",
    "  f_beta_denominator *= pre_thresh_eval_feat_var\n",
    "  f_beta_denominator += rec_thresh_eval_feat_var\n",
    "  f_beta_thresh_eval_feat_var = f_beta_numerator / f_beta_denominator\n",
    "\n",
    "  # Anomaly detection eval metrics\n",
    "  eval_metric_ops = {\n",
    "      # Time based\n",
    "      \"time_anom_tp\": (tp_thresh_eval_time_var, tp_time_update_op),\n",
    "      \"time_anom_fn\": (fn_thresh_eval_time_var, fn_time_update_op),\n",
    "      \"time_anom_fp\": (fp_thresh_eval_time_var, fp_time_update_op),\n",
    "      \"time_anom_tn\": (tn_thresh_eval_time_var, tn_time_update_op),\n",
    "\n",
    "      \"time_anom_acc\": (acc_thresh_eval_time_var, acc_time_update_op),\n",
    "      \"time_anom_pre\": (pre_thresh_eval_time_var, pre_time_update_op),\n",
    "      \"time_anom_rec\": (rec_thresh_eval_time_var, rec_time_update_op),\n",
    "      \"time_anom_f_beta\": (f_beta_thresh_eval_time_var,\n",
    "                           f_beta_time_update_op),\n",
    "\n",
    "      # Features based\n",
    "      \"feat_anom_tp\": (tp_thresh_eval_feat_var, tp_feat_update_op),\n",
    "      \"feat_anom_fn\": (fn_thresh_eval_feat_var, fn_feat_update_op),\n",
    "      \"feat_anom_fp\": (fp_thresh_eval_feat_var, fp_feat_update_op),\n",
    "      \"feat_anom_tn\": (tn_thresh_eval_feat_var, tn_feat_update_op),\n",
    "\n",
    "      \"feat_anom_acc\": (acc_thresh_eval_feat_var, acc_feat_update_op),\n",
    "      \"feat_anom_pre\": (pre_thresh_eval_feat_var, pre_feat_update_op),\n",
    "      \"feat_anom_rec\": (rec_thresh_eval_feat_var, rec_feat_update_op),\n",
    "      \"feat_anom_f_beta\": (f_beta_thresh_eval_feat_var,\n",
    "                           f_beta_feat_update_op)\n",
    "  }\n",
    "\n",
    "  return loss, eval_metric_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tune_anomaly_thresholds_unsupervised.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_anomaly_thresholds_unsupervised_training(\n",
    "    cur_batch_size,\n",
    "    time_anom_thresh_var,\n",
    "    mahalanobis_dist_time,\n",
    "    count_thresh_time_var,\n",
    "    mean_thresh_time_var,\n",
    "    var_thresh_time_var,\n",
    "    feat_anom_thresh_var,\n",
    "    mahalanobis_dist_feat,\n",
    "    count_thresh_feat_var,\n",
    "    mean_thresh_feat_var,\n",
    "    var_thresh_feat_var,\n",
    "    params,\n",
    "    dummy_var):\n",
    "  \"\"\"Tunes anomaly thresholds during unsupervised training mode.\n",
    "\n",
    "  Given dimensions of inputs, mahalanobis distances, and variables tracking\n",
    "  counts, means, and variances of mahalanobis distance, returns loss and\n",
    "  train_op.\n",
    "\n",
    "  Args:\n",
    "    cur_batch_size: Current batch size, could be partially filled.\n",
    "    time_anom_thresh_var: Time anomaly threshold variable.\n",
    "    mahalanobis_dist_time: Time major mahalanobis distance.\n",
    "    count_thresh_time_var: Time major running count of number of records.\n",
    "    mean_thresh_time_var: Time major running mean of mahalanobis distance.\n",
    "    var_thresh_time_var: Time major running variance of mahalanobis distance.\n",
    "    feat_anom_thresh_var: Feature anomaly threshold variable.\n",
    "    mahalanobis_dist_feat: Feature major mahalanobis distance.\n",
    "    count_thresh_feat_var: Feature major running count of number of records.\n",
    "    mean_thresh_feat_var: Feature major running mean of mahalanobis distance.\n",
    "    var_thresh_feat_var: Feature major running variance of mahalanobis distance.\n",
    "    params: Dictionary of parameters.\n",
    "    dummy_var: Dummy variable used to allow training mode to happen since it\n",
    "      requires a gradient to tie back to the graph dependency.\n",
    "\n",
    "  Returns:\n",
    "    loss: The scalar loss to tie our updates back to Estimator graph.\n",
    "    train_op: The train operation to tie our updates back to Estimator graph.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=\"mahalanobis_dist_thresh_vars\", reuse=tf.AUTO_REUSE):\n",
    "    # Time based\n",
    "    mahalanobis_dist_time_flat = tf.reshape(\n",
    "        tensor=mahalanobis_dist_time,\n",
    "        shape=[cur_batch_size * params[\"seq_len\"]])\n",
    "\n",
    "    singleton_time_condition = tf.equal(\n",
    "        x=cur_batch_size * params[\"seq_len\"], y=1)\n",
    "\n",
    "    var_time_var, mean_time_var, count_time_var = tf.cond(\n",
    "        pred=singleton_time_condition,\n",
    "        true_fn=lambda: singleton_batch_var_variable_updating(\n",
    "            params[\"seq_len\"],\n",
    "            mahalanobis_dist_time_flat,\n",
    "            count_thresh_time_var,\n",
    "            mean_thresh_time_var,\n",
    "            var_thresh_time_var),\n",
    "        false_fn=lambda: non_singleton_batch_var_variable_updating(\n",
    "            cur_batch_size,\n",
    "            params[\"seq_len\"],\n",
    "            mahalanobis_dist_time_flat,\n",
    "            count_thresh_time_var,\n",
    "            mean_thresh_time_var,\n",
    "            var_thresh_time_var))\n",
    "\n",
    "    # Features based\n",
    "    mahalanobis_dist_feat_flat = tf.reshape(\n",
    "        tensor=mahalanobis_dist_feat,\n",
    "        shape=[cur_batch_size * params[\"num_feat\"]])\n",
    "\n",
    "    singleton_feat_condition = tf.equal(\n",
    "        x=cur_batch_size * params[\"num_feat\"], y=1)\n",
    "\n",
    "    var_feat_var, mean_feat_var, count_feat_var = tf.cond(\n",
    "        pred=singleton_feat_condition,\n",
    "        true_fn=lambda: singleton_batch_var_variable_updating(\n",
    "            params[\"num_feat\"],\n",
    "            mahalanobis_dist_feat_flat,\n",
    "            count_thresh_feat_var,\n",
    "            mean_thresh_feat_var,\n",
    "            var_thresh_feat_var),\n",
    "        false_fn=lambda: non_singleton_batch_var_variable_updating(\n",
    "            cur_batch_size,\n",
    "            params[\"num_feat\"],\n",
    "            mahalanobis_dist_feat_flat,\n",
    "            count_thresh_feat_var,\n",
    "            mean_thresh_feat_var,\n",
    "            var_thresh_feat_var))\n",
    "\n",
    "  # Lastly use control dependencies around loss to enforce the mahalanobis\n",
    "  # variables to be assigned, the control order matters, hence the separate\n",
    "  # contexts.\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[var_time_var, var_feat_var]):\n",
    "    with tf.control_dependencies(\n",
    "        control_inputs=[mean_time_var, mean_feat_var]):\n",
    "      with tf.control_dependencies(\n",
    "          control_inputs=[count_time_var, count_feat_var]):\n",
    "        time_out = mean_time_var\n",
    "        time_out += params[\"time_thresh_scl\"] * tf.sqrt(x=var_time_var)\n",
    "        feat_out = mean_feat_var\n",
    "        feat_out += params[\"feat_thresh_scl\"] * tf.sqrt(x=var_feat_var)\n",
    "        with tf.control_dependencies(\n",
    "            control_inputs=[tf.assign(ref=time_anom_thresh_var,\n",
    "                                      value=time_out),\n",
    "                            tf.assign(ref=feat_anom_thresh_var,\n",
    "                                      value=feat_out)]):\n",
    "\n",
    "          loss = tf.reduce_sum(\n",
    "              input_tensor=tf.zeros(shape=(), dtype=tf.float64) * dummy_var)\n",
    "\n",
    "          train_op = tf.contrib.layers.optimize_loss(\n",
    "              loss=loss,\n",
    "              global_step=tf.train.get_global_step(),\n",
    "              learning_rate=params[\"learning_rate\"],\n",
    "              optimizer=\"SGD\")\n",
    "\n",
    "  return loss, train_op\n",
    "\n",
    "\n",
    "def tune_anomaly_thresholds_unsupervised_eval(\n",
    "    cur_batch_size,\n",
    "    time_anom_thresh_var,\n",
    "    mahalanobis_dist_time,\n",
    "    feat_anom_thresh_var,\n",
    "    mahalanobis_dist_feat):\n",
    "  \"\"\"Checks tuned anomaly thresholds during supervised evaluation mode.\n",
    "\n",
    "  Given dimensions of inputs, mahalanobis distances, and variables tracking\n",
    "  counts, means, and variances of mahalanobis distance, returns loss and\n",
    "  train_op.\n",
    "\n",
    "  Args:\n",
    "    cur_batch_size: Current batch size, could be partially filled.\n",
    "    time_anom_thresh_var: Time anomaly threshold variable.\n",
    "    mahalanobis_dist_time: Time major mahalanobis distance.\n",
    "    feat_anom_thresh_var: Feature anomaly threshold variable.\n",
    "    mahalanobis_dist_feat: Feature major mahalanobis distance.\n",
    "\n",
    "  Returns:\n",
    "    loss: The scalar loss to tie our updates back to Estimator graph.\n",
    "    eval_metric_ops: Evaluation metrics of threshold tuning.\n",
    "  \"\"\"\n",
    "  loss = tf.zeros(shape=[], dtype=tf.float64)\n",
    "\n",
    "  # Flag predictions as either normal or anomalous\n",
    "  # shape = (cur_batch_size,)\n",
    "  time_anom_flags = flag_anomalies_by_thresholding(\n",
    "      cur_batch_size, mahalanobis_dist_time, time_anom_thresh_var)\n",
    "\n",
    "  # shape = (cur_batch_size,)\n",
    "  feat_anom_flags = flag_anomalies_by_thresholding(\n",
    "      cur_batch_size, mahalanobis_dist_feat, feat_anom_thresh_var)\n",
    "\n",
    "  # Anomaly detection eval metrics\n",
    "  eval_metric_ops = {\n",
    "      # Time based\n",
    "      \"time_anom_tp\": tf.metrics.mean(values=time_anom_flags),\n",
    "\n",
    "      # Features based\n",
    "      \"feat_anom_tp\": tf.metrics.mean(values=feat_anom_flags)\n",
    "  }\n",
    "\n",
    "  return loss, eval_metric_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_anomalies_by_thresholding(\n",
    "    cur_batch_size, mahalanobis_dist, anom_thresh_var):\n",
    "  \"\"\"Flags anomalies by thresholding.\n",
    "\n",
    "  Given current batch size, mahalanobis distance, and anomaly threshold\n",
    "  variable, return predicted anomaly flags.\n",
    "\n",
    "  Args:\n",
    "    cur_batch_size: Current batch size, could be partially filled.\n",
    "    mahalanobis_dist: Mahalanobis distance.\n",
    "    anom_thresh_var: Anomaly threshold variable.\n",
    "\n",
    "  Returns:\n",
    "    anomaly_flags: tf.int64 vector of current batch size elements of\n",
    "    0's and 1's indicating if each sequence is anomalous or not.\n",
    "  \"\"\"\n",
    "  anom_flags = tf.where(\n",
    "      condition=tf.reduce_any(\n",
    "          input_tensor=tf.greater(\n",
    "              x=tf.abs(x=mahalanobis_dist),\n",
    "              y=anom_thresh_var),\n",
    "          axis=1),\n",
    "      x=tf.ones(shape=[cur_batch_size], dtype=tf.int64),\n",
    "      y=tf.zeros(shape=[cur_batch_size], dtype=tf.int64))\n",
    "\n",
    "  return anom_flags\n",
    "\n",
    "\n",
    "def anomaly_detection_predictions(\n",
    "    cur_batch_size,\n",
    "    seq_len,\n",
    "    num_feat,\n",
    "    mahalanobis_dist_time,\n",
    "    mahalanobis_dist_feat,\n",
    "    time_anom_thresh_var,\n",
    "    feat_anom_thresh_var,\n",
    "    X_time_abs_recon_err,\n",
    "    X_feat_abs_recon_err):\n",
    "  \"\"\"Creates Estimator predictions and export outputs.\n",
    "\n",
    "  Given dimensions of inputs, mahalanobis distances and their respective\n",
    "  thresholds, and reconstructed inputs' absolute errors, returns Estimator's\n",
    "  predictions and export outputs.\n",
    "\n",
    "  Args:\n",
    "    cur_batch_size: Current batch size, could be partially filled.\n",
    "    seq_len: Number of timesteps in sequence.\n",
    "    num_feat: Number of features.\n",
    "    mahalanobis_dist_time: Mahalanobis distance, time major.\n",
    "    mahalanobis_dist_feat: Mahalanobis distance, features major.\n",
    "    time_anom_thresh_var: Time anomaly threshold variable.\n",
    "    feat_anom_thresh_var: Features anomaly threshold variable.\n",
    "    X_time_abs_recon_err: Time major reconstructed input data's absolute\n",
    "      reconstruction error.\n",
    "    X_feat_abs_recon_err: Features major reconstructed input data's absolute\n",
    "      reconstruction error.\n",
    "\n",
    "  Returns:\n",
    "    predictions_dict: Dictionary of predictions to output for local prediction.\n",
    "    export_outputs: Dictionary to output from exported model for serving.\n",
    "  \"\"\"\n",
    "  # Flag predictions as either normal or anomalous\n",
    "  # shape = (cur_batch_size,)\n",
    "  time_anom_flags = flag_anomalies_by_thresholding(\n",
    "      cur_batch_size, mahalanobis_dist_time, time_anom_thresh_var)\n",
    "\n",
    "  # shape = (cur_batch_size,)\n",
    "  feat_anom_flags = flag_anomalies_by_thresholding(\n",
    "      cur_batch_size, mahalanobis_dist_feat, feat_anom_thresh_var)\n",
    "\n",
    "  # Create predictions dictionary\n",
    "  predictions_dict = {\n",
    "      \"X_time_abs_recon_err\": tf.reshape(\n",
    "          tensor=X_time_abs_recon_err,\n",
    "          shape=[cur_batch_size, seq_len, num_feat]),\n",
    "      \"X_feat_abs_recon_err\": tf.transpose(\n",
    "          a=tf.reshape(\n",
    "              tensor=X_feat_abs_recon_err,\n",
    "              shape=[cur_batch_size, num_feat, seq_len]),\n",
    "          perm=[0, 2, 1]),\n",
    "      \"mahalanobis_dist_time\": mahalanobis_dist_time,\n",
    "      \"mahalanobis_dist_feat\": mahalanobis_dist_feat,\n",
    "      \"time_anom_flags\": time_anom_flags,\n",
    "      \"feat_anom_flags\": feat_anom_flags}\n",
    "\n",
    "  # Create export outputs\n",
    "  export_outputs = {\n",
    "      \"predict_export_outputs\": tf.estimator.export.PredictOutput(\n",
    "          outputs=predictions_dict)\n",
    "  }\n",
    "\n",
    "  return predictions_dict, export_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## anomaly_detection.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our model function to be used in our custom estimator\n",
    "def anomaly_detection(features, labels, mode, params):\n",
    "  \"\"\"Custom Estimator model function for anomaly detection.\n",
    "\n",
    "  Given dictionary of feature tensors, labels tensor, Estimator mode, and\n",
    "  dictionary for parameters, return EstimatorSpec object for custom Estimator.\n",
    "\n",
    "  Args:\n",
    "    features: Dictionary of feature tensors.\n",
    "    labels: Labels tensor or None.\n",
    "    mode: Estimator ModeKeys. Can take values of TRAIN, EVAL, and PREDICT.\n",
    "    params: Dictionary of parameters.\n",
    "\n",
    "  Returns:\n",
    "    EstimatorSpec object.\n",
    "  \"\"\"\n",
    "  print(\"\\nanomaly_detection: features = \\n{}\".format(features))\n",
    "  print(\"anomaly_detection: labels = \\n{}\".format(labels))\n",
    "  print(\"anomaly_detection: mode = \\n{}\".format(mode))\n",
    "  print(\"anomaly_detection: params = \\n{}\".format(params))\n",
    "\n",
    "  # Get input sequence tensor into correct shape\n",
    "  # Get dynamic batch size in case there was a partially filled batch\n",
    "  cur_batch_size = tf.shape(\n",
    "      input=features[UNLABELED_CSV_COLUMNS[0]], out_type=tf.int64)[0]\n",
    "\n",
    "  # Stack all of the features into a 3-D tensor\n",
    "  # shape = (cur_batch_size, seq_len, num_feat)\n",
    "  X = tf.stack(\n",
    "      values=[features[key] for key in UNLABELED_CSV_COLUMNS], axis=2)\n",
    "\n",
    "  ##############################################################################\n",
    "\n",
    "  # Variables for calculating error distribution statistics\n",
    "  (abs_err_count_time_var,\n",
    "   abs_err_mean_time_var,\n",
    "   abs_err_cov_time_var,\n",
    "   abs_err_inv_cov_time_var,\n",
    "   abs_err_count_feat_var,\n",
    "   abs_err_mean_feat_var,\n",
    "   abs_err_cov_feat_var,\n",
    "   abs_err_inv_cov_feat_var) = create_both_mahalanobis_dist_vars(\n",
    "       seq_len=params[\"seq_len\"], num_feat=params[\"num_feat\"])\n",
    "\n",
    "  # Variables for automatically tuning anomaly thresh\n",
    "  if params[\"labeled_tune_thresh\"]:\n",
    "    (tp_thresh_time_var,\n",
    "     fn_thresh_time_var,\n",
    "     fp_thresh_time_var,\n",
    "     tn_thresh_time_var,\n",
    "     tp_thresh_feat_var,\n",
    "     fn_thresh_feat_var,\n",
    "     fp_thresh_feat_var,\n",
    "     tn_thresh_feat_var) = create_both_confusion_matrix_thresh_vars(\n",
    "         scope=\"mahalanobis_dist_thresh_vars\",\n",
    "         time_thresh_size=[params[\"num_time_anom_thresh\"]],\n",
    "         feat_thresh_size=[params[\"num_feat_anom_thresh\"]])\n",
    "  else:\n",
    "    (count_thresh_time_var,\n",
    "     mean_thresh_time_var,\n",
    "     var_thresh_time_var,\n",
    "     count_thresh_feat_var,\n",
    "     mean_thresh_feat_var,\n",
    "     var_thresh_feat_var) = create_both_mahalanobis_unsupervised_thresh_vars(\n",
    "         scope=\"mahalanobis_dist_thresh_vars\")\n",
    "\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=\"mahalanobis_dist_thresh_vars\", reuse=tf.AUTO_REUSE):\n",
    "    time_anom_thresh_var = tf.get_variable(\n",
    "        name=\"time_anom_thresh_var\",\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(shape=[], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "    feat_anom_thresh_var = tf.get_variable(\n",
    "        name=\"feat_anom_thresh_var\",\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(shape=[], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "  # Variables for tuning anomaly thresh evaluation\n",
    "  if params[\"labeled_tune_thresh\"]:\n",
    "    (tp_thresh_eval_time_var,\n",
    "     fn_thresh_eval_time_var,\n",
    "     fp_thresh_eval_time_var,\n",
    "     tn_thresh_eval_time_var,\n",
    "     tp_thresh_eval_feat_var,\n",
    "     fn_thresh_eval_feat_var,\n",
    "     fp_thresh_eval_feat_var,\n",
    "     tn_thresh_eval_feat_var) = create_both_confusion_matrix_thresh_vars(\n",
    "         scope=\"anom_thresh_eval_vars\",\n",
    "         time_thresh_size=[],\n",
    "         feat_thresh_size=[])\n",
    "\n",
    "  # Create dummy variable for graph dependency requiring a gradient for TRAIN\n",
    "  dummy_var = tf.get_variable(\n",
    "      name=\"dummy_var\",\n",
    "      dtype=tf.float64,\n",
    "      initializer=tf.zeros(shape=[], dtype=tf.float64),\n",
    "      trainable=True)\n",
    "\n",
    "################################################################################\n",
    "\n",
    "  predictions_dict = None\n",
    "  loss = None\n",
    "  train_op = None\n",
    "  eval_metric_ops = None\n",
    "  export_outputs = None\n",
    "\n",
    "  # Now branch off based on which mode we are in\n",
    "\n",
    "  # Call specific model\n",
    "  model_functions = {\n",
    "      \"dense_autoencoder\": dense_autoencoder_model,\n",
    "      \"lstm_enc_dec_autoencoder\": lstm_enc_dec_autoencoder_model,\n",
    "      \"pca\": pca_model}\n",
    "\n",
    "  # Get function pointer for selected model type\n",
    "  model_function = model_functions[params[\"model_type\"]]\n",
    "\n",
    "  # Build selected model\n",
    "  loss, train_op, X_time_orig, X_time_recon, X_feat_orig, X_feat_recon = \\\n",
    "    model_function(X, mode, params, cur_batch_size, dummy_var)\n",
    "\n",
    "  if not (mode == tf.estimator.ModeKeys.TRAIN and\n",
    "          params[\"training_mode\"] == \"reconstruction\"):\n",
    "    # shape = (cur_batch_size * seq_len, num_feat)\n",
    "    X_time_abs_recon_err = tf.abs(\n",
    "        x=X_time_orig - X_time_recon)\n",
    "\n",
    "    # Features based\n",
    "    # shape = (cur_batch_size * num_feat, seq_len)\n",
    "    X_feat_abs_recon_err = tf.abs(\n",
    "        x=X_feat_orig - X_feat_recon)\n",
    "\n",
    "    if (mode == tf.estimator.ModeKeys.TRAIN and\n",
    "        params[\"training_mode\"] == \"calculate_error_distribution_statistics\"):\n",
    "      loss, train_op = calculate_error_distribution_statistics_training(\n",
    "          cur_batch_size,\n",
    "          X_time_abs_recon_err,\n",
    "          abs_err_count_time_var,\n",
    "          abs_err_mean_time_var,\n",
    "          abs_err_cov_time_var,\n",
    "          abs_err_inv_cov_time_var,\n",
    "          X_feat_abs_recon_err,\n",
    "          abs_err_count_feat_var,\n",
    "          abs_err_mean_feat_var,\n",
    "          abs_err_cov_feat_var,\n",
    "          abs_err_inv_cov_feat_var,\n",
    "          params,\n",
    "          dummy_var)\n",
    "    elif (mode == tf.estimator.ModeKeys.EVAL and\n",
    "          params[\"training_mode\"] != \"tune_anomaly_thresholds\"):\n",
    "      loss, eval_metric_ops = reconstruction_evaluation(\n",
    "          X_time_orig, X_time_recon, params[\"training_mode\"])\n",
    "    elif (mode == tf.estimator.ModeKeys.PREDICT or\n",
    "          ((mode == tf.estimator.ModeKeys.TRAIN or\n",
    "            mode == tf.estimator.ModeKeys.EVAL) and\n",
    "           params[\"training_mode\"] == \"tune_anomaly_thresholds\")):\n",
    "      with tf.variable_scope(\n",
    "          name_or_scope=\"mahalanobis_dist_vars\", reuse=tf.AUTO_REUSE):\n",
    "        # Time based\n",
    "        # shape = (cur_batch_size, seq_len)\n",
    "        mahalanobis_dist_time = mahalanobis_dist(\n",
    "            err_vec=X_time_abs_recon_err,\n",
    "            mean_vec=abs_err_mean_time_var,\n",
    "            inv_cov=abs_err_inv_cov_time_var,\n",
    "            final_shape=params[\"seq_len\"])\n",
    "\n",
    "        # Features based\n",
    "        # shape = (cur_batch_size, num_feat)\n",
    "        mahalanobis_dist_feat = mahalanobis_dist(\n",
    "            err_vec=X_feat_abs_recon_err,\n",
    "            mean_vec=abs_err_mean_feat_var,\n",
    "            inv_cov=abs_err_inv_cov_feat_var,\n",
    "            final_shape=params[\"num_feat\"])\n",
    "\n",
    "      if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "        if params[\"labeled_tune_thresh\"]:\n",
    "          labels_norm_mask = tf.equal(x=labels, y=0)\n",
    "          labels_anom_mask = tf.equal(x=labels, y=1)\n",
    "\n",
    "          if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            loss, train_op = tune_anomaly_thresholds_supervised_training(\n",
    "                labels_norm_mask,\n",
    "                labels_anom_mask,\n",
    "                mahalanobis_dist_time,\n",
    "                tp_thresh_time_var,\n",
    "                fn_thresh_time_var,\n",
    "                fp_thresh_time_var,\n",
    "                tn_thresh_time_var,\n",
    "                time_anom_thresh_var,\n",
    "                mahalanobis_dist_feat,\n",
    "                tp_thresh_feat_var,\n",
    "                fn_thresh_feat_var,\n",
    "                fp_thresh_feat_var,\n",
    "                tn_thresh_feat_var,\n",
    "                feat_anom_thresh_var,\n",
    "                params,\n",
    "                mode,\n",
    "                dummy_var)\n",
    "          elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "            loss, eval_metric_ops = tune_anomaly_thresholds_supervised_eval(\n",
    "                labels_norm_mask,\n",
    "                labels_anom_mask,\n",
    "                time_anom_thresh_var,\n",
    "                mahalanobis_dist_time,\n",
    "                tp_thresh_eval_time_var,\n",
    "                fn_thresh_eval_time_var,\n",
    "                fp_thresh_eval_time_var,\n",
    "                tn_thresh_eval_time_var,\n",
    "                feat_anom_thresh_var,\n",
    "                mahalanobis_dist_feat,\n",
    "                tp_thresh_eval_feat_var,\n",
    "                fn_thresh_eval_feat_var,\n",
    "                fp_thresh_eval_feat_var,\n",
    "                tn_thresh_eval_feat_var,\n",
    "                params,\n",
    "                mode)\n",
    "        else:  # not params[\"labeled_tune_thresh\"]\n",
    "          if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            loss, train_op = tune_anomaly_thresholds_unsupervised_training(\n",
    "                cur_batch_size,\n",
    "                time_anom_thresh_var,\n",
    "                mahalanobis_dist_time,\n",
    "                count_thresh_time_var,\n",
    "                mean_thresh_time_var,\n",
    "                var_thresh_time_var,\n",
    "                feat_anom_thresh_var,\n",
    "                mahalanobis_dist_feat,\n",
    "                count_thresh_feat_var,\n",
    "                mean_thresh_feat_var,\n",
    "                var_thresh_feat_var,\n",
    "                params,\n",
    "                dummy_var)\n",
    "          elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "            loss, eval_metric_ops = tune_anomaly_thresholds_unsupervised_eval(\n",
    "                cur_batch_size,\n",
    "                time_anom_thresh_var,\n",
    "                mahalanobis_dist_time,\n",
    "                feat_anom_thresh_var,\n",
    "                mahalanobis_dist_feat)\n",
    "      else:  # mode == tf.estimator.ModeKeys.PREDICT\n",
    "        predictions_dict, export_outputs = anomaly_detection_predictions(\n",
    "            cur_batch_size,\n",
    "            params[\"seq_len\"],\n",
    "            params[\"num_feat\"],\n",
    "            mahalanobis_dist_time,\n",
    "            mahalanobis_dist_feat,\n",
    "            time_anom_thresh_var,\n",
    "            feat_anom_thresh_var,\n",
    "            X_time_abs_recon_err,\n",
    "            X_feat_abs_recon_err)\n",
    "\n",
    "  # Return EstimatorSpec\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=predictions_dict,\n",
    "      loss=loss,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops=eval_metric_ops,\n",
    "      export_outputs=export_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## serving.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serving input functions\n",
    "def fix_shape_and_type_for_serving(placeholder):\n",
    "  \"\"\"Fixes the shape and type of serving input strings.\n",
    "\n",
    "  Given placeholder tensor, return parsed and processed feature tensor.\n",
    "\n",
    "  Args:\n",
    "    placeholder: Placeholder tensor holding raw data from serving input\n",
    "      function.\n",
    "\n",
    "  Returns:\n",
    "    Parsed and processed feature tensor.\n",
    "  \"\"\"\n",
    "  cur_batch_size = tf.shape(input=placeholder, out_type=tf.int64)[0]\n",
    "\n",
    "  # String split each string in batch and output values from the resulting\n",
    "  # SparseTensors\n",
    "  # shape = (batch_size, seq_len)\n",
    "  split_string = tf.stack(values=tf.map_fn(\n",
    "      fn=lambda x: tf.string_split(\n",
    "          source=[placeholder[x]], delimiter=\";\").values,\n",
    "      elems=tf.range(\n",
    "          start=0, limit=cur_batch_size, dtype=tf.int64),\n",
    "      dtype=tf.string), axis=0)\n",
    "\n",
    "  # Convert each string in the split tensor to float\n",
    "  # shape = (batch_size, seq_len)\n",
    "  feature_tensor = tf.string_to_number(\n",
    "      string_tensor=split_string, out_type=tf.float64)\n",
    "\n",
    "  return feature_tensor\n",
    "\n",
    "\n",
    "def get_shape_and_set_modified_shape_2D(tensor, additional_dimension_sizes):\n",
    "  \"\"\"Fixes the shape and type of serving input strings.\n",
    "\n",
    "  Given feature tensor and additional dimension size, sequence length,\n",
    "  fixes dynamic shape ambiguity of last dimension so that we will be able to\n",
    "  use it in our DNN (since tf.layers.dense require the last dimension to be\n",
    "  known).\n",
    "\n",
    "  Args:\n",
    "    tensor: tf.float64 vector feature tensor.\n",
    "    additional_dimension_sizes: Additional dimension size, namely sequence\n",
    "      length.\n",
    "\n",
    "  Returns:\n",
    "    Feature tensor with set static shape for sequence length.\n",
    "  \"\"\"\n",
    "  # Get static shape for tensor and convert it to list\n",
    "  shape = tensor.get_shape().as_list()\n",
    "  # Set outer shape to additional_dimension_sizes[0] since know this is the\n",
    "  # correct size\n",
    "  shape[1] = additional_dimension_sizes[0]\n",
    "  # Set the shape of tensor to our modified shape\n",
    "  # shape = (batch_size, additional_dimension_sizes[0])\n",
    "  tensor.set_shape(shape=shape)\n",
    "\n",
    "  return tensor\n",
    "\n",
    "\n",
    "def serving_input_fn(seq_len):\n",
    "  \"\"\"Serving input function.\n",
    "\n",
    "  Given the sequence length, return ServingInputReceiver object.\n",
    "\n",
    "  Args:\n",
    "    seq_len: Number of timesteps in sequence.\n",
    "\n",
    "  Returns:\n",
    "    ServingInputReceiver object containing features and receiver tensors.\n",
    "  \"\"\"\n",
    "  # Create placeholders to accept the data sent to the model at serving time\n",
    "  # All features come in as a batch of strings, shape = (batch_size,),\n",
    "  # this was so because of passing the arrays to online ml-engine prediction\n",
    "  feature_placeholders = {\n",
    "      feature: tf.placeholder(\n",
    "          dtype=tf.string, shape=[None])\n",
    "      for feature in UNLABELED_CSV_COLUMNS\n",
    "  }\n",
    "\n",
    "  # Create feature tensors\n",
    "  features = {key: fix_shape_and_type_for_serving(placeholder=tensor)\n",
    "              for key, tensor in feature_placeholders.items()}\n",
    "\n",
    "  # Fix dynamic shape ambiguity of feature tensors for our DNN\n",
    "  features = {key: get_shape_and_set_modified_shape_2D(\n",
    "      tensor=tensor, additional_dimension_sizes=[seq_len])\n",
    "              for key, tensor in features.items()}\n",
    "\n",
    "  return tf.estimator.export.ServingInputReceiver(\n",
    "      features=features, receiver_tensors=feature_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging to be level of INFO\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\n",
    "def train_and_evaluate(args):\n",
    "  \"\"\"Train and evaluate custom Estimator with three training modes.\n",
    "\n",
    "  Given the dictionary of parameters, create custom Estimator and run up to\n",
    "  three training modes then return Estimator object.\n",
    "\n",
    "  Args:\n",
    "    args: Dictionary of parameters.\n",
    "\n",
    "  Returns:\n",
    "    Estimator object.\n",
    "  \"\"\"\n",
    "  # Create our custom estimator using our model function\n",
    "  estimator = tf.estimator.Estimator(\n",
    "      model_fn=anomaly_detection,\n",
    "      model_dir=args[\"output_dir\"],\n",
    "      params={key: val for key, val in args.items()})\n",
    "\n",
    "  if args[\"training_mode\"] == \"reconstruction\":\n",
    "    # Calculate max_steps\n",
    "    max_steps = int(args[\"reconstruction_epochs\"] * args[\"train_examples\"])\n",
    "    max_steps = max_steps // args[\"train_batch_size\"]\n",
    "    max_steps += args[\"previous_train_steps\"]\n",
    "\n",
    "    if args[\"model_type\"] == \"pca\":\n",
    "      # Create train spec to read in our training data\n",
    "      train_spec = tf.estimator.TrainSpec(\n",
    "          input_fn=read_dataset(\n",
    "              filename=args[\"train_file_pattern\"],\n",
    "              mode=tf.estimator.ModeKeys.EVAL,  # read through train data once\n",
    "              batch_size=args[\"train_batch_size\"],\n",
    "              params=args),\n",
    "          max_steps=max_steps)\n",
    "    else:  # dense_autoencoder or lstm_enc_dec_autoencoder\n",
    "      # Create early stopping hook to help reduce overfitting\n",
    "      early_stopping_hook = tf.contrib.estimator.stop_if_no_decrease_hook(\n",
    "          estimator=estimator,\n",
    "          metric_name=\"rmse\",\n",
    "          max_steps_without_decrease=100,\n",
    "          min_steps=1000,\n",
    "          run_every_secs=60,\n",
    "          run_every_steps=None)\n",
    "\n",
    "      # Create train spec to read in our training data\n",
    "      train_spec = tf.estimator.TrainSpec(\n",
    "          input_fn=read_dataset(\n",
    "              filename=args[\"train_file_pattern\"],\n",
    "              mode=tf.estimator.ModeKeys.TRAIN,\n",
    "              batch_size=args[\"train_batch_size\"],\n",
    "              params=args),\n",
    "          max_steps=max_steps,\n",
    "          hooks=[early_stopping_hook])\n",
    "\n",
    "    # Create eval spec to read in our validation data\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"eval_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.EVAL,\n",
    "            batch_size=args[\"eval_batch_size\"],\n",
    "            params=args),\n",
    "        steps=None,\n",
    "        start_delay_secs=args[\"start_delay_secs\"],  # start eval after N secs\n",
    "        throttle_secs=args[\"throttle_secs\"])  # evaluate every N secs\n",
    "\n",
    "    # Create train and evaluate loop to train and evaluate our estimator\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n",
    "\n",
    "    if args[\"model_type\"] == \"pca\":\n",
    "      # Check to see if we need to additionally tune principal components\n",
    "      if (args[\"k_principal_components_time\"] is None or\n",
    "          args[\"k_principal_components_feat\"] is None):\n",
    "        args[\"autotune_principal_components\"] = True\n",
    "        # Reinstantiate the estimator\n",
    "        estimator = tf.estimator.Estimator(\n",
    "            model_fn=anomaly_detection,\n",
    "            model_dir=args[\"output_dir\"],\n",
    "            params={key: val for key, val in args.items()})\n",
    "        \n",
    "        # Calculate max_steps\n",
    "        max_steps += args[\"eval_examples\"] // args[\"train_batch_size\"]\n",
    "        max_steps += args[\"previous_train_steps\"]\n",
    "\n",
    "        # Create train spec to read in our training data\n",
    "        train_spec = tf.estimator.TrainSpec(\n",
    "            input_fn=read_dataset(\n",
    "                filename=args[\"eval_file_pattern\"],\n",
    "                mode=tf.estimator.ModeKeys.EVAL,  # read through train data once\n",
    "                batch_size=args[\"train_batch_size\"],\n",
    "                params=args),\n",
    "            max_steps=max_steps)\n",
    "\n",
    "        # Create eval spec to read in our validation data\n",
    "        eval_spec = tf.estimator.EvalSpec(\n",
    "            input_fn=read_dataset(\n",
    "                filename=args[\"eval_file_pattern\"],\n",
    "                mode=tf.estimator.ModeKeys.EVAL,\n",
    "                batch_size=args[\"eval_batch_size\"],\n",
    "                params=args),\n",
    "            steps=None,\n",
    "            start_delay_secs=args[\"start_delay_secs\"],  # start eval after N sec\n",
    "            throttle_secs=args[\"throttle_secs\"])  # evaluate every N secs\n",
    "\n",
    "        # Create train and evaluate loop to train and evaluate our estimator\n",
    "        tf.estimator.train_and_evaluate(\n",
    "            estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n",
    "  else:\n",
    "    # Calculate max_steps\n",
    "    max_steps = args[\"train_examples\"] // args[\"train_batch_size\"]\n",
    "    max_steps += args[\"previous_train_steps\"]\n",
    "\n",
    "    # if args[\"training_mode\"] == \"calculate_error_distribution_statistics\"\n",
    "    # Get final mahalanobis statistics over the entire val_1 dataset\n",
    "\n",
    "    # if args[\"training_mode\"] == \"tune_anomaly_thresholds\"\n",
    "    # Tune anomaly thresholds using val_2 and val_anom datasets\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"train_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.EVAL,  # read through val data once\n",
    "            batch_size=args[\"train_batch_size\"],\n",
    "            params=args),\n",
    "        max_steps=max_steps)\n",
    "\n",
    "    if args[\"training_mode\"] == \"calculate_error_distribution_statistics\":\n",
    "      # Evaluate until the end of eval files\n",
    "      eval_steps = None\n",
    "\n",
    "      # Don't create exporter for serving yet since anomaly thresholds\n",
    "      # aren't trained yet\n",
    "      exporter = None\n",
    "    elif args[\"training_mode\"] == \"tune_anomaly_thresholds\":\n",
    "      if args[\"labeled_tune_thresh\"]:\n",
    "        # Evaluate until the end of eval files\n",
    "        eval_steps = None\n",
    "      else:\n",
    "        # Don't evaluate\n",
    "        eval_steps = 0\n",
    "\n",
    "      # Create exporter that uses serving_input_fn to create saved_model\n",
    "      # for serving\n",
    "      exporter = tf.estimator.LatestExporter(\n",
    "          name=\"exporter\",\n",
    "          serving_input_receiver_fn=lambda: serving_input_fn(args[\"seq_len\"]))\n",
    "    else:\n",
    "      print(\"{0} isn't a valid training mode!\".format(args[\"training_mode\"]))\n",
    "\n",
    "    # Create eval spec to read in our validation data and export our model\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"eval_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.EVAL,\n",
    "            batch_size=args[\"eval_batch_size\"],\n",
    "            params=args),\n",
    "        steps=eval_steps,\n",
    "        exporters=exporter,\n",
    "        start_delay_secs=args[\"start_delay_secs\"],  # start eval after N secs\n",
    "        throttle_secs=args[\"throttle_secs\"])  # evaluate every N secs\n",
    "\n",
    "  if (args[\"training_mode\"] == \"calculate_error_distribution_statistics\" or\n",
    "      args[\"training_mode\"] == \"tune_anomaly_thresholds\"):\n",
    "    # Create train and evaluate loop to train and evaluate our estimator\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n",
    "\n",
    "  return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {}\n",
    "# File arguments\n",
    "arguments[\"train_file_pattern\"] = \"data/train_norm_seq.csv\"\n",
    "arguments[\"eval_file_pattern\"] = \"data/val_norm_1_seq.csv\"\n",
    "arguments[\"output_dir\"] = \"trained_model\"\n",
    "\n",
    "# Sequence shape hyperparameters\n",
    "arguments[\"seq_len\"] = seq_len\n",
    "arguments[\"num_feat\"] = len(UNLABELED_CSV_COLUMNS)\n",
    "\n",
    "# Training parameters\n",
    "arguments[\"train_batch_size\"] = 32\n",
    "arguments[\"eval_batch_size\"] = 32\n",
    "arguments[\"previous_train_steps\"] = 0\n",
    "arguments[\"reconstruction_epochs\"] = 1.0\n",
    "arguments[\"train_examples\"] = 64000\n",
    "arguments[\"eval_examples\"] = 6400\n",
    "arguments[\"learning_rate\"] = 0.01\n",
    "arguments[\"start_delay_secs\"] = 60\n",
    "arguments[\"throttle_secs\"] = 120\n",
    "\n",
    "# Model parameters\n",
    "# [dense_autoencoder, lstm_enc_dec_autoencoder, pca]\n",
    "# arguments[\"model_type\"] = \"lstm_enc_dec_autoencoder\"\n",
    "arguments[\"model_type\"] = \"pca\"\n",
    "\n",
    "## Dense Autoencoder\n",
    "arguments[\"enc_dnn_hidden_units\"] = [64, 32, 16]\n",
    "arguments[\"latent_vector_size\"] = min(8, arguments[\"enc_dnn_hidden_units\"][-1])\n",
    "arguments[\"dec_dnn_hidden_units\"] = [16, 32, 64]\n",
    "arguments[\"time_loss_weight\"] = 1.0\n",
    "arguments[\"feat_loss_weight\"] = 1.0\n",
    "\n",
    "## LSTM Encoder-Decoder Autoencoder\n",
    "arguments[\"reverse_labels_sequence\"] = True\n",
    "### LSTM hyperparameters\n",
    "arguments[\"enc_lstm_hidden_units\"] = [64, 32, 16]\n",
    "arguments[\"dec_lstm_hidden_units\"] = [16, 32, 64]\n",
    "arguments[\"lstm_dropout_output_keep_probs\"] = [1.0, 1.0, 1.0]\n",
    "### DNN hyperparameters\n",
    "arguments[\"dnn_hidden_units\"] = [1024, 256, 64]\n",
    "\n",
    "## PCA\n",
    "arguments[\"autotune_principal_components\"] = False\n",
    "arguments[\"k_principal_components_time\"] = None\n",
    "arguments[\"k_principal_components_feat\"] = None\n",
    "\n",
    "# Anomaly detection\n",
    "arguments[\"training_mode\"] = \"reconstruction\"\n",
    "arguments[\"labeled_tune_thresh\"] = True\n",
    "arguments[\"num_time_anom_thresh\"] = 300\n",
    "arguments[\"num_feat_anom_thresh\"] = 300\n",
    "arguments[\"min_time_anom_thresh\"] = 1\n",
    "arguments[\"max_time_anom_thresh\"] = 100\n",
    "arguments[\"min_feat_anom_thresh\"] = 1\n",
    "arguments[\"max_feat_anom_thresh\"] = 100\n",
    "arguments[\"time_thresh_scl\"] = 2.0\n",
    "arguments[\"feat_thresh_scl\"] = 2.0\n",
    "arguments[\"time_anom_thresh\"] = None\n",
    "arguments[\"feat_anom_thresh\"] = None\n",
    "arguments[\"eps\"] = 10**-12\n",
    "arguments[\"f_score_beta\"] = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train reconstruction variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7b9b854e80>, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_protocol': None, '_log_step_count_steps': 100, '_model_dir': 'trained_model', '_num_ps_replicas': 0, '_global_id_in_cluster': 0, '_experimental_distribute': None, '_tf_random_seed': None, '_master': '', '_evaluation_master': '', '_device_fn': None, '_service': None, '_save_summary_steps': 100, '_num_worker_replicas': 1, '_eval_distribute': None, '_is_chief': True, '_train_distribute': None, '_task_id': 0, '_task_type': 'worker'}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "anomaly_detection: features = \n",
      "{'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'IteratorGetNext:3' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_4': <tf.Tensor 'IteratorGetNext:4' shape=(?, 30) dtype=float64>}\n",
      "anomaly_detection: labels = \n",
      "None\n",
      "anomaly_detection: mode = \n",
      "train\n",
      "anomaly_detection: params = \n",
      "{'eval_examples': 6400, 'min_time_anom_thresh': 1, 'learning_rate': 0.01, 'enc_dnn_hidden_units': [64, 32, 16], 'num_feat_anom_thresh': 300, 'train_file_pattern': 'data/train_norm_seq.csv', 'dnn_hidden_units': [1024, 256, 64], 'dec_dnn_hidden_units': [16, 32, 64], 'num_feat': 5, 'autotune_principal_components': False, 'feat_anom_thresh': None, 'f_score_beta': 0.05, 'num_time_anom_thresh': 300, 'feat_loss_weight': 1.0, 'train_batch_size': 32, 'k_principal_components_feat': None, 'start_delay_secs': 60, 'training_mode': 'reconstruction', 'throttle_secs': 120, 'eval_batch_size': 32, 'time_thresh_scl': 2.0, 'seq_len': 30, 'latent_vector_size': 8, 'labeled_tune_thresh': True, 'enc_lstm_hidden_units': [64, 32, 16], 'dec_lstm_hidden_units': [16, 32, 64], 'time_anom_thresh': None, 'output_dir': 'trained_model', 'eval_file_pattern': 'data/val_norm_1_seq.csv', 'reverse_labels_sequence': True, 'time_loss_weight': 1.0, 'model_type': 'pca', 'feat_thresh_scl': 2.0, 'lstm_dropout_output_keep_probs': [1.0, 1.0, 1.0], 'eps': 1e-12, 'min_feat_anom_thresh': 1, 'max_time_anom_thresh': 100, 'train_examples': 64000, 'reconstruction_epochs': 1.0, 'k_principal_components_time': None, 'max_feat_anom_thresh': 100, 'previous_train_steps': 0}\n",
      "value_b = \n",
      "Tensor(\"Reshape:0\", shape=(?, 5), dtype=float64)\n",
      "mean_a = \n",
      "<tf.Variable 'pca_vars/pca_time_mean_var:0' shape=(5,) dtype=float64_ref>\n",
      "mean_ab = \n",
      "Tensor(\"pca_vars_2/cond/truediv:0\", shape=(5,), dtype=float64)\n",
      "value_b = \n",
      "Tensor(\"Reshape_1:0\", shape=(?, 30), dtype=float64)\n",
      "mean_a = \n",
      "<tf.Variable 'pca_vars/pca_feat_mean_var:0' shape=(30,) dtype=float64_ref>\n",
      "mean_ab = \n",
      "Tensor(\"pca_vars_2/cond_1/truediv:0\", shape=(30,), dtype=float64)\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 124.443\n",
      "INFO:tensorflow:loss = 0.0, step = 101 (0.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.933\n",
      "INFO:tensorflow:loss = 0.0, step = 201 (0.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.438\n",
      "INFO:tensorflow:loss = 0.0, step = 301 (0.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.72\n",
      "INFO:tensorflow:loss = 0.0, step = 401 (0.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.257\n",
      "INFO:tensorflow:loss = 0.0, step = 501 (0.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.333\n",
      "INFO:tensorflow:loss = 0.0, step = 601 (0.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.177\n",
      "INFO:tensorflow:loss = 0.0, step = 701 (0.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.334\n",
      "INFO:tensorflow:loss = 0.0, step = 801 (0.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.572\n",
      "INFO:tensorflow:loss = 0.0, step = 901 (0.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.974\n",
      "INFO:tensorflow:loss = 0.0, step = 1001 (0.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.957\n",
      "INFO:tensorflow:loss = 0.0, step = 1101 (0.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.135\n",
      "INFO:tensorflow:loss = 0.0, step = 1201 (0.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.351\n",
      "INFO:tensorflow:loss = 0.0, step = 1301 (0.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.803\n",
      "INFO:tensorflow:loss = 0.0, step = 1401 (0.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.09\n",
      "INFO:tensorflow:loss = 0.0, step = 1501 (0.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.995\n",
      "INFO:tensorflow:loss = 0.0, step = 1601 (0.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.436\n",
      "INFO:tensorflow:loss = 0.0, step = 1701 (0.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.723\n",
      "INFO:tensorflow:loss = 0.0, step = 1801 (0.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.843\n",
      "INFO:tensorflow:loss = 0.0, step = 1901 (0.759 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into trained_model/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "anomaly_detection: features = \n",
      "{'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'IteratorGetNext:3' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_4': <tf.Tensor 'IteratorGetNext:4' shape=(?, 30) dtype=float64>}\n",
      "anomaly_detection: labels = \n",
      "None\n",
      "anomaly_detection: mode = \n",
      "eval\n",
      "anomaly_detection: params = \n",
      "{'eval_examples': 6400, 'min_time_anom_thresh': 1, 'learning_rate': 0.01, 'enc_dnn_hidden_units': [64, 32, 16], 'num_feat_anom_thresh': 300, 'train_file_pattern': 'data/train_norm_seq.csv', 'dnn_hidden_units': [1024, 256, 64], 'dec_dnn_hidden_units': [16, 32, 64], 'num_feat': 5, 'autotune_principal_components': False, 'feat_anom_thresh': None, 'f_score_beta': 0.05, 'num_time_anom_thresh': 300, 'feat_loss_weight': 1.0, 'train_batch_size': 32, 'k_principal_components_feat': None, 'start_delay_secs': 60, 'training_mode': 'reconstruction', 'throttle_secs': 120, 'eval_batch_size': 32, 'time_thresh_scl': 2.0, 'seq_len': 30, 'latent_vector_size': 8, 'labeled_tune_thresh': True, 'enc_lstm_hidden_units': [64, 32, 16], 'dec_lstm_hidden_units': [16, 32, 64], 'time_anom_thresh': None, 'output_dir': 'trained_model', 'eval_file_pattern': 'data/val_norm_1_seq.csv', 'reverse_labels_sequence': True, 'time_loss_weight': 1.0, 'model_type': 'pca', 'feat_thresh_scl': 2.0, 'lstm_dropout_output_keep_probs': [1.0, 1.0, 1.0], 'eps': 1e-12, 'min_feat_anom_thresh': 1, 'max_time_anom_thresh': 100, 'train_examples': 64000, 'reconstruction_epochs': 1.0, 'k_principal_components_time': None, 'max_feat_anom_thresh': 100, 'previous_train_steps': 0}\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-07-08T18:06:27Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-07-08-18:06:29\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 0.6683831, mae = 0.6548333, rmse = 0.817547\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: trained_model/model.ckpt-2000\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7b9b854208>, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_protocol': None, '_log_step_count_steps': 100, '_model_dir': 'trained_model', '_num_ps_replicas': 0, '_global_id_in_cluster': 0, '_experimental_distribute': None, '_tf_random_seed': None, '_master': '', '_evaluation_master': '', '_device_fn': None, '_service': None, '_save_summary_steps': 100, '_num_worker_replicas': 1, '_eval_distribute': None, '_is_chief': True, '_train_distribute': None, '_task_id': 0, '_task_type': 'worker'}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "anomaly_detection: features = \n",
      "{'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'IteratorGetNext:3' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_4': <tf.Tensor 'IteratorGetNext:4' shape=(?, 30) dtype=float64>}\n",
      "anomaly_detection: labels = \n",
      "None\n",
      "anomaly_detection: mode = \n",
      "train\n",
      "anomaly_detection: params = \n",
      "{'eval_examples': 6400, 'min_time_anom_thresh': 1, 'learning_rate': 0.01, 'enc_dnn_hidden_units': [64, 32, 16], 'num_feat_anom_thresh': 300, 'train_file_pattern': 'data/train_norm_seq.csv', 'dnn_hidden_units': [1024, 256, 64], 'dec_dnn_hidden_units': [16, 32, 64], 'num_feat': 5, 'autotune_principal_components': True, 'feat_anom_thresh': None, 'f_score_beta': 0.05, 'num_time_anom_thresh': 300, 'feat_loss_weight': 1.0, 'train_batch_size': 32, 'k_principal_components_feat': None, 'start_delay_secs': 60, 'training_mode': 'reconstruction', 'throttle_secs': 120, 'eval_batch_size': 32, 'time_thresh_scl': 2.0, 'seq_len': 30, 'latent_vector_size': 8, 'labeled_tune_thresh': True, 'enc_lstm_hidden_units': [64, 32, 16], 'dec_lstm_hidden_units': [16, 32, 64], 'time_anom_thresh': None, 'output_dir': 'trained_model', 'eval_file_pattern': 'data/val_norm_1_seq.csv', 'reverse_labels_sequence': True, 'time_loss_weight': 1.0, 'model_type': 'pca', 'feat_thresh_scl': 2.0, 'lstm_dropout_output_keep_probs': [1.0, 1.0, 1.0], 'eps': 1e-12, 'min_feat_anom_thresh': 1, 'max_time_anom_thresh': 100, 'train_examples': 64000, 'reconstruction_epochs': 1.0, 'k_principal_components_time': None, 'max_feat_anom_thresh': 100, 'previous_train_steps': 0}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-2000\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0, step = 2001\n",
      "INFO:tensorflow:global_step/sec: 130.604\n",
      "INFO:tensorflow:loss = 0.0, step = 2101 (0.767 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2200 into trained_model/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "anomaly_detection: features = \n",
      "{'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'IteratorGetNext:3' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_4': <tf.Tensor 'IteratorGetNext:4' shape=(?, 30) dtype=float64>}\n",
      "anomaly_detection: labels = \n",
      "None\n",
      "anomaly_detection: mode = \n",
      "eval\n",
      "anomaly_detection: params = \n",
      "{'eval_examples': 6400, 'min_time_anom_thresh': 1, 'learning_rate': 0.01, 'enc_dnn_hidden_units': [64, 32, 16], 'num_feat_anom_thresh': 300, 'train_file_pattern': 'data/train_norm_seq.csv', 'dnn_hidden_units': [1024, 256, 64], 'dec_dnn_hidden_units': [16, 32, 64], 'num_feat': 5, 'autotune_principal_components': True, 'feat_anom_thresh': None, 'f_score_beta': 0.05, 'num_time_anom_thresh': 300, 'feat_loss_weight': 1.0, 'train_batch_size': 32, 'k_principal_components_feat': None, 'start_delay_secs': 60, 'training_mode': 'reconstruction', 'throttle_secs': 120, 'eval_batch_size': 32, 'time_thresh_scl': 2.0, 'seq_len': 30, 'latent_vector_size': 8, 'labeled_tune_thresh': True, 'enc_lstm_hidden_units': [64, 32, 16], 'dec_lstm_hidden_units': [16, 32, 64], 'time_anom_thresh': None, 'output_dir': 'trained_model', 'eval_file_pattern': 'data/val_norm_1_seq.csv', 'reverse_labels_sequence': True, 'time_loss_weight': 1.0, 'model_type': 'pca', 'feat_thresh_scl': 2.0, 'lstm_dropout_output_keep_probs': [1.0, 1.0, 1.0], 'eps': 1e-12, 'min_feat_anom_thresh': 1, 'max_time_anom_thresh': 100, 'train_examples': 64000, 'reconstruction_epochs': 1.0, 'k_principal_components_time': None, 'max_feat_anom_thresh': 100, 'previous_train_steps': 0}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-07-08T18:06:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-2200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-07-08-18:06:34\n",
      "INFO:tensorflow:Saving dict for global step 2200: global_step = 2200, loss = 0.062556885, mae = 0.14969522, rmse = 0.2501138\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2200: trained_model/model.ckpt-2200\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "arguments[\"training_mode\"] = \"reconstruction\"\n",
    "arguments[\"train_file_pattern\"] = \"data/train_norm_seq.csv\"\n",
    "arguments[\"eval_file_pattern\"] = \"data/val_norm_1_seq.csv\"\n",
    "arguments[\"train_batch_size\"] = 32\n",
    "arguments[\"eval_batch_size\"] = 32\n",
    "arguments[\"previous_train_steps\"] = 0\n",
    "arguments[\"reconstruction_epochs\"] = 1.0\n",
    "arguments[\"train_examples\"] = 64000\n",
    "arguments[\"eval_examples\"] = 6400\n",
    "shutil.rmtree(\n",
    "    path=arguments[\"output_dir\"], ignore_errors=True)  # start fresh each time\n",
    "estimator = train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at any special variable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OptimizeLoss/learning_rate',\n",
       " 'anom_thresh_eval_vars/fn_thresh_feat_var',\n",
       " 'anom_thresh_eval_vars/fn_thresh_time_var',\n",
       " 'anom_thresh_eval_vars/fp_thresh_feat_var',\n",
       " 'anom_thresh_eval_vars/fp_thresh_time_var',\n",
       " 'anom_thresh_eval_vars/tn_thresh_feat_var',\n",
       " 'anom_thresh_eval_vars/tn_thresh_time_var',\n",
       " 'anom_thresh_eval_vars/tp_thresh_feat_var',\n",
       " 'anom_thresh_eval_vars/tp_thresh_time_var',\n",
       " 'dummy_var',\n",
       " 'global_step',\n",
       " 'mahalanobis_dist_thresh_vars/feat_anom_thresh_var',\n",
       " 'mahalanobis_dist_thresh_vars/fn_thresh_feat_var',\n",
       " 'mahalanobis_dist_thresh_vars/fn_thresh_time_var',\n",
       " 'mahalanobis_dist_thresh_vars/fp_thresh_feat_var',\n",
       " 'mahalanobis_dist_thresh_vars/fp_thresh_time_var',\n",
       " 'mahalanobis_dist_thresh_vars/time_anom_thresh_var',\n",
       " 'mahalanobis_dist_thresh_vars/tn_thresh_feat_var',\n",
       " 'mahalanobis_dist_thresh_vars/tn_thresh_time_var',\n",
       " 'mahalanobis_dist_thresh_vars/tp_thresh_feat_var',\n",
       " 'mahalanobis_dist_thresh_vars/tp_thresh_time_var',\n",
       " 'mahalanobis_dist_vars/abs_err_count_feat_var',\n",
       " 'mahalanobis_dist_vars/abs_err_count_time_var',\n",
       " 'mahalanobis_dist_vars/abs_err_cov_feat_var',\n",
       " 'mahalanobis_dist_vars/abs_err_cov_time_var',\n",
       " 'mahalanobis_dist_vars/abs_err_inv_cov_feat_var',\n",
       " 'mahalanobis_dist_vars/abs_err_inv_cov_time_var',\n",
       " 'mahalanobis_dist_vars/abs_err_mean_feat_var',\n",
       " 'mahalanobis_dist_vars/abs_err_mean_time_var',\n",
       " 'pca_vars/pca_feat_count_var',\n",
       " 'pca_vars/pca_feat_cov_var',\n",
       " 'pca_vars/pca_feat_eigval_var',\n",
       " 'pca_vars/pca_feat_eigvec_var',\n",
       " 'pca_vars/pca_feat_k_principal_components_var',\n",
       " 'pca_vars/pca_feat_mean_var',\n",
       " 'pca_vars/pca_time_count_var',\n",
       " 'pca_vars/pca_time_cov_var',\n",
       " 'pca_vars/pca_time_eigval_var',\n",
       " 'pca_vars/pca_time_eigvec_var',\n",
       " 'pca_vars/pca_time_k_principal_components_var',\n",
       " 'pca_vars/pca_time_mean_var']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.get_variable_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pca_variables(X, dim_name):\n",
    "  \"\"\"Print PCA variables.\n",
    "\n",
    "  Given the dictionary of parameters, create custom Estimator and run up to\n",
    "  three training modes then return Estimator object.\n",
    "\n",
    "  Args:\n",
    "    X: np.float64 2D array of feature data.\n",
    "    dim_name: Name of dimension, values can be time or feat.\n",
    "  \"\"\"\n",
    "  print(\"X_{}.shape = \\n{}\".format(dim_name, X.shape))\n",
    "\n",
    "  # Count\n",
    "  count_var = estimator.get_variable_value(\n",
    "      name=\"pca_vars/pca_{}_count_var\".format(dim_name))\n",
    "  print(\"{}_count_var = \\n{}\".format(dim_name, count_var))\n",
    "  count = X.shape[0]\n",
    "  print(\"{}_count = \\n{}\".format(dim_name, count))\n",
    "\n",
    "  # Mean\n",
    "  mean_var = estimator.get_variable_value(\n",
    "      name=\"pca_vars/pca_{}_mean_var\".format(dim_name))\n",
    "  print(\"{}_mean_var = \\n{}\".format(dim_name, mean_var))\n",
    "  mean = np.mean(X, axis=0)\n",
    "  print(\"{}_mean = \\n{}\".format(dim_name, mean))\n",
    "  print(\"{}_mean_ratio = \\n{}\".format(dim_name, mean_var / mean))\n",
    "\n",
    "  # Covariance\n",
    "  cov_var = estimator.get_variable_value(\n",
    "      name=\"pca_vars/pca_{}_cov_var\".format(dim_name))\n",
    "  if cov_var.shape[0] <= 10:\n",
    "    print(\"{}_cov_var = \\n{}\".format(dim_name, cov_var))\n",
    "  else:\n",
    "    print(\"{}_cov_var.shape = \\n{}\".format(dim_name, cov_var.shape))\n",
    "\n",
    "  if arguments[\"seq_len\"] == 1:\n",
    "    cov = np.zeros(shape=[num_tags, num_tags])\n",
    "  else:\n",
    "    cov = np.cov(m=np.transpose(a=X))\n",
    "\n",
    "  if cov.shape[0] <= 10:\n",
    "    print(\"{}_cov = \\n{}\".format(dim_name, cov))\n",
    "  else:\n",
    "    print(\"{}_cov.shape = \\n{}\".format(dim_name, cov.shape))\n",
    "\n",
    "  print(\"{}_cov_ratio = \\n{}\".format(dim_name, cov_var / cov))\n",
    "\n",
    "  # Eigenvalues\n",
    "  eigval_var = estimator.get_variable_value(\n",
    "      name=\"pca_vars/pca_{}_eigval_var\".format(dim_name))\n",
    "  if eigval_var.shape[0] <= 10:\n",
    "    print(\"{}_eigval_var = \\n{}\".format(dim_name, eigval_var))\n",
    "  else:\n",
    "    print(\"{}_eigval_var.shape = \\n{}\".format(dim_name, eigval_var.shape))\n",
    "\n",
    "  eigval, eigvec = np.linalg.eigh(a=cov)\n",
    "  if eigval.shape[0] <= 10:\n",
    "    print(\"{}_eigval = \\n{}\".format(dim_name, eigval))\n",
    "  else:\n",
    "    print(\"{}_eigval.shape = \\n{}\".format(dim_name, eigval.shape))\n",
    "\n",
    "  print(\"{}_eigval_ratio = \\n{}\".format(dim_name, eigval_var / eigval))\n",
    "\n",
    "  # Eigenvectors\n",
    "  eigvec_var = estimator.get_variable_value(\n",
    "      name=\"pca_vars/pca_{}_eigvec_var\".format(dim_name))\n",
    "  if eigvec_var.shape[0] <= 10:\n",
    "    print(\"{}_eigvec_var = \\n{}\".format(dim_name, eigvec_var))\n",
    "  else:\n",
    "    print(\"{}_eigvec_var.shape = \\n{}\".format(dim_name, eigvec_var.shape))\n",
    "\n",
    "  if eigvec.shape[0] <= 10:\n",
    "    print(\"{}_eigvec = \\n{}\".format(dim_name, eigvec))\n",
    "  else:\n",
    "    print(\"{}_eigvec.shape = \\n{}\".format(dim_name, eigvec.shape))\n",
    "\n",
    "  print(\"{}_eigvec_ratio = \\n{}\".format(dim_name, eigvec_var / eigvec))\n",
    "  \n",
    "  \n",
    "  # K principal components\n",
    "  k_principal_components_var = estimator.get_variable_value(\n",
    "    name=\"pca_vars/pca_{}_k_principal_components_var\".format(dim_name))\n",
    "  \n",
    "  print(\"{}_k_principal_components_var = \\n{}\".format(dim_name, k_principal_components_var))\n",
    "\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting PCA data:\n",
      "\n",
      "arr_train_norm_seq.shape = (64000, 5)\n",
      "arr_train_norm_seq_features.shape = (64000, 30, 5)\n",
      "\n",
      "PCA Time Variables:\n",
      "\n",
      "X_time.shape = \n",
      "(1920000, 5)\n",
      "time_count_var = \n",
      "1920000\n",
      "time_count = \n",
      "1920000\n",
      "time_mean_var = \n",
      "[0.56402427 0.52800595 0.53672165 0.54815993 0.5016344 ]\n",
      "time_mean = \n",
      "[0.56402427 0.52800595 0.53672165 0.54815993 0.5016344 ]\n",
      "time_mean_ratio = \n",
      "[1. 1. 1. 1. 1.]\n",
      "time_cov_var = \n",
      "[[ 1.73015442  0.01860566  0.10988096  0.08013573  0.70211946]\n",
      " [ 0.01860566  0.8652447   0.02764213 -0.08096995  0.03220934]\n",
      " [ 0.10988096  0.02764213  1.04434457  0.06150902 -0.11689315]\n",
      " [ 0.08013573 -0.08096995  0.06150902  1.09914152  0.05300507]\n",
      " [ 0.70211946  0.03220934 -0.11689315  0.05300507  0.70390964]]\n",
      "time_cov = \n",
      "[[ 1.73015442  0.01860566  0.10988096  0.08013573  0.70211946]\n",
      " [ 0.01860566  0.8652447   0.02764213 -0.08096995  0.03220934]\n",
      " [ 0.10988096  0.02764213  1.04434457  0.06150902 -0.11689315]\n",
      " [ 0.08013573 -0.08096995  0.06150902  1.09914152  0.05300507]\n",
      " [ 0.70211946  0.03220934 -0.11689315  0.05300507  0.70390964]]\n",
      "time_cov_ratio = \n",
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n",
      "time_eigval_var = \n",
      "[0.31273185 0.83308488 1.05175994 1.14645569 2.09876248]\n",
      "time_eigval = \n",
      "[0.31273185 0.83308488 1.05175994 1.14645569 2.09876248]\n",
      "time_eigval_ratio = \n",
      "[1. 1. 1. 1. 1.]\n",
      "time_eigvec_var = \n",
      "[[-0.44399299 -0.0794722  -0.07876198  0.04627699  0.88781157]\n",
      " [-0.05135643  0.92896322 -0.30754156  0.19853055  0.01984078]\n",
      " [ 0.21037683 -0.14128354 -0.80426796 -0.53527705  0.04911289]\n",
      " [-0.0350548   0.32702076  0.4776571  -0.80895097  0.09628395]\n",
      " [ 0.8687609   0.06170808  0.15560037  0.1323664   0.44689404]]\n",
      "time_eigvec = \n",
      "[[-0.44399299 -0.0794722  -0.07876198 -0.04627699 -0.88781157]\n",
      " [-0.05135643  0.92896322 -0.30754156 -0.19853055 -0.01984078]\n",
      " [ 0.21037683 -0.14128354 -0.80426796  0.53527705 -0.04911289]\n",
      " [-0.0350548   0.32702076  0.4776571   0.80895097 -0.09628395]\n",
      " [ 0.8687609   0.06170808  0.15560037 -0.1323664  -0.44689404]]\n",
      "time_eigvec_ratio = \n",
      "[[ 1.  1.  1. -1. -1.]\n",
      " [ 1.  1.  1. -1. -1.]\n",
      " [ 1.  1.  1. -1. -1.]\n",
      " [ 1.  1.  1. -1. -1.]\n",
      " [ 1.  1.  1. -1. -1.]]\n",
      "time_k_principal_components_var = \n",
      "4\n",
      "\n",
      "PCA Features Variables:\n",
      "\n",
      "X_feat.shape = \n",
      "(320000, 30)\n",
      "feat_count_var = \n",
      "320000\n",
      "feat_count = \n",
      "320000\n",
      "feat_mean_var = \n",
      "[ 0.50075598  1.83261288  0.67839754 -0.30150416  0.22500241  0.52926518\n",
      "  0.76815749  1.09266888  0.30489665 -0.31647729  0.62169091  1.1768723\n",
      "  0.42669958  0.08356344  0.52365513  0.78332018  0.57614388  0.16381724\n",
      "  0.27294891  0.9219631   0.85730999  0.19328735  0.13613832  0.39388259\n",
      "  0.69165146  1.18108817  0.59685433 -0.60759941  0.15085658  1.61335763]\n",
      "feat_mean = \n",
      "[ 0.50075598  1.83261288  0.67839754 -0.30150416  0.22500241  0.52926518\n",
      "  0.76815749  1.09266888  0.30489665 -0.31647729  0.62169091  1.1768723\n",
      "  0.42669958  0.08356344  0.52365513  0.78332018  0.57614388  0.16381724\n",
      "  0.27294891  0.9219631   0.85730999  0.19328735  0.13613832  0.39388259\n",
      "  0.69165146  1.18108817  0.59685433 -0.60759941  0.15085658  1.61335763]\n",
      "feat_mean_ratio = \n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "feat_cov_var.shape = \n",
      "(30, 30)\n",
      "feat_cov.shape = \n",
      "(30, 30)\n",
      "feat_cov_ratio = \n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]]\n",
      "feat_eigval_var.shape = \n",
      "(30,)\n",
      "feat_eigval.shape = \n",
      "(30,)\n",
      "feat_eigval_ratio = \n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "feat_eigvec_var.shape = \n",
      "(30, 30)\n",
      "feat_eigvec.shape = \n",
      "(30, 30)\n",
      "feat_eigvec_ratio = \n",
      "[[-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.00000001 -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          1.         -1.          1.\n",
      "   1.          1.          1.          1.         -1.         -1.\n",
      "  -1.         -1.         -1.          1.          1.         -1.\n",
      "   1.         -1.         -1.          1.          1.         -1.\n",
      "  -1.          1.          1.          1.         -1.         -1.        ]]\n",
      "feat_k_principal_components_var = \n",
      "29\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"model_type\"] == \"pca\":\n",
    "  print(\"Getting PCA data:\\n\")\n",
    "  arr_train_norm_seq = np.genfromtxt(\n",
    "      fname=\"data/train_norm_seq.csv\",\n",
    "      delimiter=\",\",\n",
    "      dtype=str)\n",
    "  print(\"arr_train_norm_seq.shape = {}\".format(arr_train_norm_seq.shape))\n",
    "\n",
    "  if num_tags == 1:\n",
    "    arr_train_norm_seq = np.expand_dims(a=arr_train_norm_seq, axis=-1)\n",
    "\n",
    "  arr_train_norm_seq_features = np.stack(\n",
    "      arrays=[np.stack(\n",
    "          arrays=[np.array(\n",
    "              arr_train_norm_seq[\n",
    "                  example_index,\n",
    "                  tag_index].split(\";\")).astype(np.float)\n",
    "                  for tag_index in range(num_tags)],\n",
    "          axis=1)\n",
    "              for example_index in range(len(arr_train_norm_seq))],\n",
    "      axis=0)\n",
    "\n",
    "  print(\"arr_train_norm_seq_features.shape = {}\".format(\n",
    "      arr_train_norm_seq_features.shape))\n",
    "\n",
    "  pca_data_len = arr_train_norm_seq_features.shape[0]\n",
    "  pca_data_seq_len = arr_train_norm_seq_features.shape[1]\n",
    "\n",
    "  # Time based\n",
    "  X_time = arr_train_norm_seq_features.reshape(\n",
    "      pca_data_len * pca_data_seq_len, num_tags)\n",
    "  print(\"\\nPCA Time Variables:\\n\")\n",
    "  print_pca_variables(X_time, \"time\")\n",
    "\n",
    "  # Features based\n",
    "  X_features = np.transpose(arr_train_norm_seq_features, [0, 2, 1]).reshape(\n",
    "      pca_data_len * num_tags, pca_data_seq_len)\n",
    "  print(\"\\nPCA Features Variables:\\n\")\n",
    "  print_pca_variables(X_features, \"feat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train error distribution statistics variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7b98de3240>, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_protocol': None, '_log_step_count_steps': 100, '_model_dir': 'trained_model', '_num_ps_replicas': 0, '_global_id_in_cluster': 0, '_experimental_distribute': None, '_tf_random_seed': None, '_master': '', '_evaluation_master': '', '_device_fn': None, '_service': None, '_save_summary_steps': 100, '_num_worker_replicas': 1, '_eval_distribute': None, '_is_chief': True, '_train_distribute': None, '_task_id': 0, '_task_type': 'worker'}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "anomaly_detection: features = \n",
      "{'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'IteratorGetNext:3' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_4': <tf.Tensor 'IteratorGetNext:4' shape=(?, 30) dtype=float64>}\n",
      "anomaly_detection: labels = \n",
      "None\n",
      "anomaly_detection: mode = \n",
      "train\n",
      "anomaly_detection: params = \n",
      "{'num_feat_anom_thresh': 300, 'train_file_pattern': 'data/val_norm_1_seq.csv', 'num_feat': 5, 'autotune_principal_components': True, 'feat_anom_thresh': None, 'time_loss_weight': 1.0, 'do_eval': True, 'feat_loss_weight': 1.0, 'k_principal_components_feat': None, 'start_delay_secs': 60, 'training_mode': 'calculate_error_distribution_statistics', 'throttle_secs': 120, 'reconstruction_epochs': 1.0, 'time_thresh_scl': 2.0, 'seq_len': 30, 'labeled_tune_thresh': True, 'enc_lstm_hidden_units': [64, 32, 16], 'dec_lstm_hidden_units': [16, 32, 64], 'output_dir': 'trained_model', 'max_feat_anom_thresh': 100, 'lstm_dropout_output_keep_probs': [1.0, 1.0, 1.0], 'train_steps': 2400, 'eps': 1e-12, 'max_time_anom_thresh': 100, 'train_examples': 6400, 'k_principal_components_time': None, 'previous_train_steps': 2200, 'eval_examples': 6400, 'model_type': 'pca', 'learning_rate': 0.01, 'enc_dnn_hidden_units': [64, 32, 16], 'dec_dnn_hidden_units': [16, 32, 64], 'eval_batch_size': 32, 'f_score_beta': 0.05, 'eval_file_pattern': 'data/val_norm_1_seq.csv', 'feat_thresh_scl': 2.0, 'dnn_hidden_units': [1024, 256, 64], 'latent_vector_size': 8, 'num_time_anom_thresh': 300, 'train_batch_size': 32, 'time_anom_thresh': None, 'reverse_labels_sequence': True, 'min_feat_anom_thresh': 1, 'min_time_anom_thresh': 1}\n",
      "value_b = \n",
      "Tensor(\"Abs:0\", shape=(?, 5), dtype=float64)\n",
      "mean_a = \n",
      "<tf.Variable 'mahalanobis_dist_vars/abs_err_mean_time_var:0' shape=(5,) dtype=float64_ref>\n",
      "mean_ab = \n",
      "Tensor(\"mahalanobis_dist_vars_2/cond/truediv:0\", shape=(5,), dtype=float64)\n",
      "value_b = \n",
      "Tensor(\"Abs_1:0\", shape=(?, 30), dtype=float64)\n",
      "mean_a = \n",
      "<tf.Variable 'mahalanobis_dist_vars/abs_err_mean_feat_var:0' shape=(30,) dtype=float64_ref>\n",
      "mean_ab = \n",
      "Tensor(\"mahalanobis_dist_vars_2/cond_1/truediv:0\", shape=(30,), dtype=float64)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-2200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2200 into trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0, step = 2201\n",
      "INFO:tensorflow:global_step/sec: 97.5487\n",
      "INFO:tensorflow:loss = 0.0, step = 2301 (1.027 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2400 into trained_model/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "anomaly_detection: features = \n",
      "{'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'IteratorGetNext:3' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_4': <tf.Tensor 'IteratorGetNext:4' shape=(?, 30) dtype=float64>}\n",
      "anomaly_detection: labels = \n",
      "None\n",
      "anomaly_detection: mode = \n",
      "eval\n",
      "anomaly_detection: params = \n",
      "{'num_feat_anom_thresh': 300, 'train_file_pattern': 'data/val_norm_1_seq.csv', 'num_feat': 5, 'autotune_principal_components': True, 'feat_anom_thresh': None, 'time_loss_weight': 1.0, 'do_eval': True, 'feat_loss_weight': 1.0, 'k_principal_components_feat': None, 'start_delay_secs': 60, 'training_mode': 'calculate_error_distribution_statistics', 'throttle_secs': 120, 'reconstruction_epochs': 1.0, 'time_thresh_scl': 2.0, 'seq_len': 30, 'labeled_tune_thresh': True, 'enc_lstm_hidden_units': [64, 32, 16], 'dec_lstm_hidden_units': [16, 32, 64], 'output_dir': 'trained_model', 'max_feat_anom_thresh': 100, 'lstm_dropout_output_keep_probs': [1.0, 1.0, 1.0], 'train_steps': 2400, 'eps': 1e-12, 'max_time_anom_thresh': 100, 'train_examples': 6400, 'k_principal_components_time': None, 'previous_train_steps': 2200, 'eval_examples': 6400, 'model_type': 'pca', 'learning_rate': 0.01, 'enc_dnn_hidden_units': [64, 32, 16], 'dec_dnn_hidden_units': [16, 32, 64], 'eval_batch_size': 32, 'f_score_beta': 0.05, 'eval_file_pattern': 'data/val_norm_1_seq.csv', 'feat_thresh_scl': 2.0, 'dnn_hidden_units': [1024, 256, 64], 'latent_vector_size': 8, 'num_time_anom_thresh': 300, 'train_batch_size': 32, 'time_anom_thresh': None, 'reverse_labels_sequence': True, 'min_feat_anom_thresh': 1, 'min_time_anom_thresh': 1}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-07-08T18:06:48Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-2400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-07-08-18:06:50\n",
      "INFO:tensorflow:Saving dict for global step 2400: global_step = 2400, loss = 0.062556885\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2400: trained_model/model.ckpt-2400\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n"
     ]
    }
   ],
   "source": [
    "arguments[\"training_mode\"] = \"calculate_error_distribution_statistics\"\n",
    "arguments[\"do_eval\"] = True\n",
    "arguments[\"train_file_pattern\"] = \"data/val_norm_1_seq.csv\"\n",
    "arguments[\"eval_file_pattern\"] = \"data/val_norm_1_seq.csv\"\n",
    "arguments[\"train_batch_size\"] = 32\n",
    "arguments[\"eval_batch_size\"] = 32\n",
    "if (arguments[\"model_type\"] == \"pca\" and\n",
    "   (arguments[\"k_principal_components_time\"] is None or\n",
    "    arguments[\"k_principal_components_feat\"] is None)):\n",
    "  arguments[\"previous_train_steps\"] = 2200\n",
    "else:\n",
    "  arguments[\"previous_train_steps\"] = 2000\n",
    "arguments[\"train_examples\"] = 6400\n",
    "arguments[\"eval_examples\"] = 6400\n",
    "estimator = train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at variable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OptimizeLoss/learning_rate',\n",
       " 'anom_thresh_eval_vars/fn_thresh_feat_var',\n",
       " 'anom_thresh_eval_vars/fn_thresh_time_var',\n",
       " 'anom_thresh_eval_vars/fp_thresh_feat_var',\n",
       " 'anom_thresh_eval_vars/fp_thresh_time_var',\n",
       " 'anom_thresh_eval_vars/tn_thresh_feat_var',\n",
       " 'anom_thresh_eval_vars/tn_thresh_time_var',\n",
       " 'anom_thresh_eval_vars/tp_thresh_feat_var',\n",
       " 'anom_thresh_eval_vars/tp_thresh_time_var',\n",
       " 'dummy_var',\n",
       " 'global_step',\n",
       " 'mahalanobis_dist_thresh_vars/feat_anom_thresh_var',\n",
       " 'mahalanobis_dist_thresh_vars/fn_thresh_feat_var',\n",
       " 'mahalanobis_dist_thresh_vars/fn_thresh_time_var',\n",
       " 'mahalanobis_dist_thresh_vars/fp_thresh_feat_var',\n",
       " 'mahalanobis_dist_thresh_vars/fp_thresh_time_var',\n",
       " 'mahalanobis_dist_thresh_vars/time_anom_thresh_var',\n",
       " 'mahalanobis_dist_thresh_vars/tn_thresh_feat_var',\n",
       " 'mahalanobis_dist_thresh_vars/tn_thresh_time_var',\n",
       " 'mahalanobis_dist_thresh_vars/tp_thresh_feat_var',\n",
       " 'mahalanobis_dist_thresh_vars/tp_thresh_time_var',\n",
       " 'mahalanobis_dist_vars/abs_err_count_feat_var',\n",
       " 'mahalanobis_dist_vars/abs_err_count_time_var',\n",
       " 'mahalanobis_dist_vars/abs_err_cov_feat_var',\n",
       " 'mahalanobis_dist_vars/abs_err_cov_time_var',\n",
       " 'mahalanobis_dist_vars/abs_err_inv_cov_feat_var',\n",
       " 'mahalanobis_dist_vars/abs_err_inv_cov_time_var',\n",
       " 'mahalanobis_dist_vars/abs_err_mean_feat_var',\n",
       " 'mahalanobis_dist_vars/abs_err_mean_time_var',\n",
       " 'pca_vars/pca_feat_count_var',\n",
       " 'pca_vars/pca_feat_cov_var',\n",
       " 'pca_vars/pca_feat_eigval_var',\n",
       " 'pca_vars/pca_feat_eigvec_var',\n",
       " 'pca_vars/pca_feat_k_principal_components_var',\n",
       " 'pca_vars/pca_feat_mean_var',\n",
       " 'pca_vars/pca_time_count_var',\n",
       " 'pca_vars/pca_time_cov_var',\n",
       " 'pca_vars/pca_time_eigval_var',\n",
       " 'pca_vars/pca_time_eigvec_var',\n",
       " 'pca_vars/pca_time_k_principal_components_var',\n",
       " 'pca_vars/pca_time_mean_var']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.get_variable_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_val_norm_1_seq.shape = (6400, 5)\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "anomaly_detection: features = \n",
      "{'tag_2': <tf.Tensor 'fifo_queue_DequeueUpTo:3' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'fifo_queue_DequeueUpTo:4' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'fifo_queue_DequeueUpTo:1' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'fifo_queue_DequeueUpTo:2' shape=(?, 30) dtype=float64>, 'tag_4': <tf.Tensor 'fifo_queue_DequeueUpTo:5' shape=(?, 30) dtype=float64>}\n",
      "anomaly_detection: labels = \n",
      "None\n",
      "anomaly_detection: mode = \n",
      "infer\n",
      "anomaly_detection: params = \n",
      "{'num_feat_anom_thresh': 300, 'train_file_pattern': 'data/val_norm_1_seq.csv', 'num_feat': 5, 'autotune_principal_components': True, 'feat_anom_thresh': None, 'time_loss_weight': 1.0, 'do_eval': True, 'feat_loss_weight': 1.0, 'k_principal_components_feat': None, 'start_delay_secs': 60, 'training_mode': 'calculate_error_distribution_statistics', 'throttle_secs': 120, 'reconstruction_epochs': 1.0, 'time_thresh_scl': 2.0, 'seq_len': 30, 'labeled_tune_thresh': True, 'enc_lstm_hidden_units': [64, 32, 16], 'dec_lstm_hidden_units': [16, 32, 64], 'output_dir': 'trained_model', 'max_feat_anom_thresh': 100, 'lstm_dropout_output_keep_probs': [1.0, 1.0, 1.0], 'train_steps': 2400, 'eps': 1e-12, 'max_time_anom_thresh': 100, 'train_examples': 6400, 'k_principal_components_time': None, 'previous_train_steps': 2200, 'eval_examples': 6400, 'model_type': 'pca', 'learning_rate': 0.01, 'enc_dnn_hidden_units': [64, 32, 16], 'dec_dnn_hidden_units': [16, 32, 64], 'eval_batch_size': 32, 'f_score_beta': 0.05, 'eval_file_pattern': 'data/val_norm_1_seq.csv', 'feat_thresh_scl': 2.0, 'dnn_hidden_units': [1024, 256, 64], 'latent_vector_size': 8, 'num_time_anom_thresh': 300, 'train_batch_size': 32, 'time_anom_thresh': None, 'reverse_labels_sequence': True, 'min_feat_anom_thresh': 1, 'min_time_anom_thresh': 1}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-2400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    }
   ],
   "source": [
    "arr_val_norm_1_seq = np.genfromtxt(\n",
    "    fname=\"data/val_norm_1_seq.csv\",\n",
    "    delimiter=\",\",\n",
    "    dtype=str)\n",
    "print(\"arr_val_norm_1_seq.shape = {}\".format(arr_val_norm_1_seq.shape))\n",
    "\n",
    "if num_tags == 1:\n",
    "  arr_val_norm_1_seq = np.expand_dims(a=arr_val_norm_1_seq, axis=-1)\n",
    "\n",
    "arr_val_norm_1_seq_features = np.stack(\n",
    "    arrays=[np.stack(\n",
    "        arrays=[np.array(\n",
    "            arr_val_norm_1_seq[\n",
    "                example_index,\n",
    "                tag_index].split(\";\")).astype(np.float)\n",
    "                for tag_index in range(num_tags)],\n",
    "        axis=1)\n",
    "            for example_index in range(len(arr_val_norm_1_seq))],\n",
    "    axis=0)\n",
    "\n",
    "dict_val_norm_1_seq_features = {\n",
    "    tag: arr_val_norm_1_seq_features[:, :, index]\n",
    "    for index, tag in enumerate(UNLABELED_CSV_COLUMNS)}\n",
    "\n",
    "val_norm_1_pred_list = [pred for pred in estimator.predict(\n",
    "    input_fn=tf.estimator.inputs.numpy_input_fn(\n",
    "        x=dict_val_norm_1_seq_features,\n",
    "        y=None,\n",
    "        batch_size=32,\n",
    "        num_epochs=1,\n",
    "        shuffle=False,\n",
    "        queue_capacity=1000))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192000, 5)\n"
     ]
    }
   ],
   "source": [
    "val_norm_1_time_abs_err = np.stack(\n",
    "    arrays=[pred[\"X_time_abs_recon_err\"]\n",
    "            for pred in val_norm_1_pred_list],\n",
    "    axis=0)\n",
    "\n",
    "data_len = val_norm_1_time_abs_err.shape[0]\n",
    "data_seq_len = val_norm_1_time_abs_err.shape[1]\n",
    "\n",
    "time_abs_err = val_norm_1_time_abs_err.reshape(\n",
    "    data_len * data_seq_len, num_tags)\n",
    "print(time_abs_err.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_count_var = estimator.get_variable_value(\n",
    "    name=\"mahalanobis_dist_vars/abs_err_count_time_var\")\n",
    "time_count_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_count = time_abs_err.shape[0]\n",
    "time_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_count_var / time_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20646753, 0.02388199, 0.09783034, 0.01630133, 0.40399493])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_mean_var = estimator.get_variable_value(\n",
    "    name=\"mahalanobis_dist_vars/abs_err_mean_time_var\")\n",
    "time_mean_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20646753, 0.02388199, 0.09783034, 0.01630133, 0.40399493])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_mean = np.mean(time_abs_err, axis = 0)\n",
    "time_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_mean_var / time_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01903039 0.00220124 0.00901716 0.00150252 0.03723676]\n",
      " [0.00220124 0.00025462 0.00104301 0.0001738  0.00430716]\n",
      " [0.00901716 0.00104301 0.00427259 0.00071194 0.01764386]\n",
      " [0.00150252 0.0001738  0.00071194 0.00011863 0.00293997]\n",
      " [0.03723676 0.00430716 0.01764386 0.00293997 0.07286116]]\n"
     ]
    }
   ],
   "source": [
    "time_cov_var = estimator.get_variable_value(\n",
    "    name=\"mahalanobis_dist_vars/abs_err_cov_time_var\")\n",
    "if time_cov_var.shape[0] <= 10:\n",
    "  print(time_cov_var)\n",
    "else:\n",
    "  print(time_cov_var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01903039 0.00220124 0.00901716 0.00150252 0.03723676]\n",
      " [0.00220124 0.00025462 0.00104301 0.0001738  0.00430716]\n",
      " [0.00901716 0.00104301 0.00427259 0.00071194 0.01764386]\n",
      " [0.00150252 0.0001738  0.00071194 0.00011863 0.00293997]\n",
      " [0.03723676 0.00430716 0.01764386 0.00293997 0.07286116]]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"seq_len\"] == 1:\n",
    "  time_cov = np.zeros(shape=[num_tags, num_tags])\n",
    "else:\n",
    "  time_cov = np.cov(m=np.transpose(a=time_abs_err))\n",
    "\n",
    "if time_cov.shape[0] <= 10:\n",
    "  print(time_cov)\n",
    "else:\n",
    "  print(time_cov.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_cov_var / time_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inverse Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.02862821e+11 -2.28026098e+10 -9.33980026e+10 -1.55663846e+10\n",
      "  -3.85721722e+11]\n",
      " [-2.28024180e+10  9.97362837e+11 -1.08034598e+10 -1.80006977e+09\n",
      "  -4.46163955e+10]\n",
      " [-9.33983480e+10 -1.08035670e+10  9.55742571e+11 -7.37556954e+09\n",
      "  -1.82771227e+11]\n",
      " [-1.55664804e+10 -1.80008077e+09 -7.37552200e+09  9.98771133e+11\n",
      "  -3.04528314e+10]\n",
      " [-3.85721646e+11 -4.46162711e+10 -1.82771411e+11 -3.04528695e+10\n",
      "   2.45254393e+11]]\n"
     ]
    }
   ],
   "source": [
    "time_inv_var = estimator.get_variable_value(\n",
    "  name=\"mahalanobis_dist_vars/abs_err_inv_cov_time_var\")\n",
    "if time_inv_var.shape[0] <= 10:\n",
    "  print(time_inv_var)\n",
    "else:\n",
    "  print(time_inv_var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.02911482e+11 -2.27990328e+10 -9.34000046e+10 -1.55642401e+10\n",
      "  -3.85746404e+11]\n",
      " [-2.27992626e+10  9.97362669e+11 -1.08038709e+10 -1.80007064e+09\n",
      "  -4.46178986e+10]\n",
      " [-9.34004919e+10 -1.08037710e+10  9.55746141e+11 -7.37359252e+09\n",
      "  -1.82771063e+11]\n",
      " [-1.55645701e+10 -1.80006028e+09 -7.37370812e+09  9.98771434e+11\n",
      "  -3.04542603e+10]\n",
      " [-3.85746259e+11 -4.46180407e+10 -1.82771301e+11 -3.04544563e+10\n",
      "   2.45267114e+11]]\n"
     ]
    }
   ],
   "source": [
    "time_inv = np.linalg.inv(\n",
    "    a=time_cov + np.eye(N=num_tags) * arguments[\"eps\"])\n",
    "if time_inv.shape[0] <= 10:\n",
    "  print(time_inv)\n",
    "else:\n",
    "  print(time_inv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99993939, 1.00015689, 0.99997857, 1.00013778, 0.99993602],\n",
       "       [1.0001384 , 1.00000017, 0.99996195, 0.99999952, 0.99996631],\n",
       "       [0.99997705, 0.99998112, 0.99999627, 1.00026812, 1.0000009 ],\n",
       "       [1.00012273, 1.00001138, 1.00024599, 0.9999997 , 0.99995308],\n",
       "       [0.99993619, 0.99996034, 1.0000006 , 0.9999479 , 0.99994813]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_inv_var / time_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000, 30)\n"
     ]
    }
   ],
   "source": [
    "val_norm_1_feat_abs_err = np.stack(\n",
    "    arrays=[pred[\"X_feat_abs_recon_err\"]\n",
    "            for pred in val_norm_1_pred_list],\n",
    "    axis=0)\n",
    "\n",
    "data_len = val_norm_1_feat_abs_err.shape[0]\n",
    "data_seq_len = val_norm_1_feat_abs_err.shape[1]\n",
    "\n",
    "feat_abs_err = np.transpose(\n",
    "    val_norm_1_feat_abs_err, [0, 2, 1]).reshape(\n",
    "        data_len * num_tags, data_seq_len)\n",
    "print(feat_abs_err.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_count_var = estimator.get_variable_value(\n",
    "    name=\"mahalanobis_dist_vars/abs_err_count_feat_var\")\n",
    "feat_count_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_count = feat_abs_err.shape[0]\n",
    "feat_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_count_var / feat_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07861308, 0.04502262, 0.05573479, 0.08672889, 0.00950109,\n",
       "       0.0202152 , 0.01288891, 0.01603039, 0.04260821, 0.06945327,\n",
       "       0.06055217, 0.00988415, 0.00333731, 0.01758617, 0.02184223,\n",
       "       0.02227233, 0.00090512, 0.01000122, 0.05418395, 0.05108574,\n",
       "       0.05069558, 0.00404208, 0.0203576 , 0.04845305, 0.03031093,\n",
       "       0.02525977, 0.03608983, 0.02137392, 0.03003674, 0.08325074])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_mean_var = estimator.get_variable_value(\n",
    "    name=\"mahalanobis_dist_vars/abs_err_mean_feat_var\")\n",
    "feat_mean_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07861308, 0.04502262, 0.05573479, 0.08672889, 0.00950109,\n",
       "       0.0202152 , 0.01288891, 0.01603039, 0.04260821, 0.06945327,\n",
       "       0.06055217, 0.00988415, 0.00333731, 0.01758617, 0.02184223,\n",
       "       0.02227233, 0.00090512, 0.01000122, 0.05418395, 0.05108574,\n",
       "       0.05069558, 0.00404208, 0.0203576 , 0.04845305, 0.03031093,\n",
       "       0.02525977, 0.03608983, 0.02137392, 0.03003674, 0.08325074])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_mean = np.mean(feat_abs_err, axis = 0)\n",
    "feat_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_mean_var / feat_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 30)\n"
     ]
    }
   ],
   "source": [
    "feat_cov_var = estimator.get_variable_value(\n",
    "    name=\"mahalanobis_dist_vars/abs_err_cov_feat_var\")\n",
    "if feat_cov_var.shape[0] <= 10:\n",
    "  print(feat_cov_var)\n",
    "else:\n",
    "  print(feat_cov_var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 30)\n"
     ]
    }
   ],
   "source": [
    "if num_tags == 1:\n",
    "  feat_cov = np.zeros(shape=[arguments[\"seq_len\"], arguments[\"seq_len\"]])\n",
    "else:\n",
    "  feat_cov = np.cov(m=np.transpose(a=feat_abs_err))\n",
    "\n",
    "if feat_cov.shape[0] <= 10:\n",
    "  print(feat_cov)\n",
    "else:\n",
    "  print(feat_cov.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cov_var / feat_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inverse Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 30)\n"
     ]
    }
   ],
   "source": [
    "feat_inv_var = estimator.get_variable_value(\n",
    "  name=\"mahalanobis_dist_vars/abs_err_inv_cov_feat_var\")\n",
    "if feat_inv_var.shape[0] <= 10:\n",
    "  print(feat_inv_var)\n",
    "else:\n",
    "  print(feat_inv_var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 30)\n"
     ]
    }
   ],
   "source": [
    "feat_inv = np.linalg.inv(\n",
    "  a=feat_cov + np.eye(N=arguments[\"seq_len\"]) * arguments[\"eps\"])\n",
    "if feat_inv.shape[0] <= 10:\n",
    "  print(feat_inv)\n",
    "else:\n",
    "  print(feat_inv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99999893, 0.99995074, 0.99999715, 0.99998969, 0.99999992,\n",
       "        0.99999758, 0.99998973, 1.00001502, 1.00003091, 1.00000921,\n",
       "        1.0000094 , 1.00000909, 0.9999719 , 0.99999043, 0.99997465,\n",
       "        0.99999022, 1.00000592, 0.99997562, 0.99997827, 0.99999044,\n",
       "        1.00003294, 0.99997105, 0.99998643, 1.00000273, 1.00000311,\n",
       "        1.00000448, 1.00000003, 0.99999896, 0.99999152, 1.00000392],\n",
       "       [0.99993982, 0.99999931, 1.0000078 , 1.00000844, 0.99999253,\n",
       "        1.00001516, 1.00002237, 1.00001741, 1.00005082, 1.00001463,\n",
       "        0.99999685, 0.9999769 , 1.00000539, 0.99999909, 1.0000704 ,\n",
       "        1.00000752, 0.99998264, 0.99999766, 1.00003787, 0.99999424,\n",
       "        1.00003062, 0.9999985 , 1.00001138, 0.99999679, 0.9999755 ,\n",
       "        1.0000076 , 0.99999501, 0.9999788 , 1.0000085 , 0.99998601],\n",
       "       [0.99999705, 1.00000717, 1.0000008 , 1.00000643, 1.00000953,\n",
       "        1.00003213, 0.99996328, 0.99996656, 1.00000971, 1.00000581,\n",
       "        1.00000604, 1.00002409, 1.00002768, 0.99998856, 1.00000967,\n",
       "        1.00000369, 0.99999651, 1.00000054, 1.00001521, 0.99997858,\n",
       "        0.99999737, 0.99999831, 0.99998594, 0.99997472, 1.00000456,\n",
       "        0.99997678, 1.00002666, 0.9999782 , 0.99999251, 0.99999983],\n",
       "       [0.99999424, 1.00000899, 1.00000664, 1.00000043, 1.00002318,\n",
       "        0.99996742, 0.99997665, 0.99998327, 1.00002648, 0.99999099,\n",
       "        1.00003422, 0.99997909, 0.99993896, 1.00000947, 0.999983  ,\n",
       "        0.99996343, 0.9999613 , 1.00001336, 0.99999701, 0.99998802,\n",
       "        0.99997811, 0.99998905, 1.00000874, 1.00001925, 1.00000863,\n",
       "        0.99999049, 1.00000652, 0.99996076, 1.00000706, 0.99999702],\n",
       "       [1.00000033, 0.99999471, 1.00001274, 1.00002188, 1.00000008,\n",
       "        0.99997831, 0.99997468, 1.00000035, 0.99998127, 0.99997588,\n",
       "        0.99997459, 0.99998026, 1.00000835, 0.99999887, 1.0000178 ,\n",
       "        0.99999103, 0.99999837, 1.00000039, 1.00000089, 1.00000113,\n",
       "        1.0000065 , 0.99996909, 0.99999724, 0.99999206, 0.99998406,\n",
       "        1.00000625, 0.99999681, 1.00001945, 0.99996654, 1.00001408],\n",
       "       [0.99999441, 1.00001555, 1.00003261, 0.99996122, 0.99997625,\n",
       "        1.00000006, 0.99999665, 1.00001266, 0.99999546, 1.00002196,\n",
       "        1.0000179 , 1.00000567, 1.00006179, 0.99995924, 0.99999067,\n",
       "        0.99999314, 1.00000576, 1.00002532, 1.00001345, 0.9999724 ,\n",
       "        0.99997856, 0.99999697, 0.9999928 , 0.99997243, 1.00000883,\n",
       "        1.00000463, 1.00001776, 1.00001002, 1.00003659, 1.00001917],\n",
       "       [0.99998765, 1.00001742, 0.99996365, 0.99997404, 0.99997289,\n",
       "        0.99999673, 0.99999992, 0.99998905, 1.00000559, 1.00005844,\n",
       "        1.00001322, 0.99999353, 1.00004978, 1.00000404, 1.00003733,\n",
       "        1.0000187 , 0.99997017, 1.00001395, 1.00003779, 0.99998147,\n",
       "        1.00001775, 1.0000096 , 1.00003738, 0.99999721, 0.99996862,\n",
       "        1.00002213, 0.99996557, 1.00004749, 0.99999675, 0.99998625],\n",
       "       [1.00001617, 1.00002689, 0.99997003, 0.9999851 , 0.99999801,\n",
       "        1.00001668, 0.99998916, 0.99999998, 0.99998181, 0.99995917,\n",
       "        1.00001994, 0.99997432, 0.99999518, 0.99996411, 1.00003724,\n",
       "        1.00002553, 1.00001066, 1.00001526, 1.00003939, 0.99998658,\n",
       "        0.99996347, 0.99999805, 0.99997819, 1.00002767, 1.0000181 ,\n",
       "        0.99998968, 0.99998077, 0.99998575, 1.00001766, 1.00002111],\n",
       "       [1.00003318, 1.00004793, 1.00001623, 1.00002235, 0.99998296,\n",
       "        0.9999886 , 1.0000035 , 0.99998131, 1.00000032, 1.00002842,\n",
       "        0.99997983, 1.00002612, 1.00002005, 1.00000823, 1.0000377 ,\n",
       "        0.99995974, 1.00001968, 1.00000106, 0.99998433, 1.00001244,\n",
       "        0.99998571, 0.99999952, 0.99999459, 0.99999438, 0.99997873,\n",
       "        1.00002527, 0.99996814, 1.0000162 , 0.99997169, 0.99993769],\n",
       "       [1.00001106, 1.00001838, 0.99999945, 0.99999034, 0.99997596,\n",
       "        1.00002337, 1.00005978, 0.99996252, 1.00003319, 1.00000037,\n",
       "        1.00000154, 1.00001246, 0.99999928, 1.00000592, 1.00000327,\n",
       "        0.99997959, 0.99997378, 1.00002539, 1.00000578, 1.00000702,\n",
       "        0.99999708, 1.00001323, 1.00006177, 0.99997885, 1.00001991,\n",
       "        1.00002791, 1.00000303, 1.00000554, 1.00002914, 0.99997743],\n",
       "       [1.00000733, 0.9999965 , 1.0000094 , 1.00003851, 0.99998205,\n",
       "        1.00001876, 1.00001937, 1.00002579, 0.99997603, 1.000001  ,\n",
       "        1.00000012, 0.99994864, 0.99998278, 0.9999856 , 0.99998567,\n",
       "        1.00000987, 1.00000801, 0.99999739, 1.00000497, 1.00000706,\n",
       "        0.99996661, 1.00000944, 0.999974  , 0.99998326, 0.99998144,\n",
       "        0.99996892, 0.99996539, 0.99997144, 0.99997903, 0.99998559],\n",
       "       [1.00001057, 0.99997309, 1.00002298, 0.99998007, 0.99998111,\n",
       "        1.00000403, 1.00000114, 0.99997088, 1.00002493, 1.00001306,\n",
       "        0.99995176, 1.00000004, 1.00002383, 1.00001065, 1.00001473,\n",
       "        1.00000847, 1.00002594, 1.00003177, 1.00002713, 0.99995362,\n",
       "        0.99998131, 1.00000949, 1.00002734, 0.99996776, 1.00002734,\n",
       "        1.00001309, 1.00001468, 1.00001457, 0.99997662, 1.00003511],\n",
       "       [0.99997795, 1.00000237, 1.00002941, 0.9999363 , 0.99999831,\n",
       "        1.00006369, 1.00004562, 0.9999942 , 1.0000165 , 1.00000289,\n",
       "        0.99997181, 1.000019  , 1.        , 1.00003207, 1.00001029,\n",
       "        0.9999755 , 1.0000355 , 0.99999739, 1.00001178, 0.99999899,\n",
       "        1.00002908, 1.00002619, 0.99997268, 1.00003127, 1.00002313,\n",
       "        1.00003358, 1.00000094, 1.00001389, 1.00001265, 1.00004495],\n",
       "       [0.9999924 , 1.00000348, 0.99998702, 1.00000993, 1.        ,\n",
       "        0.99996091, 1.00000732, 0.99995381, 1.00000625, 1.00000564,\n",
       "        0.99999248, 1.00001157, 1.00003468, 1.00000007, 1.00003551,\n",
       "        1.00000872, 1.00000885, 0.99998315, 0.9999932 , 1.00000228,\n",
       "        1.00002993, 0.99999585, 0.99997931, 1.00003305, 0.99998041,\n",
       "        0.99999061, 0.99998353, 1.00001053, 0.99996302, 0.99999221],\n",
       "       [0.99997887, 1.00007044, 1.00001037, 0.99997906, 1.00001953,\n",
       "        0.99999059, 1.00004243, 1.00003267, 1.00004802, 1.00000953,\n",
       "        0.99998668, 1.00001414, 1.00001161, 1.00003452, 0.99999963,\n",
       "        1.00003046, 1.000009  , 0.99997999, 1.00001837, 1.00000556,\n",
       "        0.99994374, 1.00000292, 0.99994798, 0.99997141, 0.99995675,\n",
       "        1.00003039, 1.00000408, 1.00002494, 0.99998493, 1.00002199],\n",
       "       [0.99998349, 1.00000984, 1.00000526, 0.99996257, 0.99999181,\n",
       "        0.99999642, 1.00001745, 1.00002018, 0.99995459, 0.99998467,\n",
       "        1.00001031, 1.00001551, 0.99996862, 1.00000464, 1.0000244 ,\n",
       "        1.00000005, 0.9999924 , 0.99999238, 1.00001772, 0.99999348,\n",
       "        1.00005682, 0.99999385, 1.00001042, 1.00001611, 0.99999059,\n",
       "        0.9999934 , 1.00004193, 1.0000345 , 0.99999677, 1.00002474],\n",
       "       [0.99999742, 0.99998543, 0.99999543, 0.99996047, 0.99999165,\n",
       "        1.00000684, 0.99996671, 1.00000533, 1.00002142, 0.99996619,\n",
       "        1.00000614, 1.00001607, 1.00003086, 1.0000072 , 1.00001394,\n",
       "        0.99999122, 1.        , 0.99999312, 1.00003537, 1.00002995,\n",
       "        1.00001386, 0.99997631, 1.00002576, 0.99995612, 1.00003218,\n",
       "        1.00002682, 1.00001986, 1.00000547, 1.0000083 , 1.00003573],\n",
       "       [0.99997707, 0.99999827, 1.00000512, 1.00001222, 1.00000074,\n",
       "        1.00002438, 1.00001874, 1.00001408, 1.00000046, 1.00003099,\n",
       "        0.99999379, 1.00003298, 1.00000308, 0.99999047, 0.99998563,\n",
       "        0.99999002, 0.99999751, 0.99999998, 0.99999802, 0.99995774,\n",
       "        1.00000102, 1.0000171 , 1.00001216, 1.00002683, 1.00004678,\n",
       "        1.00002778, 1.00001047, 0.9999884 , 1.00004282, 0.99997702],\n",
       "       [0.99997582, 1.00004298, 1.00001517, 0.99999508, 0.99999663,\n",
       "        1.00001011, 1.00003239, 1.0000363 , 0.99998504, 1.00000907,\n",
       "        1.00000438, 1.00002827, 1.00001155, 0.99997932, 1.00001475,\n",
       "        1.00001175, 1.00003441, 0.99999636, 0.99999996, 1.00002689,\n",
       "        0.99998392, 1.00006226, 0.99999925, 1.00001431, 1.00000342,\n",
       "        1.00000546, 0.99997387, 1.00002844, 1.00001993, 0.99998891],\n",
       "       [0.99999065, 1.00000035, 0.99998265, 0.99998875, 1.00000049,\n",
       "        0.99996679, 0.99998715, 0.99998717, 1.00000338, 0.99999795,\n",
       "        1.00000338, 0.99995987, 0.99999907, 1.00001344, 1.00000952,\n",
       "        0.99997906, 1.00002914, 0.99997353, 1.00003147, 1.00000116,\n",
       "        0.99998463, 0.99998061, 0.99997711, 0.99998462, 0.99996692,\n",
       "        0.9999747 , 1.00003115, 1.00001784, 0.99997519, 1.00004136],\n",
       "       [1.00002813, 1.0000276 , 0.99999529, 0.99997077, 1.00001136,\n",
       "        0.99998008, 1.00001316, 0.99996158, 0.99997032, 1.00000903,\n",
       "        0.99996794, 0.9999796 , 1.00003042, 1.00003127, 0.99994737,\n",
       "        1.00004766, 1.00001367, 0.99999644, 0.99997675, 0.99998132,\n",
       "        1.00000108, 1.00000118, 1.00001146, 1.00002052, 1.00000596,\n",
       "        0.99997318, 0.99996292, 1.00002923, 1.00002002, 1.00004169],\n",
       "       [0.99996992, 1.00000064, 1.00000167, 0.99999071, 0.99996858,\n",
       "        0.9999991 , 1.00001521, 0.99999683, 1.00000056, 1.00001286,\n",
       "        0.99999645, 1.00001446, 1.00003402, 0.99999929, 1.00000742,\n",
       "        0.99999948, 0.99998518, 1.00001987, 1.00005555, 0.99998015,\n",
       "        1.00000758, 1.00000002, 1.00001349, 1.00002919, 0.99999618,\n",
       "        1.00001192, 1.00003826, 1.00001951, 1.00000404, 0.99998896],\n",
       "       [0.99998588, 1.00001331, 0.99998804, 1.00001048, 0.99999609,\n",
       "        0.99998703, 1.00003507, 0.99997332, 0.99999645, 1.00006223,\n",
       "        0.9999776 , 1.00002079, 0.99996195, 0.99997419, 0.99994376,\n",
       "        1.00001268, 1.00003429, 1.00001494, 0.99999485, 0.99997759,\n",
       "        1.00002652, 1.00001443, 1.00000007, 0.99997227, 0.99999118,\n",
       "        0.99997857, 1.00000077, 1.00000954, 0.99999534, 0.99999044],\n",
       "       [1.00000051, 0.99999927, 0.99997418, 1.00001901, 0.99999132,\n",
       "        0.99996646, 0.99999704, 1.0000258 , 0.99998993, 0.99998011,\n",
       "        0.99997936, 0.99997037, 1.00004059, 1.00003525, 0.99997476,\n",
       "        1.00000945, 0.99995488, 1.00001934, 1.00001447, 0.9999891 ,\n",
       "        1.00002362, 1.00003313, 0.99997156, 0.99999963, 1.00000567,\n",
       "        1.00002185, 1.00002603, 0.99998502, 1.00000969, 0.99999908],\n",
       "       [0.99999829, 0.99997897, 1.00000725, 1.00001061, 0.99998747,\n",
       "        1.00000623, 0.9999702 , 1.00001899, 0.99997723, 1.00002121,\n",
       "        0.99999525, 1.00003091, 1.00002971, 0.99998192, 0.99995767,\n",
       "        0.99999498, 1.00004323, 1.00004682, 1.00000865, 0.99996073,\n",
       "        1.00000302, 0.99999202, 0.99999201, 1.0000072 , 1.00000045,\n",
       "        1.00002335, 0.99998872, 1.00000455, 1.0000118 , 0.99999898],\n",
       "       [1.00000162, 1.00001638, 0.99998514, 0.9999916 , 1.00001198,\n",
       "        1.00000455, 1.00003405, 0.99998933, 1.00002322, 1.0000208 ,\n",
       "        0.99996604, 1.0000089 , 1.00003931, 0.99998476, 1.0000244 ,\n",
       "        1.00000098, 1.0000314 , 1.00002796, 1.0000073 , 0.99997616,\n",
       "        0.99996434, 1.00001027, 0.99999084, 1.00001878, 1.0000273 ,\n",
       "        0.99999993, 1.00002423, 1.00001007, 0.99998654, 1.00001008],\n",
       "       [0.99999385, 0.99999787, 1.00002359, 1.00000731, 1.00000065,\n",
       "        1.00001805, 0.99997204, 0.99999012, 0.99996061, 1.00000682,\n",
       "        0.99996551, 1.00001638, 1.00000104, 0.99999088, 1.00001026,\n",
       "        1.00004128, 1.00003822, 1.00001581, 0.99997281, 1.00004232,\n",
       "        0.99997114, 1.00003727, 1.00001071, 1.00003146, 0.99999128,\n",
       "        1.00002771, 0.9999999 , 0.99999529, 0.99996892, 1.00000477],\n",
       "       [0.99999629, 0.99999292, 0.99997943, 0.99995773, 1.00002058,\n",
       "        1.00001364, 1.00005625, 0.99999032, 1.00002628, 1.00000833,\n",
       "        0.99996999, 1.00001245, 1.00002479, 1.00000852, 1.00001693,\n",
       "        1.00003576, 1.00000478, 0.99998801, 1.00002468, 1.00002404,\n",
       "        1.0000227 , 1.00001664, 1.00000994, 0.99998611, 1.00000412,\n",
       "        1.00001488, 0.99999384, 1.00000036, 1.00003407, 1.00003118],\n",
       "       [0.99999197, 1.00001102, 0.99998355, 0.99999528, 0.99996291,\n",
       "        1.00003317, 1.00000423, 1.0000231 , 0.99997107, 1.00003274,\n",
       "        0.99998291, 0.99997632, 1.00002233, 0.99999404, 0.99999523,\n",
       "        0.99999795, 1.00000358, 1.00005156, 1.00002295, 0.99998962,\n",
       "        1.00002265, 1.00001794, 0.99999511, 1.0000094 , 1.00001875,\n",
       "        0.99998442, 0.9999605 , 1.00003322, 1.00000046, 0.99999866],\n",
       "       [1.00000738, 0.99996632, 0.99999975, 1.00000577, 1.00000997,\n",
       "        1.00001568, 0.999974  , 1.00002444, 0.99994676, 0.99997378,\n",
       "        0.99998884, 1.00003416, 1.00003676, 0.99999385, 1.00002595,\n",
       "        1.00003318, 1.00001743, 0.99997843, 0.99998682, 1.00003311,\n",
       "        1.00002565, 0.99998346, 0.99999607, 0.99999621, 1.00000496,\n",
       "        1.00000577, 1.00001276, 1.00003299, 0.99999654, 0.99999857]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_inv_var / feat_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune anomaly thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7b8b8eda58>, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_protocol': None, '_log_step_count_steps': 100, '_model_dir': 'trained_model', '_num_ps_replicas': 0, '_global_id_in_cluster': 0, '_experimental_distribute': None, '_tf_random_seed': None, '_master': '', '_evaluation_master': '', '_device_fn': None, '_service': None, '_save_summary_steps': 100, '_num_worker_replicas': 1, '_eval_distribute': None, '_is_chief': True, '_train_distribute': None, '_task_id': 0, '_task_type': 'worker'}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "anomaly_detection: features = \n",
      "{'tag_3': <tf.Tensor 'IteratorGetNext:3' shape=(?, 30) dtype=float64>, 'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_4': <tf.Tensor 'IteratorGetNext:4' shape=(?, 30) dtype=float64>}\n",
      "anomaly_detection: labels = \n",
      "Tensor(\"IteratorGetNext:5\", shape=(?,), dtype=float64, device=/device:CPU:0)\n",
      "anomaly_detection: mode = \n",
      "train\n",
      "anomaly_detection: params = \n",
      "{'num_feat_anom_thresh': 300, 'train_file_pattern': 'data/labeled_val_mixed_seq.csv', 'num_feat': 5, 'autotune_principal_components': True, 'feat_anom_thresh': None, 'time_loss_weight': 1.0, 'do_eval': True, 'feat_loss_weight': 1.0, 'k_principal_components_feat': None, 'start_delay_secs': 60, 'training_mode': 'tune_anomaly_thresholds', 'throttle_secs': 120, 'reconstruction_epochs': 1.0, 'time_thresh_scl': 2.0, 'seq_len': 30, 'labeled_tune_thresh': True, 'enc_lstm_hidden_units': [64, 32, 16], 'dec_lstm_hidden_units': [16, 32, 64], 'output_dir': 'trained_model', 'max_feat_anom_thresh': 100, 'lstm_dropout_output_keep_probs': [1.0, 1.0, 1.0], 'train_steps': 2400, 'eps': 1e-12, 'max_time_anom_thresh': 100, 'train_examples': 6400, 'k_principal_components_time': None, 'previous_train_steps': 2400, 'eval_examples': 6400, 'model_type': 'pca', 'learning_rate': 0.01, 'enc_dnn_hidden_units': [64, 32, 16], 'dec_dnn_hidden_units': [16, 32, 64], 'eval_batch_size': 64, 'f_score_beta': 0.05, 'eval_file_pattern': 'data/labeled_val_mixed_seq.csv', 'feat_thresh_scl': 2.0, 'dnn_hidden_units': [1024, 256, 64], 'latent_vector_size': 8, 'num_time_anom_thresh': 300, 'train_batch_size': 64, 'time_anom_thresh': None, 'reverse_labels_sequence': True, 'min_feat_anom_thresh': 1, 'min_time_anom_thresh': 1}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-2400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2400 into trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0, step = 2401\n",
      "INFO:tensorflow:Saving checkpoints for 2500 into trained_model/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "anomaly_detection: features = \n",
      "{'tag_3': <tf.Tensor 'IteratorGetNext:3' shape=(?, 30) dtype=float64>, 'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_4': <tf.Tensor 'IteratorGetNext:4' shape=(?, 30) dtype=float64>}\n",
      "anomaly_detection: labels = \n",
      "Tensor(\"IteratorGetNext:5\", shape=(?,), dtype=float64, device=/device:CPU:0)\n",
      "anomaly_detection: mode = \n",
      "eval\n",
      "anomaly_detection: params = \n",
      "{'num_feat_anom_thresh': 300, 'train_file_pattern': 'data/labeled_val_mixed_seq.csv', 'num_feat': 5, 'autotune_principal_components': True, 'feat_anom_thresh': None, 'time_loss_weight': 1.0, 'do_eval': True, 'feat_loss_weight': 1.0, 'k_principal_components_feat': None, 'start_delay_secs': 60, 'training_mode': 'tune_anomaly_thresholds', 'throttle_secs': 120, 'reconstruction_epochs': 1.0, 'time_thresh_scl': 2.0, 'seq_len': 30, 'labeled_tune_thresh': True, 'enc_lstm_hidden_units': [64, 32, 16], 'dec_lstm_hidden_units': [16, 32, 64], 'output_dir': 'trained_model', 'max_feat_anom_thresh': 100, 'lstm_dropout_output_keep_probs': [1.0, 1.0, 1.0], 'train_steps': 2400, 'eps': 1e-12, 'max_time_anom_thresh': 100, 'train_examples': 6400, 'k_principal_components_time': None, 'previous_train_steps': 2400, 'eval_examples': 6400, 'model_type': 'pca', 'learning_rate': 0.01, 'enc_dnn_hidden_units': [64, 32, 16], 'dec_dnn_hidden_units': [16, 32, 64], 'eval_batch_size': 64, 'f_score_beta': 0.05, 'eval_file_pattern': 'data/labeled_val_mixed_seq.csv', 'feat_thresh_scl': 2.0, 'dnn_hidden_units': [1024, 256, 64], 'latent_vector_size': 8, 'num_time_anom_thresh': 300, 'train_batch_size': 64, 'time_anom_thresh': None, 'reverse_labels_sequence': True, 'min_feat_anom_thresh': 1, 'min_time_anom_thresh': 1}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-07-08T18:06:59Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-2500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-07-08-18:07:01\n",
      "INFO:tensorflow:Saving dict for global step 2500: feat_anom_acc = 0.999765625, feat_anom_f_beta = 0.9995326374824739, feat_anom_fn = 0, feat_anom_fp = 3, feat_anom_pre = 0.9995314696236139, feat_anom_rec = 1.0, feat_anom_tn = 6397, feat_anom_tp = 6400, global_step = 2500, loss = 0.0, time_anom_acc = 1.0, time_anom_f_beta = 1.0, time_anom_fn = 0, time_anom_fp = 0, time_anom_pre = 1.0, time_anom_rec = 1.0, time_anom_tn = 6400, time_anom_tp = 6400\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2500: trained_model/model.ckpt-2500\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "anomaly_detection: features = \n",
      "{'tag_2': <tf.Tensor 'StringToNumber:0' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'StringToNumber_1:0' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'StringToNumber_2:0' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'StringToNumber_3:0' shape=(?, 30) dtype=float64>, 'tag_4': <tf.Tensor 'StringToNumber_4:0' shape=(?, 30) dtype=float64>}\n",
      "anomaly_detection: labels = \n",
      "None\n",
      "anomaly_detection: mode = \n",
      "infer\n",
      "anomaly_detection: params = \n",
      "{'num_feat_anom_thresh': 300, 'train_file_pattern': 'data/labeled_val_mixed_seq.csv', 'num_feat': 5, 'autotune_principal_components': True, 'feat_anom_thresh': None, 'time_loss_weight': 1.0, 'do_eval': True, 'feat_loss_weight': 1.0, 'k_principal_components_feat': None, 'start_delay_secs': 60, 'training_mode': 'tune_anomaly_thresholds', 'throttle_secs': 120, 'reconstruction_epochs': 1.0, 'time_thresh_scl': 2.0, 'seq_len': 30, 'labeled_tune_thresh': True, 'enc_lstm_hidden_units': [64, 32, 16], 'dec_lstm_hidden_units': [16, 32, 64], 'output_dir': 'trained_model', 'max_feat_anom_thresh': 100, 'lstm_dropout_output_keep_probs': [1.0, 1.0, 1.0], 'train_steps': 2400, 'eps': 1e-12, 'max_time_anom_thresh': 100, 'train_examples': 6400, 'k_principal_components_time': None, 'previous_train_steps': 2400, 'eval_examples': 6400, 'model_type': 'pca', 'learning_rate': 0.01, 'enc_dnn_hidden_units': [64, 32, 16], 'dec_dnn_hidden_units': [16, 32, 64], 'eval_batch_size': 64, 'f_score_beta': 0.05, 'eval_file_pattern': 'data/labeled_val_mixed_seq.csv', 'feat_thresh_scl': 2.0, 'dnn_hidden_units': [1024, 256, 64], 'latent_vector_size': 8, 'num_time_anom_thresh': 300, 'train_batch_size': 64, 'time_anom_thresh': None, 'reverse_labels_sequence': True, 'min_feat_anom_thresh': 1, 'min_time_anom_thresh': 1}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-2500\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: trained_model/export/exporter/temp-b'1562609221'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n"
     ]
    }
   ],
   "source": [
    "arguments[\"training_mode\"] = \"tune_anomaly_thresholds\"\n",
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  arguments[\"do_eval\"] = True\n",
    "  arguments[\"train_file_pattern\"] = \"data/labeled_val_mixed_seq.csv\"\n",
    "  arguments[\"eval_file_pattern\"] = \"data/labeled_val_mixed_seq.csv\"\n",
    "else:\n",
    "  arguments[\"train_file_pattern\"] = \"data/unlabeled_val_mixed_seq.csv\"\n",
    "  arguments[\"train_file_pattern\"] = \"data/unlabeled_val_mixed_seq.csv\"\n",
    "arguments[\"train_batch_size\"] = 64\n",
    "arguments[\"eval_batch_size\"] = 64\n",
    "if arguments[\"model_type\"] == \"pca\":\n",
    "  arguments[\"previous_train_steps\"] = 2400\n",
    "else:\n",
    "  arguments[\"previous_train_steps\"] = 2200\n",
    "arguments[\"train_examples\"] = 6400\n",
    "arguments[\"eval_examples\"] = 6400\n",
    "estimator = train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192\n",
      " 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192\n",
      " 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192\n",
      " 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192\n",
      " 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192\n",
      " 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3191 3191 3191 3191\n",
      " 3191 3191 3191 3190 3190 3190 3190 3190 3190 3190 3190 3190 3190 3190\n",
      " 3190 3190 3190 3189 3188 3188 3187 3187 3186 3186 3185 3183 3183 3183\n",
      " 3183 3182 3182 3182 3179 3179 3179 3179 3179 3175 3174 3173 3173 3173\n",
      " 3172 3169 3166 3165 3161 3160 3153 3150 3144 3142 3140 3138 3135 3134\n",
      " 3131 3130 3126 3124 3122 3118 3114 3110 3103 3100 3091 3085 3080 3073\n",
      " 3066 3058 3051 3046 3037 3028 3021 3016 3011 3005 2996 2984 2974 2968\n",
      " 2961 2954 2943 2937 2926 2916 2908 2897 2885 2876 2867 2855 2849 2838\n",
      " 2823 2806 2796 2782 2761 2749 2735 2721 2709 2700 2694 2675 2660 2650\n",
      " 2630 2617 2603 2591 2574 2563 2553 2536 2525 2504 2491 2477 2454 2434\n",
      " 2422 2406 2392 2380 2368 2352 2331 2317 2297 2280 2268 2255 2238 2218\n",
      " 2195 2171 2160 2146 2132 2113 2096 2082 2064 2047 2040 2027 2012 1993\n",
      " 1968 1953 1938 1915 1893 1881 1859 1836 1812 1798 1780 1766 1746 1725\n",
      " 1711 1688 1667 1650 1633 1613 1595 1566 1555 1536 1520 1507 1482 1466\n",
      " 1443 1424 1400 1386 1368 1340 1329 1307 1293 1278 1266 1248 1233 1223\n",
      " 1209 1192 1176 1155 1134 1122 1107 1089 1069 1053 1036 1020  996  985\n",
      "  968  954  941  928  912  904]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  print(estimator.get_variable_value(\n",
    "      name=\"mahalanobis_dist_thresh_vars/tp_thresh_time_var\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    1    1    1    1\n",
      "    1    1    1    2    2    2    2    2    2    2    2    2    2    2\n",
      "    2    2    2    3    4    4    5    5    6    6    7    9    9    9\n",
      "    9   10   10   10   13   13   13   13   13   17   18   19   19   19\n",
      "   20   23   26   27   31   32   39   42   48   50   52   54   57   58\n",
      "   61   62   66   68   70   74   78   82   89   92  101  107  112  119\n",
      "  126  134  141  146  155  164  171  176  181  187  196  208  218  224\n",
      "  231  238  249  255  266  276  284  295  307  316  325  337  343  354\n",
      "  369  386  396  410  431  443  457  471  483  492  498  517  532  542\n",
      "  562  575  589  601  618  629  639  656  667  688  701  715  738  758\n",
      "  770  786  800  812  824  840  861  875  895  912  924  937  954  974\n",
      "  997 1021 1032 1046 1060 1079 1096 1110 1128 1145 1152 1165 1180 1199\n",
      " 1224 1239 1254 1277 1299 1311 1333 1356 1380 1394 1412 1426 1446 1467\n",
      " 1481 1504 1525 1542 1559 1579 1597 1626 1637 1656 1672 1685 1710 1726\n",
      " 1749 1768 1792 1806 1824 1852 1863 1885 1899 1914 1926 1944 1959 1969\n",
      " 1983 2000 2016 2037 2058 2070 2085 2103 2123 2139 2156 2172 2196 2207\n",
      " 2224 2238 2251 2264 2280 2288]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  print(estimator.get_variable_value(\n",
    "      name=\"mahalanobis_dist_thresh_vars/fn_thresh_time_var\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3208 3205 2890 2220 1378  715  312  134   32    3    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  print(estimator.get_variable_value(\n",
    "      name=\"mahalanobis_dist_thresh_vars/fp_thresh_time_var\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    3  318  988 1830 2493 2896 3074 3176 3205 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  print(estimator.get_variable_value(\n",
    "      name=\"mahalanobis_dist_thresh_vars/tn_thresh_time_var\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.311036789297659\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  print(estimator.get_variable_value(\n",
    "      name=\"mahalanobis_dist_thresh_vars/time_anom_thresh_var\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192\n",
      " 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192\n",
      " 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3192 3191\n",
      " 3191 3191 3191 3191 3191 3191 3191 3191 3191 3191 3191 3191 3191 3191\n",
      " 3191 3191 3191 3191 3191 3191 3191 3191 3191 3191 3191 3191 3190 3189\n",
      " 3189 3187 3187 3186 3186 3185 3183 3182 3181 3180 3180 3180 3180 3180\n",
      " 3180 3179 3176 3175 3175 3175 3174 3174 3174 3172 3169 3169 3169 3169\n",
      " 3168 3168 3166 3166 3164 3164 3162 3162 3161 3159 3158 3156 3154 3153\n",
      " 3151 3150 3149 3147 3145 3143 3140 3140 3139 3138 3136 3132 3128 3126\n",
      " 3119 3118 3115 3112 3109 3108 3105 3104 3102 3101 3099 3094 3089 3086\n",
      " 3081 3074 3071 3065 3062 3060 3057 3051 3047 3043 3041 3039 3035 3029\n",
      " 3020 3010 3002 2995 2987 2981 2973 2963 2955 2953 2948 2940 2931 2926\n",
      " 2914 2906 2902 2892 2884 2880 2876 2865 2855 2842 2833 2829 2828 2817\n",
      " 2813 2805 2801 2794 2788 2778 2767 2757 2746 2737 2729 2719 2711 2700\n",
      " 2692 2679 2677 2668 2658 2652 2638 2627 2612 2604 2596 2584 2580 2566\n",
      " 2555 2540 2529 2526 2506 2495 2486 2478 2462 2450 2434 2416 2406 2392\n",
      " 2386 2365 2355 2338 2318 2308 2295 2280 2269 2254 2238 2226 2215 2195\n",
      " 2182 2175 2164 2149 2138 2122 2112 2102 2093 2080 2065 2051 2036 2021\n",
      " 2003 1991 1977 1961 1941 1926 1913 1892 1874 1854 1837 1821 1808 1789\n",
      " 1774 1764 1744 1727 1711 1695 1680 1661 1641 1623 1613 1601 1581 1563\n",
      " 1546 1529 1516 1500 1485 1477 1463 1446 1429 1417 1403 1392 1378 1361\n",
      " 1346 1325 1311 1297 1280 1265]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  print(estimator.get_variable_value(\n",
    "      name=\"mahalanobis_dist_thresh_vars/tp_thresh_feat_var\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    2    3\n",
      "    3    5    5    6    6    7    9   10   11   12   12   12   12   12\n",
      "   12   13   16   17   17   17   18   18   18   20   23   23   23   23\n",
      "   24   24   26   26   28   28   30   30   31   33   34   36   38   39\n",
      "   41   42   43   45   47   49   52   52   53   54   56   60   64   66\n",
      "   73   74   77   80   83   84   87   88   90   91   93   98  103  106\n",
      "  111  118  121  127  130  132  135  141  145  149  151  153  157  163\n",
      "  172  182  190  197  205  211  219  229  237  239  244  252  261  266\n",
      "  278  286  290  300  308  312  316  327  337  350  359  363  364  375\n",
      "  379  387  391  398  404  414  425  435  446  455  463  473  481  492\n",
      "  500  513  515  524  534  540  554  565  580  588  596  608  612  626\n",
      "  637  652  663  666  686  697  706  714  730  742  758  776  786  800\n",
      "  806  827  837  854  874  884  897  912  923  938  954  966  977  997\n",
      " 1010 1017 1028 1043 1054 1070 1080 1090 1099 1112 1127 1141 1156 1171\n",
      " 1189 1201 1215 1231 1251 1266 1279 1300 1318 1338 1355 1371 1384 1403\n",
      " 1418 1428 1448 1465 1481 1497 1512 1531 1551 1569 1579 1591 1611 1629\n",
      " 1646 1663 1676 1692 1707 1715 1729 1746 1763 1775 1789 1800 1814 1831\n",
      " 1846 1867 1881 1895 1912 1927]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  print(estimator.get_variable_value(\n",
    "      name=\"mahalanobis_dist_thresh_vars/fn_thresh_feat_var\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2725 1433  970  635  373  232  135   72   30   16    6    3    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  print(estimator.get_variable_value(\n",
    "      name=\"mahalanobis_dist_thresh_vars/fp_thresh_feat_var\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 483 1775 2238 2573 2835 2976 3073 3136 3178 3192 3202 3205 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208 3208\n",
      " 3208 3208 3208 3208 3208 3208]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  print(estimator.get_variable_value(\n",
    "      name=\"mahalanobis_dist_thresh_vars/tn_thresh_feat_var\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.973244147157191\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  print(estimator.get_variable_value(\n",
    "      name=\"mahalanobis_dist_thresh_vars/feat_anom_thresh_var\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_val_mixed_seq.shape = (12800, 6)\n",
      "arr_val_mixed_seq_feat.shape = (12800, 30, 5)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "anomaly_detection: features = \n",
      "{'tag_2': <tf.Tensor 'fifo_queue_DequeueUpTo:3' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'fifo_queue_DequeueUpTo:4' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'fifo_queue_DequeueUpTo:1' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'fifo_queue_DequeueUpTo:2' shape=(?, 30) dtype=float64>, 'tag_4': <tf.Tensor 'fifo_queue_DequeueUpTo:5' shape=(?, 30) dtype=float64>}\n",
      "anomaly_detection: labels = \n",
      "None\n",
      "anomaly_detection: mode = \n",
      "infer\n",
      "anomaly_detection: params = \n",
      "{'num_feat_anom_thresh': 300, 'train_file_pattern': 'data/labeled_val_mixed_seq.csv', 'num_feat': 5, 'autotune_principal_components': True, 'feat_anom_thresh': None, 'time_loss_weight': 1.0, 'do_eval': True, 'feat_loss_weight': 1.0, 'k_principal_components_feat': None, 'start_delay_secs': 60, 'training_mode': 'tune_anomaly_thresholds', 'throttle_secs': 120, 'reconstruction_epochs': 1.0, 'time_thresh_scl': 2.0, 'seq_len': 30, 'labeled_tune_thresh': True, 'enc_lstm_hidden_units': [64, 32, 16], 'dec_lstm_hidden_units': [16, 32, 64], 'output_dir': 'trained_model', 'max_feat_anom_thresh': 100, 'lstm_dropout_output_keep_probs': [1.0, 1.0, 1.0], 'train_steps': 2400, 'eps': 1e-12, 'max_time_anom_thresh': 100, 'train_examples': 6400, 'k_principal_components_time': None, 'previous_train_steps': 2400, 'eval_examples': 6400, 'model_type': 'pca', 'learning_rate': 0.01, 'enc_dnn_hidden_units': [64, 32, 16], 'dec_dnn_hidden_units': [16, 32, 64], 'eval_batch_size': 64, 'f_score_beta': 0.05, 'eval_file_pattern': 'data/labeled_val_mixed_seq.csv', 'feat_thresh_scl': 2.0, 'dnn_hidden_units': [1024, 256, 64], 'latent_vector_size': 8, 'num_time_anom_thresh': 300, 'train_batch_size': 64, 'time_anom_thresh': None, 'reverse_labels_sequence': True, 'min_feat_anom_thresh': 1, 'min_time_anom_thresh': 1}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-2500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "arr_val_mixed_seq_labels.shape = (12800,)\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  arr_val_mixed_seq = np.genfromtxt(\n",
    "      fname=\"data/labeled_val_mixed_seq.csv\", delimiter=\",\", dtype=str)\n",
    "  print(\"arr_val_mixed_seq.shape = {}\".format(arr_val_mixed_seq.shape))\n",
    "\n",
    "  arr_val_mixed_seq_feat = np.stack(\n",
    "      arrays=[np.stack(\n",
    "          arrays=[np.array(\n",
    "              object=arr_val_mixed_seq[\n",
    "                  example_index,\n",
    "                  tag_index].split(\";\")).astype(np.float)\n",
    "                  for tag_index in range(num_tags)],\n",
    "          axis=1)\n",
    "              for example_index in range(len(arr_val_mixed_seq))],\n",
    "      axis=0)\n",
    "  print(\"arr_val_mixed_seq_feat.shape = {}\".format(arr_val_mixed_seq_feat.shape))\n",
    "\n",
    "  dict_val_mixed_seq_feat = {\n",
    "      tag: arr_val_mixed_seq_feat[:, :, index]\n",
    "      for index, tag in enumerate(UNLABELED_CSV_COLUMNS)}\n",
    "\n",
    "  val_mixed_pred_list = [pred for pred in estimator.predict(\n",
    "      input_fn=tf.estimator.inputs.numpy_input_fn(\n",
    "          x=dict_val_mixed_seq_feat,\n",
    "          y=None,\n",
    "          batch_size=128,\n",
    "          num_epochs=1,\n",
    "          shuffle=False,\n",
    "          queue_capacity=1000))]\n",
    "\n",
    "  arr_val_mixed_seq_labels = arr_val_mixed_seq[:, -1].astype(np.float64)\n",
    "  print(\"arr_val_mixed_seq_labels.shape = {}\".format(\n",
    "      arr_val_mixed_seq_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  labels_norm_mask = arr_val_mixed_seq_labels.astype(np.float64) == 0\n",
    "  labels_anom_mask = arr_val_mixed_seq_labels.astype(np.float64) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 1. 1. 1. 0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  print(arr_val_mixed_seq_labels[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_val_mixed_pred_mahalanobis_dist_time.shape = (12800, 30)\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  arr_val_mixed_pred_mahalanobis_dist_time = np.stack(\n",
    "      arrays=[pred[\"mahalanobis_dist_time\"]\n",
    "              for pred in val_mixed_pred_list], axis=0)\n",
    "  print(\"arr_val_mixed_pred_mahalanobis_dist_time.shape = {}\".format(\n",
    "      arr_val_mixed_pred_mahalanobis_dist_time.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_norm = 1.2051631207799625 & max_norm = 4.083560683584004\n",
      "min_anom = 22.95008660056102 & max_anom = 181.7704977617388\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  min_norm_mahalanobis_dist_time = np.min(np.max(\n",
    "      arr_val_mixed_pred_mahalanobis_dist_time[labels_norm_mask, :],\n",
    "      axis=-1))\n",
    "  max_norm_mahalanobis_dist_time = np.max(np.max(\n",
    "      arr_val_mixed_pred_mahalanobis_dist_time[labels_norm_mask, :],\n",
    "      axis=-1))\n",
    "  print(\"min_norm = {} & max_norm = {}\".format(\n",
    "      min_norm_mahalanobis_dist_time,\n",
    "      max_norm_mahalanobis_dist_time))\n",
    "\n",
    "  min_anom_mahalanobis_dist_time = np.min(np.max(\n",
    "      arr_val_mixed_pred_mahalanobis_dist_time[labels_anom_mask, :],\n",
    "      axis=-1))\n",
    "  max_anom_mahalanobis_dist_time = np.max(np.max(\n",
    "      arr_val_mixed_pred_mahalanobis_dist_time[labels_anom_mask, :],\n",
    "      axis=-1))\n",
    "  print(\"min_anom = {} & max_anom = {}\".format(\n",
    "      min_anom_mahalanobis_dist_time,\n",
    "      max_anom_mahalanobis_dist_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_anom_thresh.shape = (300,)\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  num_time_anom_thresh = arguments[\"num_time_anom_thresh\"]\n",
    "  time_anom_thresh = np.linspace(\n",
    "      start = arguments[\"min_time_anom_thresh\"],\n",
    "      stop = arguments[\"max_time_anom_thresh\"],\n",
    "      num = num_time_anom_thresh)\n",
    "  print(\"time_anom_thresh.shape = {}\".format(\n",
    "      time_anom_thresh.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_val_mix_pred_mahalanobis_dist_time_anom_multi_thresh.shape = (12800, 30, 300)\n",
      "arr_val_mix_pred_mahalanobis_dist_time_anom_multi_thresh.shape = (12800, 300)\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  arr_val_mix_pred_mahalanobis_dist_time_anom_multi_thresh = np.stack(\n",
    "      arrays = [arr_val_mixed_pred_mahalanobis_dist_time > anom_thresh\n",
    "                for anom_thresh in time_anom_thresh],\n",
    "      axis = -1)\n",
    "  print(\"arr_val_mix_pred_mahalanobis_dist_time_anom_multi_thresh.shape = {}\".format(\n",
    "      arr_val_mix_pred_mahalanobis_dist_time_anom_multi_thresh.shape))\n",
    "  arr_val_mix_pred_mahalanobis_dist_time_anom_multi_thresh = np.any(\n",
    "      a = arr_val_mix_pred_mahalanobis_dist_time_anom_multi_thresh,\n",
    "      axis = 1)\n",
    "  print(\"arr_val_mix_pred_mahalanobis_dist_time_anom_multi_thresh.shape = {}\".format(\n",
    "      arr_val_mix_pred_mahalanobis_dist_time_anom_multi_thresh.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_norms.shape = (12800, 300)\n",
      "predicted_anoms.shape = (12800, 300)\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  predicted_norms = arr_val_mix_pred_mahalanobis_dist_time_anom_multi_thresh == 0\n",
    "  print(\"predicted_norms.shape = {}\".format(predicted_norms.shape))\n",
    "  predicted_anoms = arr_val_mix_pred_mahalanobis_dist_time_anom_multi_thresh == 1\n",
    "  print(\"predicted_anoms.shape = {}\".format(predicted_anoms.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp.shape = (300,), fn.shape = (300,), fp.shape = (300,), tn.shape = (300,)\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  true_positives = np.sum(\n",
    "      a = np.stack(arrays = [np.logical_and(\n",
    "          labels_anom_mask, predicted_anoms[:, threshold])\n",
    "                             for threshold in range(num_time_anom_thresh)],\n",
    "                   axis = -1),\n",
    "      axis = 0)\n",
    "\n",
    "  false_negatives = np.sum(\n",
    "      a = np.stack(arrays = [np.logical_and(\n",
    "          labels_anom_mask, predicted_norms[:, threshold])\n",
    "                             for threshold in range(num_time_anom_thresh)],\n",
    "                   axis = -1),\n",
    "      axis = 0)\n",
    "\n",
    "  false_positives = np.sum(\n",
    "      a = np.stack(arrays = [np.logical_and(\n",
    "          labels_norm_mask, predicted_anoms[:, threshold])\n",
    "                             for threshold in range(num_time_anom_thresh)],\n",
    "                   axis = -1),\n",
    "      axis = 0)\n",
    "\n",
    "  true_negatives = np.sum(\n",
    "      a = np.stack(arrays = [np.logical_and(\n",
    "          labels_norm_mask, predicted_norms[:, threshold])\n",
    "                             for threshold in range(num_time_anom_thresh)],\n",
    "                   axis = -1),\n",
    "      axis = 0)\n",
    "  print(\"tp.shape = {}, fn.shape = {}, fp.shape = {}, tn.shape = {}\".format(\n",
    "      true_positives.shape,\n",
    "      false_negatives.shape,\n",
    "      false_positives.shape,\n",
    "      true_negatives.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_positives = \n",
      "[6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6399 6399 6399\n",
      " 6399 6399 6399 6399 6399 6399 6399 6399 6399 6399 6398 6398 6398 6398\n",
      " 6398 6398 6398 6397 6397 6396 6396 6396 6396 6396 6396 6395 6395 6395\n",
      " 6394 6393 6393 6392 6391 6391 6390 6390 6388 6388 6386 6382 6381 6380\n",
      " 6380 6379 6378 6376 6373 6372 6372 6371 6369 6364 6359 6357 6357 6354\n",
      " 6352 6346 6342 6340 6334 6333 6321 6313 6304 6302 6295 6288 6279 6272\n",
      " 6265 6261 6248 6243 6236 6226 6216 6207 6193 6189 6175 6155 6147 6132\n",
      " 6118 6105 6092 6080 6066 6049 6039 6022 6006 5994 5979 5960 5941 5930\n",
      " 5913 5898 5875 5860 5845 5826 5800 5779 5755 5740 5722 5691 5674 5649\n",
      " 5625 5599 5578 5549 5513 5494 5469 5441 5415 5402 5378 5344 5318 5298\n",
      " 5259 5229 5195 5172 5144 5117 5096 5065 5043 5004 4975 4950 4912 4873\n",
      " 4849 4823 4789 4768 4735 4701 4661 4628 4584 4546 4511 4484 4445 4405\n",
      " 4365 4326 4287 4256 4224 4186 4152 4120 4084 4051 4017 3982 3946 3907\n",
      " 3863 3831 3791 3752 3707 3680 3634 3603 3565 3537 3501 3459 3416 3372\n",
      " 3336 3296 3257 3223 3179 3143 3105 3055 3028 2992 2957 2921 2872 2835\n",
      " 2800 2768 2728 2697 2668 2623 2597 2555 2528 2494 2464 2437 2402 2371\n",
      " 2339 2301 2265 2223 2179 2149 2115 2084 2053 2020 1989 1962 1929 1905\n",
      " 1874 1848 1814 1785 1753 1731]\n",
      "false_negatives = \n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    2    2    2    2\n",
      "    2    2    2    3    3    4    4    4    4    4    4    5    5    5\n",
      "    6    7    7    8    9    9   10   10   12   12   14   18   19   20\n",
      "   20   21   22   24   27   28   28   29   31   36   41   43   43   46\n",
      "   48   54   58   60   66   67   79   87   96   98  105  112  121  128\n",
      "  135  139  152  157  164  174  184  193  207  211  225  245  253  268\n",
      "  282  295  308  320  334  351  361  378  394  406  421  440  459  470\n",
      "  487  502  525  540  555  574  600  621  645  660  678  709  726  751\n",
      "  775  801  822  851  887  906  931  959  985  998 1022 1056 1082 1102\n",
      " 1141 1171 1205 1228 1256 1283 1304 1335 1357 1396 1425 1450 1488 1527\n",
      " 1551 1577 1611 1632 1665 1699 1739 1772 1816 1854 1889 1916 1955 1995\n",
      " 2035 2074 2113 2144 2176 2214 2248 2280 2316 2349 2383 2418 2454 2493\n",
      " 2537 2569 2609 2648 2693 2720 2766 2797 2835 2863 2899 2941 2984 3028\n",
      " 3064 3104 3143 3177 3221 3257 3295 3345 3372 3408 3443 3479 3528 3565\n",
      " 3600 3632 3672 3703 3732 3777 3803 3845 3872 3906 3936 3963 3998 4029\n",
      " 4061 4099 4135 4177 4221 4251 4285 4316 4347 4380 4411 4438 4471 4495\n",
      " 4526 4552 4586 4615 4647 4669]\n",
      "false_positives = \n",
      "[6400 6390 5761 4447 2756 1426  623  251   57    7    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "true_negatives = \n",
      "[   0   10  639 1953 3644 4974 5777 6149 6343 6393 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400]\n",
      "tp + fn + fp + tn = \n",
      "[12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  print(\"true_positives = \\n{}\".format(true_positives))\n",
    "  print(\"false_negatives = \\n{}\".format(false_negatives))\n",
    "  print(\"false_positives = \\n{}\".format(false_positives))\n",
    "  print(\"true_negatives = \\n{}\".format(true_negatives))\n",
    "  print(\"tp + fn + fp + tn = \\n{}\".format(\n",
    "      true_positives + false_negatives + false_positives + true_negatives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5        0.50078125 0.54992188 0.65257813 0.7846875  0.88859375\n",
      " 0.95132812 0.98039062 0.99554688 0.99945313 1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.99992187 0.99992187 0.99992187 0.99992187 0.99992187\n",
      " 0.99992187 0.99992187 0.99992187 0.99992187 0.99992187 0.99992187\n",
      " 0.99992187 0.99992187 0.99984375 0.99984375 0.99984375 0.99984375\n",
      " 0.99984375 0.99984375 0.99984375 0.99976562 0.99976562 0.9996875\n",
      " 0.9996875  0.9996875  0.9996875  0.9996875  0.9996875  0.99960938\n",
      " 0.99960938 0.99960938 0.99953125 0.99945313 0.99945313 0.999375\n",
      " 0.99929687 0.99929687 0.99921875 0.99921875 0.9990625  0.9990625\n",
      " 0.99890625 0.99859375 0.99851563 0.9984375  0.9984375  0.99835938\n",
      " 0.99828125 0.998125   0.99789063 0.9978125  0.9978125  0.99773437\n",
      " 0.99757812 0.9971875  0.99679688 0.99664062 0.99664062 0.99640625\n",
      " 0.99625    0.99578125 0.99546875 0.9953125  0.99484375 0.99476562\n",
      " 0.99382812 0.99320312 0.9925     0.99234375 0.99179688 0.99125\n",
      " 0.99054688 0.99       0.98945313 0.98914062 0.988125   0.98773438\n",
      " 0.9871875  0.98640625 0.985625   0.98492187 0.98382813 0.98351563\n",
      " 0.98242188 0.98085937 0.98023437 0.9790625  0.97796875 0.97695312\n",
      " 0.9759375  0.975      0.97390625 0.97257812 0.97179688 0.97046875\n",
      " 0.96921875 0.96828125 0.96710938 0.965625   0.96414062 0.96328125\n",
      " 0.96195312 0.96078125 0.95898438 0.9578125  0.95664063 0.95515625\n",
      " 0.953125   0.95148438 0.94960937 0.9484375  0.94703125 0.94460937\n",
      " 0.94328125 0.94132812 0.93945312 0.93742187 0.93578125 0.93351562\n",
      " 0.93070312 0.92921875 0.92726562 0.92507812 0.92304688 0.92203125\n",
      " 0.92015625 0.9175     0.91546875 0.91390625 0.91085938 0.90851563\n",
      " 0.90585938 0.9040625  0.901875   0.89976563 0.898125   0.89570313\n",
      " 0.89398438 0.8909375  0.88867188 0.88671875 0.88375    0.88070313\n",
      " 0.87882812 0.87679688 0.87414063 0.8725     0.86992187 0.86726563\n",
      " 0.86414062 0.8615625  0.858125   0.85515625 0.85242187 0.8503125\n",
      " 0.84726563 0.84414062 0.84101563 0.83796875 0.83492188 0.8325\n",
      " 0.83       0.82703125 0.824375   0.821875   0.8190625  0.81648438\n",
      " 0.81382813 0.81109375 0.80828125 0.80523437 0.80179687 0.79929688\n",
      " 0.79617187 0.793125   0.78960937 0.7875     0.78390625 0.78148438\n",
      " 0.77851563 0.77632813 0.77351563 0.77023438 0.766875   0.7634375\n",
      " 0.760625   0.7575     0.75445312 0.75179688 0.74835938 0.74554688\n",
      " 0.74257812 0.73867187 0.7365625  0.73375    0.73101562 0.72820312\n",
      " 0.724375   0.72148437 0.71875    0.71625    0.713125   0.71070312\n",
      " 0.7084375  0.70492188 0.70289062 0.69960937 0.6975     0.69484375\n",
      " 0.6925     0.69039063 0.68765625 0.68523437 0.68273438 0.67976563\n",
      " 0.67695313 0.67367188 0.67023438 0.66789062 0.66523438 0.6628125\n",
      " 0.66039063 0.6578125  0.65539063 0.65328125 0.65070313 0.64882812\n",
      " 0.64640625 0.644375   0.64171875 0.63945312 0.63695313 0.63523438]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  acc_num = true_positives + true_negatives\n",
    "  acc_den = true_positives + false_negatives + false_positives + true_negatives\n",
    "  accuracy = acc_num / acc_den\n",
    "  print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5        0.50039093 0.52627251 0.59002489 0.69899519 0.81778686\n",
      " 0.91129147 0.96226131 0.99117237 0.99890744 1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  precision = true_positives / (true_positives + false_positives)\n",
    "  print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.99984375 0.99984375 0.99984375 0.99984375 0.99984375\n",
      " 0.99984375 0.99984375 0.99984375 0.99984375 0.99984375 0.99984375\n",
      " 0.99984375 0.99984375 0.9996875  0.9996875  0.9996875  0.9996875\n",
      " 0.9996875  0.9996875  0.9996875  0.99953125 0.99953125 0.999375\n",
      " 0.999375   0.999375   0.999375   0.999375   0.999375   0.99921875\n",
      " 0.99921875 0.99921875 0.9990625  0.99890625 0.99890625 0.99875\n",
      " 0.99859375 0.99859375 0.9984375  0.9984375  0.998125   0.998125\n",
      " 0.9978125  0.9971875  0.99703125 0.996875   0.996875   0.99671875\n",
      " 0.9965625  0.99625    0.99578125 0.995625   0.995625   0.99546875\n",
      " 0.99515625 0.994375   0.99359375 0.99328125 0.99328125 0.9928125\n",
      " 0.9925     0.9915625  0.9909375  0.990625   0.9896875  0.98953125\n",
      " 0.98765625 0.98640625 0.985      0.9846875  0.98359375 0.9825\n",
      " 0.98109375 0.98       0.97890625 0.97828125 0.97625    0.97546875\n",
      " 0.974375   0.9728125  0.97125    0.96984375 0.96765625 0.96703125\n",
      " 0.96484375 0.96171875 0.96046875 0.958125   0.9559375  0.95390625\n",
      " 0.951875   0.95       0.9478125  0.94515625 0.94359375 0.9409375\n",
      " 0.9384375  0.9365625  0.93421875 0.93125    0.92828125 0.9265625\n",
      " 0.92390625 0.9215625  0.91796875 0.915625   0.91328125 0.9103125\n",
      " 0.90625    0.90296875 0.89921875 0.896875   0.8940625  0.88921875\n",
      " 0.8865625  0.88265625 0.87890625 0.87484375 0.8715625  0.86703125\n",
      " 0.86140625 0.8584375  0.85453125 0.85015625 0.84609375 0.8440625\n",
      " 0.8403125  0.835      0.8309375  0.8278125  0.82171875 0.81703125\n",
      " 0.81171875 0.808125   0.80375    0.79953125 0.79625    0.79140625\n",
      " 0.78796875 0.781875   0.77734375 0.7734375  0.7675     0.76140625\n",
      " 0.75765625 0.75359375 0.74828125 0.745      0.73984375 0.73453125\n",
      " 0.72828125 0.723125   0.71625    0.7103125  0.70484375 0.700625\n",
      " 0.69453125 0.68828125 0.68203125 0.6759375  0.66984375 0.665\n",
      " 0.66       0.6540625  0.64875    0.64375    0.638125   0.63296875\n",
      " 0.62765625 0.6221875  0.6165625  0.61046875 0.60359375 0.59859375\n",
      " 0.59234375 0.58625    0.57921875 0.575      0.5678125  0.56296875\n",
      " 0.55703125 0.55265625 0.54703125 0.54046875 0.53375    0.526875\n",
      " 0.52125    0.515      0.50890625 0.50359375 0.49671875 0.49109375\n",
      " 0.48515625 0.47734375 0.473125   0.4675     0.46203125 0.45640625\n",
      " 0.44875    0.44296875 0.4375     0.4325     0.42625    0.42140625\n",
      " 0.416875   0.40984375 0.40578125 0.39921875 0.395      0.3896875\n",
      " 0.385      0.38078125 0.3753125  0.37046875 0.36546875 0.35953125\n",
      " 0.35390625 0.34734375 0.34046875 0.33578125 0.33046875 0.325625\n",
      " 0.32078125 0.315625   0.31078125 0.3065625  0.30140625 0.29765625\n",
      " 0.2928125  0.28875    0.2834375  0.27890625 0.27390625 0.27046875]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  recall = true_positives / (true_positives + false_negatives)\n",
    "  print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50062422 0.50101515 0.52689497 0.59062874 0.69952028 0.81815863\n",
      " 0.91149311 0.96235188 0.99119419 0.99891017 1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.99999961 0.99999961 0.99999961 0.99999961 0.99999961\n",
      " 0.99999961 0.99999961 0.99999961 0.99999961 0.99999961 0.99999961\n",
      " 0.99999961 0.99999961 0.99999922 0.99999922 0.99999922 0.99999922\n",
      " 0.99999922 0.99999922 0.99999922 0.99999883 0.99999883 0.99999844\n",
      " 0.99999844 0.99999844 0.99999844 0.99999844 0.99999844 0.99999805\n",
      " 0.99999805 0.99999805 0.99999766 0.99999727 0.99999727 0.99999688\n",
      " 0.99999649 0.99999649 0.9999961  0.9999961  0.99999532 0.99999532\n",
      " 0.99999453 0.99999297 0.99999257 0.99999218 0.99999218 0.99999179\n",
      " 0.9999914  0.99999061 0.99998943 0.99998904 0.99998904 0.99998865\n",
      " 0.99998786 0.99998589 0.99998392 0.99998313 0.99998313 0.99998195\n",
      " 0.99998116 0.99997878 0.99997719 0.9999764  0.99997402 0.99997362\n",
      " 0.99996883 0.99996563 0.99996203 0.99996122 0.99995841 0.99995558\n",
      " 0.99995195 0.99994911 0.99994627 0.99994464 0.99993934 0.99993729\n",
      " 0.99993442 0.99993031 0.99992619 0.99992247 0.99991665 0.99991499\n",
      " 0.99990914 0.99990075 0.99989737 0.99989102 0.99988507 0.99987951\n",
      " 0.99987394 0.99986877 0.99986271 0.99985532 0.99985095 0.99984349\n",
      " 0.99983643 0.99983111 0.99982444 0.99981593 0.99980737 0.99980239\n",
      " 0.99979465 0.99978779 0.9997772  0.99977025 0.99976327 0.99975436\n",
      " 0.99974209 0.9997321  0.99972059 0.99971334 0.9997046  0.99968942\n",
      " 0.99968102 0.99966858 0.99965653 0.99964337 0.99963264 0.9996177\n",
      " 0.99959893 0.99958893 0.99957566 0.99956066 0.99954658 0.9995395\n",
      " 0.99952633 0.99950746 0.99949288 0.99948156 0.99945924 0.99944185\n",
      " 0.9994219  0.99940825 0.99939147 0.99937512 0.99936228 0.99934314\n",
      " 0.99932941 0.99930478 0.99928622 0.99927004 0.99924513 0.99921917\n",
      " 0.99920298 0.99918527 0.99916181 0.99914716 0.99912387 0.99909953\n",
      " 0.99907045 0.99904608 0.99901304 0.998984   0.99895681 0.99893556\n",
      " 0.99890439 0.99887186 0.99883874 0.99880585 0.99877237 0.99874532\n",
      " 0.99871698 0.99868277 0.99865163 0.99862186 0.9985878  0.99855606\n",
      " 0.99852281 0.99848799 0.99845154 0.99841129 0.99836491 0.99833052\n",
      " 0.99828671 0.9982431  0.99819165 0.99816017 0.99810548 0.99806784\n",
      " 0.9980208  0.99798551 0.99793929 0.99788417 0.99782634 0.99776564\n",
      " 0.9977148  0.997657   0.9975993  0.99754785 0.99747966 0.99742244\n",
      " 0.99736062 0.99727695 0.99723062 0.99716755 0.99710478 0.99703864\n",
      " 0.99694598 0.9968739  0.99680398 0.99673851 0.99665452 0.99658773\n",
      " 0.99652385 0.99642194 0.99636146 0.99626118 0.99619497 0.99610956\n",
      " 0.99603226 0.99596107 0.99586642 0.99578027 0.99568896 0.99557726\n",
      " 0.995468   0.99533609 0.99519248 0.99509122 0.99497302 0.9948619\n",
      " 0.99474746 0.99462181 0.9945     0.9943908  0.99425321 0.99415018\n",
      " 0.99401323 0.99389485 0.99373497 0.99359384 0.99343273 0.99331855]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  f_beta_score_num = (1. + arguments[\"f_score_beta\"] ** 2) * (precision * recall)\n",
    "  f_beta_score_den = arguments[\"f_score_beta\"] ** 2 * precision + recall\n",
    "  f_beta_score = f_beta_score_num / f_beta_score_den\n",
    "  print(f_beta_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.311036789297659\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  print(time_anom_thresh[np.argmax(f_beta_score)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_val_mixed_pred_mahalanobis_dist_feat.shape = (12800, 5)\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  arr_val_mixed_pred_mahalanobis_dist_feat = np.stack(\n",
    "      arrays=[pred[\"mahalanobis_dist_feat\"]\n",
    "              for pred in val_mixed_pred_list], axis=0)\n",
    "  print(\"arr_val_mixed_pred_mahalanobis_dist_feat.shape = {}\".format(\n",
    "      arr_val_mixed_pred_mahalanobis_dist_feat.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_norm = 0.2741632778924941 & max_norm = 5.177749832401183\n",
      "min_anom = 14.39334767752749 & max_anom = 188.01714625781221\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  min_norm_mahalanobis_dist_feat = np.min(np.max(\n",
    "      arr_val_mixed_pred_mahalanobis_dist_feat[labels_norm_mask, :],\n",
    "      axis=-1))\n",
    "  max_norm_mahalanobis_dist_feat = np.max(np.max(\n",
    "      arr_val_mixed_pred_mahalanobis_dist_feat[labels_norm_mask, :],\n",
    "      axis=-1))\n",
    "  print(\"min_norm = {} & max_norm = {}\".format(\n",
    "      min_norm_mahalanobis_dist_feat,\n",
    "      max_norm_mahalanobis_dist_feat))\n",
    "\n",
    "  min_anom_mahalanobis_dist_feat = np.min(np.max(\n",
    "      arr_val_mixed_pred_mahalanobis_dist_feat[labels_anom_mask, :],\n",
    "      axis=-1))\n",
    "  max_anom_mahalanobis_dist_feat = np.max(np.max(\n",
    "      arr_val_mixed_pred_mahalanobis_dist_feat[labels_anom_mask, :],\n",
    "      axis=-1))\n",
    "  print(\"min_anom = {} & max_anom = {}\".format(\n",
    "      min_anom_mahalanobis_dist_feat,\n",
    "      max_anom_mahalanobis_dist_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_anom_thresh.shape = (300,)\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  num_feat_anom_thresh = arguments[\"num_feat_anom_thresh\"]\n",
    "  feat_anom_thresh = np.linspace(\n",
    "      start = arguments[\"min_feat_anom_thresh\"],\n",
    "      stop = arguments[\"max_feat_anom_thresh\"],\n",
    "      num = num_feat_anom_thresh)\n",
    "  print(\"feat_anom_thresh.shape = {}\".format(\n",
    "      feat_anom_thresh.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_val_mix_pred_mahalanobis_dist_feat_anom_multi_thresh.shape = (12800, 5, 300)\n",
      "arr_val_mix_pred_mahalanobis_dist_feat_anom_multi_thresh.shape = (12800, 300)\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  arr_val_mix_pred_mahalanobis_dist_feat_anom_multi_thresh = np.stack(\n",
    "      arrays = [arr_val_mixed_pred_mahalanobis_dist_feat > anom_thresh\n",
    "                for anom_thresh in feat_anom_thresh],\n",
    "      axis = -1)\n",
    "  print(\"arr_val_mix_pred_mahalanobis_dist_feat_anom_multi_thresh.shape = {}\".format(\n",
    "      arr_val_mix_pred_mahalanobis_dist_feat_anom_multi_thresh.shape))\n",
    "  arr_val_mix_pred_mahalanobis_dist_feat_anom_multi_thresh = np.any(\n",
    "      a = arr_val_mix_pred_mahalanobis_dist_feat_anom_multi_thresh,\n",
    "      axis = 1)\n",
    "  print(\"arr_val_mix_pred_mahalanobis_dist_feat_anom_multi_thresh.shape = {}\".format(\n",
    "      arr_val_mix_pred_mahalanobis_dist_feat_anom_multi_thresh.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_norms.shape = (12800, 300)\n",
      "predicted_anoms.shape = (12800, 300)\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  predicted_norms = arr_val_mix_pred_mahalanobis_dist_feat_anom_multi_thresh == 0\n",
    "  print(\"predicted_norms.shape = {}\".format(predicted_norms.shape))\n",
    "  predicted_anoms = arr_val_mix_pred_mahalanobis_dist_feat_anom_multi_thresh == 1\n",
    "  print(\"predicted_anoms.shape = {}\".format(predicted_anoms.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp.shape = (300,), fn.shape = (300,), fp.shape = (300,), tn.shape = (300,)\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  true_positives = np.sum(\n",
    "      a = np.stack(arrays = [np.logical_and(\n",
    "          labels_anom_mask, predicted_anoms[:, threshold])\n",
    "                             for threshold in range(num_feat_anom_thresh)],\n",
    "                   axis = -1),\n",
    "      axis = 0)\n",
    "\n",
    "  false_negatives = np.sum(\n",
    "      a = np.stack(arrays = [np.logical_and(\n",
    "          labels_anom_mask, predicted_norms[:, threshold])\n",
    "                             for threshold in range(num_feat_anom_thresh)],\n",
    "                   axis = -1),\n",
    "      axis = 0)\n",
    "\n",
    "  false_positives = np.sum(\n",
    "      a = np.stack(arrays = [np.logical_and(\n",
    "          labels_norm_mask, predicted_anoms[:, threshold])\n",
    "                             for threshold in range(num_feat_anom_thresh)],\n",
    "                   axis = -1),\n",
    "      axis = 0)\n",
    "\n",
    "  true_negatives = np.sum(\n",
    "      a = np.stack(arrays = [np.logical_and(\n",
    "          labels_norm_mask, predicted_norms[:, threshold])\n",
    "                             for threshold in range(num_feat_anom_thresh)],\n",
    "                   axis = -1),\n",
    "      axis = 0)\n",
    "  print(\"tp.shape = {}, fn.shape = {}, fp.shape = {}, tn.shape = {}\".format(\n",
    "      true_positives.shape,\n",
    "      false_negatives.shape,\n",
    "      false_positives.shape,\n",
    "      true_negatives.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_positives = \n",
      "[6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6399\n",
      " 6399 6398 6398 6398 6398 6398 6398 6398 6398 6398 6398 6398 6398 6397\n",
      " 6396 6396 6396 6396 6396 6396 6395 6395 6395 6395 6394 6394 6393 6392\n",
      " 6391 6388 6388 6386 6385 6383 6380 6379 6378 6377 6377 6377 6377 6377\n",
      " 6376 6374 6371 6370 6370 6370 6369 6368 6366 6364 6360 6359 6359 6359\n",
      " 6357 6356 6353 6351 6348 6347 6342 6340 6338 6335 6334 6332 6330 6329\n",
      " 6327 6325 6321 6318 6313 6309 6306 6303 6298 6292 6285 6279 6271 6269\n",
      " 6258 6252 6246 6242 6234 6229 6223 6221 6219 6216 6211 6204 6197 6191\n",
      " 6181 6171 6162 6149 6141 6135 6130 6120 6113 6104 6100 6089 6084 6073\n",
      " 6061 6046 6032 6020 6005 5989 5975 5962 5950 5945 5934 5923 5905 5893\n",
      " 5876 5862 5854 5835 5823 5813 5800 5782 5766 5744 5730 5721 5711 5694\n",
      " 5688 5670 5656 5641 5625 5605 5584 5564 5544 5527 5511 5492 5474 5455\n",
      " 5443 5420 5406 5390 5368 5354 5330 5306 5281 5258 5236 5212 5197 5176\n",
      " 5144 5120 5095 5085 5059 5041 5020 5000 4970 4948 4923 4893 4869 4842\n",
      " 4826 4791 4767 4741 4708 4689 4653 4624 4602 4572 4537 4502 4481 4442\n",
      " 4416 4389 4363 4331 4305 4281 4259 4237 4213 4185 4151 4124 4086 4052\n",
      " 4020 3989 3954 3922 3887 3857 3832 3799 3762 3732 3693 3665 3637 3599\n",
      " 3566 3542 3512 3473 3441 3416 3386 3347 3314 3279 3247 3218 3183 3152\n",
      " 3114 3086 3060 3031 3000 2984 2957 2930 2898 2870 2840 2812 2785 2752\n",
      " 2726 2688 2655 2623 2586 2560]\n",
      "false_negatives = \n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    1\n",
      "    1    2    2    2    2    2    2    2    2    2    2    2    2    3\n",
      "    4    4    4    4    4    4    5    5    5    5    6    6    7    8\n",
      "    9   12   12   14   15   17   20   21   22   23   23   23   23   23\n",
      "   24   26   29   30   30   30   31   32   34   36   40   41   41   41\n",
      "   43   44   47   49   52   53   58   60   62   65   66   68   70   71\n",
      "   73   75   79   82   87   91   94   97  102  108  115  121  129  131\n",
      "  142  148  154  158  166  171  177  179  181  184  189  196  203  209\n",
      "  219  229  238  251  259  265  270  280  287  296  300  311  316  327\n",
      "  339  354  368  380  395  411  425  438  450  455  466  477  495  507\n",
      "  524  538  546  565  577  587  600  618  634  656  670  679  689  706\n",
      "  712  730  744  759  775  795  816  836  856  873  889  908  926  945\n",
      "  957  980  994 1010 1032 1046 1070 1094 1119 1142 1164 1188 1203 1224\n",
      " 1256 1280 1305 1315 1341 1359 1380 1400 1430 1452 1477 1507 1531 1558\n",
      " 1574 1609 1633 1659 1692 1711 1747 1776 1798 1828 1863 1898 1919 1958\n",
      " 1984 2011 2037 2069 2095 2119 2141 2163 2187 2215 2249 2276 2314 2348\n",
      " 2380 2411 2446 2478 2513 2543 2568 2601 2638 2668 2707 2735 2763 2801\n",
      " 2834 2858 2888 2927 2959 2984 3014 3053 3086 3121 3153 3182 3217 3248\n",
      " 3286 3314 3340 3369 3400 3416 3443 3470 3502 3530 3560 3588 3615 3648\n",
      " 3674 3712 3745 3777 3814 3840]\n",
      "false_positives = \n",
      "[5469 2918 2012 1333  795  481  272  148   63   37   14    9    3    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "true_negatives = \n",
      "[ 931 3482 4388 5067 5605 5919 6128 6252 6337 6363 6386 6391 6397 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400 6400\n",
      " 6400 6400 6400 6400 6400 6400]\n",
      "true_positives + false_negatives + false_positives + true_negatives = \n",
      "[12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800\n",
      " 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800 12800]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  print(\"true_positives = \\n{}\".format(true_positives))\n",
    "  print(\"false_negatives = \\n{}\".format(false_negatives))\n",
    "  print(\"false_positives = \\n{}\".format(false_positives))\n",
    "  print(\"true_negatives = \\n{}\".format(true_negatives))\n",
    "  print(\"true_positives + false_negatives + false_positives + true_negatives = \\n{}\".format(true_positives + false_negatives + false_positives + true_negatives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57273438 0.77203125 0.8428125  0.89585938 0.93789062 0.96242187\n",
      " 0.97875    0.9884375  0.99507813 0.99710937 0.99890625 0.99929687\n",
      " 0.99976562 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         0.99992187\n",
      " 0.99992187 0.99984375 0.99984375 0.99984375 0.99984375 0.99984375\n",
      " 0.99984375 0.99984375 0.99984375 0.99984375 0.99984375 0.99984375\n",
      " 0.99984375 0.99976562 0.9996875  0.9996875  0.9996875  0.9996875\n",
      " 0.9996875  0.9996875  0.99960938 0.99960938 0.99960938 0.99960938\n",
      " 0.99953125 0.99953125 0.99945313 0.999375   0.99929687 0.9990625\n",
      " 0.9990625  0.99890625 0.99882812 0.99867187 0.9984375  0.99835938\n",
      " 0.99828125 0.99820312 0.99820312 0.99820312 0.99820312 0.99820312\n",
      " 0.998125   0.99796875 0.99773437 0.99765625 0.99765625 0.99765625\n",
      " 0.99757812 0.9975     0.99734375 0.9971875  0.996875   0.99679688\n",
      " 0.99679688 0.99679688 0.99664062 0.9965625  0.99632813 0.99617188\n",
      " 0.9959375  0.99585937 0.99546875 0.9953125  0.99515625 0.99492187\n",
      " 0.99484375 0.9946875  0.99453125 0.99445313 0.99429687 0.99414062\n",
      " 0.99382812 0.99359375 0.99320312 0.99289063 0.99265625 0.99242188\n",
      " 0.99203125 0.9915625  0.99101562 0.99054688 0.98992187 0.98976562\n",
      " 0.98890625 0.9884375  0.98796875 0.98765625 0.98703125 0.98664063\n",
      " 0.98617188 0.98601562 0.98585937 0.985625   0.98523437 0.9846875\n",
      " 0.98414062 0.98367187 0.98289063 0.98210937 0.98140625 0.98039062\n",
      " 0.97976562 0.97929687 0.97890625 0.978125   0.97757812 0.976875\n",
      " 0.9765625  0.97570313 0.9753125  0.97445313 0.97351562 0.97234375\n",
      " 0.97125    0.9703125  0.96914062 0.96789063 0.96679688 0.96578125\n",
      " 0.96484375 0.96445313 0.96359375 0.96273438 0.96132812 0.96039063\n",
      " 0.9590625  0.95796875 0.95734375 0.95585937 0.95492188 0.95414062\n",
      " 0.953125   0.95171875 0.95046875 0.94875    0.94765625 0.94695312\n",
      " 0.94617187 0.94484375 0.944375   0.94296875 0.941875   0.94070312\n",
      " 0.93945312 0.93789062 0.93625    0.9346875  0.933125   0.93179687\n",
      " 0.93054687 0.9290625  0.92765625 0.92617187 0.92523438 0.9234375\n",
      " 0.92234375 0.92109375 0.919375   0.91828125 0.91640625 0.91453125\n",
      " 0.91257813 0.91078125 0.9090625  0.9071875  0.90601562 0.904375\n",
      " 0.901875   0.9        0.89804688 0.89726562 0.89523438 0.89382812\n",
      " 0.8921875  0.890625   0.88828125 0.8865625  0.88460938 0.88226563\n",
      " 0.88039062 0.87828125 0.87703125 0.87429687 0.87242188 0.87039062\n",
      " 0.8678125  0.86632813 0.86351563 0.86125    0.85953125 0.8571875\n",
      " 0.85445313 0.85171875 0.85007813 0.84703125 0.845      0.84289063\n",
      " 0.84085937 0.83835938 0.83632812 0.83445313 0.83273438 0.83101563\n",
      " 0.82914062 0.82695312 0.82429688 0.8221875  0.81921875 0.8165625\n",
      " 0.8140625  0.81164063 0.80890625 0.80640625 0.80367188 0.80132812\n",
      " 0.799375   0.79679687 0.79390625 0.7915625  0.78851563 0.78632813\n",
      " 0.78414063 0.78117187 0.77859375 0.77671875 0.774375   0.77132813\n",
      " 0.76882812 0.766875   0.76453125 0.76148437 0.75890625 0.75617188\n",
      " 0.75367187 0.75140625 0.74867187 0.74625    0.74328125 0.74109375\n",
      " 0.7390625  0.73679688 0.734375   0.733125   0.73101562 0.72890625\n",
      " 0.72640625 0.72421875 0.721875   0.7196875  0.71757812 0.715\n",
      " 0.71296875 0.71       0.70742187 0.70492188 0.70203125 0.7       ]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  acc_num = true_positives + true_negatives\n",
    "  acc_den = true_positives + false_negatives + false_positives + true_negatives\n",
    "  accuracy = acc_num / acc_den\n",
    "  print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53921982 0.68684267 0.76081788 0.82762188 0.8895066  0.93009737\n",
      " 0.95923261 0.97739768 0.9902522  0.99425198 0.99781727 0.99859572\n",
      " 0.99953147 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  precision = true_positives / (true_positives + false_positives)\n",
    "  print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         0.99984375\n",
      " 0.99984375 0.9996875  0.9996875  0.9996875  0.9996875  0.9996875\n",
      " 0.9996875  0.9996875  0.9996875  0.9996875  0.9996875  0.9996875\n",
      " 0.9996875  0.99953125 0.999375   0.999375   0.999375   0.999375\n",
      " 0.999375   0.999375   0.99921875 0.99921875 0.99921875 0.99921875\n",
      " 0.9990625  0.9990625  0.99890625 0.99875    0.99859375 0.998125\n",
      " 0.998125   0.9978125  0.99765625 0.99734375 0.996875   0.99671875\n",
      " 0.9965625  0.99640625 0.99640625 0.99640625 0.99640625 0.99640625\n",
      " 0.99625    0.9959375  0.99546875 0.9953125  0.9953125  0.9953125\n",
      " 0.99515625 0.995      0.9946875  0.994375   0.99375    0.99359375\n",
      " 0.99359375 0.99359375 0.99328125 0.993125   0.99265625 0.99234375\n",
      " 0.991875   0.99171875 0.9909375  0.990625   0.9903125  0.98984375\n",
      " 0.9896875  0.989375   0.9890625  0.98890625 0.98859375 0.98828125\n",
      " 0.98765625 0.9871875  0.98640625 0.98578125 0.9853125  0.98484375\n",
      " 0.9840625  0.983125   0.98203125 0.98109375 0.97984375 0.97953125\n",
      " 0.9778125  0.976875   0.9759375  0.9753125  0.9740625  0.97328125\n",
      " 0.97234375 0.97203125 0.97171875 0.97125    0.97046875 0.969375\n",
      " 0.96828125 0.96734375 0.96578125 0.96421875 0.9628125  0.96078125\n",
      " 0.95953125 0.95859375 0.9578125  0.95625    0.95515625 0.95375\n",
      " 0.953125   0.95140625 0.950625   0.94890625 0.94703125 0.9446875\n",
      " 0.9425     0.940625   0.93828125 0.93578125 0.93359375 0.9315625\n",
      " 0.9296875  0.92890625 0.9271875  0.92546875 0.92265625 0.92078125\n",
      " 0.918125   0.9159375  0.9146875  0.91171875 0.90984375 0.90828125\n",
      " 0.90625    0.9034375  0.9009375  0.8975     0.8953125  0.89390625\n",
      " 0.89234375 0.8896875  0.88875    0.8859375  0.88375    0.88140625\n",
      " 0.87890625 0.87578125 0.8725     0.869375   0.86625    0.86359375\n",
      " 0.86109375 0.858125   0.8553125  0.85234375 0.85046875 0.846875\n",
      " 0.8446875  0.8421875  0.83875    0.8365625  0.8328125  0.8290625\n",
      " 0.82515625 0.8215625  0.818125   0.814375   0.81203125 0.80875\n",
      " 0.80375    0.8        0.79609375 0.79453125 0.79046875 0.78765625\n",
      " 0.784375   0.78125    0.7765625  0.773125   0.76921875 0.76453125\n",
      " 0.76078125 0.7565625  0.7540625  0.74859375 0.74484375 0.74078125\n",
      " 0.735625   0.73265625 0.72703125 0.7225     0.7190625  0.714375\n",
      " 0.70890625 0.7034375  0.70015625 0.6940625  0.69       0.68578125\n",
      " 0.68171875 0.67671875 0.67265625 0.66890625 0.66546875 0.66203125\n",
      " 0.65828125 0.65390625 0.64859375 0.644375   0.6384375  0.633125\n",
      " 0.628125   0.62328125 0.6178125  0.6128125  0.60734375 0.60265625\n",
      " 0.59875    0.59359375 0.5878125  0.583125   0.57703125 0.57265625\n",
      " 0.56828125 0.56234375 0.5571875  0.5534375  0.54875    0.54265625\n",
      " 0.53765625 0.53375    0.5290625  0.52296875 0.5178125  0.51234375\n",
      " 0.50734375 0.5028125  0.49734375 0.4925     0.4865625  0.4821875\n",
      " 0.478125   0.47359375 0.46875    0.46625    0.46203125 0.4578125\n",
      " 0.4528125  0.4484375  0.44375    0.439375   0.43515625 0.43\n",
      " 0.4259375  0.42       0.41484375 0.40984375 0.4040625  0.4       ]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  recall = true_positives / (true_positives + false_negatives)\n",
    "  print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53984013 0.68737947 0.76127195 0.8279778  0.88975177 0.93025953\n",
      " 0.95933014 0.97745277 0.99027628 0.99426623 0.99782271 0.99859922\n",
      " 0.99953264 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         0.99999961\n",
      " 0.99999961 0.99999922 0.99999922 0.99999922 0.99999922 0.99999922\n",
      " 0.99999922 0.99999922 0.99999922 0.99999922 0.99999922 0.99999922\n",
      " 0.99999922 0.99999883 0.99999844 0.99999844 0.99999844 0.99999844\n",
      " 0.99999844 0.99999844 0.99999805 0.99999805 0.99999805 0.99999805\n",
      " 0.99999766 0.99999766 0.99999727 0.99999688 0.99999649 0.99999532\n",
      " 0.99999532 0.99999453 0.99999414 0.99999336 0.99999218 0.99999179\n",
      " 0.9999914  0.99999101 0.99999101 0.99999101 0.99999101 0.99999101\n",
      " 0.99999061 0.99998983 0.99998865 0.99998826 0.99998826 0.99998826\n",
      " 0.99998786 0.99998747 0.99998668 0.99998589 0.99998432 0.99998392\n",
      " 0.99998392 0.99998392 0.99998313 0.99998274 0.99998155 0.99998076\n",
      " 0.99997957 0.99997918 0.99997719 0.9999764  0.99997561 0.99997441\n",
      " 0.99997402 0.99997322 0.99997242 0.99997203 0.99997123 0.99997043\n",
      " 0.99996883 0.99996763 0.99996563 0.99996403 0.99996283 0.99996162\n",
      " 0.99995961 0.9999572  0.99995437 0.99995195 0.9999487  0.99994789\n",
      " 0.99994342 0.99994097 0.99993852 0.99993688 0.9999336  0.99993155\n",
      " 0.99992908 0.99992825 0.99992743 0.99992619 0.99992412 0.99992122\n",
      " 0.99991832 0.99991582 0.99991165 0.99990747 0.99990369 0.99989822\n",
      " 0.99989484 0.99989229 0.99989017 0.99988592 0.99988293 0.99987908\n",
      " 0.99987737 0.99987265 0.99987049 0.99986574 0.99986054 0.99985401\n",
      " 0.99984788 0.99984261 0.99983599 0.99982889 0.99982265 0.99981683\n",
      " 0.99981143 0.99980918 0.9998042  0.99979921 0.999791   0.9997855\n",
      " 0.99977766 0.99977118 0.99976746 0.99975859 0.99975295 0.99974824\n",
      " 0.99974209 0.99973353 0.99972587 0.99971528 0.99970849 0.99970411\n",
      " 0.99969923 0.99969089 0.99968794 0.99967904 0.99967207 0.99966457\n",
      " 0.99965653 0.99964642 0.99963571 0.99962545 0.99961511 0.99960626\n",
      " 0.99959788 0.99958787 0.99957832 0.99956818 0.99956173 0.9995493\n",
      " 0.99954168 0.99953293 0.9995208  0.99951304 0.99949963 0.9994861\n",
      " 0.99947187 0.99945867 0.99944593 0.99943191 0.99942308 0.99941063\n",
      " 0.99939147 0.99937695 0.99936167 0.99935552 0.99933941 0.99932816\n",
      " 0.99931493 0.99930223 0.99928299 0.99926873 0.99925238 0.99923253\n",
      " 0.99921648 0.99919823 0.99918732 0.9991632  0.99914646 0.99912813\n",
      " 0.99910457 0.99909086 0.99906457 0.9990431  0.99902663 0.99900392\n",
      " 0.99897705 0.99894976 0.99893318 0.99890197 0.99888087 0.99885868\n",
      " 0.99883706 0.9988101  0.9987879  0.99876716 0.99874795 0.99872854\n",
      " 0.99870714 0.99868186 0.99865071 0.9986256  0.99858971 0.99855703\n",
      " 0.99852577 0.99849501 0.9984597  0.99842687 0.99839034 0.99835851\n",
      " 0.9983316  0.99829554 0.99825437 0.99822038 0.99817538 0.99814249\n",
      " 0.99810909 0.99806293 0.99802205 0.99799185 0.99795351 0.99790269\n",
      " 0.99786014 0.99782634 0.99778513 0.99773045 0.99768318 0.99763202\n",
      " 0.99758428 0.9975402  0.99748593 0.99743687 0.9973754  0.99732914\n",
      " 0.99728544 0.99723581 0.9971817  0.99715333 0.99710478 0.99705533\n",
      " 0.99699554 0.99694213 0.99688375 0.99682815 0.99677347 0.9967052\n",
      " 0.99665026 0.99656805 0.99649476 0.99642194 0.99633551 0.99627329]\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  f_beta_score_num = (1. + arguments[\"f_score_beta\"] ** 2) * (precision * recall)\n",
    "  f_beta_score_den = arguments[\"f_score_beta\"] ** 2 * precision + recall\n",
    "  f_beta_score = f_beta_score_num / f_beta_score_den\n",
    "  print(f_beta_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.304347826086957\n"
     ]
    }
   ],
   "source": [
    "if arguments[\"labeled_tune_thresh\"]:\n",
    "  print(feat_anom_thresh[np.argmax(f_beta_score)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unlabeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not arguments[\"labeled_tune_thresh\"]:\n",
    "  print(estimator.get_variable_value(\n",
    "      name=\"mahalanobis_dist_thresh_vars/count_thresh_feat_var\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not arguments[\"labeled_tune_thresh\"]:\n",
    "  print(estimator.get_variable_value(\n",
    "      name=\"mahalanobis_dist_thresh_vars/mean_thresh_time_var\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not arguments[\"labeled_tune_thresh\"]:\n",
    "  print(estimator.get_variable_value(\n",
    "      name=\"mahalanobis_dist_thresh_vars/var_thresh_time_var\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not arguments[\"labeled_tune_thresh\"]:\n",
    "  print(estimator.get_variable_value(\n",
    "      name=\"mahalanobis_dist_thresh_vars/time_anom_thresh_var\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not arguments[\"labeled_tune_thresh\"]:\n",
    "  print(estimator.get_variable_value(\n",
    "      name=\"mahalanobis_dist_thresh_vars/count_thresh_feat_var\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not arguments[\"labeled_tune_thresh\"]:\n",
    "  print(estimator.get_variable_value(\n",
    "      name=\"mahalanobis_dist_thresh_vars/mean_thresh_feat_var\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not arguments[\"labeled_tune_thresh\"]:\n",
    "  print(estimator.get_variable_value(\n",
    "      name=\"mahalanobis_dist_thresh_vars/var_thresh_feat_var\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not arguments[\"labeled_tune_thresh\"]:\n",
    "  print(estimator.get_variable_value(\n",
    "      name=\"mahalanobis_dist_thresh_vars/feat_anom_thresh_var\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_labeled_test_mixed_seq = np.genfromtxt(\n",
    "    fname=\"data/labeled_test_mixed_seq.csv\",\n",
    "    delimiter=\",\",\n",
    "    dtype=str)\n",
    "arr_labeled_test_mixed_seq_features = np.stack(\n",
    "    arrays=[np.stack(\n",
    "        arrays=[np.array(arr_labeled_test_mixed_seq[\n",
    "                           example_index,\n",
    "                           tag_index].split(';')).astype(np.float)\n",
    "                  for tag_index in range(num_tags)], axis=1)\n",
    "              for example_index in range(len(arr_labeled_test_mixed_seq))],\n",
    "    axis=0)\n",
    "dict_labeled_test_mixed_sequences_features = {\n",
    "    tag: arr_labeled_test_mixed_seq_features[:, :, index]\n",
    "    for index, tag in enumerate(UNLABELED_CSV_COLUMNS)}\n",
    "arr_test_labels = arr_labeled_test_mixed_seq[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "anomaly_detection: features = \n",
      "{'tag_2': <tf.Tensor 'fifo_queue_DequeueUpTo:3' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'fifo_queue_DequeueUpTo:4' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'fifo_queue_DequeueUpTo:1' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'fifo_queue_DequeueUpTo:2' shape=(?, 30) dtype=float64>, 'tag_4': <tf.Tensor 'fifo_queue_DequeueUpTo:5' shape=(?, 30) dtype=float64>}\n",
      "anomaly_detection: labels = \n",
      "None\n",
      "anomaly_detection: mode = \n",
      "infer\n",
      "anomaly_detection: params = \n",
      "{'num_feat_anom_thresh': 300, 'train_file_pattern': 'data/labeled_val_mixed_seq.csv', 'num_feat': 5, 'autotune_principal_components': True, 'feat_anom_thresh': None, 'time_loss_weight': 1.0, 'do_eval': True, 'feat_loss_weight': 1.0, 'k_principal_components_feat': None, 'start_delay_secs': 60, 'training_mode': 'tune_anomaly_thresholds', 'throttle_secs': 120, 'reconstruction_epochs': 1.0, 'time_thresh_scl': 2.0, 'seq_len': 30, 'labeled_tune_thresh': True, 'enc_lstm_hidden_units': [64, 32, 16], 'dec_lstm_hidden_units': [16, 32, 64], 'output_dir': 'trained_model', 'max_feat_anom_thresh': 100, 'lstm_dropout_output_keep_probs': [1.0, 1.0, 1.0], 'train_steps': 2400, 'eps': 1e-12, 'max_time_anom_thresh': 100, 'train_examples': 6400, 'k_principal_components_time': None, 'previous_train_steps': 2400, 'eval_examples': 6400, 'model_type': 'pca', 'learning_rate': 0.01, 'enc_dnn_hidden_units': [64, 32, 16], 'dec_dnn_hidden_units': [16, 32, 64], 'eval_batch_size': 64, 'f_score_beta': 0.05, 'eval_file_pattern': 'data/labeled_val_mixed_seq.csv', 'feat_thresh_scl': 2.0, 'dnn_hidden_units': [1024, 256, 64], 'latent_vector_size': 8, 'num_time_anom_thresh': 300, 'train_batch_size': 64, 'time_anom_thresh': None, 'reverse_labels_sequence': True, 'min_feat_anom_thresh': 1, 'min_time_anom_thresh': 1}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_model/model.ckpt-2500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "pred_list = [pred for pred in estimator.predict(\n",
    "    input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x = dict_labeled_test_mixed_sequences_features,\n",
    "        y = None,\n",
    "        batch_size = 128,\n",
    "        num_epochs = 1,\n",
    "        shuffle = False,\n",
    "        queue_capacity = 1000))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '0', '0', '0', '0', '0', '1', '1', '1', '0'], dtype='<U467')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_test_labels[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_test_example_index = np.argmax(arr_test_labels=='0')\n",
    "norm_test_example_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_feat_abs_recon_err': array([[0.02961231, 0.04731501, 0.04280788, 0.18310867, 0.11453425],\n",
       "        [0.01695931, 0.02709786, 0.02451657, 0.10486845, 0.06559509],\n",
       "        [0.02099442, 0.03354521, 0.03034976, 0.12981965, 0.08120203],\n",
       "        [0.0326694 , 0.05219969, 0.04722725, 0.20201232, 0.12635846],\n",
       "        [0.00357891, 0.00571844, 0.00517371, 0.02213031, 0.01384248],\n",
       "        [0.00761475, 0.01216696, 0.01100796, 0.04708604, 0.02945226],\n",
       "        [0.00485505, 0.00775748, 0.00701851, 0.03002136, 0.01877833],\n",
       "        [0.0060384 , 0.00964825, 0.00872917, 0.03733862, 0.02335526],\n",
       "        [0.01604984, 0.02564469, 0.02320182, 0.0992447 , 0.06207744],\n",
       "        [0.02616195, 0.04180198, 0.03782   , 0.16177327, 0.10118898],\n",
       "        [0.02280905, 0.03644465, 0.03297301, 0.14104048, 0.08822065],\n",
       "        [0.0037232 , 0.00594899, 0.0053823 , 0.02302255, 0.01440058],\n",
       "        [0.00125711, 0.00200863, 0.0018173 , 0.0077734 , 0.00486225],\n",
       "        [0.00662443, 0.01058463, 0.00957636, 0.04096241, 0.02562193],\n",
       "        [0.00822762, 0.01314623, 0.01189394, 0.05087578, 0.03182274],\n",
       "        [0.00838964, 0.01340509, 0.01212815, 0.05187759, 0.03244937],\n",
       "        [0.00034095, 0.00054477, 0.00049287, 0.00210825, 0.00131871],\n",
       "        [0.0037673 , 0.00601945, 0.00544605, 0.02329524, 0.01457114],\n",
       "        [0.02041024, 0.0326118 , 0.02950527, 0.12620739, 0.07894257],\n",
       "        [0.01924319, 0.03074708, 0.02781817, 0.11899091, 0.07442867],\n",
       "        [0.01909623, 0.03051225, 0.02760572, 0.11808214, 0.07386024],\n",
       "        [0.00152259, 0.00243281, 0.00220107, 0.00941496, 0.00588905],\n",
       "        [0.00766839, 0.01225267, 0.0110855 , 0.04741772, 0.02965972],\n",
       "        [0.0182515 , 0.02916253, 0.02638457, 0.11285874, 0.070593  ],\n",
       "        [0.01141765, 0.0182433 , 0.01650548, 0.07060142, 0.0441611 ],\n",
       "        [0.00951496, 0.01520315, 0.01375493, 0.05883605, 0.03680187],\n",
       "        [0.01359447, 0.02172146, 0.01965231, 0.08406184, 0.05258058],\n",
       "        [0.00805122, 0.01286437, 0.01163893, 0.04978498, 0.03114044],\n",
       "        [0.01131437, 0.01807827, 0.01635617, 0.06996276, 0.04376162],\n",
       "        [0.03135924, 0.05010629, 0.04533326, 0.19391088, 0.12129102]]),\n",
       " 'X_time_abs_recon_err': array([[1.32264710e-01, 1.52989871e-02, 6.26708769e-02, 1.04427616e-02,\n",
       "         2.58802305e-01],\n",
       "        [3.53154540e-01, 4.08491936e-02, 1.67334920e-01, 2.78827864e-02,\n",
       "         6.91017345e-01],\n",
       "        [1.22159276e-01, 1.41300970e-02, 5.78826275e-02, 9.64490219e-03,\n",
       "         2.39029006e-01],\n",
       "        [4.11551236e-02, 4.76039077e-03, 1.95004978e-02, 3.24934098e-03,\n",
       "         8.05282137e-02],\n",
       "        [3.27430057e-01, 3.78736567e-02, 1.55145910e-01, 2.58517485e-02,\n",
       "         6.40682261e-01],\n",
       "        [1.41723437e-01, 1.63930729e-02, 6.71526975e-02, 1.11895612e-02,\n",
       "         2.77310192e-01],\n",
       "        [1.19248835e-01, 1.37934479e-02, 5.65035758e-02, 9.41511272e-03,\n",
       "         2.33334148e-01],\n",
       "        [3.00992167e-01, 3.48156004e-02, 1.42618867e-01, 2.37643846e-02,\n",
       "         5.88951253e-01],\n",
       "        [6.93463570e-02, 8.02125542e-03, 3.28583263e-02, 5.47513749e-03,\n",
       "         1.35689989e-01],\n",
       "        [1.78531558e-01, 2.06506483e-02, 8.45934588e-02, 1.40956911e-02,\n",
       "         3.49332628e-01],\n",
       "        [9.92938925e-02, 1.14852706e-02, 4.70483420e-02, 7.83960018e-03,\n",
       "         1.94288319e-01],\n",
       "        [3.51339823e-01, 4.06392864e-02, 1.66475055e-01, 2.77395082e-02,\n",
       "         6.87466491e-01],\n",
       "        [3.35811025e-01, 3.88430788e-02, 1.59117057e-01, 2.65134553e-02,\n",
       "         6.57081298e-01],\n",
       "        [3.06832630e-03, 3.54911635e-04, 1.45386248e-03, 2.42255096e-04,\n",
       "         6.00379283e-03],\n",
       "        [3.59223371e-01, 4.15511720e-02, 1.70210509e-01, 2.83619418e-02,\n",
       "         7.02892225e-01],\n",
       "        [3.65392700e-01, 4.22647750e-02, 1.73133717e-01, 2.88490320e-02,\n",
       "         7.14963749e-01],\n",
       "        [1.89381022e-01, 2.19055999e-02, 8.97342514e-02, 1.49522942e-02,\n",
       "         3.70561770e-01],\n",
       "        [3.63545525e-01, 4.20511132e-02, 1.72258472e-01, 2.87031910e-02,\n",
       "         7.11349382e-01],\n",
       "        [1.97285385e-01, 2.28198933e-02, 9.34795690e-02, 1.55763713e-02,\n",
       "         3.86028233e-01],\n",
       "        [3.17428701e-01, 3.67168052e-02, 1.50406976e-01, 2.50621064e-02,\n",
       "         6.21112610e-01],\n",
       "        [5.62183430e-02, 6.50274518e-03, 2.66378904e-02, 4.43863486e-03,\n",
       "         1.10002409e-01],\n",
       "        [4.95899311e-01, 5.73604038e-02, 2.34971556e-01, 3.91529855e-02,\n",
       "         9.70325982e-01],\n",
       "        [7.54054724e-02, 8.72211001e-03, 3.57293119e-02, 5.95352585e-03,\n",
       "         1.47545857e-01],\n",
       "        [9.47362852e-03, 1.09580946e-03, 4.48888148e-03, 7.47976115e-04,\n",
       "         1.85370451e-02],\n",
       "        [1.53849185e-01, 1.77956516e-02, 7.28982307e-02, 1.21469314e-02,\n",
       "         3.01036638e-01],\n",
       "        [4.04643777e-01, 4.68049258e-02, 1.91732022e-01, 3.19480418e-02,\n",
       "         7.91766315e-01],\n",
       "        [3.45682853e-01, 3.99849477e-02, 1.63794617e-01, 2.72928706e-02,\n",
       "         6.76397499e-01],\n",
       "        [1.63810684e-01, 1.89478928e-02, 7.76182793e-02, 1.29334266e-02,\n",
       "         3.20528299e-01],\n",
       "        [2.41932093e-01, 2.79841537e-02, 1.14634481e-01, 1.91013852e-02,\n",
       "         4.73388430e-01],\n",
       "        [4.63730870e-01, 5.36394976e-02, 2.19729210e-01, 3.66131745e-02,\n",
       "         9.07382006e-01]]),\n",
       " 'feat_anom_flags': 0,\n",
       " 'mahalanobis_dist_feat': array([0.83468701, 0.53313629, 0.60991195, 1.77999493, 0.61188752]),\n",
       " 'mahalanobis_dist_time': array([0.53789342, 1.06333042, 0.61114748, 1.19834535, 0.87685318,\n",
       "        0.46932739, 0.63224489, 0.6852061 , 0.99398735, 0.20250663,\n",
       "        0.7768982 , 1.05017519, 0.93760628, 1.4744341 , 1.107322  ,\n",
       "        1.15204375, 0.12385959, 1.13865398, 0.06656121, 0.80435492,\n",
       "        1.0891512 , 2.09808261, 0.95006604, 1.42800239, 0.38142806,\n",
       "        1.43657159, 1.00916589, 0.30921799, 0.25708151, 1.86489219]),\n",
       " 'time_anom_flags': 0}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list[norm_test_example_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/seaborn/timeseries.py:183: UserWarning: The `tsplot` function is deprecated and will be removed in a future release. Please update your code to use the new `lineplot` function.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "flatui = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\n",
    "for i, arr in enumerate(np.split(\n",
    "    ary=pred_list[norm_test_example_index][\"X_time_abs_recon_err\"].flatten(),\n",
    "    indices_or_sections=len(UNLABELED_CSV_COLUMNS),\n",
    "    axis=0)):\n",
    "  sns.tsplot(arr, color = flatui[i%len(flatui)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "flatui = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\n",
    "for i, arr in enumerate(np.split(\n",
    "    ary=pred_list[norm_test_example_index][\"X_feat_abs_recon_err\"].flatten(),\n",
    "    indices_or_sections=len(UNLABELED_CSV_COLUMNS),\n",
    "    axis=0)):\n",
    "  sns.tsplot(arr, color = flatui[i%len(flatui)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomalous Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "anom_test_example_index = np.argmax(arr_test_labels=='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_feat_abs_recon_err': array([[6.28670108, 6.2117147 , 6.15559259, 2.90579496, 0.84970258],\n",
       "        [3.60046653, 3.55752096, 3.52537918, 1.66418244, 0.48663451],\n",
       "        [4.45712027, 4.40395672, 4.3641675 , 2.06013893, 0.60241875],\n",
       "        [6.93572348, 6.8529957 , 6.7910797 , 3.20578155, 0.93742363],\n",
       "        [0.7598038 , 0.75074102, 0.74395817, 0.35119119, 0.10269412],\n",
       "        [1.61661305, 1.59733045, 1.58289876, 0.74721957, 0.21849938],\n",
       "        [1.03072855, 1.01843425, 1.00923282, 0.47641613, 0.13931197],\n",
       "        [1.28195332, 1.26666246, 1.25521832, 0.59253549, 0.17326719],\n",
       "        [3.40738526, 3.36674272, 3.3363246 , 1.57493776, 0.46053789],\n",
       "        [5.55418922, 5.48794008, 5.43835719, 2.56721846, 0.7506972 ],\n",
       "        [4.84236676, 4.78460808, 4.74137971, 2.23820486, 0.65448818],\n",
       "        [0.79043726, 0.78100909, 0.77395277, 0.36535037, 0.1068345 ],\n",
       "        [0.2668853 , 0.26370195, 0.26131944, 0.12335786, 0.03607188],\n",
       "        [1.40636927, 1.38959441, 1.37703959, 0.65004216, 0.19008309],\n",
       "        [1.74672699, 1.72589241, 1.71029918, 0.80735992, 0.23608541],\n",
       "        [1.78112211, 1.75987728, 1.743977  , 0.8232578 , 0.24073422],\n",
       "        [0.07238284, 0.07151947, 0.0708733 , 0.03345629, 0.00978317],\n",
       "        [0.7997993 , 0.79025947, 0.78311957, 0.36967764, 0.10809986],\n",
       "        [4.33309984, 4.28141558, 4.2427335 , 2.00281507, 0.5856563 ],\n",
       "        [4.08533533, 4.03660635, 4.00013609, 1.8882951 , 0.55216876],\n",
       "        [4.05413437, 4.00577755, 3.96958583, 1.87387361, 0.54795168],\n",
       "        [0.3232455 , 0.3193899 , 0.31650425, 0.14940827, 0.04368945],\n",
       "        [1.62800056, 1.60858213, 1.59404878, 0.75248302, 0.2200385 ],\n",
       "        [3.87479835, 3.82858061, 3.79398984, 1.79098217, 0.52371285],\n",
       "        [2.42397045, 2.39505787, 2.37341881, 1.12039065, 0.32762079],\n",
       "        [2.02002799, 1.99593354, 1.97790052, 0.9336832 , 0.27302443],\n",
       "        [2.88610961, 2.85168473, 2.8259201 , 1.33399738, 0.39008293],\n",
       "        [1.70927625, 1.68888838, 1.67362947, 0.7900497 , 0.23102362],\n",
       "        [2.40204336, 2.37339231, 2.351949  , 1.11025566, 0.32465715],\n",
       "        [6.65757537, 6.57816528, 6.51873234, 3.07721788, 0.89982948]]),\n",
       " 'X_time_abs_recon_err': array([[1.22884445e-01, 1.42139769e-02, 5.82262337e-02, 9.70215682e-03,\n",
       "         2.40447944e-01],\n",
       "        [1.80417203e-01, 2.08687599e-02, 8.54869326e-02, 1.42445694e-02,\n",
       "         3.53022269e-01],\n",
       "        [2.64110159e-01, 3.05494785e-02, 1.25143095e-01, 2.08524210e-02,\n",
       "         5.16784241e-01],\n",
       "        [8.45172122e-02, 9.77606000e-03, 4.00467200e-02, 6.67292958e-03,\n",
       "         1.65374795e-01],\n",
       "        [2.14217206e-01, 2.47783878e-02, 1.01502360e-01, 1.69131979e-02,\n",
       "         4.19158721e-01],\n",
       "        [4.22285316e-02, 4.88455130e-03, 2.00091098e-02, 3.33409031e-03,\n",
       "         8.26285508e-02],\n",
       "        [5.35684140e-02, 6.19622933e-03, 2.53822768e-02, 4.22941369e-03,\n",
       "         1.04817294e-01],\n",
       "        [2.84378925e-01, 3.28939557e-02, 1.34747028e-01, 2.24527110e-02,\n",
       "         5.56444128e-01],\n",
       "        [7.75255303e-02, 8.96733595e-03, 3.67338572e-02, 6.12091184e-03,\n",
       "         1.51694174e-01],\n",
       "        [2.93458569e-01, 3.39441932e-02, 1.39049228e-01, 2.31695807e-02,\n",
       "         5.74210264e-01],\n",
       "        [2.53664679e-01, 2.93412555e-02, 1.20193722e-01, 2.00277138e-02,\n",
       "         4.96345574e-01],\n",
       "        [2.04179279e-01, 2.36173062e-02, 9.67460969e-02, 1.61206684e-02,\n",
       "         3.99517513e-01],\n",
       "        [3.91344980e-01, 4.52666611e-02, 1.85430664e-01, 3.08980552e-02,\n",
       "         7.65744564e-01],\n",
       "        [1.66784546e-01, 1.92918777e-02, 7.90273817e-02, 1.31682233e-02,\n",
       "         3.26347253e-01],\n",
       "        [3.94096280e-01, 4.55849025e-02, 1.86734311e-01, 3.11152800e-02,\n",
       "         7.71128033e-01],\n",
       "        [1.99839705e-01, 2.31153501e-02, 9.46898805e-02, 1.57780439e-02,\n",
       "         3.91026271e-01],\n",
       "        [2.50424059e-01, 2.89664148e-02, 1.18658222e-01, 1.97718555e-02,\n",
       "         4.90004655e-01],\n",
       "        [2.68492344e-01, 3.10563634e-02, 1.27219503e-01, 2.11984098e-02,\n",
       "         5.25358860e-01],\n",
       "        [2.19941667e-02, 2.54405331e-03, 1.04214776e-02, 1.73651641e-03,\n",
       "         4.30359771e-02],\n",
       "        [9.25035606e-02, 1.06998366e-02, 4.38308847e-02, 7.30347973e-03,\n",
       "         1.81001680e-01],\n",
       "        [2.17698333e-01, 2.51810478e-02, 1.03151819e-01, 1.71880450e-02,\n",
       "         4.25970240e-01],\n",
       "        [1.15108210e+01, 1.33145041e+00, 5.45416269e+00, 9.08819588e-01,\n",
       "         2.25232188e+01],\n",
       "        [6.80193576e+00, 7.86776212e-01, 3.22295553e+00, 5.37036624e-01,\n",
       "         1.33093450e+01],\n",
       "        [4.16640388e+00, 4.81925672e-01, 1.97416366e+00, 3.28952162e-01,\n",
       "         8.15240079e+00],\n",
       "        [9.61856312e+00, 1.11257397e+00, 4.55755572e+00, 7.59419208e-01,\n",
       "         1.88206386e+01],\n",
       "        [9.46601978e-02, 1.09492936e-02, 4.48527623e-02, 7.47375378e-03,\n",
       "         1.85221571e-01],\n",
       "        [9.36686835e+00, 1.08346057e+00, 4.43829539e+00, 7.39547025e-01,\n",
       "         1.83281475e+01],\n",
       "        [6.36773049e-01, 7.36551924e-02, 3.01721641e-01, 5.02754599e-02,\n",
       "         1.24597357e+00],\n",
       "        [3.36872752e+00, 3.89658881e-01, 1.59620134e+00, 2.65972823e-01,\n",
       "         6.59158777e+00],\n",
       "        [7.79330408e+00, 9.01447247e-01, 3.69269475e+00, 6.15308621e-01,\n",
       "         1.52491549e+01]]),\n",
       " 'feat_anom_flags': 1,\n",
       " 'mahalanobis_dist_feat': array([105.74953793, 104.47218608, 103.5161968 ,  48.15860538,\n",
       "         13.13485644]),\n",
       " 'mahalanobis_dist_time': array([6.05891197e-01, 1.88838137e-01, 4.17849401e-01, 8.84013181e-01,\n",
       "        5.61771491e-02, 1.19056118e+00, 1.10835921e+00, 5.64777615e-01,\n",
       "        9.34694795e-01, 6.30596421e-01, 3.42130913e-01, 1.65874612e-02,\n",
       "        1.34017000e+00, 2.87659749e-01, 1.36011525e+00, 4.80448209e-02,\n",
       "        3.18639234e-01, 4.49616320e-01, 1.33724152e+00, 8.26122642e-01,\n",
       "        8.14116437e-02, 8.19447447e+01, 4.78103690e+01, 2.87054704e+01,\n",
       "        6.82278988e+01, 8.10487836e-01, 6.64034447e+01, 3.11926411e+00,\n",
       "        2.29231188e+01, 5.49967207e+01]),\n",
       " 'time_anom_flags': 1}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list[anom_test_example_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXecXOV573/vOVN36vaiXe2qLkh0BCqACqBCxzHGMS7Y1zGOb3xjJ3GLy419Y4ckJLFjJ7GNjW0wYNNBNCEhQBIggSSQMBKqSFpJ23d2ypk+57z3jzNndvqcKbvT3u/nw2elMzNnz7Ka3zznKb+HUErBYDAYjOqHK/cFMBgMBqM0MEFnMBiMGoEJOoPBYNQITNAZDAajRmCCzmAwGDUCE3QGg8GoEZigMxgMRo3ABJ3BYDBqBCboDAaDUSNoZvKbtbS00L6+vpn8lgwGg1H17N27d5xS2prreTMq6H19fdizZ89MfksGg8Goegghp9Q8j6VcGAwGo0Zggs5gMBg1AhN0BoPBqBGYoDMYDEaNwASdwWAwagQm6AwGg1EjMEFnMBiMGoEJOoNRY0iuSQRef7Xcl8EoA0zQGYwaw7/1RTj/5f9CcrvKfSmMGYYJOoNRY0get/zVNVnmK2HMNEzQGYwaQ/IK8leXs8xXwphpmKAzGDUG9XoBsAi9HmGCzmDUGCxCr1+YoDMYNQb1MUGvV5igMxg1BhWYoNcrTNAZjBpD8kVz6E6WQ683mKAzGDUGVXLobhah1xtM0BmMGoJGIqABPwCWcqlHmKAzGDUEjaZbQAhrW6xDmKAzGDWE0rLItbRB8rhBRbHMV8SYSZigMxg1hJI/13R1A5IEKrjLfEWMmYQJOoNRQygROt/VLf+d5dHrCiboDEYNoeTQNUzQ6xIm6AxGDSF5PQAAvqtH/jsT9LqCCTqDUUMoU6KaThah1yNM0BmMGkLyeQFCwHd0AgBE1rpYVzBBZzBqCOoVQBpMIFodiNkCyiL0uiKnoBNCegghrxJCDhJCDhBCvhI93kQI2UIIORr92jj9l8tgMLKhCDoAcLZGFqHXGWoi9AiAv6OULgKwDMBfEUIWAfgWgK2U0gUAtkb/zmAwyojkFcCZzAAAzmZnOfQ6I6egU0qHKKXvRP/sAfABgFkAbgFwf/Rp9wO4dbouksFgqIN6BZCYoDeylEudkVcOnRDSB+BiAG8BaKeUDkUfGgbQnuE1dxFC9hBC9oyNjRVxqQwGIxfJETpLudQXqgWdEGIG8ASAr1JKE+aJKaUUAE33OkrpvZTSJZTSJa2trUVdLIPByE5iDt0Oyvxc6gpVgk4I0UIW84copU9GD48QQjqjj3cCGJ2eS2QwGGqRfF5w5qkIHZRC8jA/l3pBTZcLAXAfgA8opf8R99BGAHdG/3wngGdKf3kMBkMtlFJQrxfEZAEQFXSw4aJ6QqPiOVcA+DSAPxFC9kWPfRvAPwN4lBDyeQCnANw+PZfIYDDUQAN+QBLBxbUtAmxzUT2RU9Appa8DIBkevqa0l8NgMApFsc4lcUVRgO0WrSfYpCiDUSPEllskCzqL0OsGJugMRo2QEqFbbQBYhF5PMEFnMGoEKSbocg6d8BoQi5UVResIJugMRo1AvfJyCyXlAsiFUbYsun5ggp6D3z/+Av72Bz8u92UwGDmZSrlYYseYn0t9wQQ9B+8dOoZ9B46U+zIYjJxIPqUoaood42x2VhStI5ig58DlFuARfBBFqdyXwmBkhXoFQKcD0epixzibHZKTCXq9wAQ9B26PnJf0eH1lvhIGIzuSIIBrMCcc46x2UMENKkbKdFWMmYQJeg5cHvk21h39yqhewuEIfnzvw5h01aa3CfVNWecqcPZG2c/FXZs/MyMRJuhZoJTC5VYE3Vvmq2EUy5EPT+Hhp1/Czr1/KvelTAuSV4gZcymw4aL6ggl6FgLBEMIR+VbVxSL0qscZ/XB2uWvzw5l6vTHrXIWYnwvrdKkLmKBnQYnOAcAt1KYI1BPK77NWP5zl5RaWhGNTjousF70eYIKehfg3Pku5VD9OjxKh16agU68nNiWqwCL0+oIJehYSBb02RaCeqP0I3ZswJQoAnMUKEML8XOoEJuhZiI/kXCxCr3oUIXe6PWW+ktJDw2EgFARJalskPA9itrKiaJ3ABD0LSppFr9exlEsNEIvQazDlQqNToiSpywUAODsbLqoXmKBnQYnoujvaWFG0BlB+n7WYckn2Qo+Hs7Lx/3qBCXoWXG4BRoMeLU02lkOvAWo6Qo86LSa3LQLycBEritYHTNCz4BK8sFnMsFrMLIdeAyh96IFgCMFQqMxXU1qmInRLymOc1c7aFusEJuhZcLkFWC0mWC0mlkOvAVweASajQf5zjUXp1CsXepPbFgG5F516mJ9LPcAEPQsujwCb1Qyb2QS3IECSmONitRIIhhAMhjB7VgeA2sujS2mWWyhw9mgvuts1o9fEmHmYoGfB7ZlKuUgShc8fKPclMQpEEfCYoNfY+H/yPtF4OKsyLcry6LUOE/QsuNwCbNGUC8B60asZJcVSuxG6AHAciMGY8lgsQmeCXvMwQc+AJElwC0I0QpcFnXW6VC8pgl5zOXQBpMEEwqW+pacidFYYrXWYoGfA6/NDkqicQ7fIt7GsMFq9pKRcauzDWfJ5U5ZbKPB2lnKpF5igZ0B5w1vjInSWcqlelHH/tpZGGPS6WAtjrUC9QtopUQAg5qifCxP0mocJegaUW3KbxQyrOZpyEWpLBOqJ+N+nzWquvQhd8KQdKgKifi4WKxP0OoAJegaUaNxmjc+hswi9WnF5BDQYDdBqNbBZzLWXQ/elOi3Gw9saWQ69DmCCnoGplIsJOq0WRoOepVyqGLljSRa8mozQvan7ROMhNjuL0OsAJugZUKJxe1QE5GnR2hKBesLl8cJmle+0ajJC9woqInQm6LUOE/QMKG94s7kBgFwcZY6L1UstR+hUkkB93qwROmdjfi71ABP0DLg8AizmBmh4HgDk8X+WcqlaFBsHQI7QPYK3ZqwcqN8HUAoujY+LAmdvBBU8oBHm51LLMEHPgCs69q9gtZhqKqqrN5xuD+xW2YnQZpWtHDxeX5mvqjTErHPTOC0qxIaLmC96TcMEPQMujxDrbgFkQfcItSEA9UZEFOERfLEPaKUuUit5dCnqtMhlaFsE5JQLwIaLah0m6BmIz7kC0Ry6xwtKaRmvilEIHmGqBTX+a63ccVFfNELPMFgExAk6i9BrmpyCTgj5DSFklBDyftyx7xNCzhJC9kX/u356L3PmccflXAE5hx4KhxEM1tZihHogfqgo/mvtROiZl1soxASd7RatOv7+7v9W/Vw1EfrvAGxIc/zHlNKLov+9oPo7VgnJOXSLMv7POl2qjpig12qErljnZk25MMfFasQfCOLlHW+rfn5OQaeUbgfgKOaiqo2IKELw+mCLy6HbzMxxsVpxeuolQs8yWGSxAhzHWherjInJ/JaSFJND/zIh5L1oSqYx05MIIXcRQvYQQvaMjY0V8e1mjuScKyDn0AE2/l+NJEfoZpMRHEdqRtCzLbdQIBwHjvm5VB0Opzuv5xcq6D8HMA/ARQCGAPx7pidSSu+llC6hlC5pbW0t8NvNLMob3WpObFsEmONiNaL8Pu1RQec4DlZz7QwXSV4BRG8A0WiyPo+zNbKiaJXhmIkInVI6QikVKaUSgF8BuLyQ81QqyREdALbkoopxegRoNDwaoguigei0aA1F6OmWQyfD2eyQnCzlUk3MSIROCOmM++tHALyf6bnViFL4jC+KsiUX1YvSgkoIiR2zW81w1sjvknqzj/0rsAi9+phw5hehZ79HA0AI+QOA1QBaCCFnAPwDgNWEkIsAUAAnAXwx3wutZGIpl7iiqEGvg1ajYV0uVYgrqQUVkCP0odGJMl1RaZG8QtaWRQUWoVcfjkl3QnNGLnIKOqX0E2kO35fPRVUbMafFOBEghDDHxSoleUgMkO+4Dh09WZ4LKjHUJ8hbiXLA2eygXgE0HAbRamfgyhjF4nC60GS3qX4+mxRNg8sjgOc4mBoSN6jLgs4i9GojU4ReS0VRLsuUqMLUtGh+t/GM8uFwutHUmPvDWoEJehpcbtnHJT7nCshRHRP06iNThB4MhREIBMt0VaWDegWQDAui42Hj/9WHY5JF6EWTPPavYLWYWA69yqCUwukWEtJnwFQHk7MGonTJm339nAKbFq0+JpxuNNlZhF4UTo83thg6HquZ5dCrDa8/AFEUU1MuNTItSkNBIBxS2eWi+Lmwwmg1EAyF4PX50dzIIvSiSJdzBaYcFxnVQ7Ixl0Kt+LlIUS/0bMstFGIROku5VAWOSbkHnUXoReL2pOZcAcBmMcEfCCIUDpfhqhiFkG5IDKihCD029p+7bZGYLQDHswi9SnBEe9BZDr1I5KJo+hw6wIaLqgklArcn/T7tNROhR5dbqIjQCceBs1pZhF4lTESnRFmXSxEEQyEEgqGUIhow5e3ClkVXD7UfoSvr53Ln0IHotCgrilYFio9LM4vQC0eJvjOlXOKfw6h8lAg8WdC1Wg0ajIYaiNAVL3S1gm6vGQvd4J5dCOzcXu7LmDYUH5dGe+50mkLOSdF6I93Yv8KU42J1i0A94XR7QAiBJU3Xks1S/QZd1Bf1QlcxWATIgh4+fmQ6L2nGEB69H5LHA8PyleW+lGnB4XTDbGqAXqdT/Rom6Em4POm7IgDmiV6NuNwCLKYGaHg+5TGb1VT1dshqvNDjkSP02ki5SBMTEB3joKIIkub3W+1MTLry6nABWMolBeUNnq5tkaVcqo9MLahAbUToktcLcDyI3pD7yZBz6IqfSzVDKYXoGAciYYhjI+W+nGnB4XSjmQl6cSgRerqUi6nBCJ7j2HBRFZFu7F+hFvxcZC90c4pNRSZqZfyful1ARP5QEofOlvlqpgeH04WmPIaKACboKcS226QRASUXy8b/q4faj9A9qloWFThrVNCrPO0iOsan/jx4poxXMn04JvMb+weYoKfg9nih12lhMOjTPs4cF6sLl9ub0U/aZjXD4/VBFKUZvqrSoXa5hQJnrw0/F2liStAjg6fLeCXTQzgcgVvw5jVUBDBBT8HlEdKmWxRszBO9qsgVoVNKY0vBqxF5uUUegh6L0Ku7dVGJ0InZUpMRusOV/1ARwAQ9hUxj/wrMz6V6CIXD8PkDsFvT9/HWguMi9Qn1GaFHBV236AJEhmpQ0AsYKgKYoKfgcmeO6ADZcZHl0KuDTMZcCrUwLSoJ+UXoxGSW/VyqPUKfGAdns0PT0wdxeBBUjJT7kkqKo4Cxf4AJegpOjxAb8U8Hy6FXD5nG/hVqwXGR+rwgDeqLooTjwNlsNRGhc00t4Lu6AVGEODZa7ksqKROT+RtzAUzQU3B7vLBZs+fQBa8PEVGcwatiFEK2IbH449UaoVNRBPV5wZnVj4YDtTFcJDrGwTe3QNPVLf+9xgqjSoTO+tCLgFIaLYpmz6EDgCD4ZuqyGAWSK0KvdsdF6pf/DeYToQNyYbTaBV2aGJuK0AFEaqww6nC60GA0ZOy2ywQT9Dh8/gAiETFtD7rClJ8LS7tUOs4MxlwKpgYjeJ6v2ghdynPsX4GzV7fjIhUjkJyT4JpawDU2gxiNNdfpUkgPOsAEPQF3lrF/BWU1nVuoThGoJ3IVRQkhsFlM1RuhRwU9n6IooETo1VsUlSYdAKXgm1tBCAHf2V1zEXq+u0QVmKDHERv7T+PMp2BjBl1Vg8sjwKDXwaDP7FZXzdOi+RpzKXD2RlCfFzQcmo7LmnaUHnSuqRkAwHfOqr0IvYCxf4AJegK5cq4As9CtJpw5WlCB7H4u/lc2wf3rn03HpZUEqYgIHajeXnRlSpRvagEAaLq6IY4OgUZqp3XRMZm/MRfABD2BbE6LCsxCt3rIZsylYLdmjtADO7bCv2kjKKXTcXlFU3CEbqtuQY9F6M2tADDVujg6XM7LKhkRUYTLI+TdsggwQU9ATcrFYmoAwAS9Gsg29q9gs2SO0MWxUdBgoGKFT4qun8s7QrdV97SoNDEO8Hzsg0nT2QOgdky6nC4PKKV5DxUBTNATyFVEAwCe52AxN7C9olWAmgjdZjXD5famjcIVn21xZHBarq9YaHRBNGloyOt1UxF6dRZGJce43N3CyfJVa62LhQ4VAUzQE3ALAkxGA7Ta7IucrObq7YyoJ9RG6KFwGP5AMOG4JHhAffKHtjgyNG3XWAySzwtiNILw+S0eq3Y/F3FCHipS4OyNIMYGiEO1MVxU6FARwAQ9AZc7+1CRAjPoqnwkSYJH8KqK0IHUadH4LTiVKujycov8pkSBaM6dr14/F2XsX0FuXZyFyGBtLLpwOKMROutyKQ5XjrF/BRvzc6l4PF4fJIlmdFpUiI3/e6pP0CWvAC7PKVFAFsBqHv8XJ8YSInQA0HT1QKwR10XHZNSYi0XoxZHLOlfByjzRKx6nS2lBzS54uSJ0rq2jYgVdWT9XCJzVDsntKvEVTT80EAD1CgkROiDn0cWR4ZpoXZxwuqDX69BgVLcnNh4m6HGoTrmYzcxCt8LJZcylkMlxURobAbQ66BYugjhcmUVReblF/hE6EDXoclZfykWcnAAw1YOuoOnqBiSxYgvY+aD0oKvdExsPE/Q4XCpyroAcoXsELySpeleX1Tqx3bAqiqKAPIQUjzg6DL6lDXxHJ8SxEdAKdNeU18/ln0MH5NbFalwULU2MAZjqQVeopU4Xh9NVUIcLwAQ9RqyIlkMAADmHLkkUPn9gBq6MUQiuHMZcCrYMk7/i2Cj4tnbw7V2AKMaEpJKQvJ68nRYVqjZCdyhTos0Jx6dsdGtB0N0F9aADKgSdEPIbQsgoIeT9uGNNhJAthJCj0a+NBX33CkIpomXbJ6pgjRXSWNqlUlEzUwAAGo0GpgZj2hw639oOvr0TABCpsDw6pTTqhV5gDt3WCOr3gYaCuZ9cQUgxH5fElAux2kEaTBCHqr/TpVBjLkBdhP47ABuSjn0LwFZK6QIAW6N/r2qUrpVs1rkKiuizwmjl4vII4DkOZlPuoZtkPxcaDsutcXGCXnG52WAQiEQKL4pW6fi/ODEOojek/NyEEPBd3YhU+aILUZTgdLmnL+VCKd0OwJF0+BYA90f/fD+AWwv67hWEEqGpidBtioUui9ArFmU3rJrCUrLjojgxJtuztrWDb20HCIE4XFkRuuSLGnM11JegKz3o6X6vmq7uqk+5uDwCJImiebpSLhlop5Qq/8KHAbRneiIh5C5CyB5CyJ6xscrLQyqozbkCLOVSDTjdHlUFbiA1QldaFvnWdhCtFlxza8W1LsaMuQpOuUQFvcoKo+LEOLikHnQFvrNbLmCHwzN8VaVjYlL+fZStKEplE4yMdnSU0nsppUsopUtaW1szPa3sqG1zA+JSLmzJRcWiZuxfITlCl2KC3iF/be+sOEGPWecWG6FXWWFUcoyntCwqyK2LUsW2maqhmKEioHBBHyGEdAJA9KuqlduBYOUa6rvccrStrg+dpVwqHTXGXAp2qznhbisWobdE7VkrUNBp1Gmx8Bx61M+liiJ0SqkcoWcQdL5Ldl2MVPHE6EQRY/9A4YK+EcCd0T/fCeAZNS8am6jcaMDlEUAIidnjZkOr1cBo0LOUSwWTX4RuguD1IRLtNRdHh8HZm0B08oJeTUcXJMd4RXWESFGnxXytcxWIyQxoNJCcVSToXgEIBVPG/hU0nbMAVHfrYjHGXIC6tsU/ANgJoJ8QcoYQ8nkA/wxgLSHkKIBro3/PSTBUubktt0eA1dwAnlf3GcfG/ysXSilcbnVDYsBU3US54xLHRsC3TZWFYp0uoyOpLy4TUxF6YX3ohJDo+H/1CLo4oSy2SC/oxGoDMZmrerjIMemGVqNR1Z2VDjVdLp+glHZSSrWU0m5K6X2U0glK6TWU0gWU0msppcldMGkJRyIIhioz7eLyqBv7V7BazHXrib7/wBFs+ORfx6KJSiMQDCEUDueVQwemOp3EsVFwrfGC3iUfr6C0y9T6ucImRQFUnUGXFBsqyiDohFS9SZe8S7SwsX9gpidFKXB6UFW6fcbJJ+cKyK2L9ZpDf+f9w5iYdOHQsZPlvpS0qB37V4j3c6GUymP/8YLeEY3QK6jYRr0eQKMBdJkXYOdCFvTKTYMmI2YY+49H7kWvXkGXh4oKy58DZRj9P3WmcqKceNwedWP/ClZL/S65OD0opx5Onq4cgYvH6Zbzy6pTLnEROnW75DxttMMFALjGZkCrQ6SChoskrxecSV2ffSY4W2N1RuiNzRmfw3d1Qxobqah6Rz44Jl0F588BJugxXB4h6y7RZKx17ImuCPqJChX02Nh/ARH6VA96W+xxwnHg29orKuVCvQJIgS2LCtUWoUuOCRCzBUSvz/gcTecsgNKK+l3lg+zjUiURukbD4+Tpyvwf7co7Qpe3FlXqRvjpRBH0UxX7u8xT0OMi9PihongqrXWR+gr3QlfgbHZQvx80WB3RrLzYIvssSzW7LkqShMkifFyAGRZ0vU6LU2cr502hEIlE4PX5886hhyORiu6tnw68Pj8mJl0ghOBEhQq6U6Uxl0KD0QCNhoczPkJv60h4TqUJuuQVCjbmUqi28X957D9zugWQNxcB1dm66PZ4IUpS9eTQdTotTp0eqrioVuknV+PjomDNYLta65wZkova558zD063B06Xp8xXlMrU1K+63ychJDYtKo4Oy+ZPlsQoiW/vBBU8se6SckO93oKtcxWqbbhIdEzkjNA5ixXEYq3KCF0ZKirUxwUoQ4Tu9Qcw7qisf0Axp8U8Uy7xr60XlHTLVUsvBgCcrMCaiMstwNRghEajUf0axc9FHBsB19aeUmzUVFjrorytqH4idCqKkBwTGadE45FNuqrPdXFq7L9aInStFgBw6szwTH7bnOTj46Jgs9Tn+L8i6FdefhGAyiyMujxCXh/OwJSfizQ2mpI/B+KGiypE0IvZJ6owJeiVXxiV3E5AEjP2oMfDd1Zn66IjNvZfJRG6TicL+skzlSUC+VjnKtSrJ/rA2WG0NNkxd3YX9HpdRRa5nW71Y/8KUxH6cA5BL/+/XSpGQAP+EkTo0ZRLFUToUo4p0Xg0Xd2QxkerptirMOGssghdq5E9UCo2Qi8g5VJvy6LPDI2ip6sdHMehd1ZHRfai5zskBkQNutweSM7JhB50BWKxghgbKiJCj439F9m2SBpMsp9LFUToYo4p0Xj4zminSwUNgqnBMekCz/OwmhPH/n1bnld9jhnvQ+/t7qi4vKsi6PmM/tfrkouBwRH0dMkRbF9PZ2UKeh7GXApyysULShN70BUIIeA7uipi0YXkk//NFdvlQgipmuGifCN0AFWXR3c43WiyW8BxU7Is+X1w/1SVVRaAcgj6rE4MVJqguwXwPA+T0aD6NXq9Djqttq5SLoLPD8ekK07QuzA0OoFAoLJubQuJ0G1WMyKiCD9I2pQLUDmti1SQO4uKzaED1ePnIk6MARwHzp57fbHSi15tni6ONGP/4ulTeZ1j5gW9p7PiRMAteFWvK1MghETH/+snQj8bbVmcHRX0OT1doJTi1NnKSaHFZgoKiNABwAMeXFtqygWQBT0yUv6221iEXmTbIgDZcbEKUi6SYxycvRGEz925xJktIFZbSmG00rrrknFMulKGisIDJ/I6R1kidEopBgYrx4rU5RZiKZR8qLfx/4GocHcrEXq3XCispLSL8gFbSIQOAG6iydjrzLd3AqEgJKcqc9FpY2r9XOFOiwqcvUoidJUtiwqy6+JZALKd8i9+/ySu+9RX8Oae96brEotmIs3Yf2TgBKDRqj7HjAt6X48sApXk6VJIzhWIOi7W0Ro6pWVRSbn0zGoHx5GKqoko9RC7NT+xs0c/AARLI0iG/vVKaV1UllsUO1gEKBF65Qu6pGLsPx6+cxYig2cgihLu/q/f4b4/yDt49h04Ml2XWBSUUkw63SnGXJGBk9B0z1Z9nhkXdOV2vZJEwO1RvwwhHsXPpV4YGBxBa7MdRoNsjqTX6dDV3oqTA5UToSuTq4W0LQKA15y5ZSzmi17mwqjS5VJs2yIAcPZG0EDl+7mIKsb+49F0dSMwNoa//9FP8dSLr+FzH78J83q7cfh4fjnpmcIj+BCORFJy6JGBE9DMnqP6PDMu6AaDHp1tLRXVuuhyC3n1oCvUWw79zOAIujsTC4Z9PV0V5ekyFaEXJuiCMfPr+HY5t17+CF0ACClZhA5Udi86DYdA3a68IvRAcxt+IHXg1V3v4m/uugP/+87bcM783ooV9HRDRZLPB2lspLIFHZALo6cqaLio0JRLva2hOz04ErvDUpjT04WBs8MQRalMV5WIK09jLgVzgxEA4NFmXv3FGYzg7I1lHy6iXgHE2ADCFf/2VbpGKrkwKjomAEB1Dn1i0oWvPPYaDsCA792yCnfcuh4AsHBeLyYmXRVZHE03VBQ5LRdENbP7VJ+nPII+qwOnzgyXvVsAkNeVBUPhglIuNos5+vrad1wUfH44nG70zErsAOnr6UQ4EsHgyFiZriyRWFE0zw9ozuOCCSI8fPYCVCW0LpZi7F+hGvxccq2ei+fs8Bi+8PUf4dSoA9/lhnF185R3ev+8XgCoyCjdMRk15orLoUcGTgIANL0VHqH39XTCHwhidKL8UcHUUFEBKZdoZ4xH8JX0miqRM0pBtDNx6KavR84rV4oFgMstQKfVwqDPbzWbODYCKyR4aPa3RCUIumzMVXy6BYhPuZT/vZgJtUNFR08M4PN/949wuQX8z93fwuWNhoRe9P65cnHxyIcD03exBaLs543vcokMnAB0uljtRg1litCVdrfyi4CSMrEXVBStHwvdgbNRQZ+VlEOvsNZFOX1myns1mzQ2CgtEuMXsd418eyfEsVFQMVLMZRYF9XlBilgOHc9UyqVyI3Q1Y//vvn8Yd33jbvA8j1/923dwwbnzY50uCmZTA7o6WnGkQiN0jiMJmYLIwAlountBeF71ecoWoQOV0brochd2iw7Ul4Xu6cFoD3pSUdRqMaGp0VYxrosut5B3yyIAiKPDsECCO5hdqPn2TkASIY6XL8UkCZ6SDBUBADE2ABptZUfojnFAq0vxqFfYtuuaUgl/AAAgAElEQVQd/J/v3oPmRhvu+7fvYu7sWQBkT5fkRRf9c3txuAIj9AmnG3abFTw/JcmRgZN55c+BMgl6S5MdJqOhMgS9iJRLPVnonh4aTWhZjGdOT2fFtKG6PPmP/QPRlIuGwO3Nnj7jO8rviy5H6KXJoRNCwLe2ITJUGR/I6RAnxsA3Nae969q4eTu+8cOfYl5fN359z3fQ0TbV2qjp6oHkGIcU8MeO9c+bjdODIxB8/pRzlROHM3E5tOQVII2P5tXhApRJ0AkhmN3dWVGCXlgfev2kXE6fHUZPV/qR+L6eLpw8PVgRRW6n21PQ3ZY4NgKryRjrkskEXwGLLkqxfi4e7cJFCB85WLLzlZpMiy2efPFV/ONP7sNlFy7Cz+/+Fuy2xDuzKU+Xs7FjSmH0aIVF6Y7JxF2ikdMnAaA6BB2Qc6+VENVNeaEXkXKpAwvd03Eui8n0dXfCI/gwEa3Ul5NCjLkAWdBtFhO8/gDC4cxpF76lDeA4iGWyZqWURtfPlVDQ+xdBmhiDOD5asnOWEnFiPG3+/JGNW3Be/zz8+Pt/i4Y0xnpTrotxhdEK7XRJNuaKnFJaFqtE0Hu7OzAy5oC/zCZdLo8AvV6Xd1cEAJiMBvAcV/MpF8Hrw6TLk1HQ50Q7Xcp9x0Uplad+C4zQ7Y1yx0e2Oy6i0YBraStbhE4DfkASSzIlqqDrXwwACB8+ULJzlhLJMZbS4eL1+XFiYBArlpwPrTaDVYPiix4n6C1NdjTZrRUl6JRSOJyuhKEiucNFH7ObUEv5IvSoCAyU2amv0LF/YMpxsdaHi5I9XJLpmy3/LstdGBW8PoiSlPfvU/L7QD1u2Jrl/GuuFJqmjK2LMWOuErUtAoBmznxAq0PoUOWlXSSfD9TvB58k6IeOnwKlFIsWzs34Wq6hAZy9KaF1kRCChfMqqzDq9QcQDIXRHB+hD5yEpqc37+GxMkboldHuJhfRCn9zWC3mmh//VwQ9eUpUoa25EQ1GQ9nbUAvZPAUA0pj88zW2yz32ufPonWWbFpViPi6laVsEAKLVQjt/YUVG6NKE3E3ENSWO/R888iEAYNHC7CkJvit1v+jCubPx4amzCIXDJbzSwlGGipIj9HzTLUAZBb2nqw2EkLJ7uhSac1WoBwtdRdC7O1M3+QBy1NPbXf7tRYoQ5+vjIo7JuePGLjnIyBWh8+2dkCYdZTG0oiV0WoxH278Y4eOHQStE5BSUHvTklMvBIyfQ1d6CRlv2hcqaru6UzUX9c3shiiJOVIipnCNp7F8SPJAc49Ul6LJTX0vZC6OF5lwV6sFC9/TgCNqaG2FI07KoMKens+wmXU53YRG6OCoHFY09PQDURejy62b+56XR5RakhF0uQDSPHgohcvJ4Sc9bLFNj/4lOiwePfIhFC3ILHt/VDWnSAck31Y5aaYXRWIQe7XKJDOTv4aJQNkEH5LRLuQXd5SnMaVGhHiL0gcGRlAnRZPp6ujA67oC3jP29hRpziWMjAM9PCXqO32c5fdGlaPBQyqIoIHe6AECowtIuojL2H9flMulyY3BkPGv+XCHW6TI81brY09WGBqOhYgRdMeZqjo79xzxcqilCB+R2t4Gzw5Ck8jj1UUrhKqIoCtRHDj2dbW4yU9O/5UuhOQvMoYtjw+Cb22BsMEKn1aruRY+UQdCpL1oULWHbIgBwLW3gmloqLo8uOcZBGkzgjFMumAePyBFsrvw5APBd8od0fOsix3FYMKenYgTd4XSBEBLro48MnADRG8BnWIWYjbJH6MFgCCNj5Vnp5fUHIIpiUSkXq8UEr8+PiCiW8MoqB6VlMVNBVGFOzKSrfHlJl1sAxxFYTJktcNMhjo2Ca5VrOjarKWcOnWtsArS6siy6kLxKhF7aHDohBNr+RQgfrqxOF3mxRVL+/OgJEEJwzvy+nK9XJnsjyXn0eb04euJ02YLJeByTbtgsZmiini2RgRPge/oKskcur6ArUd3Z8qRdYkNFBewTVVA6ZIQadVzMZMqVTHdnG3ieL2sKzeURYDGbwOX5RhDHRsC3yj+fzWLOGaETjgPf1lFUyiX0wZ8g/PF3eb+OegXZ10SXuZ5RKNr+RRCHzlaUr4s0MZ7Ssnjw8Ifo6+mEKephnw3O2ACuqTnV02VeL3z+AE4Pln+YKl0PujYPy9x4ihJ0QshJQsifCCH7CCF78n39lFNfeUTAXeAtejzWaHGqVtMuZ4YU29zsgq7RaNDT1VbWXvRCOpaoGIE0Pha7vbVZzaqsHIptXRT++DsID90XK8iqRfJ6S54/V1AGjEIVFKUnR+iUUhw8ekJV/lyB70zfughURmF0Im5KVPK4IU06CsqfA6WJ0NdQSi+ilC7J94VNdivMpoayRXWuIqxzFZSCaq12uigReqaWxXgUT5dyUcjmKckxAUhiXhE6AGg6ugqO0CXBg9D+vQCA4J6deb2Wej0lM+ZKRjO/H+D4ikm7UEohORLH/kfGHHA43ao6XBQ0Xd0Jfi4AMLd3Fniex5EPyy/ojskpY66pDpfyCXrBEELQ191ZtkJaMT4uCrXuuHh6cBhtLU1ZWxYV+ro7cXpwFJFIebzCZevcAjpcAPBtsqDbrRbVETr1CpAET97XGdz9JiCKgE6P4J5deb1WjtBLmz9X4AxGaPrmVkxhlLqdQCSS0IOuDBQt7s8jQu/qgeR0QPJNvUd1Wi3m9s6qiIlRh9MdS7lETsk/X7kEnQLYTAjZSwi5q5AT9HZ3lG2/aKHryuJRPgxq1XHx9NAoerpyR+eAXBgVRRFnhsqTl3QWkHIRR6OCrkToVrlrKZdzZKx1sQCTrsDOHeCaWmC85joE9+8FDakfUCrl+rl0aPsXI3zkA9AKKPIru0TjI/QDRz6ERsNjwZwe1edJZ9IFyBuMjkQtBMqFPxCEPxCMpVwiAydBjA3gWtW955IpVtCvpJReAuA6AH9FCFmZ/ARCyF2EkD2EkD1jY6lLAXq7OzE24SxL/3IxXugK1lqP0M9mdllMRilylyuPXkjKRYnQubiUiyiKOf89FtqLTgMBBPfugmHZVTBcvgIIBRF6f5/q10s+AVyJWxbj0Z2zGNTvQ+RM+VMRsbH/5qmx/4NHTmDBnNnQabPvfo2H75QXXkSGUgujDqe7rEujJ9IMFWlm9+W9cUuhKEGnlJ6Nfh0F8BSAy9M8515K6RJK6ZLW1tbkh8vav+xyCzA1GGPtQoVgbmgAIaQmBd0jeOF0ezA7gw96MuUscgeCIQSDoQKGioZBLDZwBrljQvlAcObqRS9w0UXw3beBUBD6FSuhO/8SQKfLK+1CvULJp0TjUQaMwofKn3ZRhoqUCF2SJHxw7KSq/vN4NJ0ZIvQKmBh1pAwVFebholCwoBNCTIQQi/JnAOsAvJ/veRSTrnK0LhY79g8APM/BYmqoSU90paWrW2XKxdRgRFtLU1kKo8UYc/Fxt7c2lSk0zmwBMZnzFvTAzu0gFit0iy8C0euhv+CSvARdEoSS+7jEw3f1gJgtFbHwQhn75xqbAMjOrF6fH4vz6HABAGIwgGtuTel0WVABnS7xY/+SaxKSy1nQyL9CMRF6O4DXCSH7AbwN4HlK6aZ8T9Ld2Qae44qK6h5+ahN+9dBTeb+u0HVlyVgtuYdRqhFlj2imTUXp6Osuj6dLzJgr7wh9NJY/B6Y+ENR0uvDtnXlNi9JIBMG334D+shUgGtnDW7dkOcShMymDL2lfHw4DoWBJnRaTkQeMFldEp4s4MQ7O3ggSTa8cUOmwmA650yVR0M0NRnR3tuHw8fIVRmPGXI02hIsY+VcoWNAppR9SSi+M/reYUvqjQs6j02rR1dFa8HIEfyCIex98Cr995Dl48oyS5b7l4qOdWvVzGcjhspiOObO7cOrMUMGFptFxB775o5/lvf3IVYAxF6UU4uhwwoi18gHvdOfuXuHz9EUP/eldUK8Aw4pVsWP6S5cBgKooPTb2P40pFwDQ9S9CZOBEQldIOZCSetAPHjkBo0GPvu6uvM/Fd6UujAbktEs5WxcnnNEI3WYtumURKHPbokJvEftFX31jj7w2LBLBq2/uzeu1bqE4HxcFq8Vck4J+ZnBEblnMY5tTX08nfP4ARicKmzZ89NmX8cobe/Dslh15vW4q5aI+eqVeAdTvyxCh5/598u2dEEfVf3gFdm4DMRihv+iy2DFNRxf47l5V/egxL/RpTLkAcqcLKEX46AfT+n1yITrGE1wWDx45gXPm94Hn85ctTVc3JJczZp2g0D+vF2eHxyDkWA4+XTgm3bCaTdBqNYicOiH71jSn1hrVUhGC3tfTiYGzIxDF/H0VNm7Zjp6udnR1tGLL9rfyeq3LXZzTooLNXJtbi04PjuT0cElGiZ4KSaFFIhE89/LrAIBNr+Y3cKNE1Pn0oSf3oAOAxSQXudX2oiMUgjQ5kfO5VJIQ3LUDukuXgugTe/r1S5Yh9Kd9Cdvp054jtq1oeiN07cJzAQDhMm8wkibGY+IWDkdw5MOBvPrP4+EzFEZjE6Nl6kd3OF0pBdFCO1yAChH03lkdCIXDGB7L/caI58zQCPa+dwg3rb0K61Yuxe59B2M5qVyIogSP11d0URQALGYTXDVYFFVjm5uM0rVUSGH0jd3vYWLShRVLLsDxU2dw9IT6N1kh1rnJLYuAXOS2mhtU59ABdZ0u4cMHIE06YFi+KuUx/ZJlQCSM0HvvZD3HlDHX9Ao6Z7aA7+kt64ARjUQguSZjKZdjJ08jFA7nNSEaj1JoDCUVe8vd6aIMFVFK5bVzRRREgQoR9L4Cnfqe3fI6OI7g+muuwPpVyyBKEl7e8baq13q8PlBKS1YU9QjeinBuKxVujxcut5DTwyWZ5kYbLOaGgnrRn970Glqa7PjeVz8Pnufx4ivqo3SXR0CD0ZBxYXA6YhF6a+LPaLOo83PR5CHogTe3Axot9JctT3lMt+gCEKMRwd3Zf96ZitAB2dcldPhA2YZupMkJgNJYy+KUZW5hEbpm1mxoeucisG1LwvGWJjuaG204Ui5Bn3ShyW6D5JwE9biKyp8DFSLovd1yUSqfPLooSnh+6+tYdsn5aG9pwvw5PZjbO0t12mVq7L8EKReLCZJEy7rcodScHsq+GDoTMTuHPFMuI+MOvLn3Pdy09iq0NNmx/JLz8NK2Xao/JAsx5pJGhwGtDpytMeG4zarOz4VvUyfolFIEd26D7sJL0+a/iVYH3YVLENyzM6uAxiL0aRwsUtD2LwZ1uwqahC0FyavnDh49AZvVjK72lmwvy4ph9TqEP3gfkaSfqX9eb9kidNmYqzQFUaBCBN1utcBmMeU1XLR7/wGMjDlw09qrYsfWrVyKfQeOYHg0d+omVkQrUVFUPmftpF1Oq7TNTUdfT1feEfqzm3dAkihuXicPG29Ysxyj4w68+/5hVa93ebywWfP7cBbHRsC3tKX4TquN0InBAK6xKafoRU4ehzgyBMPylEHqGPolyyCNj8be2OmYqS4XIG7AqExpFylp7F9ZOVdMftm48loASInSF86djRMDgwiGQgWfe3BkLO879GAoBK/Pj+ZGW20JOiEEs/NcR7dx8w7YLCasXHZx7Ni6VXILmJooXSli5mvmlI5aHP9XetBndeTvKTGnpwsTky7VbaSSJGHj5u247KJFsRbJlcsugdGgx4sqi6OFROhyD3rqz6c2Qgfk7UW5IvTAm9sAjoN+6ZUZnzPVvpj555UEAeA4EENuH/Bi0cyeA2Iwlk3Qxbixf38giA8HzhZcEFXg29qhXXwh/K9uTrgT6p/XC1GS8OGps1lenZnjp87gzz7/DTz0VH5jOI5JZTm0VfZwMZnBJe1OzZeKEHQAUddFdYLu8gh47c292LBmRYKnQ09XOxYtnIPN23P39E75uBQv6DZz7Vnonh4cRXtrfi2LCoqni9oP6N37DmJodBy3rl8dO2Y06LF6+aV45Y3dCKnYRO/yCLDn0bIIIKUHXUFthA6oGy4K7twO7bnng7c3ZnwO39IGTd+8rP3o1OcFMTYUtMkmXwjPQ7vwXITK1OkiOcYBngdnteHQsZOQJIpFC4oTdAAwrlkH8ewAIsePxI4VWxi9/9HnIUoSHtm4Ja/NZQ6lB91uK0mHC1Bhgj4x6VLVD/rSa7sQjkRit+fxrFu5DIeOncqZvok5LZYw5VJbEfpIXhOi8Sjr6E4MqEu7PL3pNdgsJqxecUnC8Q1rlsMj+PDG7v05z+F0e/IbKgqHIU1OJHS4KNisZvgDQVUfJHx7J6TxUdAMlsGRwdOInPowYZgoE/rLliN88E8pvdIKkleYlinRA4ePYyzN3IC2fxEiJ46CBtW7QZYKcWIcXGMzCMfltUM0F4Yr1gAaLfyvvhQ7NqujFSajoaCJ0cGRMWzetgsL5s7GyJgD23dm71SKR1kO3WS3FO3holAxgh7zdFER1T27ZTv65/XGekjjWbvychBCsHlb9lt1Zf+k2VT87auScqmpHPrgcN496Apd7a3QajSqetEnXW68tusdXH/NFSkOepdfvBhNdmvOnvSIKMIj+PJrWZwYk7so0gm6Jb/xf0gSxPH0lsGBndsBAIZlmfPnCvpLlwOSiNC+3Wkfl61zSztUdPLMEL7w9X/CD/7jVymPafsXA6KI8HF1dYx00HAYVMzfH19yjIOP9qAfPPoh2lubYv3axcCZLdBfthyBHVtjFsEcx2Hh3Nk4XMDE6INPvAjCEfz7976CzrYWPPLsy6pfq/i42IkEKnhqTNBV3qYfPn4Kh46dws3rrkr7eFtLEy4+rx+bt7+VtWOg0P2T6VB2ktbKcJHLI8Dl8ao25UqG5znMntWBkyp87l/Y+iYiERG3rE+NYDU8j7Url+L1t/dnvXNTcvX5ROjphooU8vVzAZBxHV1w53Zo5ven/T7JaM9ZBGIyZ0y7SCX2QqeU4l/++wGEIxG89e4BHDuZOHSjXagURgtLu1BRxMTXvgjnv34/79dKE1Nj/wePnMjbkCsbxlVrIU06Evr+F87rxdEPB/IabnQ43di4eTuuW7MCne0t+NiN1+CdPx1SPT+hzMxYXHIBWNPbp/6HyEDFCHp3R6u8ZDhHVPfslh3QajRYvzq1n1dh3cqlOHl6CEeyTH+5PaUZ+wcArVaDBqOhZlIuZ6IeLmptc9Mxp6cz5++SUoqnX3oN5587H/N6u9M+Z8Pq5QiFw3jljcwrawsZKpIy9KDHn0f1tCgAcTj1ZxUnxhA+fDBrd0s8hNdAf8nlCO7dBZqmY4J6hZIOFb346pvYs/8gvvSZj0Kv1+GPT7+U8Djf2AS+vROhAguj/lc3IfLhUQTf3IbwsfyifNExDr65GU63gDNDowX3n6dDf9lyEJMZ/tc2x471z+tFIBiKNQOo4Y/PbEYoHMFnPnYDAODm9Suh1+vwyEZ1UbrD6YbZ1AB+SDZmq6kIXaPRoLuzLWvuOxQOY9NrO7Fq+SVZ37zXXHkZeJ7H5m2ZC0wud/7LELJhraFpUcWUq5CWRYW+2V04OzyatRXsvYNHcfL0EG5NE50rLO6fi+7OtqzdLoUYcynLmfmW9F0u8efNBt/aBnB82k6XwC7ZjybddGgm9EuWQ5p0IPLh0ZTHqNdbsgjd5RHwk1/9AeefMw+fvf1G3HD1FXjx1Z0pk9aFOi/SYBDCQ7+BZt5CEJMZwqMPqH9tICB/eDW14oOj0fx5gROi6SA6PQwrViG4cxtoIAAg/6XRgs+Px57bijUrLo3tAbBZzLhuzXJsem1nTj99QF5uofSgE4sVnL2pwJ9oiooRdEAujGa7Td/x1j643ELaYmg8dpsFSy9ejM3bMqddXB4h1p1SCmTHxdpIuZwZHAEhBLM6CjcJ6uvuhCTRmKd6Op56aRtMRgOuvSplL0oMQgg2rFmOve99gNFxR9rnOAuYKRDHRsDZm0B0qbtSY0su1PSi8xrwLW1pBT345jbw3b3Q9PSqvi7dJUvl1+5NDUYkr6dkEfp//fZRuD1efOvLnwXHcfjEresQCofxxAuvJDxP278Y0vhoxhpBJrzPPQ5pfBTWz38ZDTfdhuDO7QifPK7qtcpQEd/cEtsheu6Cvry+fy4Mq9eB+v0IvC17B82dPQsaDZ/1rj6eJ59/BYLXhzs/dmPC8Y/ftBbBYAgbX9qW8xwOpxvNUUEvRYcLUGGC3tvdgTODoxlbfzZu3o62liZcftHinOdat2ophscm8N4Hx9I+XorlFvHUkuPiwOAI2luaoNfl37KokMvOQfD68PKOt7Fu9TI0GA1Zz7Vh9QpQSrE5w3xBzAvdlp+gp0u3APkVRQGA70i10ZXcLoTe36863RI7l70R2gXnpuTRqSSB+n0lWW6x/+BRPL1pG/781nWxyLSvpwsrllyAx59/JaG7R3tO/nl0yeOG97EHoV+yHLrzL4bp5o+BGI3wPqIuSp9aPdeCg0dPoK+nE2ZTg+rvrwbdeReBa2lD4DV5yEir1WBeb7eqCD0YCuHhp1/C5RctTum8mT+nB5decA4ef/6VnPl4h9OFxmgPerEeLgoVJuidCEciGBoZT3lsdNyBXe/8CTdee6Uq+8xVyy+FXqfNmHYp1XILBVsNeaKfPpu/KVcyvbM6QAjJmEd/6bVdCAZDCb3nGc/V3YFzF8zJ2O1SkDHX6Ai4DIVKg14HvV6XVy96sqAH3n4DkERV7YrJ6JYsk828XFO7LmnAD0gSuCKnRCORCO7+2e/Q3tqEuz75kYTH7rh1PRyTLrz02tR7RjtnAaDV5ZVH9z7+IKjPC/OdXwQAcBYrGm78KAJvvIrI6ZM5X68sh+Yam3Hg8IclTbcoEI6DceU1CL7zVuz/s2wBMJDTv+b5l9/AxKQLn739xrSP337TWgyNjmPHW+9mPY9j0o0mow7UK5Qkfw5UoKAD6a1Xn9/6BiSJ4qa1maft4jE3GHHFZRfi5R1vp0T84XAEPn+gJD4uClZL7eTQzwyN5G3KlYzBoEdnW3PGCP3pl17DgrmzVd9Kb1izHIePn0rb2+70CNBo+JyRvgKlNGuEDkSHi1RPi3ZCcjpi+VhA7m7hWtuhmbdQ1Tni0S9ZBlAq7x9Vrjk6tEaK9HF5+KmXcPzUGXz9S59O+f91+cWLMa+3G394+qWYqBGtFtp5C1VH6OLYCLzPPgHDmvXQ9s2LHTfdcjuITq8ql66snhuHBhOTrpIWROMxrF4HiCICr78KAOifNxtOtyerl39EFPHA489j0cI5WHLhuWmfs3LZxehobcYjG7ekfRyQNcgteGGnckunprc0P2NFCnryflFKKZ7dsgOXnH8OuvMQmnWrlsHhdGPve4cSjhe6fzIb1qgnernc6UqF0rJYbIQOZPZ0OXTsJA4dO4Vb169UnTdct3IpOI5g06tvpl5zdOxf7bmo2wmEgtkF3ZrPtKicXlImRiW/D8F3d8OwXP3PF492/jngbPaEtIvkK946d3BkDPc+/DRWLbsEq5ZdkvI4IQSfuHUdjp44jT37p5ZbaPsXIXzsUMbhqXiEh+4DAFg++RcJxzlbI4zX34rA9q051+2JE2MgBiM+OC0X50sxUJQO7Zz50PTOhX+b3O3SPzf3xOjWHW/j7PAYPnv7jRl/txqex203XoM9732Q0gqq4HDJxWdbSG7H1dZiysVuNcNutaRE6PsOHMHpwZGMveeZuOKyC2EyGrAlKe0SG/svocmRzWJGJCLCH5j5qbpSEjPlKnCoKJ6+7k6cOjucYlr0zEvboddpsWH1CtXnammy47ILF2HTtl0pH5ouT34dS+KYXOArWYTekdiLHtr7FhAO5Z0/VyAcB90lSxF8563Y8EvMOrfAf7OUUtzz8wfBEYKvfelTGZ+3Yc1yNNoseDiuhVHbvxgIhRDJUdQMnzwO/yub0HDjn6Xtuzd95M8BjQbexx7Meh559VwzPjh6AjzPpx0gLBWGVWtjDozz5/SAEJJR0CmluP+x59HX05n2AzGeW9avgl6nxaPPpo/SlaEiq+AEZ7OnOH4WSkUJOhDdXpQ0XLRx83aYjAZcfcVlGV6VHoNeh1XLL8Erb+5JKPQU0uaWi1ox6CrUNjcdfbO7EAyGEhaXBAJBbHptJ66+4rK8U14b1qzA4PBYSqE7X2OuTD7o8dgtJtWTv8mLLgI7t4Gz2aE993zV15SMfskyUI87tgauWOvcV9/ci9ff3ocvfurP0NGa2QBKr9Phozdcjdff3hdrIdb1y00IufLowgP3gjSYYP7Yp9M+zjc2o2H9zfC/8lKKhW08omMCXFMLDhz5EAvmdBdVnM+FcdVaALIDo6nBiJ7Otoze6G/ueQ9HT5zGZ267IedAot1qxobVy/HCK2+m1QSlPdQ6OVay/DlQgYLem+S66PX5sfX13bh25VIYDaktZrlYt2oZPIIPO/f+KXZM+R9cCqdFhanx/+puXTx9tviWRYV0ni5b39gNwevDLRvyLxauXiEXupOLo3lH6EoPeq6Ui8oInbM3ATo9xJEh0HAIwd07oV96JQjPq76mZPQXXw5wXCztUsxyC6/Pj3//xYNYMHc2Pn7L2pzPv+2Ga6DVaPDHZ+RUBNfaBq6pGeFDmQU99P4+BHe/CdNtnwJnsWZ8numjdwAcB+/jD2V8jjQxBtLUgg+OniyJIVc2Yg6Mr20BpRQLo4XRdNz/6HNob23ChjRDjZI/dZL59pvlFsZnNqe2MCpL0C2jZ2pd0Dsw6fLEhHHr67vhDwRz9p5nYunFi2GzmrFl21TL21TKpZRF0dow6BoYHEFHa3NJoqK+NP48T2/ahtld7bjkvP68z2duMOKqpRfLhe64fK7LLeS9S5ToDSDWzN4gNqsFbkFQ5XFNCAHf3gFxZAih/XtB/b68honSwVms0J5zXsxOd2r9XP7/Zn/54JMYczjx7S9/FhoVHzLNjTZsWLMcz728Ay6PAEJI1gEjSik8v/sFuOZWmG66Leu5+eZWGNfeAP/WFyCOjqQ9l+gYx5DOBMHrmwbjNa0AACAASURBVLb8eTzGNesgnjmFyPEj6J/Xi6HR8ZT38f4DR/DugSP41J9dl7IVK/jO2xi940Z47v9FwvGFc2fj4vP68fhzW1NaGJUI3RYQStayCFSgoCtLhpXbvY2bt6OvpxPnnzMv28syotFocM0Vl2Hbrndi+W3ll1XKlMuUhW51C/qZwZGCPVySsdsssFstscLoydOD2HfgCG5Zv6rgIYoNa5bD6fZg1zvvA5AFwFlAyoVrbc96DTarGZJEIXjVbaHSRFsXAzu3gxgboLswe45VDfolyxA5fgSiYxzUK/+7yrfL5dCxk3hk4xb82fVrcF4e76E7bl2PQDCEpzfJ0aW2fxHEoTMJrZQKwZ3bET58AOZPfj5lAXY6zLfJOXzvkw+nPEa9AhAK4WhIlqaZEPSYA+Nrm2NWuskDRr979DnYrOYUz6Hwh0fh/OfvgvA8vI8/BP+OrQmPf/zmtRgcGcfru/clHHc4XTDqtDAQWvsROiC/+U+dGcb+g0dx07VXFTVFtW7VUgSCoVhfqNMjQKvRFJTCyUTNpFwGRwp2WUxHvKfLM5u3g+d53HCtutbTdKy49ALYLKZY2sXrD0AUxTxTLiM5zbLsefi5ANFFF8ODCL71OvSXrQDRFn+Ho18i39oH33kLktcD6PQgSY6U2RBFCXf/1+9gt1nxV3dmj5yTmT+nB5ddtAiPbtyCSCQylUdPWrJMxQg8D/wSmp4+GK9er+rcfFs7jFdvgG/zcxAnEmdOlMUWhzwhGPQ6zJk9K6/rLgTObIF+yTIEtr+MhX2yp1B8YfToiQG8vns//vzmdQmaIY6OYPIHXwcxWdD83w9Ae+75cP/nPyN8YqrGs2r5JWhraUppYXRMutFokH+XNS3oXR2t0Gh4nDo7jGe3bAfPcbj+miuKOudFi/vR2mzH5mjaxeUWYLWYSjJqq1ALKRenW4Bb8Bbsg56O3qigh8MRPP/y61i59OKibFC1Wg2uufJyvLbrHXh9/sKMucaz96AD+fm5AHJhlPp9kFxOGFYUlh5MRtM3D1xTC4J7doH6vHkPFT3xwis4eOQE/vYLn4ClgPTiHbeux+jEJF7esRua+f0Ax6ekXfxbXoB49jTMd34RhE9MRQSCIfzwJ/fh5w88kdKZZPrYpwFRTInSpajAHx5z4pz5fapSRKXAuHodpEkHzAPH0NpsTxD0+x97AQ1GA26/6dqp6xQ8mPz+10CDQTR+/x5o2jth//t/BDGZ4fzRtyF55JSKhudx2w1XY/e+g/hwYGoj0oTTjUZOAmdvApcl9ZcvFSfoGp5HT1c7Pjx1Fs9vfQMrLrsALU32os7J8xzWXrUUb+55Dx7BW/KxfyA6XajTVrWgKy6LpUq5AHJh1On2YOPm7Zh0eXDL+uLFbsOa5QgGQ9i28528O5ZoMAjJOZlb0POO0OV6AbS6mB9LsRBCoF+yDKF3d0NyOfMqiI5NTOJ/7n8cSy9eHFvNmC8rllyA3u5OPPz0SyB6AzR9cxNW0kkBP4SH74P23POhvzwx6BK8Pvz19/4Nz2zejt/8cSP+496HE0Rd09EFw+q18G3aCNE5NcgjOsYQocCRwbFpmRDNRLwDY//c3pg3+pmhUWzZvgsfuW517C6chkOY/NG3ERk6A/u3fwRtdCiIb2yG/ds/hDgxDuc934+1nH5kw2rotFo8GhelO5wu2CKhkubPgQoUdEDudNm55z2MO5y4eW1pop11q5YiHIng1Tf3lnzsX6HaDboGotahxdjmJqN4utz70FNob23CsksKb+VTuHDRAnS0NuPF13bGBNeu8vcpjuduWQQKi9ABQH/J5eCMpfMd0S9ZDurzIvTeO3m1LP74V39AOBzBN//qzoLvRDmOw5/fshYfHD2B/QePxgqjilD5nnkM0qQDls99KeF7TEy68MVv3o33PjiGH37jL/GJW9fhj89sxk9+/ccEUTff/mkgEobv6T/GjkkTExiADqFwZEby5wrxDowLertw6vQQAsEQHnzyRfAcj09+ZAMA2VPH9ZN/Qvj9fbB95dvQX5BYK9H1L4b1S3+L0Lu7IfxeXhpit1mwfvUyPL/1jZh3v2PSBVugNEst4qlIQe/r7oQoSWi0WXDl5ReW5JyLFso2rJu37Yr2LZd28wsgDypV8/j/acVlsbP4lkWFvujiEofTjZvXrlTlw5MLjuOwfvUyvP3u+zgRvY1VG6GrGSoCpiJ0NY6LAMDP6gE/qwfGden9PQpFd+GlgEYj7xNVGaFv2f4Wtmx/C5/7+E1FzxPccM2VsJpNePipl6A7ZzGo34fImQFILie8TzwE/bKroIvrtz8zNIq/+NoPMXB2GD/+/t9g/erl+Jsv3IGP37wWDz+1CT/7zaMxUdfMmg3DVdfA9/xTsWKr5BjHUb2cgih2KXS+KA6Mc0QfREnC2/sO4NnNO3DDtVegtVke/BHu/wUC27fCfOdfwrg6fQtow7obYbzuFnifeAj+HbJ75cdvXotAMISNm3cgIopwebywi6H6EHTFAuC6q6+ARqPJ8Wx1EEKwbuVS7N5/EMOj49MYoVezoI+io7U5ZRVcMXS0NsOg14EQgpvW5jfpm40Na1ZAkiieeEH24VC7IFrpQU+3SzQes8kIjiNwuTyqzssZjGj9xcMwXF5cvSflvA0m6BZdIP9ZRcvi05tew3f/9ec4/5x5+MzHri/6+xsNenzkutXYtmsvxprk92X48AEIjz4AGgzA8pm7Ys89emIAf/G1H8IjePHzu7+F5ZfKQk8Iwd998ZP42I3X4PdPvID/+t1jMVE33/5p0GAA3o2PAZCLosc0FtgsJszqKF3qTw268y4C19yK3hNyWume//k9ImIEn/6o/P/R+9wT8D75BzRc/xG5nz4L1i98JVokvRvhE8fQP68XFy1eiMeeexmOSRcopbAjUh+Cfun552Dh3Nm47YarS3retauWQZIovP5AyXPogOK4WL0pl9ODwyWZEI2H4zgsWjgXK5dejM72lpKdd35fNxbMnY2Bs8MghKgu+oljIwAhaRdbxMNxnHzHVQG/T6XbhWRZEE0pxW8feRY/+ulvsfTi8/Df//TNkn0w337TtSCEw2NvvQ9itiCwYyt8LzwF47XXQ9PTB0C257jrG3eD53nce893UlokCSH4+pc+jY9evwYPPPZ8rFCqmT0H+hWr4Hv2cUiCB5JjAkciPM5dUBp/8HwgHAfjqmvReGAvzA1GDI9N4OorLsPsWR0I7NwOz73/Cf3SK2G56ys5r41otVNF0n/6DiSPG7ffdC3ODo/h2S3y4hM7EaHprQNB72xvwUP/9Y8lF5f5fd2xVWfWaYnQq9cTnVKK04PF2+am4yc/+Fv88JtfKvl5r4tO7FlMDapTOdLYCLimFhAVd375TItOJ/olclEzU4QuSRL+/ZcP4X/ufxwb1izHf/zDV0vaktvW0oRrr7ocz27ejtD8cxHatwfgOJjv+F8AgO1vvYsvf+df0dxow33/9l3MzdBqSAjBN/73Z3DrhlX47SPP4pcPPgUAMH/8TlC/D75nH4d3YhwnA+KMFkTjMaxeByKJmG+X6yCfvf1GhA69D+e//QDahefC/rV/UD0BzDc2w/73P4Q4PgbnPd/H6qUXoa25EQ8+uQkA0GQ1gzOru7NUS0UK+nSybpXcgaAmh04pxamzgzhw7FiCF0wmqtlC1+XxwiP4irbNTYfRoIdBX3o/jnWrl4EQovpuyy0ImDxxHKK9UZUrps1igrMCPqD57l6YPn4nDFem3rGGwxF8755f4JGNW3DHrevxg7+7q2RpynjuuHU9vP4AXoac3zbd/DHwza147uXX8Y1//Cnm9nbjV/d8Gx1tmX1iAPnO5++//Fncsm4l7vvDM/jVQ09BO2c+9EuvhPeZR3HM4YVEgUUznD9X0PTNg6Z3Lq7nPfhfH78J8wwEk//vW+Cb29D4vX8GMaizaFbQnbMY1r/8G4Te3Y3AH36Lj95wdWzhefOs0vfYl/43X+Fct2YFnnj+FSzI4eA25nDgjXfexeCoXETb+e4+LJ4/H+f3L4S5IX0Xg9VsQjAYQjAUmlZDoelAWY47HRH6dNHe0oRll5yHXNIcDIXwzsGDeO/QYVwzOoyxpjZsf3ETzu9fiIW9vRkF0GY148zQKERRKkkxt1AIIbB86i9Sjnt9fnzzRz/DW+8ewP/53O349G3XT1uaYtHCObho8UI8dXIUN1+xBqaPfhIPPvki/vPXf8RlFy3CPd/9a5gajKrOxXEcvv3Xn4MoSbj3oafBcRw+8+efxcTf/AWOSrIPzOJp8kDPBSEEhlVrsfyBX6Jp6Vcx+f2vAwRo/P49BTsiNqy/CeHjh+F94iFs+Ktv4dcaDcKRCFrnlP4upO4EvbO9Bc///icZHxd8Pry1fz8OnzgJg16Hqy69FK3NTdh/6DD2HTqE/YcPY0FvLy469xw02xP745VCq0fwQd9UHYJOKcWB0SD+5xV5KTFvLn5R7UzyL9/5PxmjbUmScPD4cex+70/wB4NY0NMDk98H9Mr53dfeehu79u3H4vnzcd6C+TAlfVDPntWBHW/tw0c+/3V87MZrcPP6ldNSTC+ESZcbX/m//4Ejx0/he1/9fMzr6JgjiMcPuHBwNIhFbXpc3GnEJZ1GtJqKf6t/4tb1+OaPfoZ9V34KBx97EQ889jyuufIy/L+vfzHvfD3HcfjuVz4PSZLwi98/CY67DbcuWYajbx9Hq6VB1eyJyx9GIBxBu1XdB4lajKuuhfDAL+H4zl8DIGj6p/+Epqu7qHNav/AVRE4eR+TXP8Ha81Zjx74PYJmb+0MrFA7j2Cl1e06BGRZ0UZJAKZ3xYocawuEw3jn4AfYfOgSJUlx07jm4dPHiWKTdcWUL3IKA/YcO44Pjx3H4xAnM7uzEReeeg1ntsi9I/Ph/scNQ0403JGHTMQ+ePOjCkYkQ+OODAAi+us2PRYdP4/qFFqybZ4HdwEGUJITDYYQiEflrNP3U2tQE7TTc3udDplzxwOAg3nj3XUy63Gg2N6JzrAOhn+8FESM4sRsw+u244OIuTDZMYu+BA3j34EHMmz0bF/QvRHuLXLz98udux4WLFuCRjVvw09888v/bu/MgOa76gOPf1+dM99za3VntJVuyLQtBbNmOLyDYFSCGAA4VwpEDQhFMJTEkpIrCUIChEioEHCD/QAgJVSQQUkDsBFIYMIkTKA4bG9mWbVnWrd317mp3Z3d2Zvru9/LHjCxZtg5b0gqN+1Pq6p6e2en305v5dc/r16/5wlfv4FXXX8ObXvsKLjh/fDXDfIon5uZ594duY25+kU9++D1ce8Wl3LW7xTceabJ1JqCgp1xSS/nRrhZ3PGog0RgrmWxZm+OytXm2rM0zUjSe9ffwZVdfxsjwIB/79Bfxg5DffvX1vO+P3/qcf73ousZH3vtOpFJ87svfRL32enbqs8dtPw/jlLsePsAju/dih/NYQuIrC2EXqJbKTAxV2TSyhsFqGfM5nhTWh4YxN19CvH0blQ9+/MlhD06FME0qt/wli+99J2/ffjev19InL0g6mlKKmfl5tu/ew+4DB455j+Vn3M6p3GFHCHED8HeADvyjUuoTx3v9uvXr1V995rOMDdcZq9cZrddx8qd37/psSSl5bM9e7nnoIfwg4IKJCa6+9JLj3vwiCEMe3rmLbY8/jh8EDFSrbL5oIzunl/n4Jz7LrR96HzdcvRlD++Xbce1YCLn90Sbf3dXCiyUX5yK2pEvc++M7mVtu8LrffCWRAWgSS6SYpBwrDE3TGB4Y6Nbn8DBDtdoJx4k+0xaXl/nJ1q1MzsziJIK198+w5sAO6uluTBWgTJuFG25h554cjQPdLom1TS7appR5uUCcJFQrNQZH1iPdITRNZ+OAhb84yzf+6wfcefdPCcOIy3/lYt70ulfw0qu2PKvL06M4Zt/kDLv2TdLu+Fx4/jgXrZ846eaKXXsnefeHbyOMIm59/3t4XNW5Y/syMmixyW2xMd9C+U3UEQ1RQrcIsGjEBs3ExFMWupljrFbgonqJy8arXDDonFSC//q37+JTn/8K73jLjbzr919/Wg7O0lRy621f4Hu9G9H8ydvewNvf9Nonn5dS8rPdc/x0207wDpLXYiKp0VxxUZ6OKkqsfExRDzDE4biVkaNYKDE2UGVkoEKtUqFWKp3UOYZkbga5OP9kl9HTJXrsERofeDckMUNf+85TToq2PY8de/fy8K49dDptUnT2JjUeCwe486Yt9yulrjjR+z/nhC6E0IHHgVcAU8DPgbcopY5588HNL3yhuu1zn+eJuTnC3lFerVJmrD7M2HCdkaGhk/rpppQiCCM6vkfH8+n4HgooOg4F16XoOCe1dz4wM8NPtm6lsdykPjDAtZdeiqtcliZbNHrT0mSboBWh2zqpY9BybFZyJsu2QdMUmHaTtdYcJS1gcsHnB9/9P4pXvQ418gLGyg4X13NsHMixccDmwppFzlz9hBfEkrv2tPnmtiXmlpZZq7fYoJqUaJK2FogWGtz96BQ1U+em9QNocYpMJKFSREqhlERPU5wwwgkjclEMArxiic5QhWatQLtYISpWWTtcZ2J0hLHhOtVS6aS+8HGSPFmPbc8jCEOcXK5bl66Lk8udcEfhBQH3bH2IPY9uY2RyP2sf38dg6wA6KSpfJHf1i9GvfAlLF1zKfGpysJOwf9Zn7/4W0wsBjRQiWzDqLLPJnqOshXSkyd6kRlPmSbQc9WqJ0YJOa9dW7v/xD1lYaDA8uIbfec2vc+MNL3tKc0yaSqZnD7J7/xS79k2xZ98Uu/ZPMTk9R/oMQ/KOj9TZuH6CizasY2NvOnrMm60P7+AvPvYZDNNi02veysEgZURvcp61gqG636eBSpWhwhpc4eKHIX7o40chQRIQpBGBjJA8/VZygTQIyKMbDpVimfNH17B5YpCR6lMTvVKKqZmDp70HWpKmfORTX+CuH97D3//NB7j8RRezfXqJ79/7GEFnlqIWkCrBUsel2HK5ZnyUC351GM3QmHpgngMPzrNr3woLNR1/SEdVFboRUtZ8ylqAfkSiN3MFyqUyIwNVRgeqDFSrFJyT26GdDv6P/pvowV9Qvvl9pGnK7slp7ntsF0uNOQQwkxTZGQ8Q5we5Zl2JF084XDtROOMJ/Rrgo0qp3+g9/gCAUuqvj/U3Y2svVrfc/BXyjk6uEKO5PrHexkvbSCRCCAbKVcbXDjNSHyRKEtrtDu2OR6vj0fF9PN/HCwOkOv441ZZh4ubyFByHoutSLLqUCgUKbrfi7tn6ENPzc1jCJufVWXrCoLEU4MsUqUsSXaLnQeQFMSleGiPSCFvG2GmEnYYUopBy5FMIAyqqRUqLv5ryuNDRGHVMLMtEmDbKzpPYBSK7CPkKbnWA4ZERNq8fZt1wiUYzYKEZ0Gh5LK906DRbeIFPEHgkYUAahcgkRKUhQugIM4du5TEtGzvv4LouxVKJWqXAYMWhXs0zVMkxvxxw+/88xPzeR3CWp6G1SLvjs+xHLMSKRakhOfwhfrNY4ve0pUMVDKaFME1izcRTOm2lE2kG6CaukJRb81jJ4eFlpdDouCXapTLtYgW/WEMfHGfNxk3kSyXa8wv4Sw3iVpOk00IFbUTooScBZhRhxhFmHKInCYlhEls2kWUTWzbSciBXwHDLWKUK+VqNYr1OaXSYPT/7Of79/8vw1B5qi90vxYo7yL4Lr2TbeVewtbCBWV/RDJ/+mSlaGkMFg5ohsNshYqaDmG1RcztUJzxwQjgiGUglaCuLZmIyNb3A3O7HWZp9AsM0uebKy5AK9k9OMzs7R3JEzyinVMYtV8mXKzilMvlSEdM06TSbdJaX8ZpLtBuLeL1BnQCKpSITE+Ns3LCOgUqRL331dkzH5errrmGiCJoAoXRcP4+2YJHsg2TlxOO3a7ZALwpwFV5Jo1kQRGaMbke4ZoilHX6PQBr4MoemOVScIuvqNTaM12h1QhabHs12QDsI8cKIMI6I0wQpE5RKECToIkUBUhkoDDRhYugmtmni2DZFJ0elmGeokmeg4rBz7wF2zPgstWapGN0eRkuBgx2Weem6UTZfOUZh4Jl/zURezBOPLDL5wAJTD87TXApZKNq0Jkp0hi08PUSXHWqaR1X3KWmHbxcphY6wi7iFMoPVCufVa6wpOjS9kGYnoOWHeEHQjTMMCaOIJI5I0xiVRCAT0HSEbqEbFoZlYVs2Ts7GzeUoOjnKTo5qIU+tkGd2uc2PH97J8vwUuorpSJM9yQBabpgXlFxelBOsSRJiPyXyEq763YvPeEJ/A3CDUuqPeo//ALhKKXXzsf7mkkpR3fnSLaRCQwqdVNOQQiMVGggNtG4eEZroLnQLCCiUgkNF7a06YlkdKhR0/3XnvccaCoRACYHq5S8tlaQpiDTFkjFmGqOfsL/EMWgawrJJTJsPtUtMp4KOEkQn6BVqIbGABOh+/E/9CMFEPTmlCNpHlaGIZK2tMVJyGB2oMDpSZ/y8dYxvvIDh8XGEZXWHftX1px2x+LHk7r0d7ty5wr3TPlIqylGL0c4saztzjLZnGekcZMybYW3nIFZ64q6eh4S6hWfm8Yw8vm7jpAGFuIMT+Rjq5NoQ95Qn+En9cn42vIX9xTEqeZ16wWTI1RlyDequwVChOx90DYZcg/wz/GJqzfvsu3eWvffMsnCgSaqnKCdFORLpSqIipAWFkUswdEljqcX2HfvZs3cG0zKoVgpUywWq1WJ3TPiK++S5BqUglRpSClACTZfomjz0cSeMYhqNFRpLLRYbKzSWVlhudlBKMbCmzMuvuxwhC+Se0DDmDOzIpjjoUBjIH57W5HBrOQxbx7B0DEtDt3QMW0c3tO736xlEfsLyTIvd+5fZOdfgoNfGVx66HuKaIaY48c4ikhqx0kmkTip1lNRBKDSRousplpZiieSYzXiHrCQ2Iq7y4vMnuPLqCSzn2bWHK6VYmmwz+eA8Uw/OM7tjCZUqEk3Qypk08yZtRyepSEQhwc7HFKyAqu6fMM5I6YRKJ1QGkTSIpUaa6miaxNRTbC3BFgk5kRz3vVIlmI7KdOZdilOKsaUAK3366zVD8I5/edUvR0IXQtwE3ARwQb1++bdvvZU0TkmTBJkkJFF3SqOENO6uU0mMlkYooaOEDlo34QtNIA7NtcNzTRMoQEmFkhKZdk++IiWqt6ykRFMJQqUIUlLDxcznsYt5bDeHlc+Ry9vk8jZ5J4eZsw8nN8vq3uHGtrtzyz7isQ2G+bTkp5QiWFmhNT9Pc2GR1uISzaUlFuYWaSw0aCy3WO54REmCqeuYuo5lGtimgW1ZWJZJLmeRy+WwHRvHyWPZFjJN8To+nucTeCFhEBAEEX4UEcYJYZwQpwlx2j32Hl1TY+Om9Wx4wUYmNm+iNHR6LqdOpcKPJZ1Y0YklXiTpxJJOJPFiiRcmJAvzpPv2YT2xBy2JSPIlUqeMKpYQxQJasQiFAiLvopsGhiYwNIGuQSohloo4kaRhCJ0WamUF1VxBtJpo7WVMr4kdrBA6VaJrX051YpR6Qafumgy6OrZxepq3ZCKJ/ITIS4j9hMiPibyEyE/w2gFNr8205zMfBxhCI6fpOJpOwTAoGgaWYWKZBqZhYhoGuqmh98omU0Uap70TzhFRFOMnCStJQjuN8dKUdhLQaDU5v1Lnsvowa+rlXvLOPetE91wF7ZDtuxbYPrlAo+1hmwaFnEXJyVF1cwxWHAareZxiDjP39IOBQ9JEErRCFpd9ZhY7NFY8ljq9o/w4IpWSSyZGuP6a89HN0zd0buTFzD2+TOQnyFiSJrKbh3rLMpZEkWQhSplLI5r4xKSY6JgY2MrAFhquMHF0QV7rTrouenmpu7NWUpGmCl8qvFTRlhJPJQTEBKTEpKQiRqBxnqiywbXJuQaWY2I5Rm/qLbsmVt7AsHSEEL98TS5XXHGFuu+++57T9jKZTOb56mQT+qkcwvwcuFAIcb4QwgLeDHzrFN4vk8lkMqfgOXciVkolQoibge/R7bb4JaXUsW8LnslkMpkz6pSuClFKfQf4zmkqSyaTyWROwfNucK5MJpPpV1lCz2QymT6RJfRMJpPpE1lCz2QymT6RJfRMJpPpE6c02uKz3pgQLWDHqm3w7BkAFs52Ic6w50OMkMXZb87VONcppQZP9KLVHsx6x8lc7XSuE0Lc1+9xPh9ihCzOftPvcWZNLplMJtMnsoSeyWQyfWK1E/o/rPL2zpbnQ5zPhxghi7Pf9HWcq3pSNJPJZDJnTtbkkslkMn1iVRK6EOIGIcQOIcQuIcQtq7HNs0EIsU8IsU0I8YAQom8GfhdCfEkIcVAI8fAR62pCiLuEEDt78+rZLOPpcIw4PyqEmO7V6QNCiFefzTKeKiHEuBDibiHEo0KIR4QQf9Zb31f1eZw4+6o+j3bGm1yey82kz1VCiH3AFUqpc7Gf6zEJIX4NaAP/rJR6YW/dJ4GGUuoTvZ10VSn1/rNZzlN1jDg/CrSVUredzbKdLkKItcBapdQvhBBF4H7gt4A/pI/q8zhxvpE+qs+jrcYR+pXALqXUHqVUBPwbcOMqbDdzmiilfgg0jlp9I/Dl3vKX6X5ZzmnHiLOvKKVmlFK/6C23gO3AKH1Wn8eJs6+tRkIfBSaPeDxF//7HKuD7Qoj7e/dS7Wd1pdRMb3kWqJ/NwpxhNwshHuo1yZzTTRFHEkKcB2wB7qGP6/OoOKFP6xOyk6Kn20uUUpcBrwL+tPcTvu+pbrtdv3aX+jywAbgUmAH+9uwW5/QQQhSAfwf+XCm1cuRz/VSfzxBnX9bnIauR0KeB8SMej/XW9R2l1HRvfhC4g25zU7+a67VTHmqvPHiWy3NGKKXmlFKpUkoCX6QP6lQIYdJNcl9VSt3eW9139flMcfZjfR5pNRL68+Jm0kIIt3fyBSGEC7wSePj4f3VO+xbwtt7y24D/PItlOWMOJbme13OO16kQBT3nRgAAAMdJREFUQgD/BGxXSn36iKf6qj6PFWe/1efRVuXCol7XoM9y+GbSHz/jG11lQoj1dI/KoTvo2b/2S5xCiK8B19EdqW4OuBX4D+DrwASwH3ijUuqcPqF4jDivo/vzXAH7gHcd0dZ8zhFCvAT4EbANkL3VH6Tbvtw39XmcON9CH9Xn0bIrRTOZTKZPZCdFM5lMpk9kCT2TyWT6RJbQM5lMpk9kCT2TyWT6RJbQM5lMpk9kCT2TyWT6RJbQM5lMpk9kCT2TyWT6xP8DbmwQ+zgjCngAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "flatui = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\n",
    "for i, arr in enumerate(np.split(\n",
    "    ary=pred_list[anom_test_example_index][\"X_time_abs_recon_err\"].flatten(),\n",
    "    indices_or_sections=len(UNLABELED_CSV_COLUMNS),\n",
    "    axis=0)):\n",
    "  sns.tsplot(arr, color = flatui[i%len(flatui)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "flatui = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\n",
    "for i, arr in enumerate(np.split(\n",
    "    ary=pred_list[anom_test_example_index][\"X_feat_abs_recon_err\"].flatten(),\n",
    "    indices_or_sections=len(UNLABELED_CSV_COLUMNS),\n",
    "    axis=0)):\n",
    "  sns.tsplot(arr, color = flatui[i%len(flatui)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
