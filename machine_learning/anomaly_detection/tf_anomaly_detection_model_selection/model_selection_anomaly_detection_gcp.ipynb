{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = \"PROJECT\" # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = \"BUCKET\" # REPLACE WITH A BUCKET NAME\n",
    "REGION = \"us-central1\" # REPLACE WITH YOUR REGION e.g. us-central1\n",
    "\n",
    "# Import os environment variables\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] =  BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"TFVERSION\"] = \"1.13\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now write into a python module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile anomaly_detection_module/trainer/globals.py\n",
    "# Determine CSV and label columns\n",
    "number_of_tags = 5\n",
    "tag_columns = [\"tag_{0}\".format(tag) for tag in range(0, number_of_tags)]\n",
    "UNLABELED_CSV_COLUMNS = tag_columns\n",
    "\n",
    "LABEL_COLUMN = \"anomalous_sequence_flag\"\n",
    "LABELED_CSV_COLUMNS = UNLABELED_CSV_COLUMNS + [LABEL_COLUMN]\n",
    "\n",
    "# Set default values for each CSV column\n",
    "UNLABELED_DEFAULTS = [[\"\"] for _ in UNLABELED_CSV_COLUMNS]\n",
    "\n",
    "LABELED_DEFAULTS = UNLABELED_DEFAULTS + [[0.0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile anomaly_detection_module/trainer/input.py\n",
    "import tensorflow as tf\n",
    "from .globals import *\n",
    "\n",
    "\n",
    "# Input function functions\n",
    "def split_and_convert_string(string_tensor):\n",
    "  \"\"\"Splits and converts string tensor into dense float tensor.\n",
    "\n",
    "  Given string tensor, splits string by delimiter, converts to and returns\n",
    "  dense float tensor.\n",
    "\n",
    "  Args:\n",
    "    string_tensor: tf.string tensor.\n",
    "\n",
    "  Returns:\n",
    "    tf.float64 tensor split along delimiter.\n",
    "  \"\"\"\n",
    "  # Split string tensor into a sparse tensor based on delimiter\n",
    "  split_string = tf.string_split(source=tf.expand_dims(\n",
    "      input=string_tensor, axis=0), delimiter=\";\")\n",
    "\n",
    "  # Converts the values of the sparse tensor to floats\n",
    "  converted_tensor = tf.string_to_number(\n",
    "      string_tensor=split_string.values,\n",
    "      out_type=tf.float64)\n",
    "\n",
    "  # Create a new sparse tensor with the new converted values,\n",
    "  # because the original sparse tensor values are immutable\n",
    "  new_sparse_tensor = tf.SparseTensor(\n",
    "      indices=split_string.indices,\n",
    "      values=converted_tensor,\n",
    "      dense_shape=split_string.dense_shape)\n",
    "\n",
    "  # Create a dense tensor of the float values that were converted from text csv\n",
    "  dense_floats = tf.sparse_tensor_to_dense(\n",
    "      sp_input=new_sparse_tensor, default_value=0.0)\n",
    "\n",
    "  dense_floats_vector = tf.squeeze(input=dense_floats, axis=0)\n",
    "\n",
    "  return dense_floats_vector\n",
    "\n",
    "\n",
    "def convert_sequences_from_strings_to_floats(features, column_list, seq_len):\n",
    "  \"\"\"Converts sequences from single strings to a sequence of floats.\n",
    "\n",
    "  Given features dictionary and feature column names list, convert features\n",
    "  from strings to a sequence of floats.\n",
    "\n",
    "  Args:\n",
    "    features: Dictionary of tensors of our features as tf.strings.\n",
    "    column_list: List of column names of our features.\n",
    "    seq_len: Number of timesteps in sequence.\n",
    "\n",
    "  Returns:\n",
    "    Dictionary of tensors of our features as tf.float64s.\n",
    "  \"\"\"\n",
    "  for column in column_list:\n",
    "    features[column] = split_and_convert_string(features[column])\n",
    "    # Since we know the sequence length, set the shape to remove the ambiguity\n",
    "    features[column].set_shape([seq_len])\n",
    "\n",
    "  return features\n",
    "\n",
    "\n",
    "def decode_csv(value_column, mode, seq_len, training_mode, labeled_tune_thresh):\n",
    "  \"\"\"Decodes CSV file into tensors.\n",
    "\n",
    "  Given single string tensor and sequence length, returns features dictionary\n",
    "  of tensors and labels tensor.\n",
    "\n",
    "  Args:\n",
    "    value_column: tf.string tensor of shape () compromising entire line of\n",
    "      CSV file.\n",
    "    mode: The estimator ModeKeys. Can be TRAIN or EVAL.\n",
    "    seq_len: Number of timesteps in sequence.\n",
    "    training_mode: Which training mode we're in. Values are \"reconstruction\",\n",
    "      \"calculate_error_distribution_statistics\", and \"tune_anomaly_thresholds\".\n",
    "    labeled_tune_thresh: If tune anomaly thresholds dataset is labeled or not.\n",
    "\n",
    "  Returns:\n",
    "    Features dictionary of tensors and labels tensor.\n",
    "  \"\"\"\n",
    "  if (mode == tf.estimator.ModeKeys.TRAIN or\n",
    "      (mode == tf.estimator.ModeKeys.EVAL and\n",
    "       (training_mode != \"tune_anomaly_thresholds\" or\n",
    "        (training_mode == \"tune_anomaly_thresholds\" and\n",
    "         not labeled_tune_thresh)))):\n",
    "    # For subset of CSV files that do NOT have labels\n",
    "    columns = tf.decode_csv(\n",
    "        records=value_column,\n",
    "        record_defaults=UNLABELED_DEFAULTS,\n",
    "        field_delim=\",\")\n",
    "\n",
    "    features = dict(zip(UNLABELED_CSV_COLUMNS, columns))\n",
    "    features = convert_sequences_from_strings_to_floats(\n",
    "        features=features, column_list=UNLABELED_CSV_COLUMNS, seq_len=seq_len)\n",
    "    return features\n",
    "  else:\n",
    "    # For subset of CSV files that DO have labels\n",
    "    columns = tf.decode_csv(\n",
    "        records=value_column,\n",
    "        record_defaults=LABELED_DEFAULTS,\n",
    "        field_delim=\",\")\n",
    "\n",
    "    features = dict(zip(LABELED_CSV_COLUMNS, columns))\n",
    "\n",
    "    labels = tf.cast(x=features.pop(LABEL_COLUMN), dtype=tf.float64)\n",
    "\n",
    "    features = convert_sequences_from_strings_to_floats(\n",
    "        features=features,\n",
    "        column_list=UNLABELED_CSV_COLUMNS,\n",
    "        seq_len=seq_len)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def read_dataset(filename, mode, batch_size, params):\n",
    "  \"\"\"Reads CSV time series dataset using tf.data, doing necessary preprocessing.\n",
    "\n",
    "  Given filename, mode, batch size and other parameters, read CSV dataset using\n",
    "  Dataset API, apply necessary preprocessing, and return an input function to\n",
    "  the Estimator API.\n",
    "\n",
    "  Args:\n",
    "    filename: The file pattern that we want to read into our tf.data dataset.\n",
    "    mode: The estimator ModeKeys. Can be TRAIN or EVAL.\n",
    "    batch_size: Number of examples to read and combine into a single tensor.\n",
    "    params: Additional parameters.\n",
    "\n",
    "  Returns:\n",
    "    An input function.\n",
    "  \"\"\"\n",
    "  def _input_fn():\n",
    "    \"\"\"Wrapper input function to be used by Estimator API to get data tensors.\n",
    "\n",
    "    Returns:\n",
    "      Batched dataset object of dictionary of feature tensors and label tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create list of files that match pattern\n",
    "    file_list = tf.gfile.Glob(filename=filename)\n",
    "\n",
    "    # Create dataset from file list\n",
    "    dataset = tf.data.TextLineDataset(filenames=file_list)  # Read text file\n",
    "\n",
    "    # Decode the CSV file into a features dictionary of tensors\n",
    "    dataset = dataset.map(\n",
    "        map_func=lambda x: decode_csv(\n",
    "            value_column=x,\n",
    "            mode=mode,\n",
    "            seq_len=params[\"seq_len\"],\n",
    "            training_mode=params[\"training_mode\"],\n",
    "\t\t\tlabeled_tune_thresh=params[\"labeled_tune_thresh\"]))\n",
    "\n",
    "    # Determine amount of times to repeat file if we are training or evaluating\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      num_epochs = None  # indefinitely\n",
    "    else:\n",
    "      num_epochs = 1  # end-of-input after this\n",
    "\n",
    "    # Repeat files num_epoch times\n",
    "    dataset = dataset.repeat(count=num_epochs)\n",
    "\n",
    "    # Group the data into batches\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "\n",
    "    # Determine if we should shuffle based on if we are training or evaluating\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      dataset = dataset.shuffle(buffer_size=10 * batch_size)\n",
    "\n",
    "    # Create a iterator, then pull batch of features from the example queue\n",
    "    batched_dataset = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "    return batched_dataset\n",
    "\n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoencoder_dense.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile anomaly_detection_module/trainer/autoencoder_dense.py\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Dense autoencoder model functions\n",
    "def dense_encoder(X, params):\n",
    "  \"\"\"Dense model encoder subgraph that produces latent matrix.\n",
    "\n",
    "  Given data matrix tensor X and dictionary of parameters, process through dense\n",
    "  model encoder subgraph and return encoder latent vector for each example in\n",
    "  batch.\n",
    "\n",
    "  Args:\n",
    "    X: tf.float64 matrix tensor of input data.\n",
    "    params: Dictionary of parameters.\n",
    "\n",
    "  Returns:\n",
    "    tf.float64 matrix tensor encoder latent vector for each example in batch.\n",
    "  \"\"\"\n",
    "  # Create the input layer to our DNN\n",
    "  network = X\n",
    "\n",
    "  # Add hidden layers with the given number of units/neurons per layer\n",
    "  for units in params[\"enc_dnn_hidden_units\"]:\n",
    "    network = tf.layers.dense(\n",
    "        inputs=network,\n",
    "        units=units,\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "  latent_matrix = tf.layers.dense(\n",
    "      inputs=network,\n",
    "      units=params[\"latent_vector_size\"],\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  return latent_matrix\n",
    "\n",
    "\n",
    "def dense_decoder(latent_matrix, orig_dims, params):\n",
    "  \"\"\"Dense model decoder subgraph that produces output matrix.\n",
    "\n",
    "  Given encoder latent matrix tensor, the original dimensions of the input, and\n",
    "  dictionary of parameters, process through dense model decoder subgraph and\n",
    "  return decoder output matrix.\n",
    "\n",
    "  Args:\n",
    "    latent_matrix: tf.float64 matrix tensor of encoder latent matrix.\n",
    "    orig_dims: Original dimensions of input data.\n",
    "    params: Dictionary of parameters.\n",
    "\n",
    "  Returns:\n",
    "    tf.float64 matrix tensor decoder output vector for each example in batch.\n",
    "  \"\"\"\n",
    "  # Create the input layer to our DNN\n",
    "  network = latent_matrix\n",
    "\n",
    "  # Add hidden layers with the given number of units/neurons per layer\n",
    "  for units in params[\"dec_dnn_hidden_units\"][::-1]:\n",
    "    network = tf.layers.dense(\n",
    "        inputs=network,\n",
    "        units=units,\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "  output_matrix = tf.layers.dense(\n",
    "      inputs=network,\n",
    "      units=orig_dims,\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  return output_matrix\n",
    "\n",
    "\n",
    "def dense_autoencoder(X, orig_dims, params):\n",
    "  \"\"\"Dense model autoencoder using dense encoder and decoder networks.\n",
    "\n",
    "  Given data matrix tensor X, the original dimensions of the input, and\n",
    "  dictionary of parameters, process through dense model encoder and decoder\n",
    "  subgraphs and return reconstructed inputs as output.\n",
    "\n",
    "  Args:\n",
    "    X: tf.float64 matrix tensor of input data.\n",
    "    orig_dims: Original dimensions of input data.\n",
    "    params: Dictionary of parameters.\n",
    "\n",
    "  Returns:\n",
    "    tf.float64 matrix tensor decoder output vector for each example in batch\n",
    "    that is the reconstructed inputs.\n",
    "  \"\"\"\n",
    "  latent_matrix = dense_encoder(X, params)\n",
    "  output_matrix = dense_decoder(latent_matrix, orig_dims, params)\n",
    "\n",
    "  return output_matrix\n",
    "\n",
    "\n",
    "def dense_autoencoder_model(\n",
    "    X, mode, params, cur_batch_size, num_feat, dummy_var):\n",
    "  \"\"\"Dense autoencoder to reconstruct inputs and minimize reconstruction error.\n",
    "\n",
    "  Given data matrix tensor X, the current Estimator mode, the dictionary of\n",
    "  parameters, current batch size, and the number of features, process through\n",
    "  dense model encoder and decoder subgraphs and return reconstructed inputs\n",
    "  as output.\n",
    "\n",
    "  Args:\n",
    "    X: tf.float64 matrix tensor of input data.\n",
    "    mode: Estimator ModeKeys. Can take values of TRAIN, EVAL, and PREDICT.\n",
    "    params: Dictionary of parameters.\n",
    "    cur_batch_size: Current batch size, could be partially filled.\n",
    "    num_feat: Number of features.\n",
    "    dummy_var: Dummy variable used to allow training mode to happen since it\n",
    "      requires a gradient to tie back to the graph dependency.\n",
    "\n",
    "  Returns:\n",
    "    loss: Reconstruction loss.\n",
    "    train_op: Train operation so that Estimator can correctly add to dependency\n",
    "      graph.\n",
    "    X_time: 2D tensor representation of time major input data.\n",
    "    X_time_recon: 3D tensor representation of time major input data.\n",
    "    X_feat: 2D tensor representation of feature major input data.\n",
    "    X_feat_recon: 3D tensor representation of feature major input data.\n",
    "  \"\"\"\n",
    "  # Reshape into 2-D tensors\n",
    "  # Time based\n",
    "  # shape = (cur_batch_size * seq_len, num_feat)\n",
    "  X_time = tf.reshape(\n",
    "      tensor=X,\n",
    "      shape=[cur_batch_size * params[\"seq_len\"], num_feat])\n",
    "\n",
    "  # shape = (cur_batch_size * seq_len, num_feat)\n",
    "  X_time_recon = dense_autoencoder(X_time, num_feat, params)\n",
    "\n",
    "  # Features based\n",
    "  # shape = (cur_batch_size, num_feat, seq_len)\n",
    "  X_transposed = tf.transpose(a=X, perm=[0, 2, 1])\n",
    "  # shape = (cur_batch_size * num_feat, seq_len)\n",
    "  X_feat = tf.reshape(\n",
    "      tensor=X_transposed,\n",
    "      shape=[cur_batch_size * num_feat, params[\"seq_len\"]])\n",
    "\n",
    "  # shape = (cur_batch_size * num_feat, seq_len)\n",
    "  X_feat_recon = dense_autoencoder(X_feat, params[\"seq_len\"], params)\n",
    "\n",
    "  if (mode == tf.estimator.ModeKeys.TRAIN and\n",
    "      params[\"training_mode\"] == \"reconstruction\"):\n",
    "    X_time_recon_3d = tf.reshape(\n",
    "        tensor=X_time_recon,\n",
    "        shape=[cur_batch_size, params[\"seq_len\"], num_feat])\n",
    "    X_feat_recon_3d = tf.transpose(\n",
    "        a=tf.reshape(\n",
    "            tensor=X_feat_recon,\n",
    "            shape=[cur_batch_size, num_feat, params[\"seq_len\"]]),\n",
    "        perm=[0, 2, 1])\n",
    "\n",
    "    X_time_recon_3d_weighted = X_time_recon_3d * params[\"time_loss_weight\"]\n",
    "    X_feat_recon_3d_weighted = X_feat_recon_3d * params[\"feat_loss_weight\"]\n",
    "\n",
    "    predictions = (X_time_recon_3d_weighted + X_feat_recon_3d_weighted) \\\n",
    "      / (params[\"time_loss_weight\"] + params[\"feat_loss_weight\"])\n",
    "\n",
    "    loss = tf.losses.mean_squared_error(labels=X, predictions=predictions)\n",
    "\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step(),\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        optimizer=\"Adam\")\n",
    "\n",
    "    return loss, train_op, None, None, None, None\n",
    "  else:\n",
    "    return None, None, X_time, X_time_recon, X_feat, X_feat_recon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoencoder_lstm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile anomaly_detection_module/trainer/autoencoder_lstm.py\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# LSTM Encoder-decoder Autoencoder model functions\n",
    "def create_LSTM_stack(lstm_hidden_units, lstm_dropout_output_keep_probs):\n",
    "  \"\"\"Create LSTM stacked cells.\n",
    "\n",
    "  Given list of LSTM hidden units and list of LSTM dropout output keep\n",
    "  probabilities.\n",
    "\n",
    "  Args:\n",
    "    lstm_hidden_units: List of integers for the number of hidden units in each\n",
    "      layer.\n",
    "    lstm_dropout_output_keep_probs: List of floats for the dropout output keep\n",
    "      probabilities for each layer.\n",
    "\n",
    "  Returns:\n",
    "    MultiRNNCell object of stacked LSTM layers.\n",
    "  \"\"\"\n",
    "  # First create a list of LSTM cell objects using our list of lstm hidden\n",
    "  # unit sizes\n",
    "  lstm_cells = [tf.contrib.rnn.BasicLSTMCell(\n",
    "      num_units=units,\n",
    "      forget_bias=1.0,\n",
    "      state_is_tuple=True)\n",
    "                for units in lstm_hidden_units]\n",
    "\n",
    "  # Next apply a dropout wrapper to our stack of LSTM cells,\n",
    "  # in this case just on the outputs\n",
    "  dropout_lstm_cells = [tf.nn.rnn_cell.DropoutWrapper(\n",
    "      cell=lstm_cells[cell_index],\n",
    "      input_keep_prob=1.0,\n",
    "      output_keep_prob=lstm_dropout_output_keep_probs[cell_index],\n",
    "      state_keep_prob=1.0)\n",
    "                        for cell_index in range(len(lstm_cells))]\n",
    "\n",
    "  # Create a stack of layers of LSTM cells\n",
    "  # Combines list into MultiRNNCell object\n",
    "  stacked_lstm_cells = tf.contrib.rnn.MultiRNNCell(\n",
    "      cells=dropout_lstm_cells,\n",
    "      state_is_tuple=True)\n",
    "\n",
    "  return stacked_lstm_cells\n",
    "\n",
    "\n",
    "# The rnn_decoder function takes labels during TRAIN/EVAL\n",
    "# and a start token followed by its previous predictions during PREDICT\n",
    "# Starts with an initial state of the final encoder states\n",
    "def rnn_decoder(dec_input, init_state, cell, infer, dnn_hidden_units, num_feat):\n",
    "  \"\"\"Decoder for RNN cell.\n",
    "\n",
    "  Given list of LSTM hidden units and list of LSTM dropout output keep\n",
    "  probabilities.\n",
    "\n",
    "  Args:\n",
    "    dec_input: List of tf.float64 current batch size by number of features\n",
    "      matrix tensors input to the decoder.\n",
    "    init_state: Initial state of the decoder cell. Final state from the\n",
    "      encoder cell.\n",
    "    cell:\n",
    "    infer:\n",
    "    dnn_hidden_units:\n",
    "    num_feat:\n",
    "\n",
    "  Returns:\n",
    "    outputs: List of decoder outputs of length number of timesteps of tf.float64\n",
    "      current batch size by number of features matrix tensors.\n",
    "    state: Final cell state of the decoder.\n",
    "  \"\"\"\n",
    "  # Create the decoder variable scope\n",
    "  with tf.variable_scope(\"decoder\"):\n",
    "    # Load in our initial state from our encoder\n",
    "    # Tuple of final encoder c_state and h_state of final encoder layer\n",
    "    state = init_state\n",
    "\n",
    "    # Create an empty list to store our hidden state output for every timestep\n",
    "    outputs = []\n",
    "\n",
    "    # Begin with no previous output\n",
    "    previous_output = None\n",
    "\n",
    "    # Loop over all of our dec_input which will be seq_len long\n",
    "    for index, decoder_input in enumerate(dec_input):\n",
    "      # If there has been a previous output, we will determine the next input\n",
    "      if previous_output is not None:\n",
    "        # Create the input layer to our DNN\n",
    "        # shape = (cur_batch_size, lstm_hidden_units[-1])\n",
    "        network = previous_output\n",
    "\n",
    "        # Create our dnn variable scope\n",
    "        with tf.variable_scope(name_or_scope=\"dnn\", reuse=tf.AUTO_REUSE):\n",
    "          # Add hidden layers with the given number of units/neurons per layer\n",
    "          # shape = (cur_batch_size, dnn_hidden_units[i])\n",
    "          for units in dnn_hidden_units:\n",
    "            network = tf.layers.dense(\n",
    "                inputs=network,\n",
    "                units=units,\n",
    "                activation=tf.nn.relu)\n",
    "\n",
    "          # Connect final hidden layer to linear layer to get the logits\n",
    "          # shape = (cur_batch_size, num_feat)\n",
    "          logits = tf.layers.dense(\n",
    "              inputs=network,\n",
    "              units=num_feat,\n",
    "              activation=None)\n",
    "\n",
    "        # If we are in inference then we will overwrite our next decoder_input\n",
    "        # with the logits we just calculated. Otherwise, we leave the decoder\n",
    "        # input input as it was from the enumerated list. We have to calculate\n",
    "        # the logits even when not using them so that the correct DNN subgraph\n",
    "        # will be generated here and after the encoder-decoder for both\n",
    "        # training and inference\n",
    "        if infer:\n",
    "          # shape = (cur_batch_size, num_feat)\n",
    "          decoder_input = logits\n",
    "\n",
    "      # If this isn\"t our first time through the loop, just reuse(share) the\n",
    "      # same variables for each iteration within the current variable scope\n",
    "      if index > 0:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "      # Run the decoder input through the decoder stack picking up from the\n",
    "      # previous state\n",
    "      # output_shape = (cur_batch_size, lstm_hidden_units[-1])\n",
    "      # state_shape = # tuple of final decoder c_state and h_state\n",
    "      output, state = cell(decoder_input, state)\n",
    "\n",
    "      # Append the current decoder hidden state output to the outputs list\n",
    "      # List seq_len long of shape = (cur_batch_size, lstm_hidden_units[-1])\n",
    "      outputs.append(output)\n",
    "\n",
    "      # Set the previous output to the output just calculated\n",
    "      # shape = (cur_batch_size, lstm_hidden_units[-1])\n",
    "      previous_output = output\n",
    "  return outputs, state\n",
    "\n",
    "\n",
    "def lstm_enc_dec_autoencoder_model(\n",
    "    X, mode, params, cur_batch_size, num_feat, dummy_var):\n",
    "  \"\"\"LSTM autoencoder to reconstruct inputs and minimize reconstruction error.\n",
    "\n",
    "  Given data matrix tensor X, the current Estimator mode, the dictionary of\n",
    "  parameters, current batch size, and the number of features, process through\n",
    "  LSTM model encoder, decoder, and DNN subgraphs and return reconstructed inputs\n",
    "  as output.\n",
    "\n",
    "  Args:\n",
    "    X: tf.float64 matrix tensor of input data.\n",
    "    mode: Estimator ModeKeys. Can take values of TRAIN, EVAL, and PREDICT.\n",
    "    params: Dictionary of parameters.\n",
    "    cur_batch_size: Current batch size, could be partially filled.\n",
    "    num_feat: Number of features.\n",
    "    dummy_var: Dummy variable used to allow training mode to happen since it\n",
    "      requires a gradient to tie back to the graph dependency.\n",
    "\n",
    "  Returns:\n",
    "    loss: Reconstruction loss.\n",
    "    train_op: Train operation so that Estimator can correctly add to dependency\n",
    "      graph.\n",
    "    X_time: 2D tensor representation of time major input data.\n",
    "    X_time_recon: 3D tensor representation of time major input data.\n",
    "    X_feat: 2D tensor representation of feature major input data.\n",
    "    X_feat_recon: 3D tensor representation of feature major input data.\n",
    "  \"\"\"\n",
    "  # Unstack 3-D features tensor into a sequence(list) of 2-D tensors\n",
    "  # shape = (cur_batch_size, num_feat)\n",
    "  X_sequence = tf.unstack(value=X, num=params[\"seq_len\"], axis=1)\n",
    "\n",
    "  # Since this is an autoencoder, the features are the labels.\n",
    "  # It often works better though to have the labels in reverse order\n",
    "  # shape = (cur_batch_size, seq_len, num_feat)\n",
    "  if params[\"reverse_labels_sequence\"]:\n",
    "    Y = tf.reverse_sequence(\n",
    "        input=X,\n",
    "        seq_lengths=tf.tile(\n",
    "            input=tf.constant(value=[params[\"seq_len\"]], dtype=tf.int64),\n",
    "            multiples=tf.expand_dims(input=cur_batch_size, axis=0)),\n",
    "        seq_axis=1,\n",
    "        batch_axis=0)\n",
    "  else:\n",
    "    Y = X  # shape = (cur_batch_size, seq_len, num_feat)\n",
    "\n",
    "  ##############################################################################\n",
    "\n",
    "  # Create encoder of encoder-decoder LSTM stacks\n",
    "\n",
    "  # Create our decoder now\n",
    "  dec_stacked_lstm_cells = create_LSTM_stack(\n",
    "      params[\"dec_lstm_hidden_units\"],\n",
    "      params[\"lstm_dropout_output_keep_probs\"])\n",
    "\n",
    "  # Create the encoder variable scope\n",
    "  with tf.variable_scope(\"encoder\"):\n",
    "    # Create separate encoder cells with their own weights separate from decoder\n",
    "    enc_stacked_lstm_cells = create_LSTM_stack(\n",
    "        params[\"enc_lstm_hidden_units\"],\n",
    "        params[\"lstm_dropout_output_keep_probs\"])\n",
    "\n",
    "    # Encode the input sequence using our encoder stack of LSTMs\n",
    "    # enc_outputs = seq_len long of shape = (cur_batch_size, enc_lstm_hidden_units[-1])\n",
    "    # enc_states = tuple of final encoder c_state and h_state for each layer\n",
    "    _, enc_states = tf.nn.static_rnn(\n",
    "        cell=enc_stacked_lstm_cells,\n",
    "        inputs=X_sequence,\n",
    "        initial_state=enc_stacked_lstm_cells.zero_state(\n",
    "            batch_size=tf.cast(x=cur_batch_size, dtype=tf.int32),\n",
    "            dtype=tf.float64),\n",
    "        dtype=tf.float64)\n",
    "\n",
    "    # We just pass on the final c and h states of the encoder\"s last layer,\n",
    "    # so extract that and drop the others\n",
    "    # LSTMStateTuple shape = (cur_batch_size, lstm_hidden_units[-1])\n",
    "    enc_final_states = enc_states[-1]\n",
    "\n",
    "    # Extract the c and h states from the tuple\n",
    "    # both have shape = (cur_batch_size, lstm_hidden_units[-1])\n",
    "    enc_final_c, enc_final_h = enc_final_states\n",
    "\n",
    "    # In case the decoder\"s first layer's number of units is different than\n",
    "    # encoder's last layer's number of units, use a dense layer to map to the\n",
    "    # correct shape\n",
    "    # shape = (cur_batch_size, dec_lstm_hidden_units[0])\n",
    "    enc_final_c_dense = tf.layers.dense(\n",
    "        inputs=enc_final_c,\n",
    "        units=params[\"dec_lstm_hidden_units\"][0],\n",
    "        activation=None)\n",
    "\n",
    "    # shape = (cur_batch_size, dec_lstm_hidden_units[0])\n",
    "    enc_final_h_dense = tf.layers.dense(\n",
    "        inputs=enc_final_h,\n",
    "        units=params[\"dec_lstm_hidden_units\"][0],\n",
    "        activation=None)\n",
    "\n",
    "    # The decoder\"s first layer\"s state comes from the encoder,\n",
    "    # the rest of the layers\" initial states are zero\n",
    "    dec_init_states = tuple(\n",
    "        [tf.contrib.rnn.LSTMStateTuple(c=enc_final_c_dense,\n",
    "                                       h=enc_final_h_dense)] + \\\n",
    "        [tf.contrib.rnn.LSTMStateTuple(\n",
    "            c=tf.zeros(shape=[cur_batch_size, units], dtype=tf.float64),\n",
    "            h=tf.zeros(shape=[cur_batch_size, units], dtype=tf.float64))\n",
    "         for units in params[\"dec_lstm_hidden_units\"][1:]])\n",
    "\n",
    "  ##############################################################################\n",
    "\n",
    "  # Create decoder of encoder-decoder LSTM stacks\n",
    "\n",
    "  # Train our decoder now\n",
    "\n",
    "  # Encoder-decoders work differently during training, evaluation, and inference\n",
    "  # so we will have two separate subgraphs for each\n",
    "  if (mode == tf.estimator.ModeKeys.TRAIN and\n",
    "      params[\"training_mode\"] == \"reconstruction\"):\n",
    "    # Break 3-D labels tensor into a list of 2-D tensors\n",
    "    # shape = (cur_batch_size, num_feat)\n",
    "    unstacked_labels = tf.unstack(value=Y, num=params[\"seq_len\"], axis=1)\n",
    "\n",
    "    # Call our decoder using the labels as our inputs, the encoder final state\n",
    "    # as our initial state, our other LSTM stack as our cells, and inference\n",
    "    # set to false\n",
    "    dec_outputs, _ = rnn_decoder(\n",
    "        dec_input=unstacked_labels,\n",
    "        init_state=dec_init_states,\n",
    "        cell=dec_stacked_lstm_cells,\n",
    "        infer=False,\n",
    "        dnn_hidden_units=params[\"dnn_hidden_units\"],\n",
    "        num_feat=num_feat)\n",
    "  else:\n",
    "    # Since this is inference create fake labels. The list length needs to be\n",
    "    # the output sequence length even though only the first element is the only\n",
    "    # one actually used (as our go signal)\n",
    "    fake_labels = [tf.zeros(shape=[cur_batch_size, num_feat], dtype=tf.float64)\n",
    "                   for _ in range(params[\"seq_len\"])]\n",
    "\n",
    "    # Call our decoder using fake labels as our inputs, the encoder final state\n",
    "    # as our initial state, our other LSTM stack as our cells, and inference\n",
    "    # set to true\n",
    "    # dec_outputs = seq_len long of shape = (cur_batch_size, dec_lstm_hidden_units[-1])\n",
    "    # decoder_states = tuple of final decoder c_state and h_state for each layer\n",
    "    dec_outputs, _ = rnn_decoder(\n",
    "        dec_input=fake_labels,\n",
    "        init_state=dec_init_states,\n",
    "        cell=dec_stacked_lstm_cells,\n",
    "        infer=True,\n",
    "        dnn_hidden_units=params[\"dnn_hidden_units\"],\n",
    "        num_feat=num_feat)\n",
    "\n",
    "  # Stack together list of rank 2 decoder output tensors into one rank 3 tensor\n",
    "  # shape = (cur_batch_size, seq_len, lstm_hidden_units[-1])\n",
    "  stacked_dec_outputs = tf.stack(values=dec_outputs, axis=1)\n",
    "\n",
    "  # Reshape rank 3 decoder outputs into rank 2 by folding sequence length into\n",
    "  # batch size\n",
    "  # shape = (cur_batch_size * seq_len, lstm_hidden_units[-1])\n",
    "  reshaped_stacked_dec_outputs = tf.reshape(\n",
    "      tensor=stacked_dec_outputs,\n",
    "      shape=[cur_batch_size * params[\"seq_len\"],\n",
    "             params[\"dec_lstm_hidden_units\"][-1]])\n",
    "\n",
    "  ##############################################################################\n",
    "\n",
    "  # Create the DNN structure now after the encoder-decoder LSTM stack\n",
    "  # Create the input layer to our DNN\n",
    "  # shape = (cur_batch_size * seq_len, lstm_hidden_units[-1])\n",
    "  network = reshaped_stacked_dec_outputs\n",
    "\n",
    "  # Reuse the same variable scope as we used within our decoder (for inference)\n",
    "  with tf.variable_scope(name_or_scope=\"dnn\", reuse=tf.AUTO_REUSE):\n",
    "    # Add hidden layers with the given number of units/neurons per layer\n",
    "    for units in params[\"dnn_hidden_units\"]:\n",
    "      # shape = (cur_batch_size * seq_len, dnn_hidden_units[i])\n",
    "      network = tf.layers.dense(\n",
    "          inputs=network,\n",
    "          units=units,\n",
    "          activation=tf.nn.relu)\n",
    "\n",
    "    # Connect the final hidden layer to a dense layer with no activation to\n",
    "    # get the logits\n",
    "    # shape = (cur_batch_size * seq_len, num_feat)\n",
    "    logits = tf.layers.dense(\n",
    "        inputs=network,\n",
    "        units=num_feat,\n",
    "        activation=None)\n",
    "\n",
    "  # Now that we are through the final DNN for each sequence element for\n",
    "  # each example in the batch, reshape the predictions to match our labels.\n",
    "  # shape = (cur_batch_size, seq_len, num_feat)\n",
    "  predictions = tf.reshape(\n",
    "      tensor=logits,\n",
    "      shape=[cur_batch_size, params[\"seq_len\"], num_feat])\n",
    "\n",
    "  if (mode == tf.estimator.ModeKeys.TRAIN and\n",
    "      params[\"training_mode\"] == \"reconstruction\"):\n",
    "    loss = tf.losses.mean_squared_error(labels=Y, predictions=predictions)\n",
    "\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step(),\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        optimizer=\"Adam\")\n",
    "\n",
    "    return loss, train_op, None, None, None, None\n",
    "  else:\n",
    "    if params[\"reverse_labels_sequence\"]:\n",
    "      # shape=(cur_batch_size, seq_len, num_feat)\n",
    "      predictions = tf.reverse_sequence(\n",
    "          input=predictions,\n",
    "          seq_lengths=tf.tile(\n",
    "              input=tf.constant(value=[params[\"seq_len\"]], dtype=tf.int64),\n",
    "              multiples=tf.expand_dims(input=cur_batch_size, axis=0)),\n",
    "          seq_axis=1,\n",
    "          batch_axis=0)\n",
    "\n",
    "    # Reshape into 2-D tensors\n",
    "    # Time based\n",
    "    # shape = (cur_batch_size * seq_len, num_feat)\n",
    "    X_time = tf.reshape(\n",
    "        tensor=X,\n",
    "        shape=[cur_batch_size * params[\"seq_len\"], num_feat])\n",
    "\n",
    "    X_time_recon = tf.reshape(\n",
    "        tensor=predictions,\n",
    "        shape=[cur_batch_size * params[\"seq_len\"], num_feat])\n",
    "\n",
    "    # Features based\n",
    "    # shape = (cur_batch_size, num_feat, seq_len)\n",
    "    X_transposed = tf.transpose(a=X, perm=[0, 2, 1])\n",
    "\n",
    "    # shape = (cur_batch_size * num_feat, seq_len)\n",
    "    X_feat = tf.reshape(\n",
    "        tensor=X_transposed,\n",
    "        shape=[cur_batch_size * num_feat, params[\"seq_len\"]])\n",
    "\n",
    "    # shape = (cur_batch_size, num_feat, seq_len)\n",
    "    predictions_transposed = tf.transpose(a=predictions, perm=[0, 2, 1])\n",
    "\n",
    "    # shape = (cur_batch_size * num_feat, seq_len)\n",
    "    X_feat_recon = tf.reshape(\n",
    "        tensor=predictions_transposed,\n",
    "        shape=[cur_batch_size * num_feat, params[\"seq_len\"]])\n",
    "\n",
    "    return None, None, X_time, X_time_recon, X_feat, X_feat_recon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoencoder_pca.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile anomaly_detection_module/trainer/autoencoder_pca.py\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# PCA model functions\n",
    "def create_pca_vars(var_name, size):\n",
    "  \"\"\"Creates PCA variables.\n",
    "\n",
    "  Given variable name and size, create and return PCA variables for count,\n",
    "  mean, covariance, eigenvalues, and eignvectors.\n",
    "\n",
    "  Args:\n",
    "    var_name: String denoting which set of variables to create. Values are\n",
    "      \"time\" and \"feat\".\n",
    "    size: The size of the variable, either sequence length or number of\n",
    "      features.\n",
    "\n",
    "  Returns:\n",
    "    PCA variables for count, mean, covariance, eigenvalues, and\n",
    "    eigenvectors.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=\"pca_vars\", reuse=tf.AUTO_REUSE):\n",
    "    count_var = tf.get_variable(\n",
    "        name=\"pca_{}_count_var\".format(var_name),\n",
    "        dtype=tf.int64,\n",
    "        initializer=tf.zeros(shape=[], dtype=tf.int64),\n",
    "        trainable=False)\n",
    "\n",
    "    mean_var = tf.get_variable(\n",
    "        name=\"pca_{}_mean_var\".format(var_name),\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(shape=[size], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "    cov_var = tf.get_variable(\n",
    "        name=\"pca_{}_cov_var\".format(var_name),\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(shape=[size, size], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "    eigval_var = tf.get_variable(\n",
    "        name=\"pca_{}_eigval_var\".format(var_name),\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(shape=[size], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "    eigvec_var = tf.get_variable(\n",
    "        name=\"pca_{}_eigvec_var\".format(var_name),\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(shape=[size, size], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "  return count_var, mean_var, cov_var, eigval_var, eigvec_var\n",
    "\n",
    "\n",
    "def create_both_pca_vars(seq_len, num_feat):\n",
    "  \"\"\"Creates both time & feature major PCA variables.\n",
    "\n",
    "  Given dimensions of inputs, create and return PCA variables for count,\n",
    "  mean, covariance, eigenvalues, and eigenvectors for both time and\n",
    "  feature major representations.\n",
    "\n",
    "  Args:\n",
    "    seq_len: Number of timesteps in sequence.\n",
    "    num_feat: Number of features.\n",
    "\n",
    "  Returns:\n",
    "    PCA variables for count, mean, covariance, eigenvalues, and\n",
    "    eigenvectors for both time and feature major representations.\n",
    "  \"\"\"\n",
    "  # Time based\n",
    "  (pca_time_count_var,\n",
    "   pca_time_mean_var,\n",
    "   pca_time_cov_var,\n",
    "   pca_time_eigval_var,\n",
    "   pca_time_eigvec_var) = create_pca_vars(\n",
    "       var_name=\"time\", size=num_feat)\n",
    "\n",
    "  # Features based\n",
    "  (pca_feat_count_var,\n",
    "   pca_feat_mean_var,\n",
    "   pca_feat_cov_var,\n",
    "   pca_feat_eigval_var,\n",
    "   pca_feat_eigvec_var) = create_pca_vars(\n",
    "       var_name=\"feat\", size=seq_len)\n",
    "\n",
    "  return (pca_time_count_var,\n",
    "          pca_time_mean_var,\n",
    "          pca_time_cov_var,\n",
    "          pca_time_eigval_var,\n",
    "          pca_time_eigvec_var,\n",
    "          pca_feat_count_var,\n",
    "          pca_feat_mean_var,\n",
    "          pca_feat_cov_var,\n",
    "          pca_feat_eigval_var,\n",
    "          pca_feat_eigvec_var)\n",
    "\n",
    "def pca_model(X, mode, params, cur_batch_size, num_feat, dummy_var):\n",
    "  \"\"\"PCA to reconstruct inputs and minimize reconstruction error.\n",
    "\n",
    "  Given data matrix tensor X, the current Estimator mode, the dictionary of\n",
    "  parameters, current batch size, and the number of features, process through\n",
    "  PCA model subgraph and return reconstructed inputs as output.\n",
    "\n",
    "  Args:\n",
    "    X: tf.float64 matrix tensor of input data.\n",
    "    mode: Estimator ModeKeys. Can take values of TRAIN, EVAL, and PREDICT.\n",
    "    params: Dictionary of parameters.\n",
    "    cur_batch_size: Current batch size, could be partially filled.\n",
    "    num_feat: Number of features.\n",
    "    dummy_var: Dummy variable used to allow training mode to happen since it\n",
    "      requires a gradient to tie back to the graph dependency.\n",
    "\n",
    "  Returns:\n",
    "    loss: Reconstruction loss.\n",
    "    train_op: Train operation so that Estimator can correctly add to dependency\n",
    "      graph.\n",
    "    X_time: 2D tensor representation of time major input data.\n",
    "    X_time_recon: 3D tensor representation of time major input data.\n",
    "    X_feat: 2D tensor representation of feature major input data.\n",
    "    X_feat_recon: 3D tensor representation of feature major input data.\n",
    "  \"\"\"\n",
    "  # Reshape into 2-D tensors\n",
    "  # Time based\n",
    "  # shape = (cur_batch_size * seq_len, num_feat)\n",
    "  X_time = tf.reshape(\n",
    "      tensor=X,\n",
    "      shape=[cur_batch_size * params[\"seq_len\"], num_feat])\n",
    "\n",
    "  # Features based\n",
    "  # shape = (cur_batch_size, num_feat, seq_len)\n",
    "  X_transposed = tf.transpose(a=X, perm=[0, 2, 1])\n",
    "\n",
    "  # shape = (cur_batch_size * num_feat, seq_len)\n",
    "  X_feat = tf.reshape(\n",
    "      tensor=X_transposed,\n",
    "      shape=[cur_batch_size * num_feat, params[\"seq_len\"]])\n",
    "\n",
    "  ##############################################################################\n",
    "\n",
    "  # Variables for calculating error distribution statistics\n",
    "  (pca_time_count_var,\n",
    "   pca_time_mean_var,\n",
    "   pca_time_cov_var,\n",
    "   pca_time_eigval_var,\n",
    "   pca_time_eigvec_var,\n",
    "   pca_feat_count_var,\n",
    "   pca_feat_mean_var,\n",
    "   pca_feat_cov_var,\n",
    "   pca_feat_eigval_var,\n",
    "   pca_feat_eigvec_var) = create_both_pca_vars(params[\"seq_len\"], num_feat)\n",
    "\n",
    "  # 3. Loss function, training/eval ops\n",
    "  if (mode == tf.estimator.ModeKeys.TRAIN and\n",
    "      params[\"training_mode\"] == \"reconstruction\"):\n",
    "    with tf.variable_scope(name_or_scope=\"pca_vars\", reuse=tf.AUTO_REUSE):\n",
    "      # Check if batch is a singleton or not, very important for covariance math\n",
    "\n",
    "      # Time based ########################################\n",
    "      # shape = ()\n",
    "      singleton_condition = tf.equal(\n",
    "          x=cur_batch_size * params[\"seq_len\"], y=1)\n",
    "\n",
    "      pca_time_cov_var, pca_time_mean_var, pca_time_count_var = tf.cond(\n",
    "          pred=singleton_condition,\n",
    "          true_fn=lambda: singleton_batch_cov_variable_updating(\n",
    "              params[\"seq_len\"],\n",
    "              X_time,\n",
    "              pca_time_count_var,\n",
    "              pca_time_mean_var,\n",
    "              pca_time_cov_var),\n",
    "          false_fn=lambda: non_singleton_batch_cov_variable_updating(\n",
    "              cur_batch_size,\n",
    "              params[\"seq_len\"],\n",
    "              X_time,\n",
    "              pca_time_count_var,\n",
    "              pca_time_mean_var,\n",
    "              pca_time_cov_var))\n",
    "\n",
    "      # shape = (num_feat,) & (num_feat, num_feat)\n",
    "      pca_time_eigval_tensor, pca_time_eigvec_tensor = tf.linalg.eigh(\n",
    "          tensor=pca_time_cov_var)\n",
    "\n",
    "      # Features based ########################################\n",
    "      # shape = ()\n",
    "      singleton_features_condition = tf.equal(\n",
    "          x=cur_batch_size * num_feat, y=1)\n",
    "\n",
    "      pca_feat_cov_var, pca_feat_mean_var, pca_feat_count_var = tf.cond(\n",
    "          pred=singleton_features_condition,\n",
    "          true_fn=lambda: singleton_batch_cov_variable_updating(\n",
    "              num_feat,\n",
    "              X_feat,\n",
    "              pca_feat_count_var, pca_feat_mean_var,\n",
    "              pca_feat_cov_var),\n",
    "          false_fn=lambda: non_singleton_batch_cov_variable_updating(\n",
    "              cur_batch_size,\n",
    "              num_feat,\n",
    "              X_feat,\n",
    "              pca_feat_count_var,\n",
    "              pca_feat_mean_var,\n",
    "              pca_feat_cov_var))\n",
    "\n",
    "      # shape = (seq_len,) & (seq_len, seq_len)\n",
    "      pca_feat_eigval_tensor, pca_feat_eigvec_tensor = tf.linalg.eigh(\n",
    "          tensor=pca_feat_cov_var)\n",
    "\n",
    "    # Lastly use control dependencies around loss to enforce the mahalanobis\n",
    "    # variables to be assigned, the control order matters, hence the separate\n",
    "    # contexts\n",
    "    with tf.control_dependencies(\n",
    "        control_inputs=[pca_time_cov_var, pca_feat_cov_var]):\n",
    "      with tf.control_dependencies(\n",
    "          control_inputs=[pca_time_mean_var, pca_feat_mean_var]):\n",
    "        with tf.control_dependencies(\n",
    "            control_inputs=[pca_time_count_var, pca_feat_count_var]):\n",
    "          with tf.control_dependencies(\n",
    "              control_inputs=[tf.assign(ref=pca_time_eigval_var,\n",
    "                                        value=pca_time_eigval_tensor),\n",
    "                              tf.assign(ref=pca_time_eigvec_var,\n",
    "                                        value=pca_time_eigvec_tensor),\n",
    "                              tf.assign(ref=pca_feat_eigval_var,\n",
    "                                        value=pca_feat_eigval_tensor),\n",
    "                              tf.assign(ref=pca_feat_eigvec_var,\n",
    "                                        value=pca_feat_eigvec_tensor)]):\n",
    "            loss = tf.reduce_sum(\n",
    "                input_tensor=tf.zeros(\n",
    "                    shape=(), dtype=tf.float64) * dummy_var)\n",
    "\n",
    "            train_op = tf.contrib.layers.optimize_loss(\n",
    "                loss=loss,\n",
    "                global_step=tf.train.get_global_step(),\n",
    "                learning_rate=params[\"learning_rate\"],\n",
    "                optimizer=\"SGD\")\n",
    "\n",
    "            return loss, train_op, None, None, None, None\n",
    "  else:\n",
    "    # Time based\n",
    "    # shape = (cur_batch_size * seq_len, num_feat)\n",
    "    X_time = X_time - pca_time_mean_var\n",
    "\n",
    "    # shape = (cur_batch_size * seq_len, params[\"k_principal_components\"])\n",
    "    X_time_projected = tf.matmul(\n",
    "        a=X_time,\n",
    "        b=pca_time_eigvec_var[:, -params[\"k_principal_components\"]:])\n",
    "\n",
    "    # shape = (cur_batch_size * seq_len, num_feat)\n",
    "    X_time_recon = tf.matmul(\n",
    "        a=X_time_projected,\n",
    "        b=pca_time_eigvec_var[:, -params[\"k_principal_components\"]:],\n",
    "        transpose_b=True)\n",
    "\n",
    "    # Features based\n",
    "    # shape = (cur_batch_size * num_feat, seq_len)\n",
    "    X_feat = X_feat - pca_feat_mean_var\n",
    "\n",
    "    # shape = (cur_batch_size * num_feat, params[\"k_principal_components\"])\n",
    "    X_feat_projected = tf.matmul(\n",
    "        a=X_feat,\n",
    "        b=pca_feat_eigvec_var[:, -params[\"k_principal_components\"]:])\n",
    "\n",
    "    # shape = (cur_batch_size * num_feat, seq_len)\n",
    "    X_feat_recon = tf.matmul(\n",
    "        a=X_feat_projected,\n",
    "        b=pca_feat_eigvec_var[:, -params[\"k_principal_components\"]:],\n",
    "        transpose_b=True)\n",
    "\n",
    "    return None, None, X_time, X_time_recon, X_feat, X_feat_recon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reconstruction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile anomaly_detection_module/trainer/reconstruction.py\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def reconstruction_evaluation(X_time_orig, X_time_recon, training_mode):\n",
    "  \"\"\"Reconstruction loss on evaluation set.\n",
    "\n",
    "  Given time major original and reconstructed features data and the training\n",
    "  mode, return loss and eval_metrics_ops.\n",
    "\n",
    "  Args:\n",
    "    X_time_orig: Time major original features data.\n",
    "    X_time_recon: Time major reconstructed features data.\n",
    "    training_mode: Current training mode.\n",
    "\n",
    "  Returns:\n",
    "    loss: Scalar reconstruction loss.\n",
    "    eval_metric_ops: Evaluation metrics of reconstruction.\n",
    "  \"\"\"\n",
    "  loss = tf.losses.mean_squared_error(\n",
    "      labels=X_time_orig, predictions=X_time_recon)\n",
    "\n",
    "  eval_metric_ops = None\n",
    "\n",
    "  if training_mode == \"reconstruction\":\n",
    "    # Reconstruction eval metrics\n",
    "    eval_metric_ops = {\n",
    "        \"rmse\": tf.metrics.root_mean_squared_error(\n",
    "            labels=X_time_orig, predictions=X_time_recon),\n",
    "        \"mae\": tf.metrics.mean_absolute_error(\n",
    "            labels=X_time_orig, predictions=X_time_recon)\n",
    "    }\n",
    "\n",
    "  return loss, eval_metric_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## error_distribution_vars.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile anomaly_detection_module/trainer/error_distribution_vars.py\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def create_mahalanobis_dist_vars(var_name, size):\n",
    "  \"\"\"Creates mahalanobis distance variables.\n",
    "\n",
    "  Given variable name and size, create and return mahalanobis distance variables\n",
    "  for count, mean, covariance, and inverse covariance.\n",
    "\n",
    "  Args:\n",
    "    var_name: String denoting which set of variables to create. Values are\n",
    "      \"time\" and \"feat\".\n",
    "    size: The size of the variable, either sequence length or number of\n",
    "      features.\n",
    "\n",
    "  Returns:\n",
    "    Mahalanobis distance variables for count, mean, covariance, and inverse\n",
    "    covariance.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=\"mahalanobis_dist_vars\", reuse=tf.AUTO_REUSE):\n",
    "    count_var = tf.get_variable(\n",
    "        name=\"abs_err_count_{0}_var\".format(var_name),\n",
    "        dtype=tf.int64,\n",
    "        initializer=tf.zeros(shape=[], dtype=tf.int64),\n",
    "        trainable=False)\n",
    "\n",
    "    mean_var = tf.get_variable(\n",
    "        name=\"abs_err_mean_{0}_var\".format(var_name),\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(shape=[size], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "    cov_var = tf.get_variable(\n",
    "        name=\"abs_err_cov_{0}_var\".format(var_name),\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(shape=[size, size], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "    inv_cov_var = tf.get_variable(\n",
    "        name=\"abs_err_inv_cov_{0}_var\".format(var_name),\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(shape=[size, size], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "  return count_var, mean_var, cov_var, inv_cov_var\n",
    "\n",
    "\n",
    "def create_both_mahalanobis_dist_vars(seq_len, num_feat):\n",
    "  \"\"\"Creates both time & feature major mahalanobis distance variables.\n",
    "\n",
    "  Given dimensions of inputs, create and return mahalanobis distance variables\n",
    "  for count, mean, covariance, and inverse covariance for both time and\n",
    "  feature major representations.\n",
    "\n",
    "  Args:\n",
    "    seq_len: Number of timesteps in sequence.\n",
    "    num_feat: Number of features.\n",
    "\n",
    "  Returns:\n",
    "    Mahalanobis distance variables for count, mean, covariance, and inverse\n",
    "    covariance for both time and feature major representations.\n",
    "  \"\"\"\n",
    "  # Time based\n",
    "  (abs_err_count_time_var,\n",
    "   abs_err_mean_time_var,\n",
    "   abs_err_cov_time_var,\n",
    "   abs_err_inv_cov_time_var) = create_mahalanobis_dist_vars(\n",
    "       var_name=\"time\", size=num_feat)\n",
    "\n",
    "  # Features based\n",
    "  (abs_err_count_feat_var,\n",
    "   abs_err_mean_feat_var,\n",
    "   abs_err_cov_feat_var,\n",
    "   abs_err_inv_cov_feat_var) = create_mahalanobis_dist_vars(\n",
    "       var_name=\"feat\", size=seq_len)\n",
    "\n",
    "  return (abs_err_count_time_var,\n",
    "          abs_err_mean_time_var,\n",
    "          abs_err_cov_time_var,\n",
    "          abs_err_inv_cov_time_var,\n",
    "          abs_err_count_feat_var,\n",
    "          abs_err_mean_feat_var,\n",
    "          abs_err_cov_feat_var,\n",
    "          abs_err_inv_cov_feat_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate_error_distribution_statistics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile anomaly_detection_module/trainer/calculate_error_distribution_statistics.py\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Running covariance updating functions for mahalanobis distance variables\n",
    "def update_record_count(count_a, count_b):\n",
    "  \"\"\"Updates the running number of records processed.\n",
    "\n",
    "  Given previous running total and current batch size, return new running total.\n",
    "\n",
    "  Args:\n",
    "    count_a: tf.int64 scalar tensor of previous running total of records.\n",
    "    count_b: tf.int64 scalar tensor of current batch size.\n",
    "\n",
    "  Returns:\n",
    "    A tf.int64 scalar tensor of new running total of records.\n",
    "  \"\"\"\n",
    "  return count_a + count_b\n",
    "\n",
    "\n",
    "# Incremental covariance updating functions for mahalanobis distance variables\n",
    "\n",
    "\n",
    "def update_mean_incremental(count_a, mean_a, value_b):\n",
    "  \"\"\"Updates the running mean vector incrementally.\n",
    "\n",
    "  Given previous running total, running column means, and single example's\n",
    "  column values, return new running column means.\n",
    "\n",
    "  Args:\n",
    "    count_a: tf.int64 scalar tensor of previous running total of records.\n",
    "    mean_a: tf.float64 vector tensor of previous running column means.\n",
    "    value_b: tf.float64 vector tensor of single example's column values.\n",
    "\n",
    "  Returns:\n",
    "    A tf.float64 vector tensor of new running column means.\n",
    "  \"\"\"\n",
    "  umean_a = mean_a * tf.cast(x=count_a, dtype=tf.float64)\n",
    "  mean_ab_num = umean_a + tf.squeeze(input=value_b, axis=0)\n",
    "  mean_ab = mean_ab_num / tf.cast(x=count_a + 1, dtype=tf.float64)\n",
    "\n",
    "  return mean_ab\n",
    "\n",
    "\n",
    "# This function updates the covariance matrix incrementally\n",
    "def update_cov_incremental(\n",
    "    count_a, mean_a, cov_a, value_b, mean_ab, sample_cov):\n",
    "  \"\"\"Updates the running covariance matrix incrementally.\n",
    "\n",
    "  Given previous running total, running column means, running covariance matrix,\n",
    "  single example's column values, new running column means, and whether to use\n",
    "  sample covariance or not, return new running covariance matrix.\n",
    "\n",
    "  Args:\n",
    "    count_a: tf.int64 scalar tensor of previous running total of records.\n",
    "    mean_a: tf.float64 vector tensor of previous running column means.\n",
    "    cov_a: tf.float64 matrix tensor of previous running covariance matrix.\n",
    "    value_b: tf.float64 vector tensor of single example's column values.\n",
    "    mean_ab: tf.float64 vector tensor of new running column means.\n",
    "    sample_cov: Bool flag on whether sample or population covariance is used.\n",
    "\n",
    "  Returns:\n",
    "    A tf.float64 matrix tensor of new covariance matrix.\n",
    "  \"\"\"\n",
    "  print(\"value_b = \\n{}\".format(value_b))\n",
    "  print(\"mean_a = \\n{}\".format(mean_a))\n",
    "  print(\"mean_ab = \\n{}\".format(mean_ab))\n",
    "  mean_diff = tf.matmul(\n",
    "      a=value_b - mean_a, b=value_b - mean_ab, transpose_a=True)\n",
    "  if sample_cov:\n",
    "    ucov_a = cov_a * tf.cast(x=count_a - 1, dtype=tf.float64)\n",
    "    cov_ab = (ucov_a + mean_diff) / tf.cast(x=count_a, dtype=tf.float64)\n",
    "  else:\n",
    "    ucov_a = cov_a * tf.cast(x=count_a, dtype=tf.float64)\n",
    "    cov_ab = (ucov_a + mean_diff) / tf.cast(x=count_a + 1, dtype=tf.float64)\n",
    "\n",
    "  return cov_ab\n",
    "\n",
    "\n",
    "def singleton_batch_cov_variable_updating(\n",
    "    inner_size, X, count_variable, mean_variable, cov_variable):\n",
    "  \"\"\"Updates mahalanobis variables incrementally when number_of_rows equals 1.\n",
    "\n",
    "  Given the inner size of the matrix, the data vector X, the variable tracking\n",
    "  running record counts, the variable tracking running column means, and the\n",
    "  variable tracking running covariance matrix, returns updated running\n",
    "  covariance matrix, running column means, and running record count variables.\n",
    "\n",
    "  Args:\n",
    "    inner_size: Inner size of matrix X.\n",
    "    X: tf.float64 matrix tensor of input data.\n",
    "    count_variable: tf.int64 scalar variable tracking running record counts.\n",
    "    mean_variable: tf.float64 vector variable tracking running column means.\n",
    "    cov_variable: tf.float64 matrix variable tracking running covariance matrix.\n",
    "\n",
    "  Returns:\n",
    "    Updated running covariance matrix, running column means, and running record\n",
    "      count variables.\n",
    "  \"\"\"\n",
    "  # Calculate new combined mean for incremental covariance matrix calculation\n",
    "  # time_shape = (num_feat,), features_shape = (seq_len,)\n",
    "  mean_ab = update_mean_incremental(\n",
    "      count_a=count_variable, mean_a=mean_variable, value_b=X)\n",
    "\n",
    "  # Update running variables from single example\n",
    "  # time_shape = (), features_shape = ()\n",
    "  count_tensor = update_record_count(count_a=count_variable, count_b=1)\n",
    "\n",
    "  # time_shape = (num_feat,), features_shape = (seq_len,)\n",
    "  mean_tensor = mean_ab\n",
    "\n",
    "  # Check if inner dimension is greater than 1 to calculate covariance matrix\n",
    "  if inner_size == 1:\n",
    "    cov_tensor = tf.zeros_like(tensor=cov_variable, dtype=tf.float64)\n",
    "  else:\n",
    "    # time_shape = (num_feat, num_feat)\n",
    "    # features_shape = (seq_len, seq_len)\n",
    "    cov_tensor = update_cov_incremental(\n",
    "        count_a=count_variable,\n",
    "        mean_a=mean_variable,\n",
    "        cov_a=cov_variable,\n",
    "        value_b=X,\n",
    "        mean_ab=mean_ab,\n",
    "        sample_cov=True)\n",
    "\n",
    "  # Assign values to variables, use control dependencies around return to\n",
    "  # enforce the mahalanobis variables to be assigned, the control order matters,\n",
    "  # hence the separate contexts.\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[tf.assign(ref=cov_variable, value=cov_tensor)]):\n",
    "    with tf.control_dependencies(\n",
    "        control_inputs=[tf.assign(ref=mean_variable, value=mean_tensor)]):\n",
    "      with tf.control_dependencies(\n",
    "          control_inputs=[tf.assign(ref=count_variable, value=count_tensor)]):\n",
    "\n",
    "        return (tf.identity(input=cov_variable),\n",
    "                tf.identity(input=mean_variable),\n",
    "                tf.identity(input=count_variable))\n",
    "\n",
    "\n",
    "def singleton_batch_var_variable_updating(\n",
    "    inner_size, x, count_variable, mean_variable, var_variable):\n",
    "  \"\"\"Updates mahalanobis thresh vars incrementally when number_of_rows equals 1.\n",
    "\n",
    "  Given the inner size of the matrix, the data scalar x, the variable tracking\n",
    "  running record counts, the variable tracking the running mean, and the\n",
    "  variable tracking the running variance, returns updated running variance,\n",
    "  running mean, and running record count variables.\n",
    "\n",
    "  Args:\n",
    "    inner_size: Inner size of matrix X.\n",
    "    x: tf.float64 scalar tensor of input data.\n",
    "    count_variable: tf.int64 scalar variable tracking running record counts.\n",
    "    mean_variable: tf.float64 scalar variable tracking running mean.\n",
    "    var_variable: tf.float64 scalar variable tracking running variance.\n",
    "\n",
    "  Returns:\n",
    "    Updated running variance, running mean, and running record count variables.\n",
    "  \"\"\"\n",
    "  # Calculate new combined mean for incremental covariance matrix calculation\n",
    "  # time_shape = (), features_shape = ()\n",
    "  mean_ab = update_mean_incremental(\n",
    "      count_a=count_variable, mean_a=mean_variable, value_b=x)\n",
    "\n",
    "  # Update running variables from single example\n",
    "  # time_shape = (), features_shape = ()\n",
    "  count_tensor = update_record_count(count_a=count_variable, count_b=1)\n",
    "\n",
    "  # time_shape = (), features_shape = ()\n",
    "  mean_tensor = mean_ab\n",
    "\n",
    "  # Check if inner dimension is greater than 1 to calculate covariance matrix\n",
    "  if inner_size == 1:\n",
    "    var_tensor = tf.zeros_like(tensor=var_variable, dtype=tf.float64)\n",
    "  else:\n",
    "    # time_shape = (), features_shape = ()\n",
    "    var_tensor = update_cov_incremental(\n",
    "        count_a=count_variable,\n",
    "        mean_a=tf.reshape(tensor=mean_variable, shape=[1]),\n",
    "        cov_a=tf.reshape(tensor=var_variable, shape=[1, 1]),\n",
    "        value_b=tf.reshape(tensor=x, shape=[1,1]),\n",
    "        mean_ab=tf.reshape(tensor=mean_ab, shape=[1]),\n",
    "        sample_cov=True)\n",
    "\n",
    "    var_tensor = tf.squeeze(input=var_tensor)\n",
    "\n",
    "  # Assign values to variables, use control dependencies around return to\n",
    "  # enforce the mahalanobis variables to be assigned, the control order matters,\n",
    "  # hence the separate contexts.\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[tf.assign(ref=var_variable, value=var_tensor)]):\n",
    "    with tf.control_dependencies(\n",
    "        control_inputs=[tf.assign(ref=mean_variable, value=mean_tensor)]):\n",
    "      with tf.control_dependencies(\n",
    "          control_inputs=[tf.assign(ref=count_variable, value=count_tensor)]):\n",
    "\n",
    "        return (tf.identity(input=var_variable),\n",
    "                tf.identity(input=mean_variable),\n",
    "                tf.identity(input=count_variable))\n",
    "\n",
    "\n",
    "# Batch covariance updating functions for mahalanobis distance variables\n",
    "\n",
    "\n",
    "def update_mean_batch(count_a, mean_a, count_b, mean_b):\n",
    "  \"\"\"Updates the running mean vector with a batch of data.\n",
    "\n",
    "  Given previous running total, running column means, current batch size, and\n",
    "  batch's column means, return new running column means.\n",
    "\n",
    "  Args:\n",
    "    count_a: tf.int64 scalar tensor of previous running total of records.\n",
    "    mean_a: tf.float64 vector tensor of previous running column means.\n",
    "    count_b: tf.int64 scalar tensor of current batch size.\n",
    "    mean_b: tf.float64 vector tensor of batch's column means.\n",
    "\n",
    "  Returns:\n",
    "    A tf.float64 vector tensor of new running column means.\n",
    "  \"\"\"\n",
    "  sum_a = mean_a * tf.cast(x=count_a, dtype=tf.float64)\n",
    "  sum_b = mean_b * tf.cast(x=count_b, dtype=tf.float64)\n",
    "  mean_ab = (sum_a + sum_b) / tf.cast(x=count_a + count_b, dtype=tf.float64)\n",
    "\n",
    "  return mean_ab\n",
    "\n",
    "\n",
    "def update_cov_batch(\n",
    "    count_a, mean_a, cov_a, count_b, mean_b, cov_b, sample_cov):\n",
    "  \"\"\"Updates the running covariance matrix with batch of data.\n",
    "\n",
    "  Given previous running total, running column means, running covariance matrix,\n",
    "  current batch size, batch's column means, batch's covariance matrix, and\n",
    "  whether to use sample covariance or not, return new running covariance matrix.\n",
    "\n",
    "  Args:\n",
    "    count_a: tf.int64 scalar tensor of previous running total of records.\n",
    "    mean_a: tf.float64 vector tensor of previous running column means.\n",
    "    cov_a: tf.float64 matrix tensor of previous running covariance matrix.\n",
    "    count_b: tf.int64 scalar tensor of current batch size.\n",
    "    mean_b: tf.float64 vector tensor of batch's column means.\n",
    "    cov_b: tf.float64 matrix tensor of batch's covariance matrix.\n",
    "    sample_cov: Bool flag on whether sample or population covariance is used.\n",
    "\n",
    "  Returns:\n",
    "    A tf.float64 matrix tensor of new running covariance matrix.\n",
    "  \"\"\"\n",
    "  mean_diff = tf.expand_dims(input=mean_a - mean_b, axis=0)\n",
    "\n",
    "  if sample_cov:\n",
    "    ucov_a = cov_a * tf.cast(x=count_a - 1, dtype=tf.float64)\n",
    "    ucov_b = cov_b * tf.cast(x=count_b - 1, dtype=tf.float64)\n",
    "    den = tf.cast(x=count_a + count_b - 1, dtype=tf.float64)\n",
    "  else:\n",
    "    ucov_a = cov_a * tf.cast(x=count_a, dtype=tf.float64)\n",
    "    ucov_b = cov_b * tf.cast(x=count_b, dtype=tf.float64)\n",
    "    den = tf.cast(x=count_a + count_b, dtype=tf.float64)\n",
    "\n",
    "  mean_diff = tf.matmul(a=mean_diff, b=mean_diff, transpose_a=True)\n",
    "  mean_scaling_num = tf.cast(x=count_a * count_b, dtype=tf.float64)\n",
    "  mean_scaling_den = tf.cast(x=count_a + count_b, dtype=tf.float64)\n",
    "  mean_scaling = mean_scaling_num / mean_scaling_den\n",
    "  cov_ab = (ucov_a + ucov_b + mean_diff * mean_scaling) / den\n",
    "\n",
    "  return cov_ab\n",
    "\n",
    "\n",
    "def non_singleton_batch_cov_variable_updating(\n",
    "    cur_batch_size, inner_size, X, count_variable, mean_variable, cov_variable):\n",
    "  \"\"\"Updates mahalanobis variables when number_of_rows does NOT equal 1.\n",
    "\n",
    "  Given the current batch size, inner size of the matrix, the data matrix X,\n",
    "  the variable tracking running record counts, the variable tracking running\n",
    "  column means, and the variable tracking running covariance matrix, returns\n",
    "  updated running covariance matrix, running column means, and running record\n",
    "  count variables.\n",
    "\n",
    "  Args:\n",
    "    cur_batch_size: Number of examples in current batch (could be partial).\n",
    "    inner_size: Inner size of matrix X.\n",
    "    X: tf.float64 matrix tensor of input data.\n",
    "    count_variable: tf.int64 scalar variable tracking running record counts.\n",
    "    mean_variable: tf.float64 vector variable tracking running column means.\n",
    "    cov_variable: tf.float64 matrix variable tracking running covariance matrix.\n",
    "\n",
    "  Returns:\n",
    "    Updated running covariance matrix, running column means, and running record\n",
    "      count variables.\n",
    "  \"\"\"\n",
    "  # Find statistics of batch\n",
    "  number_of_rows = cur_batch_size * inner_size\n",
    "\n",
    "  # time_shape = (num_feat,), features_shape = (seq_len,)\n",
    "  X_mean = tf.reduce_mean(input_tensor=X, axis=0)\n",
    "\n",
    "  # time_shape = (cur_batch_size * seq_len, num_feat)\n",
    "  # features_shape = (cur_batch_size * num_feat, seq_len)\n",
    "  X_centered = X - X_mean\n",
    "\n",
    "  if inner_size > 1:\n",
    "    # time_shape = (num_feat, num_feat)\n",
    "    # features_shape = (seq_len, seq_len)\n",
    "    X_cov = tf.matmul(\n",
    "        a=X_centered,\n",
    "        b=X_centered,\n",
    "        transpose_a=True) / tf.cast(x=number_of_rows - 1, dtype=tf.float64)\n",
    "\n",
    "  # Update running variables from batch statistics\n",
    "  # time_shape = (), features_shape = ()\n",
    "  count_tensor = update_record_count(\n",
    "      count_a=count_variable, count_b=number_of_rows)\n",
    "\n",
    "  # time_shape = (num_feat,), features_shape = (seq_len,)\n",
    "  mean_tensor = update_mean_batch(\n",
    "      count_a=count_variable,\n",
    "      mean_a=mean_variable,\n",
    "      count_b=number_of_rows,\n",
    "      mean_b=X_mean)\n",
    "\n",
    "  # Check if inner dimension is greater than 1 to calculate covariance matrix\n",
    "  if inner_size == 1:\n",
    "    cov_tensor = tf.zeros_like(tensor=cov_variable, dtype=tf.float64)\n",
    "  else:\n",
    "    # time_shape = (num_feat, num_feat)\n",
    "    # features_shape = (seq_len, seq_len)\n",
    "    cov_tensor = update_cov_batch(\n",
    "        count_a=count_variable,\n",
    "        mean_a=mean_variable,\n",
    "        cov_a=cov_variable,\n",
    "        count_b=number_of_rows,\n",
    "        mean_b=X_mean,\n",
    "        cov_b=X_cov,\n",
    "        sample_cov=True)\n",
    "\n",
    "  # Assign values to variables, use control dependencies around return to\n",
    "  # enforce the mahalanobis variables to be assigned, the control order matters,\n",
    "  # hence the separate contexts.\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[tf.assign(ref=cov_variable, value=cov_tensor)]):\n",
    "    with tf.control_dependencies(\n",
    "        control_inputs=[tf.assign(ref=mean_variable, value=mean_tensor)]):\n",
    "      with tf.control_dependencies(\n",
    "          control_inputs=[tf.assign(ref=count_variable, value=count_tensor)]):\n",
    "\n",
    "        return (tf.identity(input=cov_variable),\n",
    "                tf.identity(input=mean_variable),\n",
    "                tf.identity(input=count_variable))\n",
    "\n",
    "\n",
    "def non_singleton_batch_var_variable_updating(\n",
    "    cur_batch_size, inner_size, x, count_variable, mean_variable, var_variable):\n",
    "  \"\"\"Updates mahalanobis thresh variables when number_of_rows does NOT equal 1.\n",
    "\n",
    "  Given the current batch size, inner size of the matrix, the data vector x,\n",
    "  the variable tracking the running record count, the variable tracking the\n",
    "  running mean, and the variable tracking the running variance, returns\n",
    "  updated running variance, running mean, and running record count variables.\n",
    "\n",
    "  Args:\n",
    "    cur_batch_size: Number of examples in current batch (could be partial).\n",
    "    inner_size: Inner size of matrix X.\n",
    "    x: tf.float64 vector tensor of mahalanobis distance.\n",
    "    count_variable: tf.int64 scalar variable tracking running record count.\n",
    "    mean_variable: tf.float64 scalar variable tracking running mean.\n",
    "    var_variable: tf.float64 scalar variable tracking running variance.\n",
    "\n",
    "  Returns:\n",
    "    Updated running variance, running mean, and running record count variables.\n",
    "  \"\"\"\n",
    "  # Find statistics of batch\n",
    "  number_of_rows = cur_batch_size * inner_size\n",
    "  \n",
    "  # time_shape = (), features_shape = ()\n",
    "  x_mean = tf.reduce_mean(input_tensor=x)\n",
    "\n",
    "  # time_shape = (cur_batch_size * seq_len,)\n",
    "  # features_shape = (cur_batch_size * num_feat,)\n",
    "  x_centered = x - x_mean\n",
    "\n",
    "  if inner_size > 1:\n",
    "    # time_shape = (), features_shape = ()\n",
    "    x_var = tf.reduce_sum(input_tensor=tf.square(x=x_centered))\n",
    "    x_var /= tf.cast(x=number_of_rows - 1, dtype=tf.float64)\n",
    "\n",
    "  # Update running variables from batch statistics\n",
    "  # time_shape = (), features_shape = ()\n",
    "  count_tensor = update_record_count(\n",
    "      count_a=count_variable, count_b=number_of_rows)\n",
    "\n",
    "  # time_shape = (), features_shape = ()\n",
    "  mean_tensor = update_mean_batch(\n",
    "      count_a=count_variable,\n",
    "      mean_a=mean_variable,\n",
    "      count_b=number_of_rows,\n",
    "      mean_b=x_mean)\n",
    "\n",
    "  # Check if inner dimension is greater than 1 to calculate covariance matrix\n",
    "  if inner_size == 1:\n",
    "    var_tensor = tf.zeros_like(tensor=var_variable, dtype=tf.float64)\n",
    "  else:\n",
    "    # time_shape = (num_feat, num_feat)\n",
    "    # features_shape = (seq_len, seq_len)\n",
    "    var_tensor = update_cov_batch(\n",
    "        count_a=count_variable,\n",
    "        mean_a=mean_variable,\n",
    "        cov_a=var_variable,\n",
    "        count_b=number_of_rows,\n",
    "        mean_b=tf.expand_dims(input=x_mean, axis=0),\n",
    "        cov_b=tf.reshape(tensor=x_var, shape=[1, 1]),\n",
    "        sample_cov=True)\n",
    "\n",
    "    var_tensor = tf.squeeze(input=var_tensor)\n",
    "\n",
    "  # Assign values to variables, use control dependencies around return to\n",
    "  # enforce the mahalanobis thresh variables to be assigned, the control order\n",
    "  # matters, hence the separate contexts.\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[tf.assign(ref=var_variable, value=var_tensor)]):\n",
    "    with tf.control_dependencies(\n",
    "        control_inputs=[tf.assign(ref=mean_variable, value=mean_tensor)]):\n",
    "      with tf.control_dependencies(\n",
    "          control_inputs=[tf.assign(ref=count_variable, value=count_tensor)]):\n",
    "\n",
    "        return (tf.identity(input=var_variable),\n",
    "                tf.identity(input=mean_variable),\n",
    "                tf.identity(input=count_variable))\n",
    "\n",
    "\n",
    "def mahalanobis_dist(err_vec, mean_vec, inv_cov, final_shape):\n",
    "  \"\"\"Calculates mahalanobis distance from MLE.\n",
    "\n",
    "  Given reconstruction error vector, mean reconstruction error vector, inverse\n",
    "  covariance of reconstruction error, and mahalanobis distance tensor's final\n",
    "  shape, return mahalanobis distance.\n",
    "\n",
    "  Args:\n",
    "    err_vec: tf.float64 matrix tensor of reconstruction errors.\n",
    "    mean_vec: tf.float64 vector variable tracking running column means of\n",
    "      reconstruction errors.\n",
    "    inv_cov: tf.float64 matrix variable tracking running covariance matrix of\n",
    "      reconstruction errors.\n",
    "    final_shape: Final shape of mahalanobis distance tensor.\n",
    "\n",
    "  Returns:\n",
    "    tf.float64 matrix tensor of mahalanobis distance.\n",
    "  \"\"\"\n",
    "  # time_shape = (cur_batch_size * seq_len, num_feat)\n",
    "  # features_shape = (cur_batch_size * num_feat, seq_len)\n",
    "  err_vec_cen = err_vec - mean_vec\n",
    "\n",
    "  # time_shape = (num_feat, cur_batch_size * seq_len)\n",
    "  # features_shape = (seq_len, cur_batch_size * num_feat)\n",
    "  mahalanobis_right_product = tf.matmul(\n",
    "      a=inv_cov, b=err_vec_cen, transpose_b=True)\n",
    "\n",
    "  # time_shape = (cur_batch_size * seq_len, cur_batch_size * seq_len)\n",
    "  # features_shape = (cur_batch_size * num_feat, cur_batch_size * num_feat)\n",
    "  mahalanobis_dist_vectorized = tf.matmul(\n",
    "      a=err_vec_cen, b=mahalanobis_right_product)\n",
    "\n",
    "  # time_shape = (cur_batch_size * seq_len,)\n",
    "  # features_shape = (cur_batch_size * num_feat,)\n",
    "  mahalanobis_dist_flat = tf.diag_part(input=mahalanobis_dist_vectorized)\n",
    "\n",
    "  # time_shape = (cur_batch_size, seq_len)\n",
    "  # features_shape = (cur_batch_size, num_feat)\n",
    "  mahalanobis_dist_final_shaped = tf.reshape(\n",
    "      tensor=mahalanobis_dist_flat, shape=[-1, final_shape])\n",
    "\n",
    "  # time_shape = (cur_batch_size, seq_len)\n",
    "  # features_shape = (cur_batch_size, num_feat)\n",
    "  mahalanobis_dist_final_shaped_sqrt = tf.sqrt(x=mahalanobis_dist_final_shaped)\n",
    "\n",
    "  return mahalanobis_dist_final_shaped_sqrt\n",
    "\n",
    "\n",
    "def calculate_error_distribution_statistics_training(\n",
    "    cur_batch_size,\n",
    "    num_feat,\n",
    "    X_time_abs_recon_err,\n",
    "    abs_err_count_time_var,\n",
    "    abs_err_mean_time_var,\n",
    "    abs_err_cov_time_var,\n",
    "    abs_err_inv_cov_time_var,\n",
    "    X_feat_abs_recon_err,\n",
    "    abs_err_count_feat_var,\n",
    "    abs_err_mean_feat_var,\n",
    "    abs_err_cov_feat_var,\n",
    "    abs_err_inv_cov_feat_var,\n",
    "    params,\n",
    "    dummy_var):\n",
    "  \"\"\"Calculates error distribution statistics during training mode.\n",
    "\n",
    "  Given dimensions of inputs, reconstructed inputs' absolute errors, and\n",
    "  variables tracking counts, means, and covariances of error distribution,\n",
    "  returns loss and train_op.\n",
    "\n",
    "  Args:\n",
    "    cur_batch_size: Current batch size, could be partially filled.\n",
    "    num_feat: Number of features.\n",
    "    X_time_abs_recon_err: Time major reconstructed input data's absolute\n",
    "      reconstruction error.\n",
    "    abs_err_count_time_var: Time major running count of number of records.\n",
    "    abs_err_mean_time_var: Time major running column means of absolute error.\n",
    "    abs_err_cov_time_var: Time major running covariance matrix of absolute\n",
    "      error.\n",
    "    abs_err_inv_cov_time_var: Time major running inverse covariance matrix of\n",
    "    absolute error.\n",
    "    X_feat_abs_recon_err: Feature major reconstructed input data's absolute\n",
    "      reconstruction error.\n",
    "    abs_err_count_feat_var: Feature major running count of number of records.\n",
    "    abs_err_mean_feat_var: Feature major running column means of absolute error.\n",
    "    abs_err_cov_feat_var: Feature major running covariance matrix of absolute\n",
    "      error.\n",
    "    abs_err_inv_cov_feat_var: Feature major running inverse covariance matrix of\n",
    "    absolute error.\n",
    "    params: Dictionary of parameters.\n",
    "    dummy_var: Dummy variable used to allow training mode to happen since it\n",
    "      requires a gradient to tie back to the graph dependency.\n",
    "\n",
    "  Returns:\n",
    "    loss: The scalar loss to tie our updates back to Estimator graph.\n",
    "    train_op: The train operation to tie our updates back to Estimator graph.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=\"mahalanobis_dist_vars\", reuse=tf.AUTO_REUSE):\n",
    "    # Time based\n",
    "    singleton_time_condition = tf.equal(\n",
    "        x=cur_batch_size * params[\"seq_len\"], y=1)\n",
    "\n",
    "    cov_time_var, mean_time_var, count_time_var = tf.cond(\n",
    "        pred=singleton_time_condition,\n",
    "        true_fn=lambda: singleton_batch_cov_variable_updating(\n",
    "            params[\"seq_len\"],\n",
    "            X_time_abs_recon_err,\n",
    "            abs_err_count_time_var,\n",
    "            abs_err_mean_time_var,\n",
    "            abs_err_cov_time_var),\n",
    "        false_fn=lambda: non_singleton_batch_cov_variable_updating(\n",
    "            cur_batch_size,\n",
    "            params[\"seq_len\"],\n",
    "            X_time_abs_recon_err,\n",
    "            abs_err_count_time_var,\n",
    "            abs_err_mean_time_var,\n",
    "            abs_err_cov_time_var))\n",
    "\n",
    "    # Features based\n",
    "    singleton_feat_condition = tf.equal(\n",
    "        x=cur_batch_size * num_feat, y=1)\n",
    "\n",
    "    cov_feat_var, mean_feat_var, count_feat_var = tf.cond(\n",
    "        pred=singleton_feat_condition,\n",
    "        true_fn=lambda: singleton_batch_cov_variable_updating(\n",
    "            num_feat,\n",
    "            X_feat_abs_recon_err,\n",
    "            abs_err_count_feat_var,\n",
    "            abs_err_mean_feat_var,\n",
    "            abs_err_cov_feat_var),\n",
    "        false_fn=lambda: non_singleton_batch_cov_variable_updating(\n",
    "            cur_batch_size,\n",
    "            num_feat,\n",
    "            X_feat_abs_recon_err,\n",
    "            abs_err_count_feat_var,\n",
    "            abs_err_mean_feat_var,\n",
    "            abs_err_cov_feat_var))\n",
    "\n",
    "  # Lastly use control dependencies around loss to enforce the mahalanobis\n",
    "  # variables to be assigned, the control order matters, hence the separate\n",
    "  # contexts\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[cov_time_var, cov_feat_var]):\n",
    "    with tf.control_dependencies(\n",
    "        control_inputs=[mean_time_var, mean_feat_var]):\n",
    "      with tf.control_dependencies(\n",
    "          control_inputs=[count_time_var, count_feat_var]):\n",
    "        # Time based\n",
    "        # shape = (num_feat, num_feat)\n",
    "        abs_err_inv_cov_time_tensor = \\\n",
    "          tf.matrix_inverse(input=cov_time_var + \\\n",
    "            tf.eye(num_rows=tf.shape(input=cov_time_var)[0],\n",
    "                   dtype=tf.float64) * params[\"eps\"])\n",
    "        # Features based\n",
    "        # shape = (seq_len, seq_len)\n",
    "        abs_err_inv_cov_feat_tensor = \\\n",
    "          tf.matrix_inverse(input=cov_feat_var + \\\n",
    "            tf.eye(num_rows=tf.shape(input=cov_feat_var)[0],\n",
    "                   dtype=tf.float64) * params[\"eps\"])\n",
    "\n",
    "        with tf.control_dependencies(\n",
    "            control_inputs=[tf.assign(ref=abs_err_inv_cov_time_var,\n",
    "                                      value=abs_err_inv_cov_time_tensor),\n",
    "                            tf.assign(ref=abs_err_inv_cov_feat_var,\n",
    "                                      value=abs_err_inv_cov_feat_tensor)]):\n",
    "          loss = tf.reduce_sum(\n",
    "              input_tensor=tf.zeros(shape=(), dtype=tf.float64) * dummy_var)\n",
    "\n",
    "          train_op = tf.contrib.layers.optimize_loss(\n",
    "              loss=loss,\n",
    "              global_step=tf.train.get_global_step(),\n",
    "              learning_rate=params[\"learning_rate\"],\n",
    "              optimizer=\"SGD\")\n",
    "\n",
    "  return loss, train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tune_anomaly_threshold_vars.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile anomaly_detection_module/trainer/tune_anomaly_threshold_vars.py\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def create_confusion_matrix_thresh_vars(scope, var_name, size):\n",
    "  \"\"\"Creates confusion matrix threshold variables.\n",
    "\n",
    "  Given variable scope, name, and size, create and return confusion matrix\n",
    "  threshold variables for true positives, false negatives, false positives,\n",
    "  true negatives.\n",
    "\n",
    "  Args:\n",
    "    scope: String of variable scope name.\n",
    "    var_name: String denoting which set of variables to create. Values are\n",
    "      \"time\" and \"feat\".\n",
    "    size: The size of the variable, number of time/feature thresholds.\n",
    "\n",
    "  Returns:\n",
    "    Confusion matrix threshold variables for true positives, false negatives,\n",
    "    false positives, true negatives.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=scope, reuse=tf.AUTO_REUSE):\n",
    "    tp_thresh_var = tf.get_variable(\n",
    "        name=\"tp_thresh_{0}_var\".format(var_name),\n",
    "        dtype=tf.int64,\n",
    "        initializer=tf.zeros(\n",
    "            shape=size, dtype=tf.int64),\n",
    "        trainable=False)\n",
    "\n",
    "    fn_thresh_var = tf.get_variable(\n",
    "        name=\"fn_thresh_{0}_var\".format(var_name),\n",
    "        dtype=tf.int64,\n",
    "        initializer=tf.zeros(\n",
    "            shape=size, dtype=tf.int64),\n",
    "        trainable=False)\n",
    "\n",
    "    fp_thresh_var = tf.get_variable(\n",
    "        name=\"fp_thresh_{0}_var\".format(var_name),\n",
    "        dtype=tf.int64,\n",
    "        initializer=tf.zeros(\n",
    "            shape=size, dtype=tf.int64),\n",
    "        trainable=False)\n",
    "\n",
    "    tn_thresh_var = tf.get_variable(\n",
    "        name=\"tn_thresh_{0}_var\".format(var_name),\n",
    "        dtype=tf.int64,\n",
    "        initializer=tf.zeros(\n",
    "            shape=size, dtype=tf.int64),\n",
    "        trainable=False)\n",
    "\n",
    "    return (tp_thresh_var,\n",
    "            fn_thresh_var,\n",
    "            fp_thresh_var,\n",
    "            tn_thresh_var)\n",
    "\n",
    "\n",
    "def create_both_confusion_matrix_thresh_vars(\n",
    "    scope, time_thresh_size, feat_thresh_size):\n",
    "  \"\"\"Creates both time & feature major confusion matrix threshold variables.\n",
    "\n",
    "  Given variable scope and sizes, create and return confusion\n",
    "  matrix threshold variables for true positives, false negatives, false\n",
    "  positives, and true negatives for both time and feature major\n",
    "  representations.\n",
    "\n",
    "  Args:\n",
    "    scope: String of variable scope name.\n",
    "    time_thresh_size: Variable size of number of time major thresholds.\n",
    "    feat_thresh_size: Variable size of number of feature major thresholds.\n",
    "\n",
    "  Returns:\n",
    "    Confusion matrix threshold variables for true positives, false negatives,\n",
    "    false positives, true negatives for both time and feature major\n",
    "    representations.\n",
    "  \"\"\"\n",
    "  # Time based\n",
    "  (tp_thresh_time_var,\n",
    "   fn_thresh_time_var,\n",
    "   fp_thresh_time_var,\n",
    "   tn_thresh_time_var) = create_confusion_matrix_thresh_vars(\n",
    "       scope=scope, var_name=\"time\", size=time_thresh_size)\n",
    "\n",
    "  # Features based\n",
    "  (tp_thresh_feat_var,\n",
    "   fn_thresh_feat_var,\n",
    "   fp_thresh_feat_var,\n",
    "   tn_thresh_feat_var) = create_confusion_matrix_thresh_vars(\n",
    "       scope=scope, var_name=\"feat\", size=feat_thresh_size)\n",
    "\n",
    "  return (tp_thresh_time_var,\n",
    "          fn_thresh_time_var,\n",
    "          fp_thresh_time_var,\n",
    "          tn_thresh_time_var,\n",
    "          tp_thresh_feat_var,\n",
    "          fn_thresh_feat_var,\n",
    "          fp_thresh_feat_var,\n",
    "          tn_thresh_feat_var)\n",
    "\n",
    "def create_mahalanobis_unsupervised_thresh_vars(scope, var_name):\n",
    "  \"\"\"Creates mahalanobis unsupervised threshold variables.\n",
    "\n",
    "  Given variable scope and name, create and return mahalanobis unsupervised\n",
    "  threshold variables of mean and standard deviation.\n",
    "\n",
    "  Args:\n",
    "    scope: String of variable scope name.\n",
    "    var_name: String denoting which set of variables to create. Values are\n",
    "      \"time\" and \"feat\".\n",
    "\n",
    "  Returns:\n",
    "    Mahalanobis unsupervised threshold variables of count, mean, and standard\n",
    "    deviation.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=scope, reuse=tf.AUTO_REUSE):\n",
    "    count_thresh_var = tf.get_variable(\n",
    "        name=\"count_thresh_{0}_var\".format(var_name),\n",
    "        dtype=tf.int64,\n",
    "        initializer=tf.zeros(\n",
    "            shape=[], dtype=tf.int64),\n",
    "        trainable=False)\n",
    "\n",
    "    mean_thresh_var = tf.get_variable(\n",
    "        name=\"mean_thresh_{0}_var\".format(var_name),\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(\n",
    "            shape=[], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "    var_thresh_var = tf.get_variable(\n",
    "        name=\"var_thresh_{0}_var\".format(var_name),\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(\n",
    "            shape=[], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "    return (count_thresh_var,\n",
    "            mean_thresh_var,\n",
    "            var_thresh_var)\n",
    "\n",
    "\n",
    "def create_both_mahalanobis_unsupervised_thresh_vars(scope):\n",
    "  \"\"\"Creates time & feature mahalanobis unsupervised threshold variables.\n",
    "\n",
    "  Given variable scope, create and return mahalanobis unsupervised\n",
    "  threshold variables of mean and standard deviation for both time and\n",
    "  feature major representations.\n",
    "\n",
    "  Args:\n",
    "    scope: String of variable scope name.\n",
    "\n",
    "  Returns:\n",
    "    Mahalanobis unsupervised threshold variables of mean and standard\n",
    "    deviation for both time and feature major representations.\n",
    "  \"\"\"\n",
    "  # Time based\n",
    "  (count_thresh_time_var,\n",
    "   mean_thresh_time_var,\n",
    "   var_thresh_time_var) = create_mahalanobis_unsupervised_thresh_vars(\n",
    "       scope=scope, var_name=\"time\")\n",
    "\n",
    "  # Features based\n",
    "  (count_thresh_feat_var,\n",
    "   mean_thresh_feat_var,\n",
    "   var_thresh_feat_var) = create_mahalanobis_unsupervised_thresh_vars(\n",
    "       scope=scope, var_name=\"feat\")\n",
    "\n",
    "  return (count_thresh_time_var,\n",
    "          mean_thresh_time_var,\n",
    "          var_thresh_time_var,\n",
    "          count_thresh_feat_var,\n",
    "          mean_thresh_feat_var,\n",
    "          var_thresh_feat_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tune_anomaly_thresholds_supervised.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile anomaly_detection_module/trainer/tune_anomaly_thresholds_supervised.py\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def calculate_threshold_confusion_matrix(labels_mask, preds, num_thresh):\n",
    "  \"\"\"Calculates confusion matrix based on thresholds.\n",
    "\n",
    "  Given labels mask, predictions, and number of thresholds, returns count\n",
    "  for cell in confusion matrix.\n",
    "\n",
    "  Args:\n",
    "    labels_norm_mask: tf.bool vector tensor when label was normal or \n",
    "      anomalous.\n",
    "    num_thresh: Number of anomaly thresholds to try in parallel grid search.\n",
    "\n",
    "  Returns:\n",
    "    Count for cell in confusion matrix.\n",
    "  \"\"\"\n",
    "  count = tf.reduce_sum(\n",
    "      input_tensor=tf.cast(\n",
    "          x=tf.map_fn(\n",
    "              fn=lambda threshold: tf.logical_and(\n",
    "                  x=labels_mask,\n",
    "                  y=preds[threshold, :]),\n",
    "              elems=tf.range(start=0, limit=num_thresh, dtype=tf.int64),\n",
    "              dtype=tf.bool),\n",
    "          dtype=tf.int64),\n",
    "      axis=1)\n",
    "\n",
    "  return count\n",
    "\n",
    "\n",
    "def update_anom_thresh_vars(\n",
    "    labels_norm_mask,\n",
    "    labels_anom_mask,\n",
    "    num_thresh,\n",
    "    anom_thresh,\n",
    "    mahalanobis_dist,\n",
    "    tp_at_thresh_var,\n",
    "    fn_at_thresh_var,\n",
    "    fp_at_thresh_var,\n",
    "    tn_at_thresh_var,\n",
    "    mode):\n",
    "  \"\"\"Updates anomaly threshold variables.\n",
    "\n",
    "  Given masks for when labels are normal and anomalous, the number of anomaly\n",
    "  thresholds and the thresholds themselves, the mahalanobis distance, variables\n",
    "  for the confusion matrix, and the current Estimator mode, returns the updated\n",
    "  variables for the confusion matrix.\n",
    "\n",
    "  Args:\n",
    "    labels_norm_mask: tf.bool vector tensor that is true when label was normal.\n",
    "    labels_anom_mask: tf.bool vector tensor that is true when label was\n",
    "      anomalous.\n",
    "    num_thresh: Number of anomaly thresholds to try in parallel grid search.\n",
    "    anom_thresh: tf.float64 vector tensor of grid of anomaly thresholds to try.\n",
    "    mahalanobis_dist: tf.float64 matrix tensor of mahalanobis distances across\n",
    "      batch.\n",
    "    tp_at_thresh_var: tf.int64 variable tracking number of true positives at\n",
    "      each possible anomaly threshold.\n",
    "    fn_at_thresh_var: tf.int64 variable tracking number of false negatives at\n",
    "      each possible anomaly threshold.\n",
    "    fp_at_thresh_var: tf.int64 variable tracking number of false positives at\n",
    "      each possible anomaly threshold.\n",
    "    tn_at_thresh_var: tf.int64 variable tracking number of true negatives at\n",
    "      each possible anomaly threshold.\n",
    "    mode: Estimator ModeKeys, can take values of TRAIN and EVAL.\n",
    "\n",
    "  Returns:\n",
    "    Updated confusion matrix variables.\n",
    "  \"\"\"\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    # time_shape = (num_time_anom_thresh, cur_batch_size, seq_len)\n",
    "    # feat_shape = (num_feat_anom_thresh, cur_batch_size, num_feat)\n",
    "    mahalanobis_dist_over_thresh = tf.map_fn(\n",
    "        fn=lambda anom_threshold: mahalanobis_dist > anom_threshold,\n",
    "        elems=anom_thresh,\n",
    "        dtype=tf.bool)\n",
    "  else:\n",
    "    # time_shape = (cur_batch_size, seq_len)\n",
    "    # feat_shape = (cur_batch_size, num_feat)\n",
    "    mahalanobis_dist_over_thresh = mahalanobis_dist > anom_thresh\n",
    "\n",
    "  # time_shape = (num_time_anom_thresh, cur_batch_size)\n",
    "  # feat_shape = (num_feat_anom_thresh, cur_batch_size)\n",
    "  mahalanobis_dist_any_over_thresh = tf.reduce_any(\n",
    "      input_tensor=mahalanobis_dist_over_thresh, axis=-1)\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.EVAL:\n",
    "    # time_shape = (1, cur_batch_size)\n",
    "    # feat_shape = (1, cur_batch_size)\n",
    "    mahalanobis_dist_any_over_thresh = tf.expand_dims(\n",
    "        input=mahalanobis_dist_any_over_thresh, axis=0)\n",
    "\n",
    "  # time_shape = (num_time_anom_thresh, cur_batch_size)\n",
    "  # feat_shape = (num_feat_anom_thresh, cur_batch_size)\n",
    "  predicted_normals = tf.equal(\n",
    "      x=mahalanobis_dist_any_over_thresh, y=False)\n",
    "\n",
    "  # time_shape = (num_time_anom_thresh, cur_batch_size)\n",
    "  # feat_shape = (num_feat_anom_thresh, cur_batch_size)\n",
    "  predicted_anomalies = tf.equal(\n",
    "      x=mahalanobis_dist_any_over_thresh, y=True)\n",
    "\n",
    "  # Calculate confusion matrix of current batch\n",
    "  # time_shape = (num_time_anom_thresh,)\n",
    "  # feat_shape = (num_feat_anom_thresh,)\n",
    "  tp = calculate_threshold_confusion_matrix(\n",
    "      labels_anom_mask, predicted_anomalies, num_thresh)\n",
    "\n",
    "  fn = calculate_threshold_confusion_matrix(\n",
    "      labels_anom_mask, predicted_normals, num_thresh)\n",
    "\n",
    "  fp = calculate_threshold_confusion_matrix(\n",
    "      labels_norm_mask, predicted_anomalies, num_thresh)\n",
    "\n",
    "  tn = calculate_threshold_confusion_matrix(\n",
    "      labels_norm_mask, predicted_normals, num_thresh)\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.EVAL:\n",
    "    # shape = ()\n",
    "    tp = tf.squeeze(input=tp)\n",
    "    fn = tf.squeeze(input=fn)\n",
    "    fp = tf.squeeze(input=fp)\n",
    "    tn = tf.squeeze(input=tn)\n",
    "\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[tf.assign_add(ref=tp_at_thresh_var, value=tp),\n",
    "                      tf.assign_add(ref=fn_at_thresh_var, value=fn),\n",
    "                      tf.assign_add(ref=fp_at_thresh_var, value=fp),\n",
    "                      tf.assign_add(ref=tn_at_thresh_var, value=tn)]):\n",
    "\n",
    "    return (tf.identity(input=tp_at_thresh_var),\n",
    "            tf.identity(input=fn_at_thresh_var),\n",
    "            tf.identity(input=fp_at_thresh_var),\n",
    "            tf.identity(input=tn_at_thresh_var))\n",
    "\n",
    "\n",
    "def calculate_composite_classification_metrics(tp, fn, fp, tn, f_score_beta):\n",
    "  \"\"\"Calculates compositive classification metrics from the confusion matrix.\n",
    "\n",
    "  Given variables for the confusion matrix and the value of beta for f-beta\n",
    "  score, returns accuracy, precision, recall, and f-beta score composite\n",
    "  metrics.\n",
    "\n",
    "  Args:\n",
    "    tp: tf.int64 variable tracking number of true positives at\n",
    "      each possible anomaly threshold.\n",
    "    fn: tf.int64 variable tracking number of false negatives at\n",
    "      each possible anomaly threshold.\n",
    "    fp: tf.int64 variable tracking number of false positives at\n",
    "      each possible anomaly threshold.\n",
    "    tn: tf.int64 variable tracking number of true negatives at\n",
    "      each possible anomaly threshold.\n",
    "    f_score_beta: Value of beta for f-beta score.\n",
    "\n",
    "  Returns:\n",
    "    Accuracy, precision, recall, and f-beta score composite metric tensors.\n",
    "  \"\"\"\n",
    "  # time_shape = (num_time_anom_thresh,)\n",
    "  # feat_shape = (num_feat_anom_thresh,)\n",
    "  acc = tf.cast(x=tp + tn, dtype=tf.float64) \\\n",
    "    / tf.cast(x=tp + fn + fp + tn, dtype=tf.float64)\n",
    "  tp_float64 = tf.cast(x=tp, dtype=tf.float64)\n",
    "  pre = tp_float64 / tf.cast(x=tp + fp, dtype=tf.float64)\n",
    "  rec = tp_float64 / tf.cast(x=tp + fn, dtype=tf.float64)\n",
    "  f_beta_numerator = (1.0 + f_score_beta ** 2) * (pre * rec)\n",
    "  f_beta_score = f_beta_numerator / (f_score_beta ** 2 * pre + rec)\n",
    "\n",
    "  return acc, pre, rec, f_beta_score\n",
    "\n",
    "\n",
    "def find_best_anom_thresh(\n",
    "    anom_threshs, f_beta_score, user_passed_anom_thresh, anom_thresh_var):\n",
    "  \"\"\"Find best anomaly threshold to use for anomaly classification.\n",
    "\n",
    "  Given grid of anomaly thresholds, variables for the confusion matrix, and the\n",
    "  value of beta for f-beta score, returns accuracy, precision, recall, and\n",
    "  f-beta score composite metrics.\n",
    "\n",
    "  Args:\n",
    "    anom_threshs: tf.float64 vector tensor of grid of anomaly thresholds to try.\n",
    "    f_beta_score: tf.float64 vector tensor of f-beta scores for each anomaly\n",
    "      threshold.\n",
    "    user_passed_anom_thresh: User passed anomaly threshold that overrides\n",
    "      the threshold optimization.\n",
    "    anom_thresh_var: tf.float64 variable that stores anomaly threshold value.\n",
    "\n",
    "  Returns:\n",
    "    Updated variable that stores the anomaly threshold value\n",
    "  \"\"\"\n",
    "  if user_passed_anom_thresh is None:\n",
    "    # shape = ()\n",
    "    best_anom_thresh = tf.gather(\n",
    "        params=anom_threshs, indices=tf.argmax(input=f_beta_score, axis=0))\n",
    "  else:\n",
    "    # shape = ()\n",
    "    best_anom_thresh = user_passed_anom_thresh\n",
    "\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[tf.assign(\n",
    "          ref=anom_thresh_var, value=best_anom_thresh)]):\n",
    "\n",
    "    return tf.identity(input=anom_thresh_var)\n",
    "\n",
    "\n",
    "def tune_anomaly_thresholds_supervised_training(\n",
    "    labels_norm_mask,\n",
    "    labels_anom_mask,\n",
    "    mahalanobis_dist_time,\n",
    "    tp_thresh_time_var,\n",
    "    fn_thresh_time_var,\n",
    "    fp_thresh_time_var,\n",
    "    tn_thresh_time_var,\n",
    "    time_anom_thresh_var,\n",
    "    mahalanobis_dist_feat,\n",
    "    tp_thresh_feat_var,\n",
    "    fn_thresh_feat_var,\n",
    "    fp_thresh_feat_var,\n",
    "    tn_thresh_feat_var,\n",
    "    feat_anom_thresh_var,\n",
    "    params,\n",
    "    mode,\n",
    "    dummy_var):\n",
    "  \"\"\"Tunes anomaly thresholds during supervised training mode.\n",
    "\n",
    "  Given label masks, mahalanobis distances, confusion matrices, and anomaly\n",
    "  thresholds, returns loss and train_op.\n",
    "\n",
    "  Args:\n",
    "    labels_norm_mask: tf.bool vector mask of labels for normals.\n",
    "    labels_anom_mask: tf.bool vector mask of labels for anomalies.\n",
    "    mahalanobis_dist_time: Mahalanobis distance, time major.\n",
    "    tp_thresh_time_var: tf.int64 variable to track number of true positives wrt\n",
    "      thresholds for time major case.\n",
    "    fn_thresh_time_var: tf.int64 variable to track number of false negatives wrt\n",
    "      thresholds for time major case.\n",
    "    fp_thresh_time_var: tf.int64 variable to track number of false positives wrt\n",
    "      thresholds for time major case.\n",
    "    tn_thresh_time_var: tf.int64 variable to track number of true negatives wrt\n",
    "      thresholds for time major case.\n",
    "    time_anom_thresh_var: tf.float64 variable to hold the set time anomaly\n",
    "      threshold.\n",
    "    mahalanobis_dist_feat: Mahalanobis distance, features major.\n",
    "    tp_thresh_feat_var: tf.int64 variable to track number of true positives wrt\n",
    "      thresholds for feat major case.\n",
    "    fn_thresh_feat_var: tf.int64 variable to track number of false negatives wrt\n",
    "      thresholds for feat major case.\n",
    "    fp_thresh_feat_var: tf.int64 variable to track number of false positives wrt\n",
    "      thresholds for feat major case.\n",
    "    tn_thresh_feat_var: tf.int64 variable to track number of true negatives wrt\n",
    "      thresholds for feat major case.\n",
    "    feat_anom_thresh_var: tf.float64 variable to hold the set feat anomaly\n",
    "      threshold.\n",
    "    params: Dictionary of parameters.\n",
    "    mode: Estimator ModeKeys. Can take value of only TRAIN.\n",
    "    dummy_var: Dummy variable used to allow training mode to happen since it\n",
    "      requires a gradient to tie back to the graph dependency.\n",
    "\n",
    "  Returns:\n",
    "    loss: The scalar loss to tie our updates back to Estimator graph.\n",
    "    train_op: The train operation to tie our updates back to Estimator graph.\n",
    "  \"\"\"\n",
    "  # Time based\n",
    "  # shape = (num_time_anom_thresh,)\n",
    "  time_anom_threshs = tf.linspace(\n",
    "      start=tf.constant(\n",
    "          value=params[\"min_time_anom_thresh\"], dtype=tf.float64),\n",
    "      stop=tf.constant(\n",
    "          value=params[\"max_time_anom_thresh\"], dtype=tf.float64),\n",
    "      num=params[\"num_time_anom_thresh\"])\n",
    "\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=\"mahalanobis_dist_thresh_vars\",\n",
    "      reuse=tf.AUTO_REUSE):\n",
    "    (tp_time_update_op,\n",
    "     fn_time_update_op,\n",
    "     fp_time_update_op,\n",
    "     tn_time_update_op) = \\\n",
    "      update_anom_thresh_vars(\n",
    "          labels_norm_mask,\n",
    "          labels_anom_mask,\n",
    "          params[\"num_time_anom_thresh\"],\n",
    "          time_anom_threshs,\n",
    "          mahalanobis_dist_time,\n",
    "          tp_thresh_time_var,\n",
    "          fn_thresh_time_var,\n",
    "          fp_thresh_time_var,\n",
    "          tn_thresh_time_var,\n",
    "          mode)\n",
    "\n",
    "  # Features based\n",
    "  # shape = (num_feat_anom_thresh,)\n",
    "  feat_anom_threshs = tf.linspace(\n",
    "      start=tf.constant(value=params[\"min_feat_anom_thresh\"],\n",
    "                        dtype=tf.float64),\n",
    "      stop=tf.constant(value=params[\"max_feat_anom_thresh\"],\n",
    "                       dtype=tf.float64),\n",
    "      num=params[\"num_feat_anom_thresh\"])\n",
    "\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=\"mahalanobis_dist_thresh_vars\",\n",
    "      reuse=tf.AUTO_REUSE):\n",
    "    (tp_feat_update_op,\n",
    "     fn_feat_update_op,\n",
    "     fp_feat_update_op,\n",
    "     tn_feat_update_op) = \\\n",
    "      update_anom_thresh_vars(\n",
    "          labels_norm_mask,\n",
    "          labels_anom_mask,\n",
    "          params[\"num_feat_anom_thresh\"],\n",
    "          feat_anom_threshs,\n",
    "          mahalanobis_dist_feat,\n",
    "          tp_thresh_feat_var,\n",
    "          fn_thresh_feat_var,\n",
    "          fp_thresh_feat_var,\n",
    "          tn_thresh_feat_var,\n",
    "          mode)\n",
    "\n",
    "  # Reconstruction loss on evaluation set\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[\n",
    "          tp_time_update_op,\n",
    "          fn_time_update_op,\n",
    "          fp_time_update_op,\n",
    "          tn_time_update_op,\n",
    "          tp_feat_update_op,\n",
    "          fn_feat_update_op,\n",
    "          fp_feat_update_op,\n",
    "          tn_feat_update_op]):\n",
    "    # Time based\n",
    "    _, pre_time, rec_time, f_beta_time = \\\n",
    "      calculate_composite_classification_metrics(\n",
    "          tp_thresh_time_var,\n",
    "          fn_thresh_time_var,\n",
    "          fp_thresh_time_var,\n",
    "          tn_thresh_time_var,\n",
    "          params[\"f_score_beta\"])\n",
    "\n",
    "    # Features based\n",
    "    _, pre_feat, rec_feat, f_beta_feat = \\\n",
    "      calculate_composite_classification_metrics(\n",
    "          tp_thresh_feat_var,\n",
    "          fn_thresh_feat_var,\n",
    "          fp_thresh_feat_var,\n",
    "          tn_thresh_feat_var,\n",
    "          params[\"f_score_beta\"])\n",
    "\n",
    "    with tf.control_dependencies(\n",
    "        control_inputs=[pre_time, pre_feat, rec_time, rec_feat]):\n",
    "      with tf.control_dependencies(\n",
    "          control_inputs=[f_beta_time, f_beta_feat]):\n",
    "        # Time based\n",
    "        best_anom_thresh_time = find_best_anom_thresh(\n",
    "            time_anom_threshs,\n",
    "            f_beta_time,\n",
    "            params[\"time_anom_thresh\"],\n",
    "            time_anom_thresh_var)\n",
    "\n",
    "        # Features based\n",
    "        best_anom_thresh_feat = find_best_anom_thresh(\n",
    "            feat_anom_threshs,\n",
    "            f_beta_feat,\n",
    "            params[\"feat_anom_thresh\"],\n",
    "            feat_anom_thresh_var)\n",
    "\n",
    "        with tf.control_dependencies(\n",
    "            control_inputs=[best_anom_thresh_time,\n",
    "                            best_anom_thresh_feat]):\n",
    "          loss = tf.reduce_sum(\n",
    "              input_tensor=tf.zeros(\n",
    "                  shape=(), dtype=tf.float64) * dummy_var)\n",
    "\n",
    "          train_op = tf.contrib.layers.optimize_loss(\n",
    "              loss=loss,\n",
    "              global_step=tf.train.get_global_step(),\n",
    "              learning_rate=params[\"learning_rate\"],\n",
    "              optimizer=\"SGD\")\n",
    "\n",
    "  return loss, train_op\n",
    "\n",
    "\n",
    "def tune_anomaly_thresholds_evaluation(\n",
    "    labels_norm_mask,\n",
    "    labels_anom_mask,\n",
    "    time_anom_thresh_var,\n",
    "    mahalanobis_dist_time,\n",
    "    tp_thresh_eval_time_var,\n",
    "    fn_thresh_eval_time_var,\n",
    "    fp_thresh_eval_time_var,\n",
    "    tn_thresh_eval_time_var,\n",
    "    feat_anom_thresh_var,\n",
    "    mahalanobis_dist_feat,\n",
    "    tp_thresh_eval_feat_var,\n",
    "    fn_thresh_eval_feat_var,\n",
    "    fp_thresh_eval_feat_var,\n",
    "    tn_thresh_eval_feat_var,\n",
    "    params,\n",
    "    mode):\n",
    "  \"\"\"Checks tuned anomaly thresholds during evaluation mode.\n",
    "\n",
    "  Given label masks, mahalanobis distances, confusion matrices, and anomaly\n",
    "  thresholds, returns loss and eval_metric_ops.\n",
    "\n",
    "  Args:\n",
    "    labels_norm_mask: tf.bool vector mask of labels for normals.\n",
    "    labels_anom_mask: tf.bool vector mask of labels for anomalies.\n",
    "    time_anom_thresh_var: tf.float64 scalar time anomaly threshold value.\n",
    "    mahalanobis_dist_time: Mahalanobis distance, time major.\n",
    "    tp_thresh_eval_time_var: tf.int64 variable to track number of true\n",
    "      positives wrt thresholds for time major case for evaluation.\n",
    "    fn_thresh_eval_time_var: tf.int64 variable to track number of false\n",
    "      negatives wrt thresholds for time major case for evaluation.\n",
    "    fp_thresh_eval_time_var: tf.int64 variable to track number of false\n",
    "      positives wrt thresholds for time major case for evaluation.\n",
    "    tn_thresh_eval_time_var: tf.int64 variable to track number of true\n",
    "      negatives wrt thresholds for time major case for evaluation.\n",
    "    feat_anom_thresh_var: tf.float64 scalar feature anomaly threshold value.\n",
    "    mahalanobis_dist_feat: Mahalanobis distance, features major.\n",
    "    tp_thresh_eval_feat_var: tf.int64 variable to track number of true\n",
    "      positives wrt thresholds for feat major case for evaluation.\n",
    "    fn_thresh_eval_feat_var: tf.int64 variable to track number of false\n",
    "      negatives wrt thresholds for feat major case for evaluation.\n",
    "    fp_thresh_eval_feat_var: tf.int64 variable to track number of false\n",
    "      positives wrt thresholds for feat major case for evaluation.\n",
    "    tn_thresh_eval_feat_var: tf.int64 variable to track number of true\n",
    "      negatives wrt thresholds for feat major case for evaluation.\n",
    "    params: Dictionary of parameters.\n",
    "    mode: Estimator ModeKeys. Can take value of only EVAL.\n",
    "\n",
    "  Returns:\n",
    "    loss: Scalar reconstruction loss.\n",
    "    eval_metric_ops: Evaluation metrics of reconstruction.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=\"anom_thresh_eval_vars\", reuse=tf.AUTO_REUSE):\n",
    "    # Time based\n",
    "    (tp_time_update_op,\n",
    "     fn_time_update_op,\n",
    "     fp_time_update_op,\n",
    "     tn_time_update_op) = \\\n",
    "      update_anom_thresh_vars(\n",
    "          labels_norm_mask,\n",
    "          labels_anom_mask,\n",
    "          1,\n",
    "          time_anom_thresh_var,\n",
    "          mahalanobis_dist_time,\n",
    "          tp_thresh_eval_time_var,\n",
    "          fn_thresh_eval_time_var,\n",
    "          fp_thresh_eval_time_var,\n",
    "          tn_thresh_eval_time_var,\n",
    "          mode)\n",
    "\n",
    "    # Features based\n",
    "    (tp_feat_update_op,\n",
    "     fn_feat_update_op,\n",
    "     fp_feat_update_op,\n",
    "     tn_feat_update_op) = \\\n",
    "      update_anom_thresh_vars(\n",
    "          labels_norm_mask,\n",
    "          labels_anom_mask,\n",
    "          1,\n",
    "          feat_anom_thresh_var,\n",
    "          mahalanobis_dist_feat,\n",
    "          tp_thresh_eval_feat_var,\n",
    "          fn_thresh_eval_feat_var,\n",
    "          fp_thresh_eval_feat_var,\n",
    "          tn_thresh_eval_feat_var,\n",
    "          mode)\n",
    "\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=\"anom_thresh_eval_vars\", reuse=tf.AUTO_REUSE):\n",
    "    # Time based\n",
    "    (acc_time_update_op,\n",
    "     pre_time_update_op,\n",
    "     rec_time_update_op,\n",
    "     f_beta_time_update_op) = \\\n",
    "      calculate_composite_classification_metrics(\n",
    "          tp_thresh_eval_time_var,\n",
    "          fn_thresh_eval_time_var,\n",
    "          fp_thresh_eval_time_var,\n",
    "          tn_thresh_eval_time_var,\n",
    "          params[\"f_score_beta\"])\n",
    "\n",
    "    # Features based\n",
    "    (acc_feat_update_op,\n",
    "     pre_feat_update_op,\n",
    "     rec_feat_update_op,\n",
    "     f_beta_feat_update_op) = \\\n",
    "      calculate_composite_classification_metrics(\n",
    "          tp_thresh_eval_feat_var,\n",
    "          fn_thresh_eval_feat_var,\n",
    "          fp_thresh_eval_feat_var,\n",
    "          tn_thresh_eval_feat_var,\n",
    "          params[\"f_score_beta\"])\n",
    "\n",
    "  loss = tf.zeros(shape=[], dtype=tf.float64)\n",
    "\n",
    "  # Time based\n",
    "  acc_trues = tf.cast(\n",
    "      x=tp_thresh_eval_time_var + tn_thresh_eval_time_var,\n",
    "      dtype=tf.float64)\n",
    "  acc_falses = tf.cast(\n",
    "      x=fp_thresh_eval_time_var + fn_thresh_eval_time_var,\n",
    "      dtype=tf.float64)\n",
    "  acc_thresh_eval_time_var = acc_trues / (acc_trues + acc_falses)\n",
    "\n",
    "  tp_float = tf.cast(x=tp_thresh_eval_time_var, dtype=tf.float64)\n",
    "\n",
    "  pre_denominator = tf.cast(\n",
    "      x=tp_thresh_eval_time_var + fp_thresh_eval_time_var,\n",
    "      dtype=tf.float64)\n",
    "  pre_thresh_eval_time_var = tp_float / pre_denominator\n",
    "\n",
    "  rec_denominator = tf.cast(\n",
    "      x=tp_thresh_eval_time_var + fn_thresh_eval_time_var,\n",
    "      dtype=tf.float64)\n",
    "  rec_thresh_eval_time_var = tp_float / rec_denominator\n",
    "\n",
    "  f_beta_numerator = (1.0 + params[\"f_score_beta\"] ** 2)\n",
    "  f_beta_numerator *= pre_thresh_eval_time_var\n",
    "  f_beta_numerator *= rec_thresh_eval_time_var\n",
    "  f_beta_denominator = params[\"f_score_beta\"] ** 2\n",
    "  f_beta_denominator *= pre_thresh_eval_time_var\n",
    "  f_beta_denominator += rec_thresh_eval_time_var\n",
    "  f_beta_thresh_eval_time_var = f_beta_numerator / f_beta_denominator\n",
    "\n",
    "  # Features based\n",
    "  acc_trues = tf.cast(\n",
    "      x=tp_thresh_eval_feat_var + tn_thresh_eval_feat_var,\n",
    "      dtype=tf.float64)\n",
    "  acc_falses = tf.cast(\n",
    "      x=fp_thresh_eval_feat_var + fn_thresh_eval_feat_var,\n",
    "      dtype=tf.float64)\n",
    "  acc_thresh_eval_feat_var = acc_trues / (acc_trues + acc_falses)\n",
    "\n",
    "  tp_float = tf.cast(x=tp_thresh_eval_feat_var, dtype=tf.float64)\n",
    "\n",
    "  pre_denominator = tf.cast(\n",
    "      x=tp_thresh_eval_feat_var + fp_thresh_eval_feat_var,\n",
    "      dtype=tf.float64)\n",
    "  pre_thresh_eval_feat_var = tp_float / pre_denominator\n",
    "\n",
    "  rec_denominator = tf.cast(\n",
    "      x=tp_thresh_eval_feat_var + fn_thresh_eval_feat_var,\n",
    "      dtype=tf.float64)\n",
    "  rec_thresh_eval_feat_var = tp_float / rec_denominator\n",
    "\n",
    "  f_beta_numerator = (1.0 + params[\"f_score_beta\"] ** 2)\n",
    "  f_beta_numerator *= pre_thresh_eval_feat_var\n",
    "  f_beta_numerator *= rec_thresh_eval_feat_var\n",
    "  f_beta_denominator = params[\"f_score_beta\"] ** 2\n",
    "  f_beta_denominator *= pre_thresh_eval_feat_var\n",
    "  f_beta_denominator += rec_thresh_eval_feat_var\n",
    "  f_beta_thresh_eval_feat_var = f_beta_numerator / f_beta_denominator\n",
    "\n",
    "  # Anomaly detection eval metrics\n",
    "  eval_metric_ops = {\n",
    "      # Time based\n",
    "      \"time_anom_tp\": (tp_thresh_eval_time_var, tp_time_update_op),\n",
    "      \"time_anom_fn\": (fn_thresh_eval_time_var, fn_time_update_op),\n",
    "      \"time_anom_fp\": (fp_thresh_eval_time_var, fp_time_update_op),\n",
    "      \"time_anom_tn\": (tn_thresh_eval_time_var, tn_time_update_op),\n",
    "\n",
    "      \"time_anom_acc\": (acc_thresh_eval_time_var, acc_time_update_op),\n",
    "      \"time_anom_pre\": (pre_thresh_eval_time_var, pre_time_update_op),\n",
    "      \"time_anom_rec\": (rec_thresh_eval_time_var, rec_time_update_op),\n",
    "      \"time_anom_f_beta\": (f_beta_thresh_eval_time_var,\n",
    "                           f_beta_time_update_op),\n",
    "\n",
    "      # Features based\n",
    "      \"feat_anom_tp\": (tp_thresh_eval_feat_var, tp_feat_update_op),\n",
    "      \"feat_anom_fn\": (fn_thresh_eval_feat_var, fn_feat_update_op),\n",
    "      \"feat_anom_fp\": (fp_thresh_eval_feat_var, fp_feat_update_op),\n",
    "      \"feat_anom_tn\": (tn_thresh_eval_feat_var, tn_feat_update_op),\n",
    "\n",
    "      \"feat_anom_acc\": (acc_thresh_eval_feat_var, acc_feat_update_op),\n",
    "      \"feat_anom_pre\": (pre_thresh_eval_feat_var, pre_feat_update_op),\n",
    "      \"feat_anom_rec\": (rec_thresh_eval_feat_var, rec_feat_update_op),\n",
    "      \"feat_anom_f_beta\": (f_beta_thresh_eval_feat_var,\n",
    "                           f_beta_feat_update_op)\n",
    "  }\n",
    "\n",
    "  return loss, eval_metric_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tune_anomaly_thresholds_unsupervised.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile anomaly_detection_module/trainer/tune_anomaly_thresholds_unsupervised.py\n",
    "import tensorflow as tf\n",
    "\n",
    "from .calculate_error_distribution_statistics import non_singleton_batch_var_variable_updating\n",
    "from .calculate_error_distribution_statistics import singleton_batch_var_variable_updating\n",
    "\n",
    "\n",
    "def tune_anomaly_thresholds_unsupervised_training(\n",
    "    cur_batch_size,\n",
    "    num_feat,\n",
    "    time_anom_thresh_var,\n",
    "    mahalanobis_dist_time,\n",
    "    count_thresh_time_var,\n",
    "    mean_thresh_time_var,\n",
    "    var_thresh_time_var,\n",
    "    feat_anom_thresh_var,\n",
    "    mahalanobis_dist_feat,\n",
    "    count_thresh_feat_var,\n",
    "    mean_thresh_feat_var,\n",
    "    var_thresh_feat_var,\n",
    "    params,\n",
    "    dummy_var):\n",
    "  \"\"\"Calculates error distribution statistics during training mode.\n",
    "\n",
    "  Given dimensions of inputs, mahalanobis distances, and variables tracking\n",
    "  counts, means, and variances of mahalanobis distance, returns loss and\n",
    "  train_op.\n",
    "\n",
    "  Args:\n",
    "    cur_batch_size: Current batch size, could be partially filled.\n",
    "    num_feat: Number of features.\n",
    "    time_anom_thresh_var: Time anomaly threshold variable.\n",
    "    mahalanobis_dist_time: Time major mahalanobis distance.\n",
    "    count_thresh_time_var: Time major running count of number of records.\n",
    "    mean_thresh_time_var: Time major running mean of mahalanobis distance.\n",
    "    var_thresh_time_var: Time major running variance of mahalanobis distance.\n",
    "    feat_anom_thresh_var: Feature anomaly threshold variable.\n",
    "    mahalanobis_dist_feat: Feature major mahalanobis distance.\n",
    "    count_thresh_feat_var: Feature major running count of number of records.\n",
    "    mean_thresh_feat_var: Feature major running mean of mahalanobis distance.\n",
    "    var_thresh_feat_var: Feature major running variance of mahalanobis distance.\n",
    "    params: Dictionary of parameters.\n",
    "    dummy_var: Dummy variable used to allow training mode to happen since it\n",
    "      requires a gradient to tie back to the graph dependency.\n",
    "\n",
    "  Returns:\n",
    "    loss: The scalar loss to tie our updates back to Estimator graph.\n",
    "    train_op: The train operation to tie our updates back to Estimator graph.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=\"mahalanobis_dist_thresh_vars\", reuse=tf.AUTO_REUSE):\n",
    "    # Time based\n",
    "    mahalanobis_dist_time_flat = tf.reshape(\n",
    "        tensor=mahalanobis_dist_time,\n",
    "        shape=[cur_batch_size * params[\"seq_len\"]])\n",
    "\n",
    "    singleton_time_condition = tf.equal(\n",
    "        x=cur_batch_size * params[\"seq_len\"], y=1)\n",
    "\n",
    "    var_time_var, mean_time_var, count_time_var = tf.cond(\n",
    "        pred=singleton_time_condition,\n",
    "        true_fn=lambda: singleton_batch_var_variable_updating(\n",
    "            params[\"seq_len\"],\n",
    "            mahalanobis_dist_time_flat,\n",
    "            count_thresh_time_var,\n",
    "            mean_thresh_time_var,\n",
    "            var_thresh_time_var),\n",
    "        false_fn=lambda: non_singleton_batch_var_variable_updating(\n",
    "            cur_batch_size,\n",
    "            params[\"seq_len\"],\n",
    "            mahalanobis_dist_time_flat,\n",
    "            count_thresh_time_var,\n",
    "            mean_thresh_time_var,\n",
    "            var_thresh_time_var))\n",
    "\n",
    "    # Features based\n",
    "    mahalanobis_dist_feat_flat = tf.reshape(\n",
    "        tensor=mahalanobis_dist_feat,\n",
    "        shape=[cur_batch_size * num_feat])\n",
    "\n",
    "    singleton_feat_condition = tf.equal(\n",
    "        x=cur_batch_size * num_feat, y=1)\n",
    "\n",
    "    var_feat_var, mean_feat_var, count_feat_var = tf.cond(\n",
    "        pred=singleton_feat_condition,\n",
    "        true_fn=lambda: singleton_batch_var_variable_updating(\n",
    "            num_feat,\n",
    "            mahalanobis_dist_feat_flat,\n",
    "            count_thresh_feat_var,\n",
    "            mean_thresh_feat_var,\n",
    "            var_thresh_feat_var),\n",
    "        false_fn=lambda: non_singleton_batch_var_variable_updating(\n",
    "            cur_batch_size,\n",
    "            num_feat,\n",
    "            mahalanobis_dist_feat_flat,\n",
    "            count_thresh_feat_var,\n",
    "            mean_thresh_feat_var,\n",
    "            var_thresh_feat_var))\n",
    "\n",
    "  # Lastly use control dependencies around loss to enforce the mahalanobis\n",
    "  # variables to be assigned, the control order matters, hence the separate\n",
    "  # contexts.\n",
    "  with tf.control_dependencies(\n",
    "      control_inputs=[var_time_var, var_feat_var]):\n",
    "    with tf.control_dependencies(\n",
    "        control_inputs=[mean_time_var, mean_feat_var]):\n",
    "      with tf.control_dependencies(\n",
    "          control_inputs=[count_time_var, count_feat_var]):\n",
    "        time_out = mean_time_var\n",
    "        time_out += params[\"time_thresh_scl\"] * tf.sqrt(x=var_time_var)\n",
    "        feat_out = mean_feat_var\n",
    "        feat_out += params[\"feat_thresh_scl\"] * tf.sqrt(x=var_feat_var)\n",
    "        with tf.control_dependencies(\n",
    "            control_inputs=[tf.assign(ref=time_anom_thresh_var,\n",
    "                                      value=time_out),\n",
    "                            tf.assign(ref=feat_anom_thresh_var,\n",
    "                                      value=feat_out)]):\n",
    "\n",
    "          loss = tf.reduce_sum(\n",
    "              input_tensor=tf.zeros(shape=(), dtype=tf.float64) * dummy_var)\n",
    "\n",
    "          train_op = tf.contrib.layers.optimize_loss(\n",
    "              loss=loss,\n",
    "              global_step=tf.train.get_global_step(),\n",
    "              learning_rate=params[\"learning_rate\"],\n",
    "              optimizer=\"SGD\")\n",
    "\n",
    "  return loss, train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile anomaly_detection_module/trainer/predict.py\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def anomaly_detection_predictions(\n",
    "    cur_batch_size,\n",
    "    seq_len,\n",
    "    num_feat,\n",
    "    mahalanobis_dist_time,\n",
    "    mahalanobis_dist_feat,\n",
    "    time_anom_thresh_var,\n",
    "    feat_anom_thresh_var,\n",
    "    X_time_abs_recon_err,\n",
    "    X_feat_abs_recon_err):\n",
    "  \"\"\"Creates Estimator predictions and export outputs.\n",
    "\n",
    "  Given dimensions of inputs, mahalanobis distances and their respective\n",
    "  thresholds, and reconstructed inputs' absolute errors, returns Estimator's\n",
    "  predictions and export outputs.\n",
    "\n",
    "  Args:\n",
    "    cur_batch_size: Current batch size, could be partially filled.\n",
    "    seq_len: Number of timesteps in sequence.\n",
    "    num_feat: Number of features.\n",
    "    mahalanobis_dist_time: Mahalanobis distance, time major.\n",
    "    mahalanobis_dist_feat: Mahalanobis distance, features major.\n",
    "    time_anom_thresh_var: Time anomaly threshold variable.\n",
    "    feat_anom_thresh_var: Features anomaly threshold variable.\n",
    "    X_time_abs_recon_err: Time major reconstructed input data's absolute\n",
    "      reconstruction error.\n",
    "    X_feat_abs_recon_err: Features major reconstructed input data's absolute\n",
    "      reconstruction error.\n",
    "\n",
    "  Returns:\n",
    "    predictions_dict: Dictionary of predictions to output for local prediction.\n",
    "    export_outputs: Dictionary to output from exported model for serving.\n",
    "  \"\"\"\n",
    "  # Flag predictions as either normal or anomalous\n",
    "  # shape = (cur_batch_size,)\n",
    "  time_anom_flags = tf.where(\n",
    "      condition=tf.reduce_any(\n",
    "          input_tensor=tf.greater(\n",
    "              x=tf.abs(x=mahalanobis_dist_time),\n",
    "              y=time_anom_thresh_var),\n",
    "          axis=1),\n",
    "      x=tf.ones(shape=[cur_batch_size], dtype=tf.int64),\n",
    "      y=tf.zeros(shape=[cur_batch_size], dtype=tf.int64))\n",
    "\n",
    "  # shape = (cur_batch_size,)\n",
    "  feat_anom_flags = tf.where(\n",
    "      condition=tf.reduce_any(\n",
    "          input_tensor=tf.greater(\n",
    "              x=tf.abs(x=mahalanobis_dist_feat),\n",
    "              y=feat_anom_thresh_var),\n",
    "          axis=1),\n",
    "      x=tf.ones(shape=[cur_batch_size], dtype=tf.int64),\n",
    "      y=tf.zeros(shape=[cur_batch_size], dtype=tf.int64))\n",
    "\n",
    "  # Create predictions dictionary\n",
    "  predictions_dict = {\n",
    "      \"X_time_abs_recon_err\": tf.reshape(\n",
    "          tensor=X_time_abs_recon_err,\n",
    "          shape=[cur_batch_size, seq_len, num_feat]),\n",
    "      \"X_feat_abs_recon_err\": tf.transpose(\n",
    "          a=tf.reshape(\n",
    "              tensor=X_feat_abs_recon_err,\n",
    "              shape=[cur_batch_size, num_feat, seq_len]),\n",
    "          perm=[0, 2, 1]),\n",
    "      \"mahalanobis_dist_time\": mahalanobis_dist_time,\n",
    "      \"mahalanobis_dist_feat\": mahalanobis_dist_feat,\n",
    "      \"time_anom_flags\": time_anom_flags,\n",
    "      \"feat_anom_flags\": feat_anom_flags}\n",
    "\n",
    "  # Create export outputs\n",
    "  export_outputs = {\n",
    "      \"predict_export_outputs\": tf.estimator.export.PredictOutput(\n",
    "          outputs=predictions_dict)\n",
    "  }\n",
    "\n",
    "  return predictions_dict, export_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## anomaly_detection.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile anomaly_detection_module/trainer/anomaly_detection.py\n",
    "import tensorflow as tf\n",
    "\n",
    "from .globals import *\n",
    "\n",
    "from .autoencoder_dense import dense_autoencoder_model\n",
    "from .autoencoder_lstm import lstm_enc_dec_autoencoder_model\n",
    "from .autoencoder_pca import pca_model\n",
    "from .calculate_error_distribution_statistics import calculate_error_distribution_statistics_training\n",
    "from .calculate_error_distribution_statistics import mahalanobis_dist\n",
    "from .error_distribution_vars import create_both_mahalanobis_dist_vars\n",
    "from .predict import anomaly_detection_predictions\n",
    "from .reconstruction import reconstruction_evaluation\n",
    "from .tune_anomaly_threshold_vars import create_both_confusion_matrix_thresh_vars\n",
    "from .tune_anomaly_threshold_vars import create_both_mahalanobis_unsupervised_thresh_vars\n",
    "from .tune_anomaly_thresholds_supervised import tune_anomaly_thresholds_supervised_training\n",
    "from .tune_anomaly_thresholds_supervised import tune_anomaly_thresholds_evaluation\n",
    "from .tune_anomaly_thresholds_unsupervised import tune_anomaly_thresholds_unsupervised_training\n",
    "\n",
    "\n",
    "# Create our model function to be used in our custom estimator\n",
    "def anomaly_detection(features, labels, mode, params):\n",
    "  \"\"\"Custom Estimator model function for anomaly detection.\n",
    "\n",
    "  Given dictionary of feature tensors, labels tensor, Estimator mode, and\n",
    "  dictionary for parameters, return EstimatorSpec object for custom Estimator.\n",
    "\n",
    "  Args:\n",
    "    features: Dictionary of feature tensors.\n",
    "    labels: Labels tensor or None.\n",
    "    mode: Estimator ModeKeys. Can take values of TRAIN, EVAL, and PREDICT.\n",
    "    params: Dictionary of parameters.\n",
    "\n",
    "  Returns:\n",
    "    EstimatorSpec object.\n",
    "  \"\"\"\n",
    "  print(\"\\nanomaly_detection: features = \\n{}\".format(features))\n",
    "  print(\"anomaly_detection: labels = \\n{}\".format(labels))\n",
    "  print(\"anomaly_detection: mode = \\n{}\".format(mode))\n",
    "  print(\"anomaly_detection: params = \\n{}\".format(params))\n",
    "\n",
    "  # Get input sequence tensor into correct shape\n",
    "  # Get dynamic batch size in case there was a partially filled batch\n",
    "  cur_batch_size = tf.shape(\n",
    "      input=features[UNLABELED_CSV_COLUMNS[0]], out_type=tf.int64)[0]\n",
    "\n",
    "  # Get the number of features\n",
    "  num_feat = len(UNLABELED_CSV_COLUMNS)\n",
    "\n",
    "  # Stack all of the features into a 3-D tensor\n",
    "  # shape = (cur_batch_size, seq_len, num_feat)\n",
    "  X = tf.stack(\n",
    "      values=[features[key] for key in UNLABELED_CSV_COLUMNS], axis=2)\n",
    "\n",
    "  ##############################################################################\n",
    "\n",
    "  # Variables for calculating error distribution statistics\n",
    "  (abs_err_count_time_var,\n",
    "   abs_err_mean_time_var,\n",
    "   abs_err_cov_time_var,\n",
    "   abs_err_inv_cov_time_var,\n",
    "   abs_err_count_feat_var,\n",
    "   abs_err_mean_feat_var,\n",
    "   abs_err_cov_feat_var,\n",
    "   abs_err_inv_cov_feat_var) = create_both_mahalanobis_dist_vars(\n",
    "       seq_len=params[\"seq_len\"], num_feat=num_feat)\n",
    "\n",
    "  # Variables for automatically tuning anomaly thresh\n",
    "  if params[\"labeled_tune_thresh\"]:\n",
    "    (tp_thresh_time_var,\n",
    "     fn_thresh_time_var,\n",
    "     fp_thresh_time_var,\n",
    "     tn_thresh_time_var,\n",
    "     tp_thresh_feat_var,\n",
    "     fn_thresh_feat_var,\n",
    "     fp_thresh_feat_var,\n",
    "     tn_thresh_feat_var) = create_both_confusion_matrix_thresh_vars(\n",
    "         scope=\"mahalanobis_dist_thresh_vars\",\n",
    "         time_thresh_size=[params[\"num_time_anom_thresh\"]],\n",
    "         feat_thresh_size=[params[\"num_feat_anom_thresh\"]])\n",
    "  else:\n",
    "    (count_thresh_time_var,\n",
    "     mean_thresh_time_var,\n",
    "     var_thresh_time_var,\n",
    "     count_thresh_feat_var,\n",
    "     mean_thresh_feat_var,\n",
    "     var_thresh_feat_var) = create_both_mahalanobis_unsupervised_thresh_vars(\n",
    "         scope=\"mahalanobis_dist_thresh_vars\")\n",
    "\n",
    "  with tf.variable_scope(\n",
    "      name_or_scope=\"mahalanobis_dist_thresh_vars\", reuse=tf.AUTO_REUSE):\n",
    "    time_anom_thresh_var = tf.get_variable(\n",
    "        name=\"time_anom_thresh_var\",\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(shape=[], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "    feat_anom_thresh_var = tf.get_variable(\n",
    "        name=\"feat_anom_thresh_var\",\n",
    "        dtype=tf.float64,\n",
    "        initializer=tf.zeros(shape=[], dtype=tf.float64),\n",
    "        trainable=False)\n",
    "\n",
    "  # Variables for tuning anomaly thresh evaluation\n",
    "  if params[\"labeled_tune_thresh\"]:\n",
    "    (tp_thresh_eval_time_var,\n",
    "     fn_thresh_eval_time_var,\n",
    "     fp_thresh_eval_time_var,\n",
    "     tn_thresh_eval_time_var,\n",
    "     tp_thresh_eval_feat_var,\n",
    "     fn_thresh_eval_feat_var,\n",
    "     fp_thresh_eval_feat_var,\n",
    "     tn_thresh_eval_feat_var) = create_both_confusion_matrix_thresh_vars(\n",
    "         scope=\"anom_thresh_eval_vars\", time_thresh_size=[], feat_thresh_size=[])\n",
    "\n",
    "  # Create dummy variable for graph dependency requiring a gradient for TRAIN\n",
    "  dummy_var = tf.get_variable(\n",
    "      name=\"dummy_var\",\n",
    "      dtype=tf.float64,\n",
    "      initializer=tf.zeros(shape=[], dtype=tf.float64),\n",
    "      trainable=True)\n",
    "\n",
    "################################################################################\n",
    "\n",
    "  predictions_dict = None\n",
    "  loss = None\n",
    "  train_op = None\n",
    "  eval_metric_ops = None\n",
    "  export_outputs = None\n",
    "\n",
    "  # Now branch off based on which mode we are in\n",
    "\n",
    "  # Call specific model\n",
    "  model_functions = {\n",
    "      \"dense_autoencoder\": dense_autoencoder_model,\n",
    "      \"lstm_enc_dec_autoencoder\": lstm_enc_dec_autoencoder_model,\n",
    "      \"pca\": pca_model}\n",
    "\n",
    "  # Get function pointer for selected model type\n",
    "  model_function = model_functions[params[\"model_type\"]]\n",
    "\n",
    "  # Build selected model\n",
    "  loss, train_op, X_time_orig, X_time_recon, X_feat_orig, X_feat_recon = \\\n",
    "    model_function(X, mode, params, cur_batch_size, num_feat, dummy_var)\n",
    "\n",
    "  if not (mode == tf.estimator.ModeKeys.TRAIN and\n",
    "          params[\"training_mode\"] == \"reconstruction\"):\n",
    "    # shape = (cur_batch_size * seq_len, num_feat)\n",
    "    X_time_abs_recon_err = tf.abs(\n",
    "        x=X_time_orig - X_time_recon)\n",
    "\n",
    "    # Features based\n",
    "    # shape = (cur_batch_size * num_feat, seq_len)\n",
    "    X_feat_abs_recon_err = tf.abs(\n",
    "        x=X_feat_orig - X_feat_recon)\n",
    "\n",
    "    if (mode == tf.estimator.ModeKeys.TRAIN and\n",
    "        params[\"training_mode\"] == \"calculate_error_distribution_statistics\"):\n",
    "      loss, train_op = calculate_error_distribution_statistics_training(\n",
    "          cur_batch_size,\n",
    "          num_feat,\n",
    "          X_time_abs_recon_err,\n",
    "          abs_err_count_time_var,\n",
    "          abs_err_mean_time_var,\n",
    "          abs_err_cov_time_var,\n",
    "          abs_err_inv_cov_time_var,\n",
    "          X_feat_abs_recon_err,\n",
    "          abs_err_count_feat_var,\n",
    "          abs_err_mean_feat_var,\n",
    "          abs_err_cov_feat_var,\n",
    "          abs_err_inv_cov_feat_var,\n",
    "          params,\n",
    "          dummy_var)\n",
    "    elif (mode == tf.estimator.ModeKeys.EVAL and\n",
    "          params[\"training_mode\"] != \"tune_anomaly_thresholds\"):\n",
    "      loss, eval_metric_ops = reconstruction_evaluation(\n",
    "          X_time_orig, X_time_recon, params[\"training_mode\"])\n",
    "    elif (mode == tf.estimator.ModeKeys.PREDICT or\n",
    "          ((mode == tf.estimator.ModeKeys.TRAIN or\n",
    "            mode == tf.estimator.ModeKeys.EVAL) and\n",
    "           params[\"training_mode\"] == \"tune_anomaly_thresholds\")):\n",
    "      with tf.variable_scope(\n",
    "          name_or_scope=\"mahalanobis_dist_vars\", reuse=tf.AUTO_REUSE):\n",
    "        # Time based\n",
    "        # shape = (cur_batch_size, seq_len)\n",
    "        mahalanobis_dist_time = mahalanobis_dist(\n",
    "            err_vec=X_time_abs_recon_err,\n",
    "            mean_vec=abs_err_mean_time_var,\n",
    "            inv_cov=abs_err_inv_cov_time_var,\n",
    "            final_shape=params[\"seq_len\"])\n",
    "\n",
    "        # Features based\n",
    "        # shape = (cur_batch_size, num_feat)\n",
    "        mahalanobis_dist_feat = mahalanobis_dist(\n",
    "            err_vec=X_feat_abs_recon_err,\n",
    "            mean_vec=abs_err_mean_feat_var,\n",
    "            inv_cov=abs_err_inv_cov_feat_var,\n",
    "            final_shape=num_feat)\n",
    "\n",
    "      if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "        if params[\"labeled_tune_thresh\"]:\n",
    "          labels_norm_mask = tf.equal(x=labels, y=0)\n",
    "          labels_anom_mask = tf.equal(x=labels, y=1)\n",
    "\n",
    "          if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            loss, train_op = tune_anomaly_thresholds_supervised_training(\n",
    "                labels_norm_mask,\n",
    "                labels_anom_mask,\n",
    "                mahalanobis_dist_time,\n",
    "                tp_thresh_time_var,\n",
    "                fn_thresh_time_var,\n",
    "                fp_thresh_time_var,\n",
    "                tn_thresh_time_var,\n",
    "                time_anom_thresh_var,\n",
    "                mahalanobis_dist_feat,\n",
    "                tp_thresh_feat_var,\n",
    "                fn_thresh_feat_var,\n",
    "                fp_thresh_feat_var,\n",
    "                tn_thresh_feat_var,\n",
    "                feat_anom_thresh_var,\n",
    "                params,\n",
    "                mode,\n",
    "                dummy_var)\n",
    "          elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "            loss, eval_metric_ops = tune_anomaly_thresholds_evaluation(\n",
    "                labels_norm_mask,\n",
    "                labels_anom_mask,\n",
    "                time_anom_thresh_var,\n",
    "                mahalanobis_dist_time,\n",
    "                tp_thresh_eval_time_var,\n",
    "                fn_thresh_eval_time_var,\n",
    "                fp_thresh_eval_time_var,\n",
    "                tn_thresh_eval_time_var,\n",
    "                feat_anom_thresh_var,\n",
    "                mahalanobis_dist_feat,\n",
    "                tp_thresh_eval_feat_var,\n",
    "                fn_thresh_eval_feat_var,\n",
    "                fp_thresh_eval_feat_var,\n",
    "                tn_thresh_eval_feat_var,\n",
    "                params,\n",
    "                mode)\n",
    "        else:  # not params[\"labeled_tune_thresh\"]\n",
    "          if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            loss, train_op = tune_anomaly_thresholds_unsupervised_training(\n",
    "                cur_batch_size,\n",
    "                num_feat,\n",
    "                time_anom_thresh_var,\n",
    "                mahalanobis_dist_time,\n",
    "                count_thresh_time_var,\n",
    "                mean_thresh_time_var,\n",
    "                var_thresh_time_var,\n",
    "                feat_anom_thresh_var,\n",
    "                mahalanobis_dist_feat,\n",
    "                count_thresh_feat_var,\n",
    "                mean_thresh_feat_var,\n",
    "                var_thresh_feat_var,\n",
    "                params,\n",
    "                dummy_var)\n",
    "      else:  # mode == tf.estimator.ModeKeys.PREDICT\n",
    "        predictions_dict, export_outputs = anomaly_detection_predictions(\n",
    "            cur_batch_size,\n",
    "            params[\"seq_len\"],\n",
    "            num_feat,\n",
    "            mahalanobis_dist_time,\n",
    "            mahalanobis_dist_feat,\n",
    "            time_anom_thresh_var,\n",
    "            feat_anom_thresh_var,\n",
    "            X_time_abs_recon_err,\n",
    "            X_feat_abs_recon_err)\n",
    "\n",
    "  # Return EstimatorSpec\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=predictions_dict,\n",
    "      loss=loss,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops=eval_metric_ops,\n",
    "      export_outputs=export_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## serving.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile anomaly_detection_module/trainer/serving.py\n",
    "import tensorflow as tf\n",
    "\n",
    "from .globals import *\n",
    "\n",
    "# Serving input functions\n",
    "def fix_shape_and_type_for_serving(placeholder):\n",
    "  \"\"\"Fixes the shape and type of serving input strings.\n",
    "\n",
    "  Given placeholder tensor, return parsed and processed feature tensor.\n",
    "\n",
    "  Args:\n",
    "    placeholder: Placeholder tensor holding raw data from serving input\n",
    "      function.\n",
    "\n",
    "  Returns:\n",
    "    Parsed and processed feature tensor.\n",
    "  \"\"\"\n",
    "  cur_batch_size = tf.shape(input=placeholder, out_type=tf.int64)[0]\n",
    "\n",
    "  # String split each string in batch and output values from the resulting\n",
    "  # SparseTensors\n",
    "  # shape = (batch_size, seq_len)\n",
    "  split_string = tf.stack(values=tf.map_fn(\n",
    "      fn=lambda x: tf.string_split(\n",
    "          source=[placeholder[x]], delimiter=\",\").values,\n",
    "      elems=tf.range(\n",
    "          start=0, limit=cur_batch_size, dtype=tf.int64),\n",
    "      dtype=tf.string), axis=0)\n",
    "\n",
    "  # Convert each string in the split tensor to float\n",
    "  # shape = (batch_size, seq_len)\n",
    "  feature_tensor = tf.string_to_number(\n",
    "      string_tensor=split_string, out_type=tf.float64)\n",
    "\n",
    "  return feature_tensor\n",
    "\n",
    "\n",
    "def get_shape_and_set_modified_shape_2D(tensor, additional_dimension_sizes):\n",
    "  \"\"\"Fixes the shape and type of serving input strings.\n",
    "\n",
    "  Given feature tensor and additional dimension size, sequence length,\n",
    "  fixes dynamic shape ambiguity of last dimension so that we will be able to\n",
    "  use it in our DNN (since tf.layers.dense require the last dimension to be\n",
    "  known).\n",
    "\n",
    "  Args:\n",
    "    tensor: tf.float64 vector feature tensor.\n",
    "    additional_dimension_sizes: Additional dimension size, namely sequence\n",
    "      length.\n",
    "\n",
    "  Returns:\n",
    "    Feature tensor with set static shape for sequence length.\n",
    "  \"\"\"\n",
    "  # Get static shape for tensor and convert it to list\n",
    "  shape = tensor.get_shape().as_list()\n",
    "  # Set outer shape to additional_dimension_sizes[0] since know this is the\n",
    "  # correct size\n",
    "  shape[1] = additional_dimension_sizes[0]\n",
    "  # Set the shape of tensor to our modified shape\n",
    "  # shape = (batch_size, additional_dimension_sizes[0])\n",
    "  tensor.set_shape(shape=shape)\n",
    "\n",
    "  return tensor\n",
    "\n",
    "\n",
    "def serving_input_fn(seq_len):\n",
    "  \"\"\"Serving input function.\n",
    "\n",
    "  Given the sequence length, return ServingInputReceiver object.\n",
    "\n",
    "  Args:\n",
    "    seq_len: Number of timesteps in sequence.\n",
    "\n",
    "  Returns:\n",
    "    ServingInputReceiver object containing features and receiver tensors.\n",
    "  \"\"\"\n",
    "  # Create placeholders to accept the data sent to the model at serving time\n",
    "  # All features come in as a batch of strings, shape = (batch_size,),\n",
    "  # this was so because of passing the arrays to online ml-engine prediction\n",
    "  feature_placeholders = {\n",
    "      feature: tf.placeholder(\n",
    "          dtype=tf.string, shape=[None])\n",
    "      for feature in UNLABELED_CSV_COLUMNS\n",
    "  }\n",
    "\n",
    "  # Create feature tensors\n",
    "  features = {key: fix_shape_and_type_for_serving(placeholder=tensor)\n",
    "              for key, tensor in feature_placeholders.items()}\n",
    "\n",
    "  # Fix dynamic shape ambiguity of feature tensors for our DNN\n",
    "  features = {key: get_shape_and_set_modified_shape_2D(\n",
    "      tensor=tensor, additional_dimension_sizes=[seq_len])\n",
    "              for key, tensor in features.items()}\n",
    "\n",
    "  return tf.estimator.export.ServingInputReceiver(\n",
    "      features=features, receiver_tensors=feature_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile anomaly_detection_module/trainer/model.py\n",
    "import tensorflow as tf\n",
    "\n",
    "from .anomaly_detection import anomaly_detection\n",
    "from .input import read_dataset\n",
    "from .serving import serving_input_fn\n",
    "\n",
    "# Set logging to be level of INFO\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\n",
    "def train_and_evaluate(args):\n",
    "  \"\"\"Train and evaluate custom Estimator with three training modes.\n",
    "\n",
    "  Given the dictionary of parameters, create custom Estimator and run up to\n",
    "  three training modes then return Estimator object.\n",
    "\n",
    "  Args:\n",
    "    args: Dictionary of parameters.\n",
    "\n",
    "  Returns:\n",
    "    Estimator object.\n",
    "  \"\"\"\n",
    "  # Create our custom estimator using our model function\n",
    "  estimator = tf.estimator.Estimator(\n",
    "      model_fn=anomaly_detection,\n",
    "      model_dir=args[\"output_dir\"],\n",
    "      params={key: val for key, val in args.items()})\n",
    "\n",
    "  if args[\"training_mode\"] == \"reconstruction\":\n",
    "    if args[\"model_type\"] == \"pca\":\n",
    "      estimator.train(\n",
    "          input_fn=read_dataset(\n",
    "              filename=args[\"train_file_pattern\"],\n",
    "              mode=tf.estimator.ModeKeys.EVAL,\n",
    "              batch_size=args[\"train_batch_size\"],\n",
    "              params=args),\n",
    "          steps=None)\n",
    "    else:  # dense_autoencoder or lstm_enc_dec_autoencoder\n",
    "      # Create early stopping hook to help reduce overfitting\n",
    "      early_stopping_hook = tf.contrib.estimator.stop_if_no_decrease_hook(\n",
    "          estimator=estimator,\n",
    "          metric_name=\"rmse\",\n",
    "          max_steps_without_decrease=100,\n",
    "          min_steps=1000,\n",
    "          run_every_secs=60,\n",
    "          run_every_steps=None)\n",
    "\n",
    "      # Create train spec to read in our training data\n",
    "      train_spec = tf.estimator.TrainSpec(\n",
    "          input_fn=read_dataset(\n",
    "              filename=args[\"train_file_pattern\"],\n",
    "              mode=tf.estimator.ModeKeys.TRAIN,\n",
    "              batch_size=args[\"train_batch_size\"],\n",
    "              params=args),\n",
    "          max_steps=args[\"train_steps\"],\n",
    "          hooks=[early_stopping_hook])\n",
    "\n",
    "      # Create eval spec to read in our validation data and export our model\n",
    "      eval_spec = tf.estimator.EvalSpec(\n",
    "          input_fn=read_dataset(\n",
    "              filename=args[\"eval_file_pattern\"],\n",
    "              mode=tf.estimator.ModeKeys.EVAL,\n",
    "              batch_size=args[\"eval_batch_size\"],\n",
    "              params=args),\n",
    "          steps=None,\n",
    "          start_delay_secs=args[\"start_delay_secs\"],  # start eval after N secs\n",
    "          throttle_secs=args[\"throttle_secs\"])  # evaluate every N secs\n",
    "\n",
    "      # Create train and evaluate loop to train and evaluate our estimator\n",
    "      tf.estimator.train_and_evaluate(\n",
    "          estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n",
    "  else:\n",
    "    # if args[\"training_mode\"] == \"calculate_error_distribution_statistics\"\n",
    "    # Get final mahalanobis statistics over the entire val_1 dataset\n",
    "\n",
    "    # if args[\"training_mode\"] == \"tune_anomaly_thresholds\"\n",
    "    # Tune anomaly thresholds using val_2 and val_anom datasets\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"train_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.EVAL,  # read through val data once\n",
    "            batch_size=args[\"train_batch_size\"],\n",
    "            params=args),\n",
    "        max_steps=args[\"train_steps\"])\n",
    "\n",
    "    if args[\"training_mode\"] == \"calculate_error_distribution_statistics\":\n",
    "      # Evaluate until the end of eval files\n",
    "      eval_steps = None\n",
    "        \n",
    "      # Don't create exporter for serving yet since anomaly thresholds\n",
    "      # aren't trained yet\n",
    "      exporter = None\n",
    "    elif args[\"training_mode\"] == \"tune_anomaly_thresholds\":\n",
    "      if args[\"labeled_tune_thresh\"]:\n",
    "        # Evaluate until the end of eval files\n",
    "        eval_steps = None\n",
    "      else:\n",
    "        # Don't evaluate\n",
    "        eval_steps = 0\n",
    "        \n",
    "      # Create exporter that uses serving_input_fn to create saved_model\n",
    "      # for serving\n",
    "      exporter = tf.estimator.LatestExporter(\n",
    "          name=\"exporter\",\n",
    "          serving_input_receiver_fn=lambda: serving_input_fn(args[\"seq_len\"]))\n",
    "    else:\n",
    "      print(\"{0} isn't a valid training mode!\".format(args[\"training_mode\"]))\n",
    "\n",
    "    # Create eval spec to read in our validation data and export our model\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=read_dataset(\n",
    "            filename=args[\"eval_file_pattern\"],\n",
    "            mode=tf.estimator.ModeKeys.EVAL,\n",
    "            batch_size=args[\"eval_batch_size\"],\n",
    "            params=args),\n",
    "        steps=eval_steps,\n",
    "        exporters=exporter,\n",
    "        start_delay_secs=args[\"start_delay_secs\"],  # start eval after N secs\n",
    "        throttle_secs=args[\"throttle_secs\"])  # evaluate every N secs\n",
    "\n",
    "  if (args[\"training_mode\"] == \"calculate_error_distribution_statistics\" or \n",
    "      args[\"training_mode\"] == \"tune_anomaly_thresholds\"):\n",
    "    # Create train and evaluate loop to train and evaluate our estimator\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile anomaly_detection_module/trainer/task.py\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "from .model import train_and_evaluate\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  parser = argparse.ArgumentParser()\n",
    "  # File arguments\n",
    "  parser.add_argument(\n",
    "      \"--train_file_pattern\",\n",
    "      help=\"GCS location to read training data.\",\n",
    "      required=True\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--eval_file_pattern\",\n",
    "      help=\"GCS location to read evaluation data.\",\n",
    "      required=True\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--output_dir\",\n",
    "      help=\"GCS location to write checkpoints and export models.\",\n",
    "      required=True\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--job-dir\",\n",
    "      help=\"This model ignores this field, but it is required by gcloud.\",\n",
    "      default=\"junk\"\n",
    "  )\n",
    "\n",
    "  # Sequence shape hyperparameters\n",
    "  parser.add_argument(\n",
    "      \"--seq_len\",\n",
    "      help=\"Number of timesteps to include in each example.\",\n",
    "      type=int,\n",
    "      default=32\n",
    "  )\n",
    "\n",
    "  # Training parameters\n",
    "  parser.add_argument(\n",
    "      \"--train_batch_size\",\n",
    "      help=\"Number of examples in training batch.\",\n",
    "      type=int,\n",
    "      default=32\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--eval_batch_size\",\n",
    "      help=\"Number of examples in evaluation batch.\",\n",
    "      type=int,\n",
    "      default=32\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--train_steps\",\n",
    "      help=\"Number of batches to train.\",\n",
    "      type=int,\n",
    "      default=2000\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--learning_rate\",\n",
    "      help=\"How quickly or slowly we train our model by scaling the gradient.\",\n",
    "      type=float,\n",
    "      default=0.1\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--start_delay_secs\",\n",
    "      help=\"Number of seconds to wait before first evaluation.\",\n",
    "      type=int,\n",
    "      default=60\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--throttle_secs\",\n",
    "      help=\"Number of seconds to wait between evaluations.\",\n",
    "      type=int,\n",
    "      default=120\n",
    "  )\n",
    "\n",
    "  # Model hyperparameters\n",
    "  # dense_autoencoder, lstm_enc_dec_autoencoder, pca\n",
    "  parser.add_argument(\n",
    "      \"--model_type\",\n",
    "      help=\"Which model type we will use.\",\n",
    "      type=str,\n",
    "      default=\"dense_autoencoder\"\n",
    "  )\n",
    "  ## Dense Autoencoder\n",
    "  parser.add_argument(\n",
    "      \"--enc_dnn_hidden_units\",\n",
    "      help=\"Hidden layer sizes to use for encoder DNN.\",\n",
    "      default=\"1024 256 64\"\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--latent_vector_size\",\n",
    "      help=\"Number of neurons for latent vector between encoder and decoder.\",\n",
    "      type=int,\n",
    "      default=8\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--dec_dnn_hidden_units\",\n",
    "      help=\"Hidden layer sizes to use for decoder DNN.\",\n",
    "      default=\"64 256 1024\"\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--time_loss_weight\",\n",
    "      help=\"Amount to weight the time based loss.\",\n",
    "      type=float,\n",
    "      default=1.0\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--feat_loss_weight\",\n",
    "      help=\"Amount to weight the features based loss.\",\n",
    "      type=float,\n",
    "      default=1.0\n",
    "  )\n",
    "  ## LSTM Encoder-Decoder Autoencoder\n",
    "  parser.add_argument(\n",
    "      \"--reverse_labels_sequence\",\n",
    "      help=\"Whether we should reverse the labels sequence dimension or not.\",\n",
    "      type=bool,\n",
    "      default=True\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--enc_lstm_hidden_units\",\n",
    "      help=\"Hidden layer sizes to use for LSTM encoder.\",\n",
    "      default=\"64 32 16\"\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--dec_lstm_hidden_units\",\n",
    "      help=\"Hidden layer sizes to use for LSTM decoder.\",\n",
    "      default=\"16 32 64\"\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--lstm_dropout_output_keep_probs\",\n",
    "      help=\"Keep probabilties for LSTM outputs.\",\n",
    "      default=\"1.0 1.0 1.0\"\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--dnn_hidden_units\",\n",
    "      help=\"Hidden layer sizes to use for DNN.\",\n",
    "      default=\"1024 256 64\"\n",
    "  )\n",
    "  ## PCA\n",
    "  parser.add_argument(\n",
    "      \"--k_principal_components\",\n",
    "      help=\"Top k principal components to keep after eigendecomposition.\",\n",
    "      type=int,\n",
    "      default=3\n",
    "  )\n",
    "\n",
    "  # Anomaly detection\n",
    "  # reconstruction, calculate_error_distribution_statistics,\n",
    "  # and tune_anomaly_thresholds\n",
    "  parser.add_argument(\n",
    "      \"--training_mode\",\n",
    "      help=\"Which training mode we are in.\",\n",
    "      type=str,\n",
    "      default=\"reconstruction\"\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--labeled_tune_thresh\",\n",
    "      help=\"If we have a labeled dataset for supervised anomaly tuning.\",\n",
    "      type=bool,\n",
    "      default=True\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--num_time_anom_thresh\",\n",
    "      help=\"Number of anomaly thresholds to evaluate in time dimension.\",\n",
    "      type=int,\n",
    "      default=120\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--num_feat_anom_thresh\",\n",
    "      help=\"Number of anomaly thresholds to evaluate in features dimension.\",\n",
    "      type=int,\n",
    "      default=120\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--min_time_anom_thresh\",\n",
    "      help=\"Minimum anomaly threshold to evaluate in time dimension.\",\n",
    "      type=float,\n",
    "      default=100.0\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--max_time_anom_thresh\",\n",
    "      help=\"Maximum anomaly threshold to evaluate in time dimension.\",\n",
    "      type=float,\n",
    "      default=2000.0\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--min_feat_anom_thresh\",\n",
    "      help=\"Minimum anomaly threshold to evaluate in features dimension.\",\n",
    "      type=float,\n",
    "      default=100.0\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--max_feat_anom_thresh\",\n",
    "      help=\"Maximum anomaly threshold to evaluate in features dimension.\",\n",
    "      type=float,\n",
    "      default=2000.0\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--time_thresh_scl\",\n",
    "      help=\"Max num of std devs for time mahalanobis distance to be normal.\",\n",
    "      type=float,\n",
    "      default=2.0\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--feat_thresh_scl\",\n",
    "      help=\"Max num of std devs for feature mahalanobis distance to be normal.\",\n",
    "      type=float,\n",
    "      default=2.0\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--time_anom_thresh\",\n",
    "      help=\"Anomaly threshold in time dimension.\",\n",
    "      type=float,\n",
    "      default=None\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--feat_anom_thresh\",\n",
    "      help=\"Anomaly threshold in features dimension.\",\n",
    "      type=float,\n",
    "      default=None\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--eps\",\n",
    "      help=\"Added to the cov matrix before inversion to avoid being singular.\",\n",
    "      type=str,\n",
    "      default=\"1e-12\"\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--f_score_beta\",\n",
    "      help=\"Value of beta of the f-beta score.\",\n",
    "      type=float,\n",
    "      default=0.05\n",
    "  )\n",
    "\n",
    "  # Parse all arguments\n",
    "  args = parser.parse_args()\n",
    "  arguments = args.__dict__\n",
    "\n",
    "  # Unused args provided by service\n",
    "  arguments.pop(\"job_dir\", None)\n",
    "  arguments.pop(\"job-dir\", None)\n",
    "\n",
    "  # Fix list arguments\n",
    "  ## Dense Autoencoder\n",
    "  arguments[\"enc_dnn_hidden_units\"] = [\n",
    "      int(x) for x in arguments[\"enc_dnn_hidden_units\"].split(\" \")]\n",
    "  arguments[\"dec_dnn_hidden_units\"] = [\n",
    "      int(x) for x in arguments[\"dec_dnn_hidden_units\"].split(\" \")]\n",
    "\n",
    "  ## LSTM Encoder-Decoder Autoencoder\n",
    "  arguments[\"enc_lstm_hidden_units\"] = [\n",
    "      int(x) for x in arguments[\"enc_lstm_hidden_units\"].split(\" \")]\n",
    "  arguments[\"dec_lstm_hidden_units\"] = [\n",
    "      int(x) for x in arguments[\"dec_lstm_hidden_units\"].split(\" \")]\n",
    "  arguments[\"lstm_dropout_output_keep_probs\"] = [\n",
    "      float(x) for x in arguments[\"lstm_dropout_output_keep_probs\"].split(\" \")]\n",
    "  arguments[\"dnn_hidden_units\"] = [\n",
    "      int(x) for x in arguments[\"dnn_hidden_units\"].split(\" \")]\n",
    "\n",
    "  # Fix eps argument\n",
    "  arguments[\"eps\"] = float(arguments[\"eps\"])\n",
    "\n",
    "  # Append trial_id to path if we are doing hptuning\n",
    "  # This code can be removed if you are not using hyperparameter tuning\n",
    "  arguments[\"output_dir\"] = os.path.join(\n",
    "      arguments[\"output_dir\"],\n",
    "      json.loads(\n",
    "          os.environ.get(\"TF_CONFIG\", \"{}\")\n",
    "          ).get(\"task\", {}).get(\"trial\", \"\")\n",
    "      )\n",
    "\n",
    "  # Run the training job\n",
    "  train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train reconstruction variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "\n",
      "anomaly_detection: features = \n",
      "{'tag_4': <tf.Tensor 'IteratorGetNext:4' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'IteratorGetNext:3' shape=(?, 30) dtype=float64>}\n",
      "anomaly_detection: labels = \n",
      "None\n",
      "anomaly_detection: mode = \n",
      "train\n",
      "anomaly_detection: params = \n",
      "{'model_type': 'lstm_enc_dec_autoencoder', 'eval_file_pattern': 'data/val_norm_1_seq.csv', 'num_feat_anom_thresh': 300, 'lstm_dropout_output_keep_probs': [0.9, 0.95, 1.0], 'feat_loss_weight': 1.0, 'latent_vector_size': 8, 'throttle_secs': 120, 'feat_anom_thresh': None, 'labeled_tune_thresh': True, 'reverse_labels_sequence': True, 'min_time_anom_thresh': 100.0, 'enc_lstm_hidden_units': [64, 32, 16], 'training_mode': 'reconstruction', 'f_score_beta': 0.05, 'dec_lstm_hidden_units': [16, 32, 64], 'seq_len': 30, 'min_feat_anom_thresh': 100.0, 'learning_rate': 0.1, 'eps': 1e-12, 'eval_batch_size': 32, 'time_loss_weight': 1.0, 'dec_dnn_hidden_units': [64, 256, 1024], 'train_batch_size': 32, 'num_time_anom_thresh': 300, 'dnn_hidden_units': [1024, 256, 64], 'start_delay_secs': 60, 'enc_dnn_hidden_units': [1024, 256, 64], 'train_steps': 2000, 'output_dir': '/home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/', 'max_feat_anom_thresh': 2000.0, 'time_anom_thresh': None, 'k_principal_components': 3, 'time_thresh_scl': 2.0, 'max_time_anom_thresh': 2000.0, 'feat_thresh_scl': 2.0, 'train_file_pattern': 'data/train_norm_seq.csv'}\n",
      "\n",
      "anomaly_detection: features = \n",
      "{'tag_4': <tf.Tensor 'IteratorGetNext:4' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'IteratorGetNext:3' shape=(?, 30) dtype=float64>}\n",
      "anomaly_detection: labels = \n",
      "None\n",
      "anomaly_detection: mode = \n",
      "eval\n",
      "anomaly_detection: params = \n",
      "{'model_type': 'lstm_enc_dec_autoencoder', 'eval_file_pattern': 'data/val_norm_1_seq.csv', 'num_feat_anom_thresh': 300, 'lstm_dropout_output_keep_probs': [0.9, 0.95, 1.0], 'feat_loss_weight': 1.0, 'latent_vector_size': 8, 'throttle_secs': 120, 'feat_anom_thresh': None, 'labeled_tune_thresh': True, 'reverse_labels_sequence': True, 'min_time_anom_thresh': 100.0, 'enc_lstm_hidden_units': [64, 32, 16], 'training_mode': 'reconstruction', 'f_score_beta': 0.05, 'dec_lstm_hidden_units': [16, 32, 64], 'seq_len': 30, 'min_feat_anom_thresh': 100.0, 'learning_rate': 0.1, 'eps': 1e-12, 'eval_batch_size': 32, 'time_loss_weight': 1.0, 'dec_dnn_hidden_units': [64, 256, 1024], 'train_batch_size': 32, 'num_time_anom_thresh': 300, 'dnn_hidden_units': [1024, 256, 64], 'start_delay_secs': 60, 'enc_dnn_hidden_units': [1024, 256, 64], 'train_steps': 2000, 'output_dir': '/home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/', 'max_feat_anom_thresh': 2000.0, 'time_anom_thresh': None, 'k_principal_components': 3, 'time_thresh_scl': 2.0, 'max_time_anom_thresh': 2000.0, 'feat_thresh_scl': 2.0, 'train_file_pattern': 'data/train_norm_seq.csv'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_eval_distribute': None, '_protocol': None, '_num_ps_replicas': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3bd1217d30>, '_save_checkpoints_steps': None, '_service': None, '_num_worker_replicas': 1, '_log_step_count_steps': 100, '_is_chief': True, '_master': '', '_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_device_fn': None, '_experimental_distribute': None, '_global_id_in_cluster': 0, '_tf_random_seed': None, '_train_distribute': None, '_evaluation_master': '', '_save_checkpoints_secs': 600, '_model_dir': '/home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/', '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_task_type': 'worker', '_task_id': 0, '_keep_checkpoint_every_n_hours': 10000}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/anomaly_detection_module/trainer/autoencoder_lstm.py:26: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/anomaly_detection_module/trainer/autoencoder_lstm.py:41: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/anomaly_detection_module/trainer/autoencoder_lstm.py:208: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/anomaly_detection_module/trainer/autoencoder_lstm.py:226: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-07-03 15:59:44.291848: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2019-07-03 15:59:44.309691: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000189999 Hz\n",
      "2019-07-03 15:59:44.320738: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55d71a216de0 executing computations on platform Host. Devices:\n",
      "2019-07-03 15:59:44.320792: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-07-03 15:59:44.332043: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.4372226, step = 1\n",
      "INFO:tensorflow:global_step/sec: 2.28581\n",
      "INFO:tensorflow:loss = 2.192668, step = 101 (43.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.80023\n",
      "INFO:tensorflow:loss = 2.0124278, step = 201 (12.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.4212\n",
      "INFO:tensorflow:loss = 1.853826, step = 301 (13.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.04443\n",
      "INFO:tensorflow:loss = 1.7222569, step = 401 (12.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.09117\n",
      "INFO:tensorflow:loss = 1.5792913, step = 501 (14.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.14219\n",
      "INFO:tensorflow:loss = 1.4590247, step = 601 (14.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.78158\n",
      "INFO:tensorflow:loss = 1.3866546, step = 701 (14.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.88717\n",
      "INFO:tensorflow:loss = 1.3067068, step = 801 (14.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.94306\n",
      "INFO:tensorflow:loss = 1.2485459, step = 901 (14.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.86185\n",
      "INFO:tensorflow:loss = 1.2313526, step = 1001 (14.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.87298\n",
      "INFO:tensorflow:loss = 1.1977092, step = 1101 (14.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.40605\n",
      "INFO:tensorflow:loss = 1.1813729, step = 1201 (13.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.41254\n",
      "INFO:tensorflow:loss = 1.1839418, step = 1301 (13.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.84423\n",
      "INFO:tensorflow:loss = 1.1698232, step = 1401 (14.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.10366\n",
      "INFO:tensorflow:loss = 1.1672858, step = 1501 (14.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.07297\n",
      "INFO:tensorflow:loss = 1.1661357, step = 1601 (14.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.11425\n",
      "INFO:tensorflow:loss = 1.1570879, step = 1701 (14.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.04892\n",
      "INFO:tensorflow:loss = 1.1615819, step = 1801 (14.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.03849\n",
      "INFO:tensorflow:loss = 1.1522129, step = 1901 (14.208 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-07-03T16:05:45Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-07-03-16:06:10\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 1.1634965, mae = 0.9278662, rmse = 1.078655\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/model.ckpt-2000\n",
      "INFO:tensorflow:Loss for final step: 1.1821407.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf trained_model\n",
    "export PYTHONPATH=$PYTHONPATH:$PWD/anomaly_detection_module\n",
    "python3 -m trainer.task \\\n",
    "  --train_file_pattern=\"data/train_norm_seq.csv\" \\\n",
    "  --eval_file_pattern=\"data/val_norm_1_seq.csv\" \\\n",
    "  --output_dir=$PWD/trained_model \\\n",
    "  --job-dir=./tmp \\\n",
    "  --seq_len=30 \\\n",
    "  --train_batch_size=32 \\\n",
    "  --eval_batch_size=32 \\\n",
    "  --train_steps=2000 \\\n",
    "  --learning_rate=0.1 \\\n",
    "  --start_delay_secs=60 \\\n",
    "  --throttle_secs=120 \\\n",
    "  --model_type=\"lstm_enc_dec_autoencoder\" \\\n",
    "  --reverse_labels_sequence=True \\\n",
    "  --enc_lstm_hidden_units=\"64 32 16\" \\\n",
    "  --dec_lstm_hidden_units=\"16 32 64\" \\\n",
    "  --lstm_dropout_output_keep_probs=\"0.9 0.95 1.0\" \\\n",
    "  --dnn_hidden_units=\"1024 256 64\" \\\n",
    "  --training_mode=\"reconstruction\" \\\n",
    "  --labeled_tune_thresh=True \\\n",
    "  --num_time_anom_thresh=300 \\\n",
    "  --num_feat_anom_thresh=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train error distribution statistics variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "anomaly_detection: features = \n",
      "{'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'IteratorGetNext:3' shape=(?, 30) dtype=float64>, 'tag_4': <tf.Tensor 'IteratorGetNext:4' shape=(?, 30) dtype=float64>}\n",
      "anomaly_detection: labels = \n",
      "None\n",
      "anomaly_detection: mode = \n",
      "train\n",
      "anomaly_detection: params = \n",
      "{'dec_lstm_hidden_units': [16, 32, 64], 'time_thresh_scl': 2.0, 'train_steps': 2200, 'learning_rate': 0.1, 'dec_dnn_hidden_units': [64, 256, 1024], 'max_time_anom_thresh': 2000.0, 'min_time_anom_thresh': 100.0, 'seq_len': 30, 'eps': 1e-12, 'reverse_labels_sequence': True, 'output_dir': '/home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/', 'time_loss_weight': 1.0, 'dnn_hidden_units': [1024, 256, 64], 'train_batch_size': 32, 'eval_file_pattern': 'data/val_norm_1_seq.csv', 'latent_vector_size': 8, 'feat_loss_weight': 1.0, 'model_type': 'lstm_enc_dec_autoencoder', 'train_file_pattern': 'data/val_norm_1_seq.csv', 'max_feat_anom_thresh': 2000.0, 'start_delay_secs': 60, 'min_feat_anom_thresh': 100.0, 'num_time_anom_thresh': 300, 'f_score_beta': 0.05, 'labeled_tune_thresh': True, 'eval_batch_size': 32, 'enc_dnn_hidden_units': [1024, 256, 64], 'lstm_dropout_output_keep_probs': [0.9, 0.95, 1.0], 'k_principal_components': 3, 'num_feat_anom_thresh': 300, 'training_mode': 'calculate_error_distribution_statistics', 'time_anom_thresh': None, 'feat_thresh_scl': 2.0, 'throttle_secs': 120, 'enc_lstm_hidden_units': [64, 32, 16], 'feat_anom_thresh': None}\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "value_b = \n",
      "Tensor(\"Abs:0\", shape=(?, 5), dtype=float64)\n",
      "mean_a = \n",
      "<tf.Variable 'mahalanobis_dist_vars/abs_err_mean_time_var:0' shape=(5,) dtype=float64_ref>\n",
      "mean_ab = \n",
      "Tensor(\"mahalanobis_dist_vars_2/cond/truediv:0\", shape=(5,), dtype=float64)\n",
      "value_b = \n",
      "Tensor(\"Abs_1:0\", shape=(?, 30), dtype=float64)\n",
      "mean_a = \n",
      "<tf.Variable 'mahalanobis_dist_vars/abs_err_mean_feat_var:0' shape=(30,) dtype=float64_ref>\n",
      "mean_ab = \n",
      "Tensor(\"mahalanobis_dist_vars_2/cond_1/truediv:0\", shape=(30,), dtype=float64)\n",
      "\n",
      "anomaly_detection: features = \n",
      "{'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'IteratorGetNext:3' shape=(?, 30) dtype=float64>, 'tag_4': <tf.Tensor 'IteratorGetNext:4' shape=(?, 30) dtype=float64>}\n",
      "anomaly_detection: labels = \n",
      "None\n",
      "anomaly_detection: mode = \n",
      "eval\n",
      "anomaly_detection: params = \n",
      "{'dec_lstm_hidden_units': [16, 32, 64], 'time_thresh_scl': 2.0, 'train_steps': 2200, 'learning_rate': 0.1, 'dec_dnn_hidden_units': [64, 256, 1024], 'max_time_anom_thresh': 2000.0, 'min_time_anom_thresh': 100.0, 'seq_len': 30, 'eps': 1e-12, 'reverse_labels_sequence': True, 'output_dir': '/home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/', 'time_loss_weight': 1.0, 'dnn_hidden_units': [1024, 256, 64], 'train_batch_size': 32, 'eval_file_pattern': 'data/val_norm_1_seq.csv', 'latent_vector_size': 8, 'feat_loss_weight': 1.0, 'model_type': 'lstm_enc_dec_autoencoder', 'train_file_pattern': 'data/val_norm_1_seq.csv', 'max_feat_anom_thresh': 2000.0, 'start_delay_secs': 60, 'min_feat_anom_thresh': 100.0, 'num_time_anom_thresh': 300, 'f_score_beta': 0.05, 'labeled_tune_thresh': True, 'eval_batch_size': 32, 'enc_dnn_hidden_units': [1024, 256, 64], 'lstm_dropout_output_keep_probs': [0.9, 0.95, 1.0], 'k_principal_components': 3, 'num_feat_anom_thresh': 300, 'training_mode': 'calculate_error_distribution_statistics', 'time_anom_thresh': None, 'feat_thresh_scl': 2.0, 'throttle_secs': 120, 'enc_lstm_hidden_units': [64, 32, 16], 'feat_anom_thresh': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_tf_random_seed': None, '_num_worker_replicas': 1, '_experimental_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fef995cea90>, '_eval_distribute': None, '_save_checkpoints_secs': 600, '_global_id_in_cluster': 0, '_model_dir': '/home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/', '_log_step_count_steps': 100, '_task_id': 0, '_device_fn': None, '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_protocol': None, '_keep_checkpoint_max': 5, '_train_distribute': None, '_evaluation_master': '', '_save_checkpoints_steps': None, '_service': None, '_num_ps_replicas': 0, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_save_summary_steps': 100, '_task_type': 'worker'}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/anomaly_detection_module/trainer/autoencoder_lstm.py:26: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/anomaly_detection_module/trainer/autoencoder_lstm.py:41: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/anomaly_detection_module/trainer/autoencoder_lstm.py:208: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/anomaly_detection_module/trainer/autoencoder_lstm.py:226: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-07-03 16:06:19.944055: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2019-07-03 16:06:19.963464: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000189999 Hz\n",
      "2019-07-03 16:06:19.975337: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55fa89bad7d0 executing computations on platform Host. Devices:\n",
      "2019-07-03 16:06:19.975378: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-07-03 16:06:19.987397: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/model.ckpt-2000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0, step = 2001\n",
      "INFO:tensorflow:global_step/sec: 6.37583\n",
      "INFO:tensorflow:loss = 0.0, step = 2101 (15.685 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2200 into /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-07-03T16:06:59Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/model.ckpt-2200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-07-03-16:07:23\n",
      "INFO:tensorflow:Saving dict for global step 2200: global_step = 2200, loss = 1.1634965\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2200: /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/model.ckpt-2200\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export PYTHONPATH=$PYTHONPATH:$PWD/anomaly_detection_module\n",
    "python3 -m trainer.task \\\n",
    "  --train_file_pattern=\"data/val_norm_1_seq.csv\" \\\n",
    "  --eval_file_pattern=\"data/val_norm_1_seq.csv\" \\\n",
    "  --output_dir=$PWD/trained_model \\\n",
    "  --job-dir=./tmp \\\n",
    "  --seq_len=30 \\\n",
    "  --train_batch_size=32 \\\n",
    "  --eval_batch_size=32 \\\n",
    "  --train_steps=2200 \\\n",
    "  --model_type=\"lstm_enc_dec_autoencoder\" \\\n",
    "  --reverse_labels_sequence=True \\\n",
    "  --enc_lstm_hidden_units=\"64 32 16\" \\\n",
    "  --dec_lstm_hidden_units=\"16 32 64\" \\\n",
    "  --lstm_dropout_output_keep_probs=\"0.9 0.95 1.0\" \\\n",
    "  --dnn_hidden_units=\"1024 256 64\" \\\n",
    "  --training_mode=\"calculate_error_distribution_statistics\" \\\n",
    "  --labeled_tune_thresh=True \\\n",
    "  --eps=\"1e-12\" \\\n",
    "  --num_time_anom_thresh=300 \\\n",
    "  --num_feat_anom_thresh=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune anomaly thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "anomaly_detection: features = \n",
      "{'tag_4': <tf.Tensor 'IteratorGetNext:4' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'IteratorGetNext:3' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>}\n",
      "anomaly_detection: labels = \n",
      "Tensor(\"IteratorGetNext:5\", shape=(?,), dtype=float64, device=/device:CPU:0)\n",
      "anomaly_detection: mode = \n",
      "train\n",
      "anomaly_detection: params = \n",
      "{'dec_lstm_hidden_units': [16, 32, 64], 'enc_dnn_hidden_units': [1024, 256, 64], 'max_feat_anom_thresh': 80.0, 'throttle_secs': 120, 'start_delay_secs': 60, 'min_feat_anom_thresh': 20.0, 'lstm_dropout_output_keep_probs': [0.9, 0.95, 1.0], 'num_time_anom_thresh': 300, 'seq_len': 30, 'f_score_beta': 0.05, 'time_loss_weight': 1.0, 'reverse_labels_sequence': True, 'latent_vector_size': 8, 'training_mode': 'tune_anomaly_thresholds', 'feat_thresh_scl': 2.0, 'train_steps': 2400, 'k_principal_components': 3, 'eval_batch_size': 32, 'labeled_tune_thresh': True, 'output_dir': '/home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/', 'feat_anom_thresh': None, 'enc_lstm_hidden_units': [64, 32, 16], 'dnn_hidden_units': [1024, 256, 64], 'train_batch_size': 32, 'num_feat_anom_thresh': 300, 'dec_dnn_hidden_units': [64, 256, 1024], 'max_time_anom_thresh': 20.0, 'min_time_anom_thresh': 1.0, 'model_type': 'lstm_enc_dec_autoencoder', 'learning_rate': 0.1, 'eps': 1e-12, 'time_thresh_scl': 2.0, 'train_file_pattern': 'data/labeled_val_mixed_seq.csv', 'feat_loss_weight': 1.0, 'time_anom_thresh': None, 'eval_file_pattern': 'data/labeled_val_mixed_seq.csv'}\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "\n",
      "anomaly_detection: features = \n",
      "{'tag_4': <tf.Tensor 'IteratorGetNext:4' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'IteratorGetNext:3' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'IteratorGetNext:1' shape=(?, 30) dtype=float64>, 'tag_2': <tf.Tensor 'IteratorGetNext:2' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'IteratorGetNext:0' shape=(?, 30) dtype=float64>}\n",
      "anomaly_detection: labels = \n",
      "Tensor(\"IteratorGetNext:5\", shape=(?,), dtype=float64, device=/device:CPU:0)\n",
      "anomaly_detection: mode = \n",
      "eval\n",
      "anomaly_detection: params = \n",
      "{'dec_lstm_hidden_units': [16, 32, 64], 'enc_dnn_hidden_units': [1024, 256, 64], 'max_feat_anom_thresh': 80.0, 'throttle_secs': 120, 'start_delay_secs': 60, 'min_feat_anom_thresh': 20.0, 'lstm_dropout_output_keep_probs': [0.9, 0.95, 1.0], 'num_time_anom_thresh': 300, 'seq_len': 30, 'f_score_beta': 0.05, 'time_loss_weight': 1.0, 'reverse_labels_sequence': True, 'latent_vector_size': 8, 'training_mode': 'tune_anomaly_thresholds', 'feat_thresh_scl': 2.0, 'train_steps': 2400, 'k_principal_components': 3, 'eval_batch_size': 32, 'labeled_tune_thresh': True, 'output_dir': '/home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/', 'feat_anom_thresh': None, 'enc_lstm_hidden_units': [64, 32, 16], 'dnn_hidden_units': [1024, 256, 64], 'train_batch_size': 32, 'num_feat_anom_thresh': 300, 'dec_dnn_hidden_units': [64, 256, 1024], 'max_time_anom_thresh': 20.0, 'min_time_anom_thresh': 1.0, 'model_type': 'lstm_enc_dec_autoencoder', 'learning_rate': 0.1, 'eps': 1e-12, 'time_thresh_scl': 2.0, 'train_file_pattern': 'data/labeled_val_mixed_seq.csv', 'feat_loss_weight': 1.0, 'time_anom_thresh': None, 'eval_file_pattern': 'data/labeled_val_mixed_seq.csv'}\n",
      "\n",
      "anomaly_detection: features = \n",
      "{'tag_4': <tf.Tensor 'StringToNumber:0' shape=(?, 30) dtype=float64>, 'tag_0': <tf.Tensor 'StringToNumber_1:0' shape=(?, 30) dtype=float64>, 'tag_1': <tf.Tensor 'StringToNumber_2:0' shape=(?, 30) dtype=float64>, 'tag_2': <tf.Tensor 'StringToNumber_4:0' shape=(?, 30) dtype=float64>, 'tag_3': <tf.Tensor 'StringToNumber_3:0' shape=(?, 30) dtype=float64>}\n",
      "anomaly_detection: labels = \n",
      "None\n",
      "anomaly_detection: mode = \n",
      "infer\n",
      "anomaly_detection: params = \n",
      "{'dec_lstm_hidden_units': [16, 32, 64], 'enc_dnn_hidden_units': [1024, 256, 64], 'max_feat_anom_thresh': 80.0, 'throttle_secs': 120, 'start_delay_secs': 60, 'min_feat_anom_thresh': 20.0, 'lstm_dropout_output_keep_probs': [0.9, 0.95, 1.0], 'num_time_anom_thresh': 300, 'seq_len': 30, 'f_score_beta': 0.05, 'time_loss_weight': 1.0, 'reverse_labels_sequence': True, 'latent_vector_size': 8, 'training_mode': 'tune_anomaly_thresholds', 'feat_thresh_scl': 2.0, 'train_steps': 2400, 'k_principal_components': 3, 'eval_batch_size': 32, 'labeled_tune_thresh': True, 'output_dir': '/home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/', 'feat_anom_thresh': None, 'enc_lstm_hidden_units': [64, 32, 16], 'dnn_hidden_units': [1024, 256, 64], 'train_batch_size': 32, 'num_feat_anom_thresh': 300, 'dec_dnn_hidden_units': [64, 256, 1024], 'max_time_anom_thresh': 20.0, 'min_time_anom_thresh': 1.0, 'model_type': 'lstm_enc_dec_autoencoder', 'learning_rate': 0.1, 'eps': 1e-12, 'time_thresh_scl': 2.0, 'train_file_pattern': 'data/labeled_val_mixed_seq.csv', 'feat_loss_weight': 1.0, 'time_anom_thresh': None, 'eval_file_pattern': 'data/labeled_val_mixed_seq.csv'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_num_ps_replicas': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_tf_random_seed': None, '_model_dir': '/home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/', '_train_distribute': None, '_eval_distribute': None, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_num_worker_replicas': 1, '_is_chief': True, '_master': '', '_device_fn': None, '_task_id': 0, '_task_type': 'worker', '_experimental_distribute': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_service': None, '_global_id_in_cluster': 0, '_keep_checkpoint_max': 5, '_protocol': None, '_save_checkpoints_secs': 600, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdd1b066cf8>, '_evaluation_master': ''}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/anomaly_detection_module/trainer/autoencoder_lstm.py:26: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/anomaly_detection_module/trainer/autoencoder_lstm.py:41: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/anomaly_detection_module/trainer/autoencoder_lstm.py:208: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/anomaly_detection_module/trainer/autoencoder_lstm.py:226: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-07-03 16:07:32.579008: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2019-07-03 16:07:32.597875: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000189999 Hz\n",
      "2019-07-03 16:07:32.609996: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55a36c911b60 executing computations on platform Host. Devices:\n",
      "2019-07-03 16:07:32.610026: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-07-03 16:07:32.621024: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/model.ckpt-2200\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2200 into /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0, step = 2201\n",
      "INFO:tensorflow:global_step/sec: 3.89261\n",
      "INFO:tensorflow:loss = 0.0, step = 2301 (25.691 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2400 into /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/metrics_impl.py:363: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Starting evaluation at 2019-07-03T16:08:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/model.ckpt-2400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-07-03-16:09:15\n",
      "INFO:tensorflow:Saving dict for global step 2400: feat_anom_acc = 0.5, feat_anom_f_beta = nan, feat_anom_fn = 6400, feat_anom_fp = 0, feat_anom_pre = nan, feat_anom_rec = 0.0, feat_anom_tn = 6400, feat_anom_tp = 0, global_step = 2400, loss = 0.0, time_anom_acc = 0.5, time_anom_f_beta = 0.4964818668252081, time_anom_fn = 5567, time_anom_fp = 833, time_anom_pre = 0.5, time_anom_rec = 0.13015625, time_anom_tn = 5567, time_anom_tp = 833\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2400: /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/model.ckpt-2400\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default', 'predict_export_outputs']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/model.ckpt-2400\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/jupyter/artificial_intelligence/machine_learning/anomaly_detection/tf_anomaly_detection_model_selection/trained_model/export/exporter/temp-b'1562170155'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export PYTHONPATH=$PYTHONPATH:$PWD/anomaly_detection_module\n",
    "python3 -m trainer.task \\\n",
    "  --train_file_pattern=\"data/labeled_val_mixed_seq.csv\" \\\n",
    "  --eval_file_pattern=\"data/labeled_val_mixed_seq.csv\" \\\n",
    "  --output_dir=$PWD/trained_model \\\n",
    "  --job-dir=./tmp \\\n",
    "  --seq_len=30 \\\n",
    "  --train_batch_size=32 \\\n",
    "  --eval_batch_size=32 \\\n",
    "  --train_steps=2400 \\\n",
    "  --model_type=\"lstm_enc_dec_autoencoder\" \\\n",
    "  --reverse_labels_sequence=True \\\n",
    "  --enc_lstm_hidden_units=\"64 32 16\" \\\n",
    "  --dec_lstm_hidden_units=\"16 32 64\" \\\n",
    "  --lstm_dropout_output_keep_probs=\"0.9 0.95 1.0\" \\\n",
    "  --dnn_hidden_units=\"1024 256 64\" \\\n",
    "  --training_mode=\"tune_anomaly_thresholds\" \\\n",
    "  --labeled_tune_thresh=True \\\n",
    "  --num_time_anom_thresh=300 \\\n",
    "  --num_feat_anom_thresh=300 \\\n",
    "  --min_time_anom_thresh=1.0 \\\n",
    "  --max_time_anom_thresh=20.0 \\\n",
    "  --min_feat_anom_thresh=20.0 \\\n",
    "  --max_feat_anom_thresh=80.0 \\\n",
    "  --f_score_beta=0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy data over to bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil -m cp -r data/* gs://$BUCKET/anomaly_detection/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train reconstruction variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/anomaly_detection/trained_model\n",
    "JOBNAME=job_anomaly_detection_reconstruction_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$PWD/anomaly_detection_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=1.13 \\\n",
    "  -- \\\n",
    "  --train_file_pattern=gs://$BUCKET/anomaly_detection/data/train_norm_seq.csv \\\n",
    "  --eval_file_pattern=gs://$BUCKET/anomaly_detection/data/val_norm_1_seq.csv \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --seq_len=30 \\\n",
    "  --train_batch_size=32 \\\n",
    "  --eval_batch_size=32 \\\n",
    "  --train_steps=2000 \\\n",
    "  --learning_rate=0.1 \\\n",
    "  --start_delay_secs=60 \\\n",
    "  --throttle_secs=120 \\\n",
    "  --model_type=\"lstm_enc_dec_autoencoder\" \\\n",
    "  --reverse_labels_sequence=True \\\n",
    "  --enc_lstm_hidden_units=\"64 32 16\" \\\n",
    "  --dec_lstm_hidden_units=\"16 32 64\" \\\n",
    "  --lstm_dropout_output_keep_probs=\"0.9 0.95 1.0\" \\\n",
    "  --dnn_hidden_units=\"1024 256 64\" \\\n",
    "  --training_mode=\"reconstruction\" \\\n",
    "  --labeled_tune_thresh=True \\\n",
    "  --num_time_anom_thresh=300 \\\n",
    "  --num_feat_anom_thresh=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning of reconstruction hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile hyperparam_reconstruction.yaml\n",
    "trainingInput:\n",
    "  scaleTier: STANDARD_1\n",
    "  hyperparameters:\n",
    "    hyperparameterMetricTag: rmse\n",
    "    goal: MINIMIZE\n",
    "    maxTrials: 30\n",
    "    maxParallelTrials: 1\n",
    "    params:\n",
    "    - parameterName: enc_lstm_hidden_units\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: [\"64 32 16\", \"256 128 16\", \"64 64 64\"]\n",
    "    - parameterName: dec_lstm_hidden_units\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: [\"16 32 64\", \"16 128 256\", \"64 64 64\"]\n",
    "    - parameterName: lstm_dropout_output_keep_probs\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: [\"0.9 1.0 1.0\", \"0.95 0.95 1.0\", \"0.95 0.95 0.95\"]\n",
    "    - parameterName: dnn_hidden_units\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: [\"256 128 64\", \"256 128 16\", \"64 64 64\"]\n",
    "    - parameterName: train_batch_size\n",
    "      type: INTEGER\n",
    "      minValue: 8\n",
    "      maxValue: 512\n",
    "      scaleType: UNIT_LOG_SCALE\n",
    "    - parameterName: learning_rate\n",
    "      type: DOUBLE\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.1\n",
    "      scaleType: UNIT_LINEAR_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/anomaly_detection/hyperparam_reconstruction\n",
    "JOBNAME=job_anomaly_detection_hyperparam_reconstruction_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$PWD/anomaly_detection_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --config=hyperparam_reconstruction.yaml \\\n",
    "  --runtime-version=1.13 \\\n",
    "  -- \\\n",
    "  --train_file_pattern=gs://$BUCKET/anomaly_detection/data/train_norm_seq.csv \\\n",
    "  --eval_file_pattern=gs://$BUCKET/anomaly_detection/data/val_norm_1_seq.csv \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --seq_len=30 \\\n",
    "  --horizon=0 \\\n",
    "  --reverse_labels_sequence=True \\\n",
    "  --train_batch_size=32 \\\n",
    "  --eval_batch_size=32 \\\n",
    "  --train_steps=2000 \\\n",
    "  --start_delay_secs=60 \\\n",
    "  --throttle_secs=120 \\\n",
    "  --training_mode=\"reconstruction\" \\\n",
    "  --labeled_tune_thresh=True \\\n",
    "  --num_time_anom_thresh=300 \\\n",
    "  --num_feat_anom_thresh=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train error distribution variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/anomaly_detection/trained_model\n",
    "JOBNAME=job_anomaly_detection_calculate_error_distribution_statistics_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$PWD/anomaly_detection_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=1.13 \\\n",
    "  -- \\\n",
    "  --train_file_pattern=gs://$BUCKET/anomaly_detection/data/val_norm_1_seq.csv \\\n",
    "  --eval_file_pattern=gs://$BUCKET/anomaly_detection/data/val_norm_1_seq.csv \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --seq_len=30 \\\n",
    "  --train_batch_size=32 \\\n",
    "  --eval_batch_size=32 \\\n",
    "  --train_steps=2200 \\\n",
    "  --model_type=\"lstm_enc_dec_autoencoder\" \\\n",
    "  --reverse_labels_sequence=True \\\n",
    "  --enc_lstm_hidden_units=\"64 32 16\" \\\n",
    "  --dec_lstm_hidden_units=\"16 32 64\" \\\n",
    "  --lstm_dropout_output_keep_probs=\"0.9 0.95 1.0\" \\\n",
    "  --dnn_hidden_units=\"1024 256 64\" \\\n",
    "  --training_mode=\"calculate_error_distribution_statistics\" \\\n",
    "  --labeled_tune_thresh=True \\\n",
    "  --eps=\"1e-12\" \\\n",
    "  --num_time_anom_thresh=300 \\\n",
    "  --num_feat_anom_thresh=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune anomaly thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/anomaly_detection/trained_model\n",
    "JOBNAME=job_anomaly_detection_tune_anomaly_thresholds_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$PWD/anomaly_detection_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=1.13 \\\n",
    "  -- \\\n",
    "  --train_file_pattern=gs://$BUCKET/anomaly_detection/data/labeled_val_mixed_seq.csv \\\n",
    "  --eval_file_pattern=gs://$BUCKET/anomaly_detection/data/labeled_val_mixed_seq.csv \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --seq_len=30 \\\n",
    "  --train_batch_size=32 \\\n",
    "  --eval_batch_size=32 \\\n",
    "  --train_steps=2400 \\\n",
    "  --model_type=\"lstm_enc_dec_autoencoder\" \\\n",
    "  --reverse_labels_sequence=True \\\n",
    "  --enc_lstm_hidden_units=\"64 32 16\" \\\n",
    "  --dec_lstm_hidden_units=\"16 32 64\" \\\n",
    "  --lstm_dropout_output_keep_probs=\"0.9 0.95 1.0\" \\\n",
    "  --dnn_hidden_units=\"1024 256 64\" \\\n",
    "  --training_mode=\"tune_anomaly_thresholds\" \\\n",
    "  --labeled_tune_thresh=True \\\n",
    "  --num_time_anom_thresh=300 \\\n",
    "  --num_feat_anom_thresh=300 \\\n",
    "  --min_time_anom_thresh=2.0 \\\n",
    "  --max_time_anom_thresh=15.0 \\\n",
    "  --min_feat_anom_thresh=20 \\\n",
    "  --max_feat_anom_thresh=60 \\\n",
    "  --f_score_beta=0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"anomaly_detection\"\n",
    "MODEL_VERSION=\"v1\"\n",
    "MODEL_LOCATION=$(gsutil ls gs://$BUCKET/anomaly_detection/trained_model/export/exporter/ | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models create $MODEL_NAME --regions $REGION\n",
    "gcloud ml-engine versions create $MODEL_VERSION --model $MODEL_NAME --origin $MODEL_LOCATION --runtime-version 1.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNLABELED_CSV_COLUMNS = [\"tag_{0}\".format(tag) for tag in range(0, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled_test_mixed_sequences_array.shape = (12800, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "labeled_test_mixed_sequences_array = np.loadtxt(\n",
    "    fname=\"data/labeled_test_mixed_seq.csv\", dtype=str, delimiter=\",\")\n",
    "print(\"labeled_test_mixed_sequences_array.shape = {}\".format(\n",
    "    labeled_test_mixed_sequences_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels = ['1' '1' '1' '0' '0' '0' '1' '1' '1' '1']\n"
     ]
    }
   ],
   "source": [
    "number_of_prediction_instances = 10\n",
    "print(\"labels = {}\".format(\n",
    "  labeled_test_mixed_sequences_array[0:number_of_prediction_instances, -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local prediction from local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"tag_0\": \"0.69531315;1.13063381;1.46212831;0.72515986;-0.72285522;-0.48608379;0.66008214;1.39027465;0.84784508;0.15064029;-0.86813038;-0.19376341;1.33326618;1.22342092;0.73982218;-0.2687485;0.09466024;0.62380527;1.9415848;1.20261854;0.2626776;10.47418518;-0.73694674;8.68714408;-17.87462629;-8.19666606;-6.97080639;16.66439155;9.85067447;12.07285213\";\"tag_1\": \"0.46246721;1.98239347;-0.1224569;-0.38657805;1.81182516;1.03408165;-1.48166642;1.27670001;1.91766873;-0.58962765;-0.08759287;1.97567123;-0.44497447;-1.07307304;1.57404985;1.01763811;-0.83888524;1.25820476;2.03154979;-1.02087098;-0.16190532;-22.80037943;4.01040199;-10.56761472;21.24277391;-28.76669081;-9.91877985;8.1263494;17.63656283;6.75155559\";\"tag_2\": \"0.83586452;1.42071377;0.27984876;0.14046254;1.84246963;0.843375;-1.07942606;0.4688217;1.26009013;-0.37743756;0.0258541;1.16555777;0.84946758;-0.72737033;0.74098267;1.80826962;0.06362211;-0.43868715;1.2166949;0.28497154;-0.26348582;-13.79850614;11.03782568;-6.36478403;-13.46177157;15.49712164;5.01001882;-9.51763023;-16.77774528;20.42561615\";\"tag_3\": \"0.74390452;1.92560347;0.22207084;-0.95415575;1.05609213;2.57393237;-0.18518758;-1.02718177;1.57433792;2.0535059;-0.47719256;-0.84692429;1.92646145;1.70267046;-0.86601494;-0.33048165;2.05015344;0.67986642;-0.84139593;0.32709427;2.40334715;3.18328661;21.13453484;-5.98529535;24.80347973;-1.57661726;11.73650973;-18.1477837;22.55738228;-6.67760474\";\"tag_4\": \"3.01915072e-01;2.31332898e+00;-5.45217009e-01;-5.39524824e-01;1.79865613e+00;-3.59134973e-04;-6.80317702e-01;1.86590218e+00;1.28621946e+00;-1.32070497e+00;8.15005512e-01;1.68109784e+00;-6.31576853e-01;4.07883604e-02;2.59227204e+00;2.67542342e-01;-9.09099946e-01;1.64580659e+00;3.82030180e-01;-1.66405359e+00;8.97211472e-01;3.61637454e+01;-1.24419978e+01;-9.46690785e-01;-2.81479886e+01;1.02336044e+01;-2.85161288e+00;1.61043540e+01;8.19273921e+00;1.94679025e+01\"}\n",
      "{\"tag_0\": \"0.32659557;1.70834305;1.03658194;0.3728755;-0.14941015;0.17796767;0.5951484;1.56920624;0.51615289;0.24583007;-0.38862205;0.39999747;1.51814653;1.59409035;1.04761384;-0.28680096;0.02029794;0.92772286;1.43876813;1.10253889;0.15068011;-7.62973052;-4.12969105;10.53793039;-14.52386284;7.36346678;2.46009908;5.55724826;-8.49050709;-16.16093508\";\"tag_1\": \"0.23580937;2.29253464;-0.06410265;-0.58673404;1.60476811;0.45939014;-0.83243642;1.30604201;1.79073091;-0.75671679;-0.23865647;2.13701905;-0.20404476;-0.90013159;1.63769963;0.68552713;-0.91879876;0.88843976;2.07360963;-0.18968242;-0.38795707;38.98802874;-8.59332318;-11.05998211;-9.14155513;-12.30762032;-15.27292428;-0.21332125;-21.08292712;3.67080665\";\"tag_2\": \"0.53898411;1.48614147;0.15182079;0.16628258;1.08577347;0.83660671;-0.9229579;1.07668101;1.97370765;0.06846435;-0.53254714;1.9344981;0.80394988;-0.48938679;0.67829763;1.53840162;-0.21384718;0.21105341;1.94280978;-0.06060416;-0.63002577;-10.53559023;15.13786772;8.06955406;-1.93710853;15.20979572;-1.29045997;3.27617933;20.11280679;7.05304747\";\"tag_3\": \"0.91923183;2.4696539;0.29687597;-1.70585032;1.12187305;2.14367297;-0.15159792;-1.51824127;1.71190298;1.56119722;-0.92716414;-0.35227766;1.72773322;1.02898934;-0.62754116;-0.42707799;2.56078479;1.10831855;-1.26357448;0.1537006;2.64076427;5.9679612;-22.80912306;-10.29589466;15.65951098;4.58556242;-12.16807704;21.67647833;27.45761979;1.64627241\";\"tag_4\": \"0.18910473;2.20997581;-0.33265955;-0.78181711;1.92231801;-0.15528367;-0.64268762;2.22552325;1.70556734;-0.86880577;1.24764031;1.85403894;-0.76681031;-0.36240673;1.90436684;0.1317081;-0.781419;1.80111391;0.98559643;-1.38588407;1.05226066;28.33329087;9.50898734;4.01013892;33.04181327;6.91534048;10.58686405;-31.30403426;-0.29243753;-24.4484404\"}\n",
      "{\"tag_0\": \"0.85767654;1.63733634;1.41421623;0.44501659;-0.24336809;0.23882574;1.06528387;1.95472939;1.27742764;0.34756755;-0.86624914;0.28404749;1.72714028;1.84856175;1.03084215;-0.21563853;-0.22353935;0.43196623;1.83376625;1.06434528;0.5779875;-4.23935305;-2.53658408;-25.65199155;-13.27001947;15.48234602;0.45527009;7.09655924;0.45129342;34.9165641\";\"tag_1\": \"3.60208809e-01;1.48878715e+00;-4.88659578e-01;-2.97910948e-03;2.03330313e+00;1.00785333e+00;-1.17375668e+00;1.12480746e+00;1.62411507e+00;-1.18767924e+00;-1.88131255e-01;2.40954837e+00;4.61751638e-01;-7.03898791e-01;1.98659387e+00;8.50067252e-01;-1.22548044e+00;7.01338817e-01;1.64464016e+00;-4.82483620e-01;1.05571102e-01;-2.26120651e+01;-5.35210672e+00;1.59274588e+01;-3.16803290e+01;-2.10968785e+01;-1.43673800e+01;1.90070293e+00;-1.81892234e+01;1.99484709e+00\";\"tag_2\": \"0.69752995;1.96984006;0.43619183;-0.43336307;1.56161897;0.45212722;-0.24252803;1.20878174;1.64463636;-0.47902834;-0.10869425;1.5614367;0.62219643;-0.74612635;0.99550083;1.56355351;0.05909044;-0.11045648;1.53579786;0.09329922;-0.73473282;15.68350507;9.66280854;14.01627946;-0.21601275;33.36422512;-2.45692468;6.47927727;15.23534979;-27.58976286\";\"tag_3\": \"1.61407591e-01;1.79372033e+00;-1.79569480e-01;-1.04572426e+00;7.97587718e-01;1.73738440e+00;-1.58413852e-01;-1.01295556e+00;1.41568672e+00;1.67998114e+00;-3.22093314e-01;-1.18274717e+00;1.47636213e+00;1.48139338e+00;-1.39143076e+00;-2.50517976e-01;1.85131865e+00;1.07011331e+00;-1.26744483e+00;1.39153755e-03;2.50137190e+00;1.42456684e+00;1.93695886e+01;-9.99844704e+00;-3.75199048e+01;4.34352954e+00;-1.16131878e+01;1.64406215e+01;2.48232398e+01;3.89101266e+00\";\"tag_4\": \"0.96154405;2.61790029;-0.21990943;-0.57554296;2.63910371;0.71663478;-1.50014004;1.52711577;1.28862749;-1.43790625;1.3049176;1.62409377;-0.51825785;-0.24798188;2.02282833;0.37753285;-1.24196955;2.1219236;1.06636617;-1.64433636;1.67845645;-31.65370822;15.50012171;11.31080011;-40.79315563;10.84507342;-6.51981199;-31.33620742;-4.53585886;-8.15189857\"}\n",
      "{\"tag_0\": \"0.45517797;1.02124947;1.45611902;0.37539319;-0.72964357;-0.03092467;0.66670521;1.85846744;1.31654568;-0.02950217;-0.1556246;-0.12983188;0.95568528;1.72813256;0.45453849;-0.49440549;-0.5934403;0.50361394;1.94521325;1.19283138;0.4666996;-0.93186907;0.27137676;0.63282559;1.7557703;0.44028565;-0.52814927;-0.30912607;0.30759779;1.22239428\";\"tag_1\": \"0.82344263;1.58016627;0.10915432;-0.18050275;2.16363917;0.49626086;-1.15851593;0.94761217;1.87188779;-0.3808242;-0.06394783;1.61701797;0.39965263;-0.50287863;2.13545296;0.72973059;-0.54160089;0.94301818;1.53996495;-0.85958407;-0.29411346;2.16826087;0.55470961;-0.42485955;1.09374362;1.2154349;-0.52638442;0.62391114;1.75993086;-0.45052393\";\"tag_2\": \"0.90667709;1.66869666;0.23361695;-0.65774366;1.32249593;1.19116517;-1.07967487;1.21064935;1.06091562;0.04563317;0.26999543;1.32296346;0.17260656;-0.69465092;1.25234289;1.55233989;-0.64010597;0.27775929;1.52706088;0.17468853;-0.27993568;1.03044926;0.74703809;-0.38563179;0.0212343;1.78287403;0.03286677;-0.84712259;1.14287051;0.70488673\";\"tag_3\": \"0.75148341;1.96718;-0.17821641;-0.8256825;1.22026722;2.32257165;0.16819824;-0.80782651;1.91172633;1.92738579;-0.29934958;-1.12350993;2.31933239;1.08103608;-0.84626352;-0.75043083;1.98573651;1.00857024;-1.70488203;-0.05720264;2.20746135;0.72890683;-1.73739143;1.27655865;1.7683288;0.04172774;-1.19000858;1.01429612;1.80961455;-0.18049512\";\"tag_4\": \"0.01244405;1.91113385;-0.5819165;-0.28986305;2.51312038;0.54356912;-0.62576478;1.78551184;1.22646749;-1.03396626;1.13674476;2.24975166;-1.08517893;0.07476933;2.40095954;0.17596255;-0.44935642;1.62027744;0.69308584;-0.94738423;0.94294319;2.07981761;-0.92849586;0.22983808;2.18907516;-0.47296219;-0.32191314;2.63224636;-0.02013369;-1.01470332\"}\n",
      "{\"tag_0\": \"0.17181336;1.33551142;1.59245333;0.45573682;-0.09430236;-0.02146308;1.06439321;1.28677485;1.25939374;-0.33099706;-1.0063076;0.06761497;1.49455815;1.29858626;0.89440364;-0.15941468;-0.10882161;0.61011478;1.80884028;1.01206605;-0.25487306;-0.05395416;-0.18368158;1.14673133;1.53117496;0.35818351;0.06032439;-0.10844228;0.22034885;1.28586095\";\"tag_1\": \"0.31998296;1.70154893;-0.47868641;-0.67520758;1.65216464;0.82344132;-1.45105255;1.0324313;1.55524177;-1.12943866;0.24059404;2.03249645;0.45291042;-0.73546439;1.39335909;1.21092307;-1.37143479;1.21166023;2.05952505;-0.90551399;-0.42319744;2.04384704;0.17970919;-1.25199932;1.64865898;1.84962178;-0.68763444;0.60540564;2.21812988;0.02769404\";\"tag_2\": \"0.85581872;1.89524011;-0.45872456;-0.28310331;1.41032649;0.83587205;-0.15393482;0.90208275;1.98575938;-0.03146615;-0.49296257;1.09522469;0.18523139;-0.76580604;0.72058259;1.64249685;-0.81494654;0.01557976;1.66545988;-0.07638955;-0.10339073;1.58841878;0.93285617;-0.7463028;0.36338133;1.60395596;-0.13757574;-0.49529755;1.5426722;1.07202239\";\"tag_3\": \"0.31718891;2.17783802;0.45737963;-1.59985962;1.46860227;1.87215944;0.02971402;-0.71324433;1.49735846;2.06010211;-0.53565274;-0.55399286;1.93424762;1.14758581;-0.85642347;-0.73587345;2.48507302;0.6264022;-1.04567742;-0.18264689;2.25852064;0.15816768;-1.38937694;1.25377487;1.92590876;0.20701733;-1.56393675;1.72428073;2.39324021;-0.01653834\";\"tag_4\": \"0.11033411;2.51909349;-0.26284319;-0.62751845;2.69717895;0.38807364;-1.13074351;1.57956272;1.29169151;-1.43206157;1.18178764;2.4695817;-0.90564013;-0.2447061;2.76461623;-0.04479748;-1.09327745;1.96776962;0.74760738;-1.3105693;1.42153679;1.55155792;-0.95676245;0.59545794;2.00417514;-0.41124897;-0.99365571;2.31837632;0.89953785;-1.2764112\"}\n",
      "{\"tag_0\": \"0.58686315;1.27991911;1.42252709;0.48987633;-0.38464696;-0.2389153;0.9070687;2.03024924;0.91756811;0.32166405;-0.07089616;0.18093941;1.32650014;1.41697795;0.90202306;-0.00499395;-0.02176243;0.61217752;2.00176705;1.03325327;0.56271003;-0.88538415;0.00366124;1.1120963;1.46986362;1.10214919;-0.13908198;-0.08485155;-0.09214516;1.56208542\";\"tag_1\": \"0.47758707;2.17613628;-0.5536095;-0.90268644;1.94064727;0.9566802;-1.24040603;1.22286882;1.64647882;-0.48314756;-0.12774327;2.49285671;0.42578928;-0.73133311;2.19028753;0.98069583;-0.77851445;0.50888166;1.42813718;-0.81029604;-0.28103167;1.81169399;0.45822417;-0.77523377;1.6642782;1.79657662;-0.66003356;0.26483423;1.65175203;-0.57617348\";\"tag_2\": \"0.27632541;1.3259891;-0.01698105;-0.6080404;1.53436066;1.25344672;-1.08750704;0.9417666;1.76355259;-0.35234805;-0.28299357;1.42343524;0.25838185;-0.47134628;0.9902623;1.20197932;-0.1441354;0.39207169;1.21534727;0.59383335;-0.94995983;1.57334655;1.50603034;-0.32585311;0.37420638;1.44511709;0.43080681;-0.0057029;1.28402611;1.23339387\";\"tag_3\": \"0.2731434;2.68454365;0.51596552;-0.8007488;1.01152121;2.17749522;0.1446247;-1.46459661;1.12518437;1.77201779;-0.90553643;-0.99454472;1.53227442;1.23344781;-1.53416443;-0.02376392;1.70736288;1.33269835;-1.57884304;-0.21835789;2.2222712;0.39702671;-1.08549704;0.42453942;2.65539394;0.30261504;-1.4374645;1.42076204;1.79379544;-1.00518648\";\"tag_4\": \"0.89484613;1.95815281;-0.41665477;-0.71573516;2.05418792;-0.06515335;-0.6753446;1.73727343;0.89249232;-0.97478849;1.03968971;2.07474821;-1.218766;-0.45836379;2.16477731;-0.40632322;-0.73908489;1.63789047;0.65199463;-1.18052222;1.69898186;1.68040472;-1.50206223;0.02654646;2.09376287;-0.30198348;-0.49576912;2.45655073;0.2922704;-1.63747885\"}\n",
      "{\"tag_0\": \"0.68274728;1.35574408;1.08701665;0.7540707;-0.07094747;-0.64376172;0.4532093;1.54226877;1.02799626;-0.55486957;-1.01003173;0.38446063;0.98417685;1.11860503;0.98870804;-0.76981994;0.06731276;0.8982164;1.3091531;0.81095882;-0.22436569;-11.21603242;8.19183008;9.39583342;-15.63025345;-17.2949048;0.55077907;7.32351525;0.4378029;21.34937162\";\"tag_1\": \"0.9814846;1.8816111;-0.57815882;-0.65202549;1.50627635;0.22681144;-1.19353806;0.72599849;1.86746932;-0.7780742;0.33690984;2.48846523;-0.32394314;-1.20357102;1.51111945;0.91385185;-0.83642535;1.2879764;1.72979544;-0.66028164;0.07890131;21.68877666;14.47623079;-15.2975203;-18.80821572;-16.29315729;7.1710363;-8.64157371;30.00364911;-0.95202684\";\"tag_2\": \"0.4877794;1.97375487;0.10856565;-0.02139395;1.78964671;1.16281048;-1.11589792;0.67678001;1.49389353;-0.39899146;0.26720234;1.07622426;0.57910259;-0.99255698;1.36391551;1.19156059;-0.74439798;0.35148004;1.60851755;0.75201479;-0.78489665;-13.02266312;-15.87018459;-2.21312483;-6.63111378;13.09518485;-1.3523901;9.14479749;-15.83866688;-14.64962189\";\"tag_3\": \"0.39262499;1.84248455;0.66538568;-0.97448947;0.72875554;2.45774084;-0.28575535;-1.15228513;1.21421017;1.65466837;-0.4538717;-0.23903848;1.53606024;1.47727536;-1.49612339;-0.15404219;2.16540269;1.00151033;-0.95500716;0.63388964;2.11757311;-4.20139966;16.27616106;-11.25169115;28.87306415;5.51829928;15.10583954;20.57482225;-38.67354421;-1.56985649\";\"tag_4\": \"4.26564251e-01;1.74101992e+00;-2.58210896e-01;3.17557990e-02;1.91949937e+00;2.23712909e-01;-1.54533677e+00;1.79438470e+00;9.75111404e-01;-1.20687008e+00;1.25639342e+00;1.66799389e+00;-8.24974944e-01;-9.17013845e-02;1.98139771e+00;9.28336236e-02;-5.57871130e-01;1.66814929e+00;9.39769195e-01;-1.65626805e+00;1.21962795e+00;-1.57535828e+01;-1.16882027e+01;-2.28619214e+00;-3.71850730e+01;-8.39710862e-01;-2.51122193e+00;2.77029736e+01;-3.36760168e+00;-1.70928936e+01\"}\n",
      "{\"tag_0\": \"0.55925174;1.82829847;0.87750684;0.64970464;-0.49876772;-0.65837145;1.40602193;1.95820938;0.93219723;-0.59573272;-0.4764096;0.66128721;1.49629899;1.04926079;0.14548558;-0.68989177;0.07807339;0.92859821;1.68011135;0.8626833;0.08425844;-7.65805084;-5.62735753;-26.38152838;10.47953417;9.72711029;0.83269728;-18.32732795;-0.370429;27.14276846\";\"tag_1\": \"0.7314032;1.56654327;-0.31453104;-0.19732422;1.7894363;0.74613204;-1.25493317;0.95032056;1.40367202;-0.66865971;0.52837807;1.76364772;0.47365985;-0.83440272;2.17525217;1.36908003;-0.8534343;0.7586044;2.19748486;-1.0036567;0.10850088;20.49705933;-7.15665685;14.78527972;-25.6732667;-19.99979727;-9.94979305;-6.76538506;-21.38895225;3.85085308\";\"tag_2\": \"0.6873656;1.41044625;-0.49149215;-0.10505723;1.40526937;0.62151958;-0.70315306;0.50979184;1.08277699;-0.40880139;-0.59467932;1.32652526;0.82899361;-0.23899564;1.05688937;1.19949119;-0.13443461;0.46242193;1.26306342;0.5881876;-0.85575647;15.01524181;16.46347718;0.25240478;5.15019525;-20.46997992;11.84676103;13.52466198;10.38231323;-27.73356774\";\"tag_3\": \"0.06465722;2.41284728;0.59387048;-0.99871948;1.49286027;2.0173956;-0.47215554;-1.36953125;1.91552966;1.679495;-0.32414028;-0.72687935;1.40797732;1.67034206;-1.02111285;-0.55945292;2.60799967;0.72132548;-1.13894695;-0.04191595;1.95852994;6.89638285;16.54570294;3.36073562;17.67014438;-1.31969121;-17.08019722;-18.89289947;18.50914208;9.54449453\";\"tag_4\": \"1.03392991e-01;1.74551912e+00;-1.69304576e-01;1.79643026e-03;2.05635877e+00;2.66894161e-01;-8.47228773e-01;1.88905496e+00;1.02522324e+00;-1.19916183e+00;1.24098261e+00;1.53099111e+00;-6.94633279e-01;-4.90001253e-02;2.13625392e+00;-5.62751556e-01;-4.91056891e-01;2.24119155e+00;9.98262988e-01;-1.54452305e+00;1.76856530e+00;-1.60440508e+01;1.64594460e+01;-5.42271615e+00;2.47765005e+01;-1.24006025e+01;-1.88346267e+01;-2.81747347e+01;6.86336726e+00;-2.33428262e+01\"}\n",
      "{\"tag_0\": \"0.32545143;1.5194965;1.21693154;-0.18534988;-0.8099424;-0.10557138;1.3504185;1.06301203;0.97053949;0.12151303;-0.94128024;-0.23346417;1.62409508;1.08526752;0.23511941;-0.27786835;-0.80988861;0.57809225;1.327797;0.75310073;-0.3688385;-6.93762881;5.60543661;8.63238081;19.64096416;-6.83633187;9.67804192;6.63396728;-2.97426318;-12.23564656\";\"tag_1\": \"0.15716835;2.00620553;0.12904877;-0.50504456;1.83560186;0.99062713;-0.78935528;1.03394105;2.10286109;-1.17361043;0.47834675;1.82286926;0.3563198;-0.64715512;1.24278807;0.82933368;-1.34378266;1.15290279;1.34714507;-0.78687303;-0.31217761;-19.66216483;11.63218756;-20.95092568;29.070461;-15.85852335;16.24067349;2.87319307;41.18184521;1.27498142\";\"tag_2\": \"0.27351636;1.58312744;-0.02979228;0.02810493;1.17391101;0.96770706;-0.2587417;0.94621802;1.5333258;0.20375701;0.27209905;1.44069378;0.48344005;-1.02804084;0.46732773;1.10082146;-0.36483811;-0.19187776;1.49852063;0.36182817;-0.33532654;-13.75735029;21.79984613;13.10540645;9.64697676;-25.57654641;-6.16969637;7.98340791;14.83828602;11.19102682\";\"tag_3\": \"0.39373851;2.08785678;0.5534782;-0.84405175;0.89649926;2.11607735;0.02323814;-0.69977682;1.42702734;2.0979925;-0.98343466;-0.67365259;2.12490749;1.07380313;-1.39150689;-0.34547585;1.67715509;0.83481965;-0.99871306;0.41699153;2.13024693;16.30493629;-20.12016434;-13.95221058;18.40843017;-2.54016959;-7.89056471;-16.48855085;-21.60034908;-6.26330408\";\"tag_4\": \"0.78521014;2.48261421;-1.05975471;-0.70813239;1.83769761;0.17926454;-1.30469229;1.33576307;1.66423118;-1.74808253;1.385292;2.24803209;-1.35200869;-0.43971377;2.53675332;0.06863259;-1.00753921;2.10482032;0.43833329;-0.84927696;1.13328031;-27.11115974;-17.87512786;-0.11508594;17.50402375;5.07729378;10.35053954;-17.48106327;0.15658772;16.05720621\"}\n",
      "{\"tag_0\": \"0.96566257;1.11975954;1.18105921;0.06356424;-0.75485578;0.06621564;0.46006993;1.30128046;0.79593133;0.36352791;-0.62654413;0.02682026;1.09512875;1.14307279;0.71165903;-0.89686119;-0.46289551;0.69002904;1.5714267;0.79098489;0.57307643;11.35341564;-0.90552259;21.34489259;18.25158658;-13.46879385;1.6570299;-0.96097341;7.06806218;-12.97623268\";\"tag_1\": \"0.17202193;1.7202725;0.11327513;-0.41814951;2.22389967;0.26097971;-1.40399151;0.77095797;2.10707929;-0.99731955;-0.1774563;2.22616186;0.31798527;-0.34254922;1.97163118;0.62506475;-1.45142854;0.97544497;1.65759909;-0.47004323;-0.35010933;-24.87357133;9.63978832;12.05834358;21.6536439;14.2672347;9.03728373;0.55752399;22.6352191;1.93053125\";\"tag_2\": \"0.95749459;1.89585675;0.17033552;-0.60242864;1.11346079;0.90018007;-0.95107862;0.93231585;1.8760192;-0.54110837;-0.24375787;1.58821742;0.51345112;-0.78094126;1.35138898;0.93586365;-0.71789995;0.20427924;2.0670912;0.14505794;-0.96710125;8.62707495;11.43356176;2.9773854;1.72782367;21.87751608;-4.36436294;12.15437215;10.07217467;-26.21803208\";\"tag_3\": \"3.59059400e-02;2.12190068e+00;-1.48142453e-01;-1.32365427e+00;7.87992235e-01;1.75621129e+00;-3.30798270e-02;-6.86487005e-01;1.57076249e+00;1.62353695e+00;-5.01166029e-01;-1.17651177e+00;1.52622463e+00;1.39533483e+00;-1.03309229e+00;-3.78553612e-01;2.24258499e+00;8.29298659e-01;-1.69949051e+00;3.92291150e-01;2.36682019e+00;-1.66577145e+01;1.52195409e+01;-1.45681286e+01;-4.81979620e+01;3.56492166e+00;-7.04477511e+00;1.63277097e+01;-4.69053139e+01;-2.19434733e+00\";\"tag_4\": \"0.91232029;2.49751837;-0.42256534;-0.86146102;2.64788065;0.57833072;-1.48502489;1.71731149;1.15948681;-1.21051282;0.60162524;1.99225665;-1.29820605;0.07678027;2.06260276;-0.06430074;-1.32310193;2.00861243;1.32755604;-1.40879236;0.90898306;20.57738827;-12.65953901;6.01538405;26.24660643;8.91259197;-1.39645758;36.85885587;-0.76831274;17.59336383\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('test_sequences.json', 'w') as outfile:\n",
    "  test_data_normal_string_list = labeled_test_mixed_sequences_array.tolist()[0:number_of_prediction_instances]\n",
    "  json_string = \"\"\n",
    "  for example in test_data_normal_string_list:\n",
    "    json_string += \"{\" + ';'.join([\"{0}: \\\"{1}\\\"\".format('\\\"' + UNLABELED_CSV_COLUMNS[i] + '\\\"', example[i]) \n",
    "                                   for i in range(len(UNLABELED_CSV_COLUMNS))]) + \"}\\n\"\n",
    "  json_string = json_string.replace(' ', '').replace(':', ': ').replace(',', ', ')\n",
    "  print(json_string)\n",
    "  outfile.write(\"%s\" % json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_FEAT_ABS_RECON_ERR                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              X_TIME_ABS_RECON_ERR                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              FEAT_ANOM_FLAGS  MAHALANOBIS_DIST_FEAT                                                                                 MAHALANOBIS_DIST_TIME                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           TIME_ANOM_FLAGS\n",
      "[[0.1926741961027786, 0.1667347751460374, 0.17550509834900457, 0.30572248923001755, 0.25509870801441037], [1.8452688438972216, 1.5357610548539626, 1.8443692583490046, 1.4408043392300176, 1.5264206619855898], [1.0776408361027787, 0.049269825146037394, 0.47200314834900453, 0.2202230592300175, 1.2346244419855896], [0.6532002261027786, 1.3927879851460374, 0.7831515416509955, 0.9762840607699824, 0.9944916580144103], [1.8647436738972216, 0.0468711651460374, 0.20261862834900457, 0.24964414923001754, 0.5807100980144104], [0.04355763389722142, 1.0457312448539626, 0.9276045483490045, 1.2237218492300175, 1.2211619219855896], [0.8271814161027786, 0.0037160548539625915, 0.16069455165099544, 0.33192224076998245, 1.7434376919855896], [1.3112568538972214, 1.1065483151460374, 0.9619237216509955, 1.1260507107699824, 0.7879754180144104], [0.9541468738972214, 0.3150634248539626, 1.3092150883490046, 0.5687425092300176, 1.5705447880144103], [1.7139318961027785, 1.6654802448539625, 1.3359362383490045, 1.5620822692300176, 0.17241390801441037], [1.6701016138972213, 0.9517798951460374, 0.19683213165099545, 0.20327602076998244, 1.8148302019855895], [0.6213453938972214, 1.2286771751460375, 0.8206294016509954, 0.8922178707699825, 0.3705800119855896], [1.5272472861027786, 0.6275426648539626, 0.9390527183490047, 1.1788054992300177, 1.2579829780144103], [0.6639105638972215, 1.4645747648539627, 1.0606658883490045, 1.4407830992300175, 1.4862752980144103], [1.8752612138972216, 0.6279155451460374, 0.6925058216509954, 0.44213779076998244, 1.0010560519855898], [0.7110855061027787, 1.0725833051460374, 0.37362783165099545, 0.9118745707699825, 1.2970471419855896], [0.1796243861027786, 1.5435322748539626, 1.1116840083490047, 1.1114605092300176, 0.12414857801441037], [2.049584123897221, 1.4713639848539626, 0.10985849834900457, 1.6106514392300175, 1.1490879280144104], [0.8662556461027786, 1.1242113551460373, 0.8873522216509955, 0.8126018907699825, 0.2438245480144104], [0.8770765861027786, 0.7089091451460374, 0.002478631650995433, 0.5088930707699825, 1.94802641198559], [1.6013254538972215, 1.2569376748539625, 1.3555825283490046, 1.2737427192300175, 0.3485937619855896], [0.0848263861027786, 0.8874030648539626, 0.23482605834900455, 0.6419754792300175, 1.1123597480144103], [0.7626166161027785, 0.6975907251460374, 0.8964145716509955, 0.8012913407699824, 0.9700266980144103], [1.3103024138972215, 0.1657187051460374, 0.017276398349004574, 0.4904392507699824, 1.5542542919855897], [0.6525934938972214, 1.1284491548539626, 1.2608225183490047, 0.9790208392300175, 1.6107726219855896], [1.5841433661027786, 0.5491697448539625, 0.12370614165099544, 1.0461526292300176, 0.4496923480144104], [0.5921354938972214, 0.9188944851460374, 0.5960266216509955, 0.9373658207699824, 1.8761910980144103], [1.0459756138972214, 0.3144259351460374, 0.7544732483490046, 0.38454837076998244, 0.13808969198558962], [1.1858027061027787, 1.1786425648539625, 1.3530159883490047, 1.0243338092300176, 1.7652765619855895], [0.48243077389722144, 0.5510978848539627, 0.13566872165099544, 0.7494427592300175, 0.8669449819855897]]  [[0.1926741961027786, 0.1667347751460374, 0.17550509834900457, 0.30572248923001755, 0.25509870801441037], [1.8452688438972216, 1.5357610548539626, 1.8443692583490046, 1.4408043392300176, 1.5264206619855898], [1.0776408361027787, 0.049269825146037394, 0.47200314834900453, 0.2202230592300175, 1.2346244419855896], [0.6532002261027786, 1.3927879851460374, 0.7831515416509955, 0.9762840607699824, 0.9944916580144103], [1.8647436738972216, 0.0468711651460374, 0.20261862834900457, 0.24964414923001754, 0.5807100980144104], [0.04355763389722142, 1.0457312448539626, 0.9276045483490045, 1.2237218492300175, 1.2211619219855896], [0.8271814161027786, 0.0037160548539625915, 0.16069455165099544, 0.33192224076998245, 1.7434376919855896], [1.3112568538972214, 1.1065483151460374, 0.9619237216509955, 1.1260507107699824, 0.7879754180144104], [0.9541468738972214, 0.3150634248539626, 1.3092150883490046, 0.5687425092300176, 1.5705447880144103], [1.7139318961027785, 1.6654802448539625, 1.3359362383490045, 1.5620822692300176, 0.17241390801441037], [1.6701016138972213, 0.9517798951460374, 0.19683213165099545, 0.20327602076998244, 1.8148302019855895], [0.6213453938972214, 1.2286771751460375, 0.8206294016509954, 0.8922178707699825, 0.3705800119855896], [1.5272472861027786, 0.6275426648539626, 0.9390527183490047, 1.1788054992300177, 1.2579829780144103], [0.6639105638972215, 1.4645747648539627, 1.0606658883490045, 1.4407830992300175, 1.4862752980144103], [1.8752612138972216, 0.6279155451460374, 0.6925058216509954, 0.44213779076998244, 1.0010560519855898], [0.7110855061027787, 1.0725833051460374, 0.37362783165099545, 0.9118745707699825, 1.2970471419855896], [0.1796243861027786, 1.5435322748539626, 1.1116840083490047, 1.1114605092300176, 0.12414857801441037], [2.049584123897221, 1.4713639848539626, 0.10985849834900457, 1.6106514392300175, 1.1490879280144104], [0.8662556461027786, 1.1242113551460373, 0.8873522216509955, 0.8126018907699825, 0.2438245480144104], [0.8770765861027786, 0.7089091451460374, 0.002478631650995433, 0.5088930707699825, 1.94802641198559], [1.6013254538972215, 1.2569376748539625, 1.3555825283490046, 1.2737427192300175, 0.3485937619855896], [0.0848263861027786, 0.8874030648539626, 0.23482605834900455, 0.6419754792300175, 1.1123597480144103], [0.7626166161027785, 0.6975907251460374, 0.8964145716509955, 0.8012913407699824, 0.9700266980144103], [1.3103024138972215, 0.1657187051460374, 0.017276398349004574, 0.4904392507699824, 1.5542542919855897], [0.6525934938972214, 1.1284491548539626, 1.2608225183490047, 0.9790208392300175, 1.6107726219855896], [1.5841433661027786, 0.5491697448539625, 0.12370614165099544, 1.0461526292300176, 0.4496923480144104], [0.5921354938972214, 0.9188944851460374, 0.5960266216509955, 0.9373658207699824, 1.8761910980144103], [1.0459756138972214, 0.3144259351460374, 0.7544732483490046, 0.38454837076998244, 0.13808969198558962], [1.1858027061027787, 1.1786425648539625, 1.3530159883490047, 1.0243338092300176, 1.7652765619855895], [0.48243077389722144, 0.5510978848539627, 0.13566872165099544, 0.7494427592300175, 0.8669449819855897]]  0                [5.779162381961459, 5.138791234001083, 5.26259426575918, 3.6899269976051037, 5.789651007925731]       [2.442493101704649, 2.546271489936297, 1.8514733502088236, 1.5269396316628294, 2.52957103496651, 1.9205411685893952, 2.305912288317667, 1.0863633594333606, 2.3649180487766777, 2.877720954327283, 2.7297099297686627, 1.7680708096079414, 1.7869090993687649, 1.6404831963360949, 1.7386071953952542, 1.4470205045488491, 2.7453307194861005, 3.736256776288349, 1.6908925994514539, 2.210165885606912, 2.112461215228318, 2.0959436054293894, 0.7350843718133653, 2.162456962838539, 1.3656942737585436, 2.6312422396732957, 1.5211612964377095, 1.953281577839982, 1.4655687389094967, 1.7910963244133324]   1\n",
      "[[0.5461502238972215, 0.07020584485396258, 0.24764685165099543, 0.14581918923001758, 0.1640371719855896], [1.9862937338972213, 1.0264628048539626, 1.1019568283490047, 1.6381537192300175, 2.0737017519855896], [0.5030010761027786, 0.23329847485396266, 0.005912021650995414, 0.25259966923001753, 0.5487188319855896], [0.023578233897221385, 1.6080784651460374, 0.9153716816509954, 0.6890838707699825, 1.5806724180144103], [1.5829907838972215, 0.3149382348539626, 0.6543385683490046, 0.7209160392300176, 0.7674890280144104], [0.3301557061027786, 1.0570948248539624, 1.0213207383490046, 1.1840306192300176, 1.5895690719855897], [0.6962732461027786, 0.4378172851460374, 0.7227889116509955, 0.05344744923001754, 1.4347914819855896], [1.2450555638972214, 1.3740013451460376, 0.6961842916509955, 0.8561158807699825, 0.8607586880144105], [0.17150689389722137, 1.0859872148539627, 1.2029293483490047, 1.0456324392300176, 1.9859322880144104], [1.1958155461027786, 1.0629815748539626, 1.6319331083490045, 1.3073447292300175, 0.3295514519855896], [1.6811772538972214, 0.3051085151460374, 1.1235583116509955, 0.034128550769982446, 2.2758949219855893], [0.9510969338972215, 0.8867590651460373, 0.6581743116509955, 0.6857052607699825, 0.9607366019855896], [1.7481528361027785, 0.9042470548539625, 1.5700609383490047, 0.6600816092300176, 1.8579691280144104], [0.1951867838972214, 1.6231808148539626, 1.1787977183490046, 1.1798989792300176, 1.2086024180144104], [1.8264575138972214, 0.6750935851460373, 0.6438113816509954, 0.11541453076998245, 1.2330289519855897], [1.3533445361027785, 1.2534784551460374, 0.24618950165099543, 1.1349859307699823, 1.7132965919855898], [0.1112577161027786, 1.4784438748539626, 1.0205981783490046, 1.2995097392300174, 0.18263322801441037], [2.251712393897221, 1.3519461148539627, 0.8542009183490047, 1.5771632092300176, 1.5317940880144103], [0.7343655261027786, 1.2773792251460374, 0.9397885916509954, 0.7371911107699824, 0.28806988801441036], [0.5011952361027786, 0.2510466651460374, 0.06490995834900459, 0.6835378107699824, 1.4657911019855896], [1.3887915938972215, 0.9717572248539625, 1.8242847383490048, 0.8370914892300176, 0.7188814519855897], [0.14163227610277862, 0.3824079848539626, 0.10230242834900455, 0.7940963092300175, 1.4203928280144102], [1.6006841661027786, 0.8679576251460375, 1.3952377116509953, 1.0594358707699825, 1.1522734480144103], [1.3035188838972214, 0.6862079151460374, 0.8440557883490045, 0.7949088507699824, 1.0860329319855897], [1.1151059338972213, 1.5113741248539625, 1.1417524883490047, 1.1018773092300176, 1.8210951019855897], [0.9830720461027785, 0.8539154748539626, 0.28109014165099544, 0.8744357692300175, 0.21844388801441036], [0.4002954638972215, 0.8043383051460373, 0.8689960216509955, 0.7993723807699824, 1.2693867580144105], [1.3649306238972214, 0.5300436151460374, 1.2076450083490047, 0.28356678076998243, 0.08369178801441035], [0.7456624161027786, 1.9070171248539625, 0.9206814883490047, 0.8715904192300175, 2.0410025119855892], [0.05623465610277861, 0.7667192748539626, 0.13388724165099544, 1.0795210592300175, 0.5844770719855896]]     [[0.5461502238972215, 0.07020584485396258, 0.24764685165099543, 0.14581918923001758, 0.1640371719855896], [1.9862937338972213, 1.0264628048539626, 1.1019568283490047, 1.6381537192300175, 2.0737017519855896], [0.5030010761027786, 0.23329847485396266, 0.005912021650995414, 0.25259966923001753, 0.5487188319855896], [0.023578233897221385, 1.6080784651460374, 0.9153716816509954, 0.6890838707699825, 1.5806724180144103], [1.5829907838972215, 0.3149382348539626, 0.6543385683490046, 0.7209160392300176, 0.7674890280144104], [0.3301557061027786, 1.0570948248539624, 1.0213207383490046, 1.1840306192300176, 1.5895690719855897], [0.6962732461027786, 0.4378172851460374, 0.7227889116509955, 0.05344744923001754, 1.4347914819855896], [1.2450555638972214, 1.3740013451460376, 0.6961842916509955, 0.8561158807699825, 0.8607586880144105], [0.17150689389722137, 1.0859872148539627, 1.2029293483490047, 1.0456324392300176, 1.9859322880144104], [1.1958155461027786, 1.0629815748539626, 1.6319331083490045, 1.3073447292300175, 0.3295514519855896], [1.6811772538972214, 0.3051085151460374, 1.1235583116509955, 0.034128550769982446, 2.2758949219855893], [0.9510969338972215, 0.8867590651460373, 0.6581743116509955, 0.6857052607699825, 0.9607366019855896], [1.7481528361027785, 0.9042470548539625, 1.5700609383490047, 0.6600816092300176, 1.8579691280144104], [0.1951867838972214, 1.6231808148539626, 1.1787977183490046, 1.1798989792300176, 1.2086024180144104], [1.8264575138972214, 0.6750935851460373, 0.6438113816509954, 0.11541453076998245, 1.2330289519855897], [1.3533445361027785, 1.2534784551460374, 0.24618950165099543, 1.1349859307699823, 1.7132965919855898], [0.1112577161027786, 1.4784438748539626, 1.0205981783490046, 1.2995097392300174, 0.18263322801441037], [2.251712393897221, 1.3519461148539627, 0.8542009183490047, 1.5771632092300176, 1.5317940880144103], [0.7343655261027786, 1.2773792251460374, 0.9397885916509954, 0.7371911107699824, 0.28806988801441036], [0.5011952361027786, 0.2510466651460374, 0.06490995834900459, 0.6835378107699824, 1.4657911019855896], [1.3887915938972215, 0.9717572248539625, 1.8242847383490048, 0.8370914892300176, 0.7188814519855897], [0.14163227610277862, 0.3824079848539626, 0.10230242834900455, 0.7940963092300175, 1.4203928280144102], [1.6006841661027786, 0.8679576251460375, 1.3952377116509953, 1.0594358707699825, 1.1522734480144103], [1.3035188838972214, 0.6862079151460374, 0.8440557883490045, 0.7949088507699824, 1.0860329319855897], [1.1151059338972213, 1.5113741248539625, 1.1417524883490047, 1.1018773092300176, 1.8210951019855897], [0.9830720461027785, 0.8539154748539626, 0.28109014165099544, 0.8744357692300175, 0.21844388801441036], [0.4002954638972215, 0.8043383051460373, 0.8689960216509955, 0.7993723807699824, 1.2693867580144105], [1.3649306238972214, 0.5300436151460374, 1.2076450083490047, 0.28356678076998243, 0.08369178801441035], [0.7456624161027786, 1.9070171248539625, 0.9206814883490047, 0.8715904192300175, 2.0410025119855892], [0.05623465610277861, 0.7667192748539626, 0.13388724165099544, 1.0795210592300175, 0.5844770719855896]]     0                [6.304617048731647, 6.138812581727021, 5.536883931690182, 5.552070689923312, 4.827559085510039]       [2.360807008150394, 2.958678839475689, 2.13561074863536, 2.921438181757887, 1.77887327464589, 1.6108030879178812, 2.0165830134119127, 1.6786687873575696, 2.2060358221844236, 2.2994951268630848, 3.383583928679968, 0.6198213856791773, 2.5491179019074903, 2.1758570035761062, 2.2303025227588105, 2.251728214402842, 2.6996775421714214, 2.830755392882346, 1.9923622595005384, 2.1616818522250076, 2.4264002660474246, 2.3628116441664853, 1.6893803401383172, 0.7248686234259698, 1.6421476586469892, 2.0759904104416345, 1.1312458015927636, 2.498209721109119, 3.0574787145809736, 2.6574772493101935]   0\n",
      "[[0.0940580861027786, 0.3451636651460374, 0.15590137165099544, 0.5015215992300176, 0.5545364519855895], [1.2908476238972215, 1.0769800848539626, 1.3266827483490047, 1.7620923192300175, 1.5970770819855897], [1.0964155661027786, 0.17415332485396257, 0.08137122834900457, 0.3673879992300175, 0.8331614419855897], [0.8073508361027786, 0.9929414851460374, 1.1749255716509954, 0.5507377407699825, 1.6590071780144102], [2.0866743438972213, 0.08304234485396261, 0.9758375383490046, 0.4452592292300176, 0.8123442080144103], [0.3373692061027786, 1.9279791148539625, 0.9145150983490047, 1.1665400292300176, 0.8721900819855897], [1.1635873961027787, 0.6041928251460373, 0.017344191650995433, 0.05595917923001753, 1.5295666219855897], [1.6994817938972213, 1.3151900551460374, 1.1992808316509955, 1.1940799107699824, 0.028238278014410367], [0.7201272938972214, 0.4034214348539626, 1.1378441483490047, 0.9160043992300175, 1.7132850380144102], [0.9343906761027786, 1.4401032248539625, 0.7318036383490045, 1.6471589092300176, 0.06190476801441036], [1.4350087738972215, 0.2543744951460374, 0.6714771016509955, 0.20562593076998245, 2.2532144519855897], [1.3475218538972213, 1.1559159251460374, 0.13133684165099543, 0.6064303007699825, 1.2329185319855898], [1.0065024361027786, 1.2392462348539626, 1.6146296783490046, 0.5786008492300175, 1.6667957880144104], [0.17773725389722142, 1.1413726548539624, 0.8910724783490047, 1.4456937892300175, 0.7525637280144104], [1.6500233938972215, 1.1130128551460374, 0.8324134316509955, 0.08055094076998245, 1.0472929519855896], [1.3795374561027787, 1.0461516351460374, 0.21972246834900455, 0.5979554707699825, 1.3053980519855897], [0.1278863561027786, 1.1915554048539625, 1.7583618283490046, 0.6964868192300175, 0.04671689801441037], [1.9061777138972216, 0.9338697748539626, 0.3111846183490045, 1.4277683192300175, 1.1742928080144104], [0.19142065610277859, 0.9908870851460374, 0.8984554016509954, 0.6097916207699825, 0.2760034319855896], [0.6825072561027786, 0.4988333651460374, 0.14589244834900456, 0.8231130207699825, 2.1581567419855894], [1.8693408938972216, 1.5113970748539625, 1.8748115783490047, 0.9727372392300175, 0.44565321198558966], [9.14376949610278, 11.386045484853963, 7.278816588349004, 24.959578299230017, 24.13282198198559], [10.781424446102779, 15.837939465146038, 7.627562581650996, 7.806674249230017, 4.279469701985589], [25.439496356102776, 2.3296031851460373, 5.382606001650996, 3.0211449507699824, 30.52444930198559], [14.15613227610278, 15.768337814853963, 21.759638568349004, 21.778926159230018, 20.42363712801441], [19.602829443897225, 5.623248924853963, 5.328505008349004, 23.40768676923002, 0.6345146680144104], [8.998577056102778, 7.128205114853963, 15.774908161650995, 9.593038339230018, 21.40425683198559], [17.092579806102776, 1.6251512848539627, 14.368728651650995, 8.583372040769982, 4.74538292801441], [14.861832833897221, 18.659089155146038, 21.761990031650996, 20.70462700923002, 27.46706413198559], [9.796007153897222, 12.401208535146036, 7.639165768349004, 9.269680640769982, 17.41608159198559]]                                      [[0.0940580861027786, 0.3451636651460374, 0.15590137165099544, 0.5015215992300176, 0.5545364519855895], [1.2908476238972215, 1.0769800848539626, 1.3266827483490047, 1.7620923192300175, 1.5970770819855897], [1.0964155661027786, 0.17415332485396257, 0.08137122834900457, 0.3673879992300175, 0.8331614419855897], [0.8073508361027786, 0.9929414851460374, 1.1749255716509954, 0.5507377407699825, 1.6590071780144102], [2.0866743438972213, 0.08304234485396261, 0.9758375383490046, 0.4452592292300176, 0.8123442080144103], [0.3373692061027786, 1.9279791148539625, 0.9145150983490047, 1.1665400292300176, 0.8721900819855897], [1.1635873961027787, 0.6041928251460373, 0.017344191650995433, 0.05595917923001753, 1.5295666219855897], [1.6994817938972213, 1.3151900551460374, 1.1992808316509955, 1.1940799107699824, 0.028238278014410367], [0.7201272938972214, 0.4034214348539626, 1.1378441483490047, 0.9160043992300175, 1.7132850380144102], [0.9343906761027786, 1.4401032248539625, 0.7318036383490045, 1.6471589092300176, 0.06190476801441036], [1.4350087738972215, 0.2543744951460374, 0.6714771016509955, 0.20562593076998245, 2.2532144519855897], [1.3475218538972213, 1.1559159251460374, 0.13133684165099543, 0.6064303007699825, 1.2329185319855898], [1.0065024361027786, 1.2392462348539626, 1.6146296783490046, 0.5786008492300175, 1.6667957880144104], [0.17773725389722142, 1.1413726548539624, 0.8910724783490047, 1.4456937892300175, 0.7525637280144104], [1.6500233938972215, 1.1130128551460374, 0.8324134316509955, 0.08055094076998245, 1.0472929519855896], [1.3795374561027787, 1.0461516351460374, 0.21972246834900455, 0.5979554707699825, 1.3053980519855897], [0.1278863561027786, 1.1915554048539625, 1.7583618283490046, 0.6964868192300175, 0.04671689801441037], [1.9061777138972216, 0.9338697748539626, 0.3111846183490045, 1.4277683192300175, 1.1742928080144104], [0.19142065610277859, 0.9908870851460374, 0.8984554016509954, 0.6097916207699825, 0.2760034319855896], [0.6825072561027786, 0.4988333651460374, 0.14589244834900456, 0.8231130207699825, 2.1581567419855894], [1.8693408938972216, 1.5113970748539625, 1.8748115783490047, 0.9727372392300175, 0.44565321198558966], [9.14376949610278, 11.386045484853963, 7.278816588349004, 24.959578299230017, 24.13282198198559], [10.781424446102779, 15.837939465146038, 7.627562581650996, 7.806674249230017, 4.279469701985589], [25.439496356102776, 2.3296031851460373, 5.382606001650996, 3.0211449507699824, 30.52444930198559], [14.15613227610278, 15.768337814853963, 21.759638568349004, 21.778926159230018, 20.42363712801441], [19.602829443897225, 5.623248924853963, 5.328505008349004, 23.40768676923002, 0.6345146680144104], [8.998577056102778, 7.128205114853963, 15.774908161650995, 9.593038339230018, 21.40425683198559], [17.092579806102776, 1.6251512848539627, 14.368728651650995, 8.583372040769982, 4.74538292801441], [14.861832833897221, 18.659089155146038, 21.761990031650996, 20.70462700923002, 27.46706413198559], [9.796007153897222, 12.401208535146036, 7.639165768349004, 9.269680640769982, 17.41608159198559]]                                      1                [149.46182360579286, 109.31326275801212, 131.32045736217637, 162.55681939659837, 182.8573999846083]   [2.25067312150549, 2.4998117443435355, 1.8168550767572478, 1.6674255239657438, 2.8180170967674645, 2.889925865977877, 2.336105556564381, 2.5148054207280626, 2.2063109738265183, 2.9844605982933667, 2.6725573263650317, 2.2601630895548492, 2.451505107950239, 2.18665083530748, 2.763026528167184, 1.9079005762762558, 3.2930167849140886, 2.815566695438622, 2.1488578099456177, 2.407082854459213, 3.0029468787176516, 64.92981880711933, 35.70349066942042, 62.620050950854605, 62.322422696597, 65.60663254039311, 46.47227254843703, 43.468220736669856, 66.74176710934972, 36.07553758219317]           1\n",
      "[[0.18047348389722143, 0.5150746548539626, 0.44968429834900453, 0.6364070792300176, 0.3147984503144104], [1.5793673138972215, 1.6411020148539626, 0.9944041683490046, 1.8548069792300175, 1.8662704019855896], [0.7490298361027786, 0.3855407948539626, 0.15989729165099542, 0.24701569076998245, 0.9387205319855896], [0.8902445461027786, 1.6466044351460374, 1.5067421516509953, 0.7596562007699825, 1.8717905180144103], [2.107100763897221, 0.8699095348539625, 0.8720772383490045, 0.8605479092300174, 1.5211848680144102], [0.5936140061027786, 1.3319587148539624, 1.2425898483490045, 1.7189194792300175, 1.7295150419855896], [1.1787152561027787, 0.052058654853962605, 0.8107562016509955, 0.22421106076998243, 2.0203434719855893], [1.2408811938972215, 0.9872125651460375, 0.6953733916509954, 1.2628679707699826, 0.4815671000144104], [0.5521753638972214, 0.5931658348539626, 0.9146274783490047, 0.17148773923001753, 1.9036332480144103], [0.8424544661027785, 1.4244457948539626, 1.5499629283490046, 1.3088009492300177, 0.3127260721144104], [0.7164653438972214, 0.1715336451460374, 0.7764410216509954, 0.10093130923001753, 1.5897531619855896], [1.4192375538972215, 1.3025364051460373, 0.19109393165099542, 0.7163722607699825, 1.2485510619855897], [1.0554176261027786, 1.1588401948539626, 0.8965187783490047, 0.8566028692300176, 1.6107667080144104], [0.48218839389722146, 1.0675776848539626, 0.8121222283490046, 1.1192131792300175, 0.5554536340144104], [1.5940784538972215, 0.9516139751460373, 1.0299966516509955, 0.5720489607699825, 1.7041371119855897], [0.5651286561027786, 1.0155398551460373, 0.3231203016509954, 0.5152439607699825, 1.6938476619855896], [0.6076131961027786, 0.6861116948539625, 1.3997399983490046, 0.9177645592300177, 0.38001956361441036], [1.8371433638972212, 0.7991825748539625, 0.6577090983490046, 0.7468711692300176, 2.0707300480144104], [0.44783916610277863, 1.1936202351460374, 1.2151849716509955, 0.9598649607699824, 0.4829381899855896], [0.4833840061027786, 0.5870205551460375, 0.1075260383490046, 0.15667529076998243, 2.2915776519855893], [1.7684119638972213, 0.9430374248539626, 1.0720257083490046, 1.4443605792300176, 1.0861303919855896], [2.0537640938972213, 22.04214190514604, 11.898874418349005, 17.145925050769982, 6.30260278801441], [16.83486630610278, 7.050748844853963, 11.503413351650996, 6.552972189230017, 13.06745471801441], [20.736852753897224, 3.9802041851460372, 7.435762161650995, 3.4562118907699824, 22.779991718014408], [7.887955756102778, 29.223932634853963, 37.72958918834901, 29.858210439230017, 20.91424741801441], [15.496665516102778, 11.472204784853963, 4.244313468349004, 17.045561389230016, 9.892074048014411], [9.695645516102779, 15.162804895146037, 4.4696596883490045, 2.6775923207699823, 21.250114918014408], [13.779200746102779, 2.9441381048539625, 11.521846848349004, 3.2850865292300178, 0.3268705999855896], [13.688604993897222, 22.68976526514604, 14.927519821650996, 35.33889141076998, 30.421104018014407], [12.206937196102778, 19.83767118485396, 8.091637211650996, 8.036820220769982, 27.68184408198559]]                                     [[0.18047348389722143, 0.5150746548539626, 0.44968429834900453, 0.6364070792300176, 0.3147984503144104], [1.5793673138972215, 1.6411020148539626, 0.9944041683490046, 1.8548069792300175, 1.8662704019855896], [0.7490298361027786, 0.3855407948539626, 0.15989729165099542, 0.24701569076998245, 0.9387205319855896], [0.8902445461027786, 1.6466044351460374, 1.5067421516509953, 0.7596562007699825, 1.8717905180144103], [2.107100763897221, 0.8699095348539625, 0.8720772383490045, 0.8605479092300174, 1.5211848680144102], [0.5936140061027786, 1.3319587148539624, 1.2425898483490045, 1.7189194792300175, 1.7295150419855896], [1.1787152561027787, 0.052058654853962605, 0.8107562016509955, 0.22421106076998243, 2.0203434719855893], [1.2408811938972215, 0.9872125651460375, 0.6953733916509954, 1.2628679707699826, 0.4815671000144104], [0.5521753638972214, 0.5931658348539626, 0.9146274783490047, 0.17148773923001753, 1.9036332480144103], [0.8424544661027785, 1.4244457948539626, 1.5499629283490046, 1.3088009492300177, 0.3127260721144104], [0.7164653438972214, 0.1715336451460374, 0.7764410216509954, 0.10093130923001753, 1.5897531619855896], [1.4192375538972215, 1.3025364051460373, 0.19109393165099542, 0.7163722607699825, 1.2485510619855897], [1.0554176261027786, 1.1588401948539626, 0.8965187783490047, 0.8566028692300176, 1.6107667080144104], [0.48218839389722146, 1.0675776848539626, 0.8121222283490046, 1.1192131792300175, 0.5554536340144104], [1.5940784538972215, 0.9516139751460373, 1.0299966516509955, 0.5720489607699825, 1.7041371119855897], [0.5651286561027786, 1.0155398551460373, 0.3231203016509954, 0.5152439607699825, 1.6938476619855896], [0.6076131961027786, 0.6861116948539625, 1.3997399983490046, 0.9177645592300177, 0.38001956361441036], [1.8371433638972212, 0.7991825748539625, 0.6577090983490046, 0.7468711692300176, 2.0707300480144104], [0.44783916610277863, 1.1936202351460374, 1.2151849716509955, 0.9598649607699824, 0.4829381899855896], [0.4833840061027786, 0.5870205551460375, 0.1075260383490046, 0.15667529076998243, 2.2915776519855893], [1.7684119638972213, 0.9430374248539626, 1.0720257083490046, 1.4443605792300176, 1.0861303919855896], [2.0537640938972213, 22.04214190514604, 11.898874418349005, 17.145925050769982, 6.30260278801441], [16.83486630610278, 7.050748844853963, 11.503413351650996, 6.552972189230017, 13.06745471801441], [20.736852753897224, 3.9802041851460372, 7.435762161650995, 3.4562118907699824, 22.779991718014408], [7.887955756102778, 29.223932634853963, 37.72958918834901, 29.858210439230017, 20.91424741801441], [15.496665516102778, 11.472204784853963, 4.244313468349004, 17.045561389230016, 9.892074048014411], [9.695645516102779, 15.162804895146037, 4.4696596883490045, 2.6775923207699823, 21.250114918014408], [13.779200746102779, 2.9441381048539625, 11.521846848349004, 3.2850865292300178, 0.3268705999855896], [13.688604993897222, 22.68976526514604, 14.927519821650996, 35.33889141076998, 30.421104018014407], [12.206937196102778, 19.83767118485396, 8.091637211650996, 8.036820220769982, 27.68184408198559]]                                     1                [130.15844995605676, 165.05066325797472, 153.5070722213646, 174.38037375404676, 185.1713234429191]    [2.0513594721897133, 2.7191466763860928, 1.6267341610078283, 2.659782191302525, 1.9632426447433389, 2.276419132865058, 2.7001681140068814, 1.799206373841418, 2.39309267460402, 2.188786950012706, 2.2660257819907663, 2.398869280269625, 0.9790113454227258, 1.5561497606296537, 1.6664943939331318, 1.9675424157694572, 2.100764768701091, 2.0751719351448696, 1.74974664315365, 2.8544810912237435, 2.105311303279753, 45.94854667545251, 38.144888520525456, 48.92097727310473, 87.74705273166738, 45.33147982298009, 47.469852598349654, 30.969623258701535, 87.15582904665146, 58.264857493120935]        1\n",
      "[[0.029037933897221396, 0.046312670146037405, 0.23952762855099544, 0.4294671292300175, 0.2477360919855896], [1.7068964638972215, 1.4638224948539627, 1.7498244983490048, 1.7516950492300176, 2.2200577719855894], [0.5604764761027786, 0.3386999749460374, 0.23358513025099542, 0.5521462692300175, 1.0834336819855896], [0.17424464610277862, 1.4281658951460374, 0.5730005026509954, 0.9760126307699825, 0.9900140880144104], [1.9255217138972214, 0.11664203914603738, 0.3432322303490046, 0.054804150769982435, 1.4010755180144103], [0.4355911861027786, 1.7144897848539626, 1.6959409283490046, 1.5093624492300175, 1.2939199419855896], [1.4006089361027785, 0.17091795185396258, 0.48014286765099545, 0.09564306923001753, 1.7716623819855897], [1.2195340338972214, 1.6336027051460376, 0.7982469116509954, 1.3643455307699826, 0.1662484880144104], [0.6434258238972215, 0.6472427248539625, 0.6279553583490045, 0.6297198892300175, 1.9488542780144102], [0.9578461161027786, 1.0404634848539625, 1.5795957983490045, 1.6734815892300177, 0.3198964180144104], [1.4811346038972215, 0.9742621761460375, 0.7819214066509954, 0.5082634707699825, 1.80556403198559], [1.4740933438972215, 1.3186694441460374, 0.13855365465099542, 1.3597689707699825, 1.0306298719855898], [1.6040489461027785, 0.8356762048539625, 1.3649272583490046, 0.4659872592300176, 1.2428014580144104], [0.8030500238972214, 1.6296677148539627, 0.5195031583490046, 0.8424260392300176, 1.2231382280144103], [1.5665304838972214, 0.4900113511460374, 1.2869841416509953, 0.3904295607699825, 1.4004376719855898], [0.5946544661027786, 0.7843997111460375, 0.43907023065099543, 0.6922561207699824, 1.8853171419855899], [0.004768933897221411, 1.2842785048539624, 1.2699517183490046, 1.0670725692300176, 0.4822166380144104], [2.3000913038972213, 1.5245812548539626, 0.4435081863490045, 0.9207150192300175, 2.1091284980144103], [0.3907746861027786, 0.6545671961460373, 0.5566046686509954, 0.7726966407699825, 0.042621538014410376], [1.1092122161027786, 0.3676211782660374, 0.5966333433490045, 0.2533989607699825, 1.5144607519855897], [2.114719823897221, 0.8175879048539625, 1.9730876683490048, 1.5567822692300175, 0.6451448219855898], [9.402857193897221, 19.93815101514604, 8.300660871650996, 12.640593769230017, 22.37290668198559], [16.530616793897224, 8.617305874853963, 14.108069301650996, 14.546972679230018, 9.94565948198559], [36.32350306610278, 0.2517709941460374, 9.853970041650996, 4.962914980769982, 33.32173123198559], [12.48701061610278, 16.22355211514604, 19.590540601650996, 20.944237859230018, 24.16803383801441], [15.231321186102779, 14.713478815146036, 1.2021677316509953, 12.460011319230018, 5.178473598014411], [10.273123536102778, 11.759779184853963, 3.897339388349004, 3.5468357007699822, 20.81307744198559], [24.837167086102777, 2.6414656248539625, 8.078658628349004, 0.6411830692300176, 7.17671153198559], [8.697772353897221, 24.78234828485396, 37.72528849834901, 19.733594649230017, 32.19808872801441], [11.53921223610278, 21.025946584853962, 7.778276568349005, 15.116323170769983, 7.379339601985589]]                                         [[0.029037933897221396, 0.046312670146037405, 0.23952762855099544, 0.4294671292300175, 0.2477360919855896], [1.7068964638972215, 1.4638224948539627, 1.7498244983490048, 1.7516950492300176, 2.2200577719855894], [0.5604764761027786, 0.3386999749460374, 0.23358513025099542, 0.5521462692300175, 1.0834336819855896], [0.17424464610277862, 1.4281658951460374, 0.5730005026509954, 0.9760126307699825, 0.9900140880144104], [1.9255217138972214, 0.11664203914603738, 0.3432322303490046, 0.054804150769982435, 1.4010755180144103], [0.4355911861027786, 1.7144897848539626, 1.6959409283490046, 1.5093624492300175, 1.2939199419855896], [1.4006089361027785, 0.17091795185396258, 0.48014286765099545, 0.09564306923001753, 1.7716623819855897], [1.2195340338972214, 1.6336027051460376, 0.7982469116509954, 1.3643455307699826, 0.1662484880144104], [0.6434258238972215, 0.6472427248539625, 0.6279553583490045, 0.6297198892300175, 1.9488542780144102], [0.9578461161027786, 1.0404634848539625, 1.5795957983490045, 1.6734815892300177, 0.3198964180144104], [1.4811346038972215, 0.9742621761460375, 0.7819214066509954, 0.5082634707699825, 1.80556403198559], [1.4740933438972215, 1.3186694441460374, 0.13855365465099542, 1.3597689707699825, 1.0306298719855898], [1.6040489461027785, 0.8356762048539625, 1.3649272583490046, 0.4659872592300176, 1.2428014580144104], [0.8030500238972214, 1.6296677148539627, 0.5195031583490046, 0.8424260392300176, 1.2231382280144103], [1.5665304838972214, 0.4900113511460374, 1.2869841416509953, 0.3904295607699825, 1.4004376719855898], [0.5946544661027786, 0.7843997111460375, 0.43907023065099543, 0.6922561207699824, 1.8853171419855899], [0.004768933897221411, 1.2842785048539624, 1.2699517183490046, 1.0670725692300176, 0.4822166380144104], [2.3000913038972213, 1.5245812548539626, 0.4435081863490045, 0.9207150192300175, 2.1091284980144103], [0.3907746861027786, 0.6545671961460373, 0.5566046686509954, 0.7726966407699825, 0.042621538014410376], [1.1092122161027786, 0.3676211782660374, 0.5966333433490045, 0.2533989607699825, 1.5144607519855897], [2.114719823897221, 0.8175879048539625, 1.9730876683490048, 1.5567822692300175, 0.6451448219855898], [9.402857193897221, 19.93815101514604, 8.300660871650996, 12.640593769230017, 22.37290668198559], [16.530616793897224, 8.617305874853963, 14.108069301650996, 14.546972679230018, 9.94565948198559], [36.32350306610278, 0.2517709941460374, 9.853970041650996, 4.962914980769982, 33.32173123198559], [12.48701061610278, 16.22355211514604, 19.590540601650996, 20.944237859230018, 24.16803383801441], [15.231321186102779, 14.713478815146036, 1.2021677316509953, 12.460011319230018, 5.178473598014411], [10.273123536102778, 11.759779184853963, 3.897339388349004, 3.5468357007699822, 20.81307744198559], [24.837167086102777, 2.6414656248539625, 8.078658628349004, 0.6411830692300176, 7.17671153198559], [8.697772353897221, 24.78234828485396, 37.72528849834901, 19.733594649230017, 32.19808872801441], [11.53921223610278, 21.025946584853962, 7.778276568349005, 15.116323170769983, 7.379339601985589]]                                         1                [179.08257007672975, 149.49212080302127, 155.00013090647155, 129.53370837880757, 194.73826246858275]  [2.7092446906276666, 3.0091971601662073, 1.571605462407812, 2.274346330476212, 2.5441284566361584, 2.3706033160171684, 2.261296674528312, 2.7336481156262185, 1.6283285632242306, 2.812627283121429, 1.694379781381864, 2.8162866180905333, 2.028772448765502, 2.459057112476801, 2.225074274888211, 1.6255207666357068, 2.3521861348658333, 3.3656847719928793, 2.1110116241954153, 1.5653974192905564, 3.7535251982336546, 50.72960866888865, 44.54458538282463, 81.89032177351432, 61.22385466178557, 42.971330957121864, 40.81034735982659, 44.28098824071802, 90.34493024213553, 47.12709289342993]        1\n",
      "[[0.42544713389722144, 0.36096841485396264, 0.17514779165099542, 0.016786429230017552, 0.10163147801441036], [1.6737919138972215, 1.5829957448539627, 1.2493304983490046, 1.5679272792300176, 1.4425774219855896], [0.9984433561027786, 0.1190265148539626, 0.3074410983490045, 0.23573081076998245, 1.2398533019855897], [0.07262278610277861, 0.9568073651460374, 1.4061555916509954, 0.6612527507699825, 1.5584738280144104], [1.7026621138972213, 0.15321907485396263, 0.3058116483490046, 0.5767499792300176, 1.4537360580144103], [0.42722479610277864, 1.5486483848539625, 1.7367685283490044, 1.6893531692300177, 0.9569485319855897], [0.9770928061027786, 0.6699597051460373, 0.06224530165099543, 0.3203318792300176, 1.4701722819855896], [1.2009853838972215, 1.5373562051460374, 0.8313997116509955, 1.3488126707699823, 0.003206968014410394], [0.6291598538972214, 0.7602226848539626, 0.9465410483490047, 1.0648694792300175, 1.8135495780144104], [1.6946513061027786, 1.4818213948539625, 1.1692136683490046, 1.2198511492300175, 0.11555419801441039], [1.4039293838972213, 0.8825008751460375, 0.9729952116509955, 0.03776693076998244, 1.74878457198559], [1.4594356838972213, 0.6927267651460374, 0.7508918916509955, 0.7907936907699824, 1.1781840519855897], [1.6362018761027786, 0.6398708548539624, 1.0687093483490047, 1.1046136092300176, 1.1867135780144105], [0.4893375638972214, 1.7121583648539627, 0.5471639883490045, 0.7986575092300177, 1.5423736480144103], [1.9121590338972216, 0.4114032751460374, 0.7867806216509954, 0.01791544076998247, 1.1782821819855898], [0.9032172361027786, 1.2230171351460375, 0.5091975716509954, 0.9179167207699824, 2.1990108319855897], [0.2779341761027786, 0.6588602248539626, 1.5206233983490047, 0.6546893092300176, 0.07597571801441039], [1.9837123038972215, 0.5772417148539626, 0.8597479083490047, 1.2047988292300176, 2.0562591780144106], [0.5805823161027786, 0.8375883451460374, 1.0610144416509955, 0.6715960907699825, 0.26437765198558966], [1.0380776361027786, 1.1619671651460375, 0.20043473165099543, 1.0050648607699824, 1.7343340819855897], [1.7053089238972214, 0.9873180348539625, 1.7530352583490048, 1.1135024192300176, 1.2401335119855896], [6.556167956102779, 11.896212864853963, 0.05033385834900456, 19.09264474076998, 12.59770164801441], [9.578776923897221, 5.266359355146037, 7.940614878349004, 5.885781749230018, 5.838153831985589], [34.337623556102784, 4.260492944853963, 12.051878031650995, 9.705489900769981, 16.88723152198559], [25.361709783897222, 20.74142873485396, 18.455736798349005, 19.14606867923002, 27.870223771985593], [11.684714976102779, 15.403931954853963, 0.6670020816509954, 22.494101980769983, 2.2188638680144104], [15.81200980389722, 14.392721945146038, 3.9590171016509954, 11.322926049230018, 19.089865538014408], [25.721023443897224, 0.4910024548539626, 10.453906268349005, 0.48036886923001754, 3.0868949380144106], [11.815552743897221, 35.600713344853965, 15.483424831650996, 15.979949960769982, 25.06918654198559], [0.4666616061027786, 19.27423041514604, 9.644906551650996, 11.976715129230017, 12.349695881985589]]                            [[0.42544713389722144, 0.36096841485396264, 0.17514779165099542, 0.016786429230017552, 0.10163147801441036], [1.6737919138972215, 1.5829957448539627, 1.2493304983490046, 1.5679272792300176, 1.4425774219855896], [0.9984433561027786, 0.1190265148539626, 0.3074410983490045, 0.23573081076998245, 1.2398533019855897], [0.07262278610277861, 0.9568073651460374, 1.4061555916509954, 0.6612527507699825, 1.5584738280144104], [1.7026621138972213, 0.15321907485396263, 0.3058116483490046, 0.5767499792300176, 1.4537360580144103], [0.42722479610277864, 1.5486483848539625, 1.7367685283490044, 1.6893531692300177, 0.9569485319855897], [0.9770928061027786, 0.6699597051460373, 0.06224530165099543, 0.3203318792300176, 1.4701722819855896], [1.2009853838972215, 1.5373562051460374, 0.8313997116509955, 1.3488126707699823, 0.003206968014410394], [0.6291598538972214, 0.7602226848539626, 0.9465410483490047, 1.0648694792300175, 1.8135495780144104], [1.6946513061027786, 1.4818213948539625, 1.1692136683490046, 1.2198511492300175, 0.11555419801441039], [1.4039293838972213, 0.8825008751460375, 0.9729952116509955, 0.03776693076998244, 1.74878457198559], [1.4594356838972213, 0.6927267651460374, 0.7508918916509955, 0.7907936907699824, 1.1781840519855897], [1.6362018761027786, 0.6398708548539624, 1.0687093483490047, 1.1046136092300176, 1.1867135780144105], [0.4893375638972214, 1.7121583648539627, 0.5471639883490045, 0.7986575092300177, 1.5423736480144103], [1.9121590338972216, 0.4114032751460374, 0.7867806216509954, 0.01791544076998247, 1.1782821819855898], [0.9032172361027786, 1.2230171351460375, 0.5091975716509954, 0.9179167207699824, 2.1990108319855897], [0.2779341761027786, 0.6588602248539626, 1.5206233983490047, 0.6546893092300176, 0.07597571801441039], [1.9837123038972215, 0.5772417148539626, 0.8597479083490047, 1.2047988292300176, 2.0562591780144106], [0.5805823161027786, 0.8375883451460374, 1.0610144416509955, 0.6715960907699825, 0.26437765198558966], [1.0380776361027786, 1.1619671651460375, 0.20043473165099543, 1.0050648607699824, 1.7343340819855897], [1.7053089238972214, 0.9873180348539625, 1.7530352583490048, 1.1135024192300176, 1.2401335119855896], [6.556167956102779, 11.896212864853963, 0.05033385834900456, 19.09264474076998, 12.59770164801441], [9.578776923897221, 5.266359355146037, 7.940614878349004, 5.885781749230018, 5.838153831985589], [34.337623556102784, 4.260492944853963, 12.051878031650995, 9.705489900769981, 16.88723152198559], [25.361709783897222, 20.74142873485396, 18.455736798349005, 19.14606867923002, 27.870223771985593], [11.684714976102779, 15.403931954853963, 0.6670020816509954, 22.494101980769983, 2.2188638680144104], [15.81200980389722, 14.392721945146038, 3.9590171016509954, 11.322926049230018, 19.089865538014408], [25.721023443897224, 0.4910024548539626, 10.453906268349005, 0.48036886923001754, 3.0868949380144106], [11.815552743897221, 35.600713344853965, 15.483424831650996, 15.979949960769982, 25.06918654198559], [0.4666616061027786, 19.27423041514604, 9.644906551650996, 11.976715129230017, 12.349695881985589]]                            1                [183.862580115439, 166.05116282817673, 100.71731275969852, 139.17151863067943, 148.36657566165312]    [2.591295863532382, 2.0572920587971906, 1.7232266631948507, 2.4554824347354467, 2.214495281896194, 2.53449622789144, 1.878230813020813, 2.742776271436858, 1.621388457189981, 2.56612760100196, 2.664878100914728, 0.9082306090753258, 1.7818732969207676, 2.845468178608947, 2.486340972510497, 2.0678772687477958, 2.8285779661899397, 2.805156643098083, 1.723421059271605, 2.074241008488954, 2.329345639329877, 48.198052816426895, 21.680651614129115, 66.75842496810053, 71.78318667986146, 57.3951260389209, 45.88366110535359, 47.68194243526698, 81.49161303182586, 40.88614828785414]                1\n",
      "[[0.2395990538972214, 0.27531667485396266, 0.6222232883490046, 0.13789293223001753, 0.35846537198558964], [1.4752610638972214, 1.1340756648539625, 1.1660834783490046, 1.6732150892300175, 1.9007099719855896], [0.6980493361027786, 0.10518884485396263, 0.4569590183490046, 0.018258705230017547, 0.4187284819855896], [0.7334241061027786, 1.6072712151460375, 1.2153420816509954, 0.8984541957699824, 1.0558554080144105], [1.9864182938972215, 0.5686701148539626, 0.2647675383490045, 0.5230311402300175, 1.0338171680144104], [0.6464094261027786, 1.5207928948539626, 1.6715414383490046, 1.7383817792300174, 0.9089110719855897], [1.3347777461027786, 0.5411480551460374, 0.4162856116509954, 0.32022070123001756, 1.5331675619855898], [2.116815603897221, 1.3973533051460374, 0.9279940316509954, 0.6856473327699825, 0.47525710801441035], [0.4335703538972214, 0.22701366485396263, 0.7932138483490045, 0.6860846692300175, 1.8256845780144104], [1.0852661861027786, 1.7808203148539627, 0.8205172983490046, 1.5347860692300175, 0.5100937719855896], [1.3073772138972215, 0.05930139514603738, 0.7289681816509954, 0.06072940123001758, 1.6165733719855897], [0.9697871438972214, 0.6457721251460373, 0.8622048116509955, 0.46800882876998245, 0.3726877519855896], [0.8637207161027786, 1.2958380848539626, 1.5448206383490046, 0.8315848192300175, 1.4924001780144103], [0.21719457389722138, 1.7221274848539627, 0.49710449834900455, 0.8701620692300176, 0.5536352680144103], [1.3629612038972214, 0.5214204051460374, 1.3144631916509955, 0.28335817546998243, 1.5230320519855898], [0.6157173861027786, 0.9928029951460373, 0.5913326116509954, 1.2070078907699826, 2.1890341819855896], [0.1600441161027786, 1.3809204448539625, 1.4180359283490047, 0.8849138492300175, 0.8055374680144104], [1.5916270338972214, 1.2015658548539625, 0.22123564834900455, 0.8943492892300176, 1.8315407180144103], [0.34051732610277863, 0.6323968451460373, 0.9626111616509954, 0.9859137897699825, 0.5228473719855897], [0.3651727461027786, 1.1282783451460374, 0.48131305834900456, 0.8645275607699825, 1.8829327119855896], [1.4791153838972215, 1.4243862348539627, 1.5494853783490046, 1.1461921992300175, 0.47951071198558964], [1.9484723461027786, 21.389308305146038, 1.9876507816509954, 18.79337418923002, 15.648090641985588], [17.26366979610278, 9.331269595146036, 8.730467788349005, 15.630824510769981, 20.708023568014408], [16.494658716102776, 0.06602911514603738, 13.546814238349004, 4.561849730769982, 36.35647935801441], [8.550978556102779, 19.062515495146037, 33.87727233834901, 28.391413810769983, 21.30794698198559], [15.464161603897221, 15.026752174853963, 0.6805878316509955, 12.861758889230018, 3.6421004980144107], [6.713086443897221, 7.098191275146037, 10.820766851650996, 15.048233810769982, 26.468259448014408], [18.402534886102778, 3.9183824951460373, 21.796087128349004, 1.8362360607699824, 4.48899520801441], [8.696766736102779, 36.90975700514604, 19.048205938349003, 19.12290181076998, 32.72119237198559], [2.307432246102779, 8.590337004853962, 2.834244218349004, 8.758880339230018, 6.356527921985589]]                                 [[0.2395990538972214, 0.27531667485396266, 0.6222232883490046, 0.13789293223001753, 0.35846537198558964], [1.4752610638972214, 1.1340756648539625, 1.1660834783490046, 1.6732150892300175, 1.9007099719855896], [0.6980493361027786, 0.10518884485396263, 0.4569590183490046, 0.018258705230017547, 0.4187284819855896], [0.7334241061027786, 1.6072712151460375, 1.2153420816509954, 0.8984541957699824, 1.0558554080144105], [1.9864182938972215, 0.5686701148539626, 0.2647675383490045, 0.5230311402300175, 1.0338171680144104], [0.6464094261027786, 1.5207928948539626, 1.6715414383490046, 1.7383817792300174, 0.9089110719855897], [1.3347777461027786, 0.5411480551460374, 0.4162856116509954, 0.32022070123001756, 1.5331675619855898], [2.116815603897221, 1.3973533051460374, 0.9279940316509954, 0.6856473327699825, 0.47525710801441035], [0.4335703538972214, 0.22701366485396263, 0.7932138483490045, 0.6860846692300175, 1.8256845780144104], [1.0852661861027786, 1.7808203148539627, 0.8205172983490046, 1.5347860692300175, 0.5100937719855896], [1.3073772138972215, 0.05930139514603738, 0.7289681816509954, 0.06072940123001758, 1.6165733719855897], [0.9697871438972214, 0.6457721251460373, 0.8622048116509955, 0.46800882876998245, 0.3726877519855896], [0.8637207161027786, 1.2958380848539626, 1.5448206383490046, 0.8315848192300175, 1.4924001780144103], [0.21719457389722138, 1.7221274848539627, 0.49710449834900455, 0.8701620692300176, 0.5536352680144103], [1.3629612038972214, 0.5214204051460374, 1.3144631916509955, 0.28335817546998243, 1.5230320519855898], [0.6157173861027786, 0.9928029951460373, 0.5913326116509954, 1.2070078907699826, 2.1890341819855896], [0.1600441161027786, 1.3809204448539625, 1.4180359283490047, 0.8849138492300175, 0.8055374680144104], [1.5916270338972214, 1.2015658548539625, 0.22123564834900455, 0.8943492892300176, 1.8315407180144103], [0.34051732610277863, 0.6323968451460373, 0.9626111616509954, 0.9859137897699825, 0.5228473719855897], [0.3651727461027786, 1.1282783451460374, 0.48131305834900456, 0.8645275607699825, 1.8829327119855896], [1.4791153838972215, 1.4243862348539627, 1.5494853783490046, 1.1461921992300175, 0.47951071198558964], [1.9484723461027786, 21.389308305146038, 1.9876507816509954, 18.79337418923002, 15.648090641985588], [17.26366979610278, 9.331269595146036, 8.730467788349005, 15.630824510769981, 20.708023568014408], [16.494658716102776, 0.06602911514603738, 13.546814238349004, 4.561849730769982, 36.35647935801441], [8.550978556102779, 19.062515495146037, 33.87727233834901, 28.391413810769983, 21.30794698198559], [15.464161603897221, 15.026752174853963, 0.6805878316509955, 12.861758889230018, 3.6421004980144107], [6.713086443897221, 7.098191275146037, 10.820766851650996, 15.048233810769982, 26.468259448014408], [18.402534886102778, 3.9183824951460373, 21.796087128349004, 1.8362360607699824, 4.48899520801441], [8.696766736102779, 36.90975700514604, 19.048205938349003, 19.12290181076998, 32.72119237198559], [2.307432246102779, 8.590337004853962, 2.834244218349004, 8.758880339230018, 6.356527921985589]]                                 1                [117.06472232024947, 165.4922015310678, 160.3903145224053, 150.030010605174, 203.16856102834308]      [2.3048101739446283, 2.4091364562155473, 2.160731560570147, 1.9700875914721467, 2.1293387061020455, 2.4110169314583336, 1.5156788786496116, 2.829841527683704, 2.3529390241903334, 2.700849241777967, 2.4189074254451333, 1.4562115603488552, 1.8775532850665584, 3.246412057988083, 2.353635591367449, 2.138886940249092, 2.297155475807693, 2.362342781221407, 1.8297186872917237, 1.97845481386409, 2.110221246308118, 54.426457032349624, 50.59117128837303, 70.40573060817412, 82.8426755561869, 44.66838241487258, 52.05844385143648, 54.91032079719693, 87.03848855688828, 20.538321748324066]           1\n",
      "[[0.3368013638972214, 0.5904809808539626, 0.3086495843490045, 0.3012200972300175, 0.3389222839855896], [1.5721079138972214, 1.7251043548539626, 1.4886596983490046, 1.0827446692300176, 2.2540024619855896], [0.9784079561027785, 0.2969915514460374, 0.4477399163490046, 0.42474938323001754, 0.6895186719855897], [0.4475887261027786, 1.6998004451460373, 0.7893113116509953, 1.3764796507699824, 1.7300651580144104], [2.268327573897221, 0.2435924458539626, 0.8245178583490047, 0.2328064132300176, 1.4208717080144104], [0.4076164761027786, 1.4640768148539625, 1.0057336383490045, 1.2588632492300176, 1.6722916919855895], [1.3736500161027785, 0.22890078185396262, 0.17776295365099543, 0.5602359677699824, 1.4357507519855897], [1.6782473238972215, 1.4677988051460376, 1.0914003126509955, 1.0032245797699826, 0.3763636740144104], [0.22396058389722137, 0.6380214548539624, 0.5773131543490047, 0.2175289112300176, 1.9804756280144102], [1.1728077761027786, 1.7332839348539624, 1.1326571283490046, 1.2534935992300176, 0.23852981098558962], [1.5926095838972214, 0.4930400701460374, 0.29204608325099546, 0.2539146795699824, 2.3871486119855896], [0.6268351338972215, 0.7924653431460373, 0.9038371676509955, 0.5524121997699825, 1.0454544119855897], [1.1162086261027786, 0.6587026648539624, 1.0630067083490047, 0.8062368792300176, 1.0580730660144104], [0.4085650538972214, 1.5779946648539624, 1.1578182683490046, 1.2071654692300176, 1.3567765380144103], [1.3003481538972215, 0.6817016061460375, 1.2188801736509953, 0.24249062536998245, 1.5786313519855897], [0.5591005061027786, 0.6060530181460374, 0.5114573196509955, 0.30862820925998247, 1.4463215619855896], [0.10753741610277859, 1.2565165848539626, 1.4410505583490045, 0.7748599192300176, 0.16111585301441037], [1.9883250938972215, 0.9363958148539626, 0.5595010693490046, 1.1690603692300177, 1.9505760180144103], [0.5788683361027785, 0.5249354791460374, 0.9985677146509955, 0.26482555376998246, 0.14980677098558964], [0.7422045061027785, 0.3494750045460374, 0.037669683650995434, 0.32289879986998243, 1.9367404719855899], [1.5580502838972214, 1.1525777048539625, 1.4560761083490046, 0.7050029692300175, 0.38140325798558966], [3.5929150738972213, 9.448061515146037, 16.501612101650995, 10.916201089230018, 15.65866571801441], [17.978609703897224, 16.14944351514604, 7.297984698349004, 11.911725289230018, 8.34872440801441], [20.872722143897224, 4.665072864853963, 7.270163761650996, 3.2319735892300177, 12.724640681985589], [9.02203811610278, 23.364288315146037, 17.139156201650994, 31.21583191076998, 31.681608481985588], [17.353729063897223, 14.215907984853963, 1.7950901116509954, 11.742090410769983, 2.4244371080144105], [14.039734773897221, 17.82409471514604, 8.461556918349004, 1.9790721992300178, 18.47812871801441], [29.829744623897223, 1.9475542251460374, 22.369127901650995, 1.8283102392300177, 11.01023111801441], [8.061700123897221, 19.50861848485396, 26.066811101650995, 18.146894389230017, 23.64399398198559], [0.4221339938972214, 3.7442699151460372, 3.6421429316509957, 12.054696510769983, 13.657388081985589]]                                 [[0.3368013638972214, 0.5904809808539626, 0.3086495843490045, 0.3012200972300175, 0.3389222839855896], [1.5721079138972214, 1.7251043548539626, 1.4886596983490046, 1.0827446692300176, 2.2540024619855896], [0.9784079561027785, 0.2969915514460374, 0.4477399163490046, 0.42474938323001754, 0.6895186719855897], [0.4475887261027786, 1.6998004451460373, 0.7893113116509953, 1.3764796507699824, 1.7300651580144104], [2.268327573897221, 0.2435924458539626, 0.8245178583490047, 0.2328064132300176, 1.4208717080144104], [0.4076164761027786, 1.4640768148539625, 1.0057336383490045, 1.2588632492300176, 1.6722916919855895], [1.3736500161027785, 0.22890078185396262, 0.17776295365099543, 0.5602359677699824, 1.4357507519855897], [1.6782473238972215, 1.4677988051460376, 1.0914003126509955, 1.0032245797699826, 0.3763636740144104], [0.22396058389722137, 0.6380214548539624, 0.5773131543490047, 0.2175289112300176, 1.9804756280144102], [1.1728077761027786, 1.7332839348539624, 1.1326571283490046, 1.2534935992300176, 0.23852981098558962], [1.5926095838972214, 0.4930400701460374, 0.29204608325099546, 0.2539146795699824, 2.3871486119855896], [0.6268351338972215, 0.7924653431460373, 0.9038371676509955, 0.5524121997699825, 1.0454544119855897], [1.1162086261027786, 0.6587026648539624, 1.0630067083490047, 0.8062368792300176, 1.0580730660144104], [0.4085650538972214, 1.5779946648539624, 1.1578182683490046, 1.2071654692300176, 1.3567765380144103], [1.3003481538972215, 0.6817016061460375, 1.2188801736509953, 0.24249062536998245, 1.5786313519855897], [0.5591005061027786, 0.6060530181460374, 0.5114573196509955, 0.30862820925998247, 1.4463215619855896], [0.10753741610277859, 1.2565165848539626, 1.4410505583490045, 0.7748599192300176, 0.16111585301441037], [1.9883250938972215, 0.9363958148539626, 0.5595010693490046, 1.1690603692300177, 1.9505760180144103], [0.5788683361027785, 0.5249354791460374, 0.9985677146509955, 0.26482555376998246, 0.14980677098558964], [0.7422045061027785, 0.3494750045460374, 0.037669683650995434, 0.32289879986998243, 1.9367404719855899], [1.5580502838972214, 1.1525777048539625, 1.4560761083490046, 0.7050029692300175, 0.38140325798558966], [3.5929150738972213, 9.448061515146037, 16.501612101650995, 10.916201089230018, 15.65866571801441], [17.978609703897224, 16.14944351514604, 7.297984698349004, 11.911725289230018, 8.34872440801441], [20.872722143897224, 4.665072864853963, 7.270163761650996, 3.2319735892300177, 12.724640681985589], [9.02203811610278, 23.364288315146037, 17.139156201650994, 31.21583191076998, 31.681608481985588], [17.353729063897223, 14.215907984853963, 1.7950901116509954, 11.742090410769983, 2.4244371080144105], [14.039734773897221, 17.82409471514604, 8.461556918349004, 1.9790721992300178, 18.47812871801441], [29.829744623897223, 1.9475542251460374, 22.369127901650995, 1.8283102392300177, 11.01023111801441], [8.061700123897221, 19.50861848485396, 26.066811101650995, 18.146894389230017, 23.64399398198559], [0.4221339938972214, 3.7442699151460372, 3.6421429316509957, 12.054696510769983, 13.657388081985589]]                                 1                [157.89955527366985, 134.9035274104375, 151.98358760552873, 139.21510881574025, 162.23068223996805]   [2.116546557948079, 2.7108652769097206, 1.3775087423850665, 2.373715045760969, 2.8291829038119514, 1.8231823333345294, 1.8996188098436562, 2.2706366783282967, 2.4878161112855093, 2.5564284013235237, 2.7364862100407987, 1.0333127929623769, 0.9530954543440322, 1.8559452450841771, 2.2089331499075207, 1.537647745966087, 2.7863793810560185, 2.4098497297158543, 2.246518101003105, 2.2413700031798736, 2.237391237411867, 40.104333984384425, 43.745544133470744, 39.70746875364806, 79.4530710235275, 43.64000699599771, 53.702715001073074, 70.48929272378163, 64.47094207721548, 33.08040106331805]    1\n",
      "[[0.3779620208972214, 0.09834047485396263, 0.6388717333490046, 0.4600727612300175, 0.09612052198558962], [1.6127771038972214, 1.8992909448539628, 1.9808888183490045, 1.6235087992300175, 1.7848654619855895], [0.8523905581027785, 0.3549727348539626, 0.19098918434900458, 0.47314518323001753, 0.33530035198558966], [0.4086996131027786, 1.3991541551460374, 1.1803042046509955, 1.0641668407699825, 1.5608882580144103], [2.0659004938972214, 0.4844183248539626, 0.9104952683490046, 0.14560073123001754, 1.4444706280144104], [0.2427106528527786, 1.5341661248539626, 1.7975172483490047, 1.1819293792300176, 1.2739481619855897], [1.2973894461027786, 0.4899906551460374, 0.006741726349004551, 0.33989761436998245, 1.2682709719855896], [2.0834583938972213, 1.2938934951460375, 1.3493711716509953, 0.5139284897699825, 0.2603607180144104], [0.7351101638972214, 0.49578728485396256, 0.8707890083490046, 0.6918044722300175, 1.7175292380144103], [1.0043149141027787, 1.5442738048539626, 1.1800949383490047, 1.3755039592300176, 0.3094363119855896], [1.4623415938972215, 0.44519407514603737, 0.28443439903099543, 0.16520091776998244, 2.0906579719855896], [0.7666434738972214, 1.0926966251460375, 0.16014968365099544, 0.8732094267699825, 0.49598880198558964], [1.2003013271027787, 0.5379942048539625, 1.6231996383490046, 0.9294602992300176, 1.6334779580144103], [0.2832453098972214, 1.0547262448539625, 0.6901683153490046, 1.2185591892300176, 0.9922207380144104], [1.6216120038972215, 0.7473411651460373, 1.1417543096509954, 0.06840865076998245, 0.8090585419855896], [0.6156748621027786, 0.7670553751460374, 0.3920726576509954, 0.2975369110799824, 1.3764883219855897], [0.4447523221027786, 1.3659530048539625, 1.4060897483490047, 1.3166420092300175, 0.22085769801441038], [1.7733756338972213, 0.7207141748539625, 0.5265883203490045, 1.2266208092300175, 1.5635187480144104], [0.7531545751027786, 0.6144769751460374, 1.2892756316509955, 0.6678637397699825, 0.006687098014410364], [1.1577111311027786, 0.3269332951460374, 0.20631363534900454, 0.8797811007699824, 2.2645673019855894], [2.221255043897221, 1.3072556348539626, 1.9199514083490048, 1.1617827792300175, 1.2001841819855896], [10.240730616102779, 21.586882864853962, 4.754065688349004, 27.965184110769982, 14.60135588198559], [13.865974983897221, 13.022320985146036, 21.418116601650997, 11.339806010769982, 12.442866568014411], [26.45330841610278, 2.6489674948539625, 15.565902101650996, 4.337310249230018, 12.67689717801441], [19.471712983897223, 41.089800284853965, 20.928728501650994, 11.560479889230018, 35.933205058014416], [15.314295283897222, 6.976872604853963, 4.146142071650996, 21.772359110769983, 4.353162961985589], [11.925562416102778, 23.057462415146038, 18.876289401650997, 1.8489317707699824, 16.25605703801441], [19.347901316102778, 6.886526394853963, 6.953025648349004, 2.5960758592300177, 4.81379509198559], [5.846717313897221, 20.69496180514604, 18.646151798349006, 16.012992410769982, 47.04729562198559], [4.757684883897221, 14.325919775146037, 7.278958098349005, 5.585193409230017, 11.49853742198559]]                               [[0.3779620208972214, 0.09834047485396263, 0.6388717333490046, 0.4600727612300175, 0.09612052198558962], [1.6127771038972214, 1.8992909448539628, 1.9808888183490045, 1.6235087992300175, 1.7848654619855895], [0.8523905581027785, 0.3549727348539626, 0.19098918434900458, 0.47314518323001753, 0.33530035198558966], [0.4086996131027786, 1.3991541551460374, 1.1803042046509955, 1.0641668407699825, 1.5608882580144103], [2.0659004938972214, 0.4844183248539626, 0.9104952683490046, 0.14560073123001754, 1.4444706280144104], [0.2427106528527786, 1.5341661248539626, 1.7975172483490047, 1.1819293792300176, 1.2739481619855897], [1.2973894461027786, 0.4899906551460374, 0.006741726349004551, 0.33989761436998245, 1.2682709719855896], [2.0834583938972213, 1.2938934951460375, 1.3493711716509953, 0.5139284897699825, 0.2603607180144104], [0.7351101638972214, 0.49578728485396256, 0.8707890083490046, 0.6918044722300175, 1.7175292380144103], [1.0043149141027787, 1.5442738048539626, 1.1800949383490047, 1.3755039592300176, 0.3094363119855896], [1.4623415938972215, 0.44519407514603737, 0.28443439903099543, 0.16520091776998244, 2.0906579719855896], [0.7666434738972214, 1.0926966251460375, 0.16014968365099544, 0.8732094267699825, 0.49598880198558964], [1.2003013271027787, 0.5379942048539625, 1.6231996383490046, 0.9294602992300176, 1.6334779580144103], [0.2832453098972214, 1.0547262448539625, 0.6901683153490046, 1.2185591892300176, 0.9922207380144104], [1.6216120038972215, 0.7473411651460373, 1.1417543096509954, 0.06840865076998245, 0.8090585419855896], [0.6156748621027786, 0.7670553751460374, 0.3920726576509954, 0.2975369110799824, 1.3764883219855897], [0.4447523221027786, 1.3659530048539625, 1.4060897483490047, 1.3166420092300175, 0.22085769801441038], [1.7733756338972213, 0.7207141748539625, 0.5265883203490045, 1.2266208092300175, 1.5635187480144104], [0.7531545751027786, 0.6144769751460374, 1.2892756316509955, 0.6678637397699825, 0.006687098014410364], [1.1577111311027786, 0.3269332951460374, 0.20631363534900454, 0.8797811007699824, 2.2645673019855894], [2.221255043897221, 1.3072556348539626, 1.9199514083490048, 1.1617827792300175, 1.2001841819855896], [10.240730616102779, 21.586882864853962, 4.754065688349004, 27.965184110769982, 14.60135588198559], [13.865974983897221, 13.022320985146036, 21.418116601650997, 11.339806010769982, 12.442866568014411], [26.45330841610278, 2.6489674948539625, 15.565902101650996, 4.337310249230018, 12.67689717801441], [19.471712983897223, 41.089800284853965, 20.928728501650994, 11.560479889230018, 35.933205058014416], [15.314295283897222, 6.976872604853963, 4.146142071650996, 21.772359110769983, 4.353162961985589], [11.925562416102778, 23.057462415146038, 18.876289401650997, 1.8489317707699824, 16.25605703801441], [19.347901316102778, 6.886526394853963, 6.953025648349004, 2.5960758592300177, 4.81379509198559], [5.846717313897221, 20.69496180514604, 18.646151798349006, 16.012992410769982, 47.04729562198559], [4.757684883897221, 14.325919775146037, 7.278958098349005, 5.585193409230017, 11.49853742198559]]                               1                [152.22019864029, 190.91821509033718, 139.68386440815698, 140.96136122799788, 209.32924574218939]     [2.454914295945614, 2.8807203830467007, 1.8683726307513973, 1.7003078998239625, 2.5889537761049346, 2.5652328309545385, 1.8620427172427376, 3.1225946425503817, 1.5547693581257882, 2.1643762278372844, 2.417269080113517, 2.262181130097954, 2.6130825689461417, 1.7059006163299495, 2.5434421962731357, 1.6719639488178777, 2.3436175837980597, 2.21840685471762, 2.2979551899195805, 2.6929577802250764, 2.9664479867733977, 67.55817452276169, 49.40605166020639, 56.18272131366201, 106.81902608375768, 56.88589885520079, 67.51142221220091, 34.83503461244773, 83.13379306723152, 32.897650682457574]    1\n",
      "[[0.32900218089722144, 0.3666501048539626, 0.36635876834900455, 0.5048294552300175, 0.13074807998558963], [2.189621633897221, 1.6205222148539626, 1.4589328283490046, 1.6573511592300176, 1.4165915819855897], [1.2152825901027786, 0.15706101485396257, 0.13890107834900456, 0.48943170223001753, 0.7135484419855898], [0.3322234327027786, 1.4670199351460373, 0.7490532216509954, 1.0396742557699823, 1.1108101500144103], [2.048185563897221, 0.03526117514603738, 0.5783679683490046, 0.2125351652300176, 1.4687681780144104], [0.030777201102778595, 1.7929891248539627, 1.1489520683490047, 1.5678597892300175, 1.6771137519855899], [0.9650461621027786, 0.5691300851460374, 0.08094884834900457, 0.012575909230017557, 2.2080460719855894], [1.5639807438972215, 1.1980628251460375, 1.2069420616509954, 1.3901163607699825, 0.3874249679144104], [0.5580582108972214, 0.5184502748539626, 0.5239316383490045, 0.6441129142300176, 1.3956508080144103], [0.8350907261027786, 1.7781877148539627, 0.7296820783490046, 1.6317259792300176, 0.29427221441441037], [1.2929881538972214, 0.4627270451460374, 0.7246820716509954, 0.5484520217699824, 1.9379923919855895], [0.7639809938972215, 0.6759561451460374, 0.6773298116509954, 0.6907830157699825, 0.5532967379855895], [1.4341005461027785, 1.2120874248539626, 1.6493024183490046, 1.1247558092300176, 1.8324026080144102], [0.6821208898972214, 0.9936278448539626, 1.3337549183490047, 1.1213083792300176, 0.8664713090144103], [1.4939841438972215, 0.5341033651460374, 0.6086089116509954, 0.5171105577699824, 0.8830734419855897], [1.4509782661027786, 0.9637210251460373, 0.15825667165099544, 0.45770868676998244, 1.6355594919855896], [0.2275823865027786, 1.0996055448539626, 1.8218077383490046, 0.8339915792300177, 0.3675677480144104], [2.2745019838972214, 1.4854781548539626, 0.9937050683490045, 1.1622289592300175, 1.4756046680144104], [0.9129310671027786, 1.3611347151460373, 1.0394445416509954, 0.29974552735998244, 0.13740395301441038], [1.1370623851027786, 0.8264817651460374, 0.4148785783490046, 0.5567234177699825, 1.6322849419855896], [1.4163019238972214, 1.6799346248539626, 1.8310565283490046, 0.9113971192300176, 0.8533529819855896], [0.6447780858972214, 10.458295434853962, 3.5236027816509954, 10.649492210769981, 18.786049118014407], [11.412422083897221, 21.96333277514604, 12.360166121650996, 1.9987194907699823, 4.909640448014411], [19.761521016102776, 8.388265845146037, 9.339310008349004, 5.645467959230018, 25.41656808198559], [16.230861883897223, 14.430544595146037, 15.710390401650995, 15.203689189230017, 18.208899718014408], [13.43345588389722, 7.701752314853962, 1.8128148783490048, 15.629906010769982, 5.311242451985589], [20.385299383897223, 5.155869085146037, 18.454434408349005, 5.230667130769982, 19.87278198198559], [25.027596783897224, 1.4829656048539626, 27.502453938349003, 1.1804148317699825, 15.499414018014411], [18.404901516102775, 39.53942034514604, 35.66978705834901, 39.40692838923002, 26.46919368198559], [10.47667408389722, 11.309417205146037, 8.163866911650995, 18.887825210769982, 15.41742541801441]]                                  [[0.32900218089722144, 0.3666501048539626, 0.36635876834900455, 0.5048294552300175, 0.13074807998558963], [2.189621633897221, 1.6205222148539626, 1.4589328283490046, 1.6573511592300176, 1.4165915819855897], [1.2152825901027786, 0.15706101485396257, 0.13890107834900456, 0.48943170223001753, 0.7135484419855898], [0.3322234327027786, 1.4670199351460373, 0.7490532216509954, 1.0396742557699823, 1.1108101500144103], [2.048185563897221, 0.03526117514603738, 0.5783679683490046, 0.2125351652300176, 1.4687681780144104], [0.030777201102778595, 1.7929891248539627, 1.1489520683490047, 1.5678597892300175, 1.6771137519855899], [0.9650461621027786, 0.5691300851460374, 0.08094884834900457, 0.012575909230017557, 2.2080460719855894], [1.5639807438972215, 1.1980628251460375, 1.2069420616509954, 1.3901163607699825, 0.3874249679144104], [0.5580582108972214, 0.5184502748539626, 0.5239316383490045, 0.6441129142300176, 1.3956508080144103], [0.8350907261027786, 1.7781877148539627, 0.7296820783490046, 1.6317259792300176, 0.29427221441441037], [1.2929881538972214, 0.4627270451460374, 0.7246820716509954, 0.5484520217699824, 1.9379923919855895], [0.7639809938972215, 0.6759561451460374, 0.6773298116509954, 0.6907830157699825, 0.5532967379855895], [1.4341005461027785, 1.2120874248539626, 1.6493024183490046, 1.1247558092300176, 1.8324026080144102], [0.6821208898972214, 0.9936278448539626, 1.3337549183490047, 1.1213083792300176, 0.8664713090144103], [1.4939841438972215, 0.5341033651460374, 0.6086089116509954, 0.5171105577699824, 0.8830734419855897], [1.4509782661027786, 0.9637210251460373, 0.15825667165099544, 0.45770868676998244, 1.6355594919855896], [0.2275823865027786, 1.0996055448539626, 1.8218077383490046, 0.8339915792300177, 0.3675677480144104], [2.2745019838972214, 1.4854781548539626, 0.9937050683490045, 1.1622289592300175, 1.4756046680144104], [0.9129310671027786, 1.3611347151460373, 1.0394445416509954, 0.29974552735998244, 0.13740395301441038], [1.1370623851027786, 0.8264817651460374, 0.4148785783490046, 0.5567234177699825, 1.6322849419855896], [1.4163019238972214, 1.6799346248539626, 1.8310565283490046, 0.9113971192300176, 0.8533529819855896], [0.6447780858972214, 10.458295434853962, 3.5236027816509954, 10.649492210769981, 18.786049118014407], [11.412422083897221, 21.96333277514604, 12.360166121650996, 1.9987194907699823, 4.909640448014411], [19.761521016102776, 8.388265845146037, 9.339310008349004, 5.645467959230018, 25.41656808198559], [16.230861883897223, 14.430544595146037, 15.710390401650995, 15.203689189230017, 18.208899718014408], [13.43345588389722, 7.701752314853962, 1.8128148783490048, 15.629906010769982, 5.311242451985589], [20.385299383897223, 5.155869085146037, 18.454434408349005, 5.230667130769982, 19.87278198198559], [25.027596783897224, 1.4829656048539626, 27.502453938349003, 1.1804148317699825, 15.499414018014411], [18.404901516102775, 39.53942034514604, 35.66978705834901, 39.40692838923002, 26.46919368198559], [10.47667408389722, 11.309417205146037, 8.163866911650995, 18.887825210769982, 15.41742541801441]]                                  1                [163.56374332649955, 165.45739988086166, 183.57477051741975, 164.88442652856347, 174.86751143492012]  [2.1928333852699398, 2.7618524100774784, 1.9109679281033873, 1.9489879208309275, 2.7219224352965448, 2.765620600656895, 2.8335219101816493, 2.1053017595400227, 1.2373381869648636, 3.0894254809100814, 1.7645842680405865, 1.0736496744598496, 2.0874772755498263, 1.3905000295637346, 1.2201356674463542, 2.1737742710085146, 2.92913939963439, 2.5298977372169706, 3.046140706098121, 1.323984897702465, 2.7358299345212234, 34.759928823909696, 57.761901705780815, 51.630574692567265, 49.94366856001436, 41.59273700123233, 57.042726394999725, 77.69759038577588, 104.10173722144998, 46.4624197491941]  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.\n",
      "WARNING: 2019-07-02 07:51:36.822802: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2019-07-02 07:51:36.842084: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000189999 Hz\n",
      "2019-07-02 07:51:36.854763: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5649e83c7770 executing computations on platform Host. Devices:\n",
      "2019-07-02 07:51:36.854796: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-07-02 07:51:36.866556: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:tensorflow:From /usr/lib/google-cloud-sdk/lib/third_party/ml_sdk/cloud/ml/prediction/frameworks/tf_prediction_lib.py:210: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /usr/lib/google-cloud-sdk/lib/third_party/ml_sdk/cloud/ml/prediction/frameworks/tf_prediction_lib.py:210: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "model_dir=$(ls ${PWD}/trained_model/export/exporter | tail -1)\n",
    "gcloud ml-engine local predict \\\n",
    "  --model-dir=${PWD}/trained_model/export/exporter/${model_dir} \\\n",
    "  --json-instances=./test_sequences.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCloud ML-Engine prediction from deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_normal_string_list = labeled_test_mixed_sequences_array.tolist()[0:number_of_prediction_instances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format dataframe to instances list to get sent to ML-Engine\n",
    "instances = [{UNLABELED_CSV_COLUMNS[i]: example[i]\n",
    "              for i in range(len(UNLABELED_CSV_COLUMNS))} \n",
    "             for example in labeled_test_mixed_sequences_array.tolist()[0:number_of_prediction_instances]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag_0': '0.04578242,2.08372546,-0.83918422,-0.41474361,2.10320029,0.28201425,-0.5887248,1.54971347,1.19260349,-1.47547528,1.90855823,0.85980201,-1.28879067,0.90236718,2.11371783,-0.47262889,0.05883223,2.28804074,-0.62779903,-0.63861997,1.83978207,0.15363023,-0.52416,1.54875903,0.89105011,-1.34568675,0.83059211,1.28443223,-0.94734609,0.72088739',\n",
       "  'tag_1': '0.20497854,1.90747437,0.32244349,-1.02107467,0.32484215,1.41744456,0.37542937,-0.734835,0.68677674,2.03719356,-0.58006658,-0.85696386,0.99925598,1.83628808,-0.25620223,-0.70086999,1.91524559,1.8430773,-0.75249804,-0.33719583,1.62865099,1.25911638,-0.32587741,0.20599461,1.50016247,0.92088306,-0.54718117,0.05728738,1.55035588,0.9228112',\n",
       "  'tag_2': '0.4525886,2.12145276,0.74908665,-0.50606804,0.47970213,1.20468805,0.11638895,-0.68484022,1.58629859,1.61301974,0.08025137,-0.5435459,1.21613622,1.33774939,-0.41542232,-0.09654433,1.38876751,0.386942,-0.61026872,0.27460487,1.63266603,0.51190956,-0.61933107,0.2943599,1.53790602,0.15337736,-0.31894312,1.03155675,1.63009949,0.14141478',\n",
       "  'tag_3': '0.606869,1.74195085,0.52136957,-0.67513755,0.55079066,1.52486836,-0.03077573,-0.8249042,0.86988902,1.86322878,0.09787049,-0.59107136,1.47995201,1.74192961,-0.14099128,-0.61072806,1.41260702,1.91179795,-0.51145538,-0.20774656,1.57488923,0.94312199,-0.50014483,-0.18929274,1.28016735,1.34729914,-0.63621931,-0.08340186,1.32548032,1.05058927',\n",
       "  'tag_4': '0.10053401,1.88205338,1.59025716,-0.63885894,-0.22507738,1.57679464,2.09907041,-0.4323427,-1.21491207,0.18321881,2.17046292,0.72621273,-0.90235026,-1.13064258,1.35668877,1.65267986,0.23148414,-0.79345521,0.11180817,2.30365913,0.70422648,-0.75672703,-0.61439398,1.90988701,1.96640534,-0.09405963,-1.52055838,0.49372241,2.12090928,1.2225777'},\n",
       " {'tag_0': '0.78460684,2.22475035,-0.26454446,0.26203485,1.8214474,-0.09169909,-0.45781663,1.48351218,0.40996351,-0.95735893,1.91963387,1.18955355,-1.50969622,0.4336434,2.06491413,-1.11488792,0.1271989,2.49016901,-0.49590891,-0.26273862,1.62724821,0.09682434,-1.36222755,1.5419755,1.35356255,-0.74461543,0.63875208,1.60338724,-0.5072058,0.18222196',\n",
       "  'tag_1': '0.44191916,1.39817612,0.60501179,-1.23636515,0.68665155,1.42880814,-0.06610397,-1.00228803,1.45770053,1.43469489,0.0666048,-0.51504575,1.27596037,1.99489413,-0.30338027,-0.88176514,1.85015719,1.72365943,-0.90566591,0.12066665,1.34347054,0.7541213,-0.49624431,-0.3144946,1.88308744,1.22562879,-0.43262499,-0.1583303,2.27873044,1.13843259',\n",
       "  'tag_2': '0.02943665,1.37904033,0.27117148,-0.63828818,0.93142207,1.29840424,-0.44570541,-0.41910079,1.48001285,1.90901661,-0.84647481,-0.38109081,1.84714444,1.45588122,-0.36672788,0.030894,1.29768168,1.13128442,-0.66270509,0.34199346,2.10136824,0.37938593,-1.11815421,1.12113929,1.41883599,-0.00400664,-0.59191252,1.48472851,1.19776499,0.14319626',\n",
       "  'tag_3': '0.4469657,1.93930023,0.55374618,-0.38793736,1.02206255,1.48517713,0.35459396,-0.55496937,1.34677895,1.60849124,0.26701796,-0.38455875,0.96122812,1.48104549,0.18573198,-0.83383942,1.60065625,1.87830972,-0.4360446,-0.3823913,1.138238,1.09524282,-0.75828936,-0.49376234,1.40302382,1.17558228,-0.49822587,0.01757973,1.17273693,1.38066757',\n",
       "  'tag_4': '0.51966989,2.42933447,0.90435155,-1.2250397,-0.41185631,1.94520179,1.7904242,-0.50512597,-1.63029957,0.68518417,2.63152764,1.31636932,-1.50233641,-0.8529697,1.58866167,2.06892931,0.17299949,-1.17616137,0.06756283,1.82142382,1.07451417,-1.06476011,-0.79664073,1.44166565,2.17672782,0.13718883,-0.91375404,0.27194093,2.39663523,0.94010979'},\n",
       " {'tag_0': '0.14439853,1.52930424,-0.85795895,-0.56889422,2.32513096,-0.09891259,-0.92513078,1.93793841,0.95858391,-0.69593406,1.67346539,1.58597847,-0.76804582,0.41619387,1.88848001,-1.14108084,0.11057026,2.14463433,0.04703596,-0.44405064,2.10779751,-8.90531288,-10.54296783,-25.20103974,-13.91767566,19.84128606,-8.76012044,-16.85412319,15.10028945,10.03446377',\n",
       "  'tag_1': '0.02654965,1.4486934,0.54586664,-0.62122817,0.45475566,2.29969243,-0.23247951,-0.94347674,0.77513475,1.81181654,0.11733882,-0.78420261,1.61095955,1.51308597,-0.74129954,-0.67443832,1.56326872,1.30558309,-0.61917377,-0.12712005,1.88311039,11.7577588,-15.46622615,-1.95788987,16.14005113,5.99496224,7.49991843,1.9968646,-18.28737584,-12.02949522',\n",
       "  'tag_2': '0.12118213,1.60376625,0.35845473,-0.89784207,1.25292104,1.1915986,0.25973931,-0.92219733,1.41492765,1.00888714,-0.3943936,0.14574666,1.89171318,1.16815598,-0.55532993,0.49680597,2.03544533,0.58826812,-0.6213719,0.42297595,2.15189508,7.55590009,-7.35047908,-5.1055225,22.03672207,5.60558851,-15.49782466,-14.09164515,-21.48490653,7.91624927',\n",
       "  'tag_3': '0.80266811,2.06323883,0.66853451,-0.24959123,0.74640574,1.46768654,0.35710569,-0.8929334,1.21715091,1.94830542,0.09552058,-0.30528379,0.87974736,1.7468403,0.22059557,-0.29680896,0.99763333,1.72891483,-0.30864511,-0.52196651,1.27388375,25.26072481,8.10782076,-2.71999844,22.08007267,23.70883328,9.89418485,-8.28222553,21.00577352,-8.96853413',\n",
       "  'tag_4': '0.91016917,1.9527098,1.18879416,-1.30337446,-0.45671149,1.2278228,1.88519934,0.32739444,-1.35765232,0.29372795,2.60884717,1.58855125,-1.31116307,-0.39693101,1.40292567,1.66103077,0.30891582,-0.81866009,0.63163615,2.51378946,0.80128593,24.4884547,4.63510242,30.88008202,-20.06800441,-0.27888195,21.75988955,-4.38975021,27.82269685,17.77171431'},\n",
       " {'tag_0': '0.4189301,1.81782393,-0.51057322,-0.65178793,2.34555738,-0.35515739,-0.94025864,1.47933781,0.79063198,-0.60399785,0.95492196,1.65769417,-0.81696101,0.72064501,1.83253507,-0.32667204,-0.36915658,2.07559998,-0.20938255,-0.24492739,2.00686858,2.29222071,-16.59640969,20.97530937,-7.64949914,-15.2582089,-9.4571889,-13.54074413,13.92706161,-11.96848058',\n",
       "  'tag_1': '0.88678797,2.01281533,0.75725411,-1.27489112,1.24162285,1.70367203,0.42377197,-0.61549925,0.96487915,1.79615911,0.20017967,-0.93082309,1.53055351,1.439291,-0.57990066,-0.64382654,1.05782501,1.17089589,-0.82190692,-0.21530724,1.31475074,-21.67042859,7.42246216,-3.60849087,29.59564595,11.8439181,-14.79109158,3.31585142,-22.31805195,20.2093845',\n",
       "  'tag_2': '0.7267678,1.27148767,0.11718621,-1.22965865,1.14916074,1.51967335,-0.5336727,-0.41828989,1.19171098,1.82704643,-0.49935752,0.08598957,1.17360228,1.08920573,-0.75291315,-0.0460368,1.6768235,0.9347926,-0.93810147,0.38460954,1.34910921,12.17595792,-11.22632985,-7.15867866,38.00667269,4.52139697,4.74674319,11.79893035,-14.65043632,-7.81455371',\n",
       "  'tag_3': '0.93755359,2.15595349,0.05413082,-0.45850969,1.16169442,2.02006599,0.07693545,-0.96172146,0.47263425,1.60994746,0.40207782,-0.41522575,1.15774938,1.42035969,-0.27090245,-0.21409745,1.21891107,1.04801768,-0.65871845,0.14447122,1.74550709,-16.84477854,6.8541187,-3.15506538,30.15935695,17.3467079,-2.37644581,3.58623304,-35.0377449,-7.73567371',\n",
       "  'tag_4': '4.08342677e-02,2.22190312e+00,1.29435325e+00,-1.51615780e+00,-1.16555215e+00,2.08514776e+00,2.37597619e+00,-1.25934382e-01,-1.54800053e+00,4.29066459e-02,1.94538588e+00,1.60418378e+00,-1.25513399e+00,-1.99820916e-01,2.05976983e+00,2.04948038e+00,-2.43868456e-02,-1.71509733e+00,8.38570908e-01,2.64721037e+00,1.44176311e+00,-5.94697007e+00,-1.27118220e+01,-2.24243590e+01,-2.05586147e+01,-9.53644133e+00,-2.08944822e+01,6.82503318e-01,-3.00654713e+01,2.80374768e+01'},\n",
       " {'tag_0': '0.26749455,1.94535308,-0.32201986,0.06421197,2.16397833,-0.19713457,-1.16215232,1.45799065,0.88188244,-0.7193895,1.71959122,1.71254996,-1.36559233,1.04150664,1.8049871,-0.35619785,0.24322555,2.53854792,-0.15231807,-0.8707556,2.35317644,9.64131381,16.76907341,-36.08504645,-12.248554,-14.99286457,-10.03466692,-24.59871047,8.93622897,-11.30075562',\n",
       "  'tag_1': '3.25400645e-01,1.83553581e+00,3.30133402e-02,-1.05645258e+00,2.55071276e-01,2.08620310e+00,5.42631267e-01,-1.26188939e+00,1.01895604e+00,1.41217680e+00,-6.02548861e-01,-9.46956129e-01,1.20738952e+00,2.00138103e+00,-1.18298036e-01,-4.12686396e-01,1.65599182e+00,1.89629457e+00,-2.82853881e-01,4.09213688e-03,1.18930122e+00,-1.95664377e+01,8.98901919e+00,1.19942321e-01,-1.58518388e+01,-1.43417655e+01,1.21314925e+01,3.01317894e+00,2.51540616e+01,2.13976599e+01',\n",
       "  'tag_2': '3.75558731e-02,2.02690800e+00,4.34983714e-02,-2.95917001e-01,6.20315732e-01,1.97302443e+00,-2.03059366e-01,-5.21163410e-01,9.05038860e-01,1.85667930e+00,-5.04837905e-01,1.38529847e-01,1.64201076e+00,7.96586660e-01,-1.00990064e+00,-1.61986729e-01,1.54703522e+00,7.20591688e-01,-2.79521167e-01,8.73716845e-01,2.25017117e+00,-8.02357737e+00,-1.38309858e+01,-9.57688654e+00,-1.93134571e+01,-9.25084230e-01,4.17442289e+00,8.35574213e+00,3.80023720e+01,8.05536007e+00',\n",
       "  'tag_3': '0.73061364,2.05284156,0.85329278,-0.67486612,0.24634236,1.81050896,0.39678958,-1.06319902,0.9308664,1.9746281,-0.20711696,-1.05862246,0.76713377,1.14357255,-0.08928305,-0.39110961,1.36821908,1.22186153,-0.47155013,0.04774755,1.85792878,12.94174028,14.84811919,-4.66176847,21.24538437,12.76115783,-3.24568919,0.94232958,20.03474116,-14.81517666',\n",
       "  'tag_4': '0.60336881,2.57569049,1.4390664,-0.63438137,-1.0454428,1.64955266,2.1272951,0.18938423,-1.59322156,0.0357363,2.16119675,1.38626259,-0.88716874,-0.86750551,1.75607039,2.24094986,-0.12658392,-1.75349578,0.31301118,1.87009347,1.00077754,22.7285394,10.3012922,33.67736395,-23.81240112,-4.82284088,21.16871016,7.53234425,-31.84245601,7.73497232'},\n",
       " {'tag_0': '0.66390375,1.91224853,-0.75998674,0.16583383,1.94111873,-0.18876818,-0.73863619,1.439442,0.86761647,-1.45619469,1.642386,1.6978923,-1.39774526,0.72779418,2.15061565,-0.66476062,-0.03947756,2.22216892,-0.3421257,-0.79962102,1.94376554,-6.31771134,9.81723354,-34.09916694,25.6001664,-11.44625836,16.05046642,25.95948006,12.05400936,-0.22820499',\n",
       "  'tag_1': '0.73268173,1.95470906,0.49073983,-0.58509405,0.52493239,1.9203617,-0.29824639,-1.16564289,1.131936,1.85353471,-0.51078756,-0.32101345,1.01158417,2.08387168,-0.03968996,-0.85130382,1.03057354,0.94895503,-0.46587503,-0.79025385,1.35903135,12.26792618,-4.89464604,4.63220626,21.11314205,15.77564527,-14.02100863,0.86271577,35.97242666,-18.9025171',\n",
       "  'tag_2': '0.10193571,1.526414,0.5845246,-1.12907209,0.58289515,2.01385203,0.2148382,-0.55431621,1.22362455,1.44629717,-0.69591171,-0.47380839,1.34579285,0.82424749,-0.50969712,-0.23211407,1.7977069,1.13683141,-0.78393094,0.07664877,2.03011876,0.32741736,8.21769838,-11.77479453,18.7328203,-0.38991858,-3.6819336,10.73098977,-15.20634133,-9.36782305',\n",
       "  'tag_3': '0.31793294,1.86907379,0.0654157,-0.36010624,0.87789649,1.99049968,0.62147839,-1.04766616,1.36601599,1.52099766,0.26337958,-0.48964718,1.40576012,1.09980402,0.28323107,-0.61677021,0.95583582,1.50594534,-0.37044958,-0.70391835,1.41464893,-18.79149823,6.18692826,-9.40434339,19.44721519,-22.19295547,11.62407256,0.78151538,-15.67880345,12.27786164',\n",
       "  'tag_4': '0.25400124,1.79821014,1.59548602,-1.20284111,-1.09810334,1.31258125,1.825805,0.35242575,-1.45791686,0.24007852,2.10441729,1.53381677,-0.83108086,-1.18674093,1.5339149,2.55464355,0.279657,-1.70062646,0.62001037,2.0899668,1.59576623,-12.24206893,6.19378655,17.24286424,28.22585649,-1.86323115,-18.73423282,-2.73126222,25.42481926,12.7053286'},\n",
       " {'tag_0': '0.47805567,1.71371768,-0.45959272,-0.49496749,2.22487491,-0.40795281,-1.09632113,2.35527222,0.67202697,-0.84680957,1.54583383,1.20824376,-0.6252641,0.45565119,1.60141782,-0.37726077,0.0784125,1.83008365,-0.10206071,-0.12671613,1.717572,-1.71001573,-17.02521318,-16.2562021,-8.31252194,15.70261822,6.95154306,-18.16407827,-8.45831012,-2.06897563',\n",
       "  'tag_1': '0.64702999,1.50578898,0.47690216,-1.2355579,0.94038343,1.89250621,-0.16943474,-1.02563999,0.59872698,2.15253363,0.31241192,-0.27405881,1.6675514,2.0938408,-0.14970709,-0.62108968,1.75263376,1.57327917,-0.26068353,-0.75656503,1.79609955,-21.01759499,-8.95955628,0.3056842,-18.69080218,15.39846549,-6.72647796,-3.54666918,-36.53804369,8.96205032',\n",
       "  'tag_2': '0.89930679,1.44316698,0.73404252,-0.93825858,0.54185104,1.94862494,-0.13920211,-0.65091053,1.07029735,1.0976008,-0.45188468,-0.58512131,1.82190414,0.774188,-1.03737969,-0.31424911,1.69511943,0.49831915,-0.68552766,0.75839656,1.82656888,-1.71056728,9.00755129,13.82389774,34.15435584,-0.40350433,-10.54368335,22.07317063,19.32528944,3.11132772',\n",
       "  'tag_3': '4.39039443e-01,1.97436160e+00,3.19405216e-01,-5.97307685e-01,8.24177651e-01,2.03952829e+00,6.21367212e-01,-3.84500822e-01,9.87231180e-01,1.83593258e+00,3.61875912e-01,-1.66862318e-01,1.13273133e+00,1.17130858e+00,1.77883353e-02,-9.05861380e-01,1.18606036e+00,1.19549580e+00,-6.84767279e-01,-5.63381050e-01,1.44733871e+00,1.90945207e+01,-1.53296780e+01,-4.26070322e+00,-2.80902673e+01,1.31629054e+01,-1.47470873e+01,-1.53508955e+00,-1.88217553e+01,9.06002685e+00',\n",
       "  'tag_4': '0.71409809,2.25634269,0.7743612,-0.70022269,-0.67818445,1.26454379,1.88880028,-0.11962439,-1.47005186,0.86572649,1.97220609,0.72832047,-1.13676746,-0.19800255,1.87866477,2.5446669,-0.44990475,-1.475908,0.87848009,2.23856543,0.83514343,16.00372336,-20.35239085,-36.00084664,21.6635797,-3.28646778,-26.11262673,-4.13336249,33.07682509,6.71216064'},\n",
       " {'tag_0': '0.57525798,1.81056453,-0.73995134,-0.20913211,2.50678419,-0.16915986,-1.1351934,1.91670394,0.4624172,-0.93435116,1.8310662,0.86529175,-0.87775201,0.64702167,1.53880477,-0.32064389,0.1309192,2.22678171,-0.34041172,-0.50374789,1.7965069,3.83137169,18.21706632,21.11117876,-8.7835815,17.59218568,14.27819139,30.06820124,8.30015674,0.66059061',\n",
       "  'tag_1': '9.62194296e-01,2.09681767e+00,7.47217637e-02,-1.32808713e+00,6.15305761e-01,1.83579013e+00,6.00614097e-01,-1.09608549e+00,1.00973477e+00,2.10499725e+00,-1.21326755e-01,-4.20752028e-01,1.03041598e+00,1.94970798e+00,-3.09988291e-01,-2.34339703e-01,1.62822990e+00,1.30810913e+00,-1.53222164e-01,2.22383106e-02,1.52429102e+00,-9.07634820e+00,-1.57777302e+01,5.03678618e+00,-2.29925750e+01,1.45876213e+01,-1.74523814e+01,-1.57584091e+00,1.98803318e+01,-3.37255660e+00',\n",
       "  'tag_2': '5.85733086e-01,1.76574320e+00,7.24823418e-01,-5.12227810e-01,1.10160136e+00,1.28281714e+00,9.93205480e-02,-8.14316811e-01,8.54396656e-01,1.40974063e+00,-1.49625816e-02,-6.26753666e-01,1.34009021e+00,1.43490177e+00,-9.41796672e-01,-2.34373818e-01,1.71813406e+00,8.36584571e-01,-7.21484213e-01,2.39413818e-01,1.73315961e+00,-1.62245286e+01,7.57506820e+00,-6.99308026e+00,-1.68620727e+01,-1.51800661e+00,8.73864042e+00,-2.20920444e+01,-2.57897276e+01,-3.36505943e+00',\n",
       "  'tag_3': '6.02366608e-01,1.38389118e+00,7.25895894e-01,-1.07533314e+00,5.33952924e-01,1.56000976e+00,-2.59089457e-01,-7.02078069e-01,5.18675422e-01,1.55464011e+00,4.72318312e-02,-2.51265689e-01,1.10738339e+00,1.50831198e+00,5.86558854e-02,-7.48169849e-03,1.07600643e+00,1.47020688e+00,3.63209570e-02,-2.17522891e-02,1.00614948e+00,1.12173476e+01,1.22128718e+01,3.53312010e+00,-3.09146854e+01,-1.14409439e+01,2.28021871e+00,2.12945675e+00,1.84480409e+01,-1.17535500e+01',\n",
       "  'tag_4': '6.94555002e-01,2.60963518e+00,1.04515139e+00,-1.37443244e+00,-1.06523899e+00,2.02792441e+00,1.79138347e+00,-2.07309560e-02,-1.62484291e+00,5.94162529e-01,2.74278133e+00,1.40108713e+00,-7.02440348e-01,-1.00114382e+00,1.93426407e+00,1.80195428e+00,1.94516865e-01,-1.59494330e+00,5.05439489e-01,2.29237319e+00,7.37035976e-01,-1.53030330e+01,-7.99309169e+00,1.30802734e+01,3.20372412e+01,-2.06880439e+00,-1.81224960e+01,-1.06545984e+01,2.39996267e+01,1.40130208e+01'},\n",
       " {'tag_0': '6.16418637e-01,1.85123372e+00,-6.13933942e-01,-1.70242997e-01,2.30435711e+00,-4.25403675e-03,-1.05893283e+00,2.32191501e+00,9.73566780e-01,-7.65858298e-01,1.70079821e+00,1.00510009e+00,-9.61844711e-01,5.21701926e-01,1.86006862e+00,-3.77218246e-01,-2.06295706e-01,2.01183225e+00,-5.14697959e-01,-9.19254515e-01,2.45971166e+00,-1.00022740e+01,1.41044316e+01,-2.62148518e+01,1.97101696e+01,1.55527519e+01,-1.16871058e+01,-1.91094447e+01,6.08517393e+00,4.99614150e+00',\n",
       "  'tag_1': '0.47005379,2.27100426,0.72668605,-1.02744084,0.85613164,1.90587944,-0.11827734,-0.92218018,0.8675006,1.91598712,-0.07348076,-0.72098331,0.90970752,1.42643956,-0.37562785,-0.39534206,1.73766632,1.09242749,-0.24276366,0.04478002,1.67896895,21.95859618,-12.65060767,3.02068081,41.4615136,7.34858592,-22.6857491,7.25823971,-20.32324849,-13.95420646',\n",
       "  'tag_2': '9.15955235e-01,2.25797232e+00,4.68072686e-01,-9.03220703e-01,1.18757877e+00,2.07460075e+00,2.83825228e-01,-1.07228767e+00,1.14787251e+00,1.45717844e+00,-7.35089738e-03,1.16933818e-01,1.90028314e+00,9.67251817e-01,-8.64670808e-01,-1.14989156e-01,1.68317325e+00,8.03671822e-01,-1.01219213e+00,4.83397137e-01,2.19703491e+00,5.03114919e+00,-2.11410331e+01,-1.52888186e+01,-2.06516450e+01,-3.86905857e+00,-1.85992059e+01,7.23010915e+00,1.89232353e+01,7.55604160e+00',\n",
       "  'tag_3': '7.61219272e-01,1.92465531e+00,7.74291694e-01,-7.63020330e-01,4.46747242e-01,1.48307589e+00,-3.87511036e-02,-2.12781979e-01,9.92950983e-01,1.67665047e+00,1.35945593e-01,-5.72062916e-01,1.23060681e+00,1.51970570e+00,2.32737860e-01,3.60959969e-03,1.61778852e+00,1.52776732e+00,-3.66717229e-01,-5.78634590e-01,1.46292929e+00,-2.76640376e+01,-1.10386595e+01,4.63845676e+00,1.18616264e+01,-2.14712126e+01,-1.54778526e+00,2.89722237e+00,-1.57118459e+01,5.88633992e+00',\n",
       "  'tag_4': '0.45175324,2.14049818,0.69093307,-1.20525554,-1.08883791,1.62958088,1.62390369,0.095272,-1.36189652,0.66506903,2.44629069,0.85162152,-1.27784524,-0.63658802,1.16469126,1.73212104,0.13477502,-1.20788603,0.34894562,2.62020002,1.5558169,14.9569886,-12.08723385,-12.32126446,-35.57757234,4.70879568,-15.90042432,5.16942781,47.40292834,11.85417014'},\n",
       " {'tag_0': '5.67458797e-01,2.42807825e+00,-9.76825974e-01,-9.37668166e-02,2.28664218e+00,2.07679415e-01,-7.26589546e-01,1.80243736e+00,7.96514827e-01,-5.96634110e-01,1.53144477e+00,1.00243761e+00,-1.19564393e+00,9.20577506e-01,1.73244076e+00,-1.21252165e+00,1.08742296e-02,2.51295860e+00,-6.74474451e-01,-8.98605769e-01,1.65475854e+00,8.83234702e-01,1.16508787e+01,-1.95230644e+01,1.64693185e+01,1.36719125e+01,2.06237560e+01,2.52660534e+01,-1.81664449e+01,1.07151307e+01',\n",
       "  'tag_1': '0.73836342,1.99223553,0.52877433,-1.09530662,0.33645214,2.16470244,-0.19741677,-0.82634951,0.89016359,2.14990103,-0.09101373,-0.30424283,1.58380074,1.36534116,-0.16239005,-0.59200771,1.47131886,1.85719147,-0.9894214,-0.45476845,2.05164794,10.83000875,-21.59161946,-8.01655253,-14.05883128,8.07346563,-4.78415577,1.85467892,-39.16770703,-10.93770389',\n",
       "  'tag_2': '0.64344227,1.73601633,0.41598458,-0.47196972,0.85545147,1.42603557,0.35803235,-0.92985856,0.80101514,1.00676558,-0.44759857,-0.40024631,1.92638592,1.61083842,-0.33152541,0.11882683,2.09889124,1.27078857,-0.76236104,0.69196208,2.10814003,-3.24651928,-12.08308262,9.61639351,-15.4333069,2.08989838,18.73151791,27.77953744,35.94687056,-7.88678341',\n",
       "  'tag_3': '8.05975966e-01,1.95849767e+00,7.90578213e-01,-7.38527745e-01,5.13681676e-01,1.86900630e+00,3.13722420e-01,-1.08896985e+00,9.45259425e-01,1.93287249e+00,-2.47305511e-01,-3.89636505e-01,1.42590232e+00,1.42245489e+00,-2.15964047e-01,-1.56562176e-01,1.13513809e+00,1.46337547e+00,1.40098341e-03,-2.55576907e-01,1.21254363e+00,-1.03483457e+01,-1.69757298e+00,5.94661447e+00,1.55048357e+01,-1.53287595e+01,-4.92952062e+00,-8.79268321e-01,3.97080749e+01,-1.85866787e+01',\n",
       "  'tag_4': '4.86380798e-01,1.77222430e+00,1.06918116e+00,-7.55177432e-01,-1.11313546e+00,2.03274647e+00,2.56367879e+00,-3.17922499e-02,-1.04001809e+00,6.13605036e-02,2.29362511e+00,9.08929456e-01,-1.47676989e+00,-5.10838591e-01,1.23870616e+00,1.99119221e+00,-1.19350300e-02,-1.11997195e+00,2.18228765e-01,1.98791766e+00,1.20898570e+00,-1.84304164e+01,-4.55400773e+00,2.57722008e+01,-1.78532670e+01,5.66687517e+00,2.02284147e+01,-1.51437813e+01,2.68248264e+01,-1.50617927e+01'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response = {'predictions': [{'time_anom_flags': 1, 'X_time_abs_recon_err': [[0.1926741961027786, 0.1667347751460374, 0.17550509834900457, 0.30572248923001755, 0.25509870801441037], [1.8452688438972216, 1.5357610548539626, 1.8443692583490046, 1.4408043392300176, 1.5264206619855898], [1.0776408361027787, 0.049269825146037394, 0.47200314834900453, 0.2202230592300175, 1.2346244419855896], [0.6532002261027786, 1.3927879851460374, 0.7831515416509955, 0.9762840607699824, 0.9944916580144103], [1.8647436738972216, 0.0468711651460374, 0.20261862834900457, 0.24964414923001754, 0.5807100980144104], [0.04355763389722142, 1.0457312448539626, 0.9276045483490045, 1.2237218492300175, 1.2211619219855896], [0.8271814161027786, 0.0037160548539625915, 0.16069455165099544, 0.33192224076998245, 1.7434376919855896], [1.3112568538972214, 1.1065483151460374, 0.9619237216509955, 1.1260507107699824, 0.7879754180144104], [0.9541468738972214, 0.3150634248539626, 1.3092150883490046, 0.5687425092300176, 1.5705447880144103], [1.7139318961027785, 1.6654802448539625, 1.3359362383490045, 1.5620822692300176, 0.17241390801441037], [1.6701016138972213, 0.9517798951460374, 0.19683213165099545, 0.20327602076998244, 1.8148302019855895], [0.6213453938972214, 1.2286771751460375, 0.8206294016509954, 0.8922178707699825, 0.3705800119855896], [1.5272472861027786, 0.6275426648539626, 0.9390527183490047, 1.1788054992300177, 1.2579829780144103], [0.6639105638972215, 1.4645747648539627, 1.0606658883490045, 1.4407830992300175, 1.4862752980144103], [1.8752612138972216, 0.6279155451460374, 0.6925058216509954, 0.44213779076998244, 1.0010560519855898], [0.7110855061027787, 1.0725833051460374, 0.37362783165099545, 0.9118745707699825, 1.2970471419855896], [0.1796243861027786, 1.5435322748539626, 1.1116840083490047, 1.1114605092300176, 0.12414857801441037], [2.049584123897221, 1.4713639848539626, 0.10985849834900457, 1.6106514392300175, 1.1490879280144104], [0.8662556461027786, 1.1242113551460373, 0.8873522216509955, 0.8126018907699825, 0.2438245480144104], [0.8770765861027786, 0.7089091451460374, 0.002478631650995433, 0.5088930707699825, 1.94802641198559], [1.6013254538972215, 1.2569376748539625, 1.3555825283490046, 1.2737427192300175, 0.3485937619855896], [0.0848263861027786, 0.8874030648539626, 0.23482605834900455, 0.6419754792300175, 1.1123597480144103], [0.7626166161027785, 0.6975907251460374, 0.8964145716509955, 0.8012913407699824, 0.9700266980144103], [1.3103024138972215, 0.1657187051460374, 0.017276398349004574, 0.4904392507699824, 1.5542542919855897], [0.6525934938972214, 1.1284491548539626, 1.2608225183490047, 0.9790208392300175, 1.6107726219855896], [1.5841433661027786, 0.5491697448539625, 0.12370614165099544, 1.0461526292300176, 0.4496923480144104], [0.5921354938972214, 0.9188944851460374, 0.5960266216509955, 0.9373658207699824, 1.8761910980144103], [1.0459756138972214, 0.3144259351460374, 0.7544732483490046, 0.38454837076998244, 0.13808969198558962], [1.1858027061027787, 1.1786425648539625, 1.3530159883490047, 1.0243338092300176, 1.7652765619855895], [0.48243077389722144, 0.5510978848539627, 0.13566872165099544, 0.7494427592300175, 0.8669449819855897]], 'mahalanobis_dist_feat': [5.779162381961458, 5.138791234001083, 5.26259426575918, 3.6899269976051032, 5.78965100792573], 'X_feat_abs_recon_err': [[0.1926741961027786, 0.1667347751460374, 0.17550509834900457, 0.30572248923001755, 0.25509870801441037], [1.8452688438972216, 1.5357610548539626, 1.8443692583490046, 1.4408043392300176, 1.5264206619855898], [1.0776408361027787, 0.049269825146037394, 0.47200314834900453, 0.2202230592300175, 1.2346244419855896], [0.6532002261027786, 1.3927879851460374, 0.7831515416509955, 0.9762840607699824, 0.9944916580144103], [1.8647436738972216, 0.0468711651460374, 0.20261862834900457, 0.24964414923001754, 0.5807100980144104], [0.04355763389722142, 1.0457312448539626, 0.9276045483490045, 1.2237218492300175, 1.2211619219855896], [0.8271814161027786, 0.0037160548539625915, 0.16069455165099544, 0.33192224076998245, 1.7434376919855896], [1.3112568538972214, 1.1065483151460374, 0.9619237216509955, 1.1260507107699824, 0.7879754180144104], [0.9541468738972214, 0.3150634248539626, 1.3092150883490046, 0.5687425092300176, 1.5705447880144103], [1.7139318961027785, 1.6654802448539625, 1.3359362383490045, 1.5620822692300176, 0.17241390801441037], [1.6701016138972213, 0.9517798951460374, 0.19683213165099545, 0.20327602076998244, 1.8148302019855895], [0.6213453938972214, 1.2286771751460375, 0.8206294016509954, 0.8922178707699825, 0.3705800119855896], [1.5272472861027786, 0.6275426648539626, 0.9390527183490047, 1.1788054992300177, 1.2579829780144103], [0.6639105638972215, 1.4645747648539627, 1.0606658883490045, 1.4407830992300175, 1.4862752980144103], [1.8752612138972216, 0.6279155451460374, 0.6925058216509954, 0.44213779076998244, 1.0010560519855898], [0.7110855061027787, 1.0725833051460374, 0.37362783165099545, 0.9118745707699825, 1.2970471419855896], [0.1796243861027786, 1.5435322748539626, 1.1116840083490047, 1.1114605092300176, 0.12414857801441037], [2.049584123897221, 1.4713639848539626, 0.10985849834900457, 1.6106514392300175, 1.1490879280144104], [0.8662556461027786, 1.1242113551460373, 0.8873522216509955, 0.8126018907699825, 0.2438245480144104], [0.8770765861027786, 0.7089091451460374, 0.002478631650995433, 0.5088930707699825, 1.94802641198559], [1.6013254538972215, 1.2569376748539625, 1.3555825283490046, 1.2737427192300175, 0.3485937619855896], [0.0848263861027786, 0.8874030648539626, 0.23482605834900455, 0.6419754792300175, 1.1123597480144103], [0.7626166161027785, 0.6975907251460374, 0.8964145716509955, 0.8012913407699824, 0.9700266980144103], [1.3103024138972215, 0.1657187051460374, 0.017276398349004574, 0.4904392507699824, 1.5542542919855897], [0.6525934938972214, 1.1284491548539626, 1.2608225183490047, 0.9790208392300175, 1.6107726219855896], [1.5841433661027786, 0.5491697448539625, 0.12370614165099544, 1.0461526292300176, 0.4496923480144104], [0.5921354938972214, 0.9188944851460374, 0.5960266216509955, 0.9373658207699824, 1.8761910980144103], [1.0459756138972214, 0.3144259351460374, 0.7544732483490046, 0.38454837076998244, 0.13808969198558962], [1.1858027061027787, 1.1786425648539625, 1.3530159883490047, 1.0243338092300176, 1.7652765619855895], [0.48243077389722144, 0.5510978848539627, 0.13566872165099544, 0.7494427592300175, 0.8669449819855897]], 'feat_anom_flags': 0, 'mahalanobis_dist_time': [2.442493101704649, 2.546271489936297, 1.8514733502088239, 1.5269396316628294, 2.52957103496651, 1.9205411685893952, 2.305912288317667, 1.0863633594333606, 2.3649180487766777, 2.8777209543272826, 2.7297099297686622, 1.7680708096079414, 1.786909099368765, 1.6404831963360946, 1.7386071953952542, 1.4470205045488493, 2.7453307194861005, 3.736256776288349, 1.6908925994514539, 2.210165885606912, 2.112461215228318, 2.0959436054293894, 0.7350843718133653, 2.162456962838539, 1.3656942737585436, 2.6312422396732957, 1.5211612964377095, 1.953281577839982, 1.4655687389094965, 1.7910963244133324]}, {'time_anom_flags': 0, 'X_time_abs_recon_err': [[0.5461502238972215, 0.07020584485396258, 0.24764685165099543, 0.14581918923001758, 0.1640371719855896], [1.9862937338972213, 1.0264628048539626, 1.1019568283490047, 1.6381537192300175, 2.0737017519855896], [0.5030010761027786, 0.23329847485396266, 0.005912021650995414, 0.25259966923001753, 0.5487188319855896], [0.023578233897221385, 1.6080784651460374, 0.9153716816509954, 0.6890838707699825, 1.5806724180144103], [1.5829907838972215, 0.3149382348539626, 0.6543385683490046, 0.7209160392300176, 0.7674890280144104], [0.3301557061027786, 1.0570948248539624, 1.0213207383490046, 1.1840306192300176, 1.5895690719855897], [0.6962732461027786, 0.4378172851460374, 0.7227889116509955, 0.05344744923001754, 1.4347914819855896], [1.2450555638972214, 1.3740013451460376, 0.6961842916509955, 0.8561158807699825, 0.8607586880144105], [0.17150689389722137, 1.0859872148539627, 1.2029293483490047, 1.0456324392300176, 1.9859322880144104], [1.1958155461027786, 1.0629815748539626, 1.6319331083490045, 1.3073447292300175, 0.3295514519855896], [1.6811772538972214, 0.3051085151460374, 1.1235583116509955, 0.034128550769982446, 2.2758949219855893], [0.9510969338972215, 0.8867590651460373, 0.6581743116509955, 0.6857052607699825, 0.9607366019855896], [1.7481528361027785, 0.9042470548539625, 1.5700609383490047, 0.6600816092300176, 1.8579691280144104], [0.1951867838972214, 1.6231808148539626, 1.1787977183490046, 1.1798989792300176, 1.2086024180144104], [1.8264575138972214, 0.6750935851460373, 0.6438113816509954, 0.11541453076998245, 1.2330289519855897], [1.3533445361027785, 1.2534784551460374, 0.24618950165099543, 1.1349859307699823, 1.7132965919855898], [0.1112577161027786, 1.4784438748539626, 1.0205981783490046, 1.2995097392300174, 0.18263322801441037], [2.251712393897221, 1.3519461148539627, 0.8542009183490047, 1.5771632092300176, 1.5317940880144103], [0.7343655261027786, 1.2773792251460374, 0.9397885916509954, 0.7371911107699824, 0.28806988801441036], [0.5011952361027786, 0.2510466651460374, 0.06490995834900459, 0.6835378107699824, 1.4657911019855896], [1.3887915938972215, 0.9717572248539625, 1.8242847383490048, 0.8370914892300176, 0.7188814519855897], [0.14163227610277862, 0.3824079848539626, 0.10230242834900455, 0.7940963092300175, 1.4203928280144102], [1.6006841661027786, 0.8679576251460375, 1.3952377116509953, 1.0594358707699825, 1.1522734480144103], [1.3035188838972214, 0.6862079151460374, 0.8440557883490045, 0.7949088507699824, 1.0860329319855897], [1.1151059338972213, 1.5113741248539625, 1.1417524883490047, 1.1018773092300176, 1.8210951019855897], [0.9830720461027785, 0.8539154748539626, 0.28109014165099544, 0.8744357692300175, 0.21844388801441036], [0.4002954638972215, 0.8043383051460373, 0.8689960216509955, 0.7993723807699824, 1.2693867580144105], [1.3649306238972214, 0.5300436151460374, 1.2076450083490047, 0.28356678076998243, 0.08369178801441035], [0.7456624161027786, 1.9070171248539625, 0.9206814883490047, 0.8715904192300175, 2.0410025119855892], [0.05623465610277861, 0.7667192748539626, 0.13388724165099544, 1.0795210592300175, 0.5844770719855896]], 'mahalanobis_dist_feat': [6.304617048731646, 6.138812581727021, 5.5368839316901814, 5.552070689923312, 4.827559085510038], 'X_feat_abs_recon_err': [[0.5461502238972215, 0.07020584485396258, 0.24764685165099543, 0.14581918923001758, 0.1640371719855896], [1.9862937338972213, 1.0264628048539626, 1.1019568283490047, 1.6381537192300175, 2.0737017519855896], [0.5030010761027786, 0.23329847485396266, 0.005912021650995414, 0.25259966923001753, 0.5487188319855896], [0.023578233897221385, 1.6080784651460374, 0.9153716816509954, 0.6890838707699825, 1.5806724180144103], [1.5829907838972215, 0.3149382348539626, 0.6543385683490046, 0.7209160392300176, 0.7674890280144104], [0.3301557061027786, 1.0570948248539624, 1.0213207383490046, 1.1840306192300176, 1.5895690719855897], [0.6962732461027786, 0.4378172851460374, 0.7227889116509955, 0.05344744923001754, 1.4347914819855896], [1.2450555638972214, 1.3740013451460376, 0.6961842916509955, 0.8561158807699825, 0.8607586880144105], [0.17150689389722137, 1.0859872148539627, 1.2029293483490047, 1.0456324392300176, 1.9859322880144104], [1.1958155461027786, 1.0629815748539626, 1.6319331083490045, 1.3073447292300175, 0.3295514519855896], [1.6811772538972214, 0.3051085151460374, 1.1235583116509955, 0.034128550769982446, 2.2758949219855893], [0.9510969338972215, 0.8867590651460373, 0.6581743116509955, 0.6857052607699825, 0.9607366019855896], [1.7481528361027785, 0.9042470548539625, 1.5700609383490047, 0.6600816092300176, 1.8579691280144104], [0.1951867838972214, 1.6231808148539626, 1.1787977183490046, 1.1798989792300176, 1.2086024180144104], [1.8264575138972214, 0.6750935851460373, 0.6438113816509954, 0.11541453076998245, 1.2330289519855897], [1.3533445361027785, 1.2534784551460374, 0.24618950165099543, 1.1349859307699823, 1.7132965919855898], [0.1112577161027786, 1.4784438748539626, 1.0205981783490046, 1.2995097392300174, 0.18263322801441037], [2.251712393897221, 1.3519461148539627, 0.8542009183490047, 1.5771632092300176, 1.5317940880144103], [0.7343655261027786, 1.2773792251460374, 0.9397885916509954, 0.7371911107699824, 0.28806988801441036], [0.5011952361027786, 0.2510466651460374, 0.06490995834900459, 0.6835378107699824, 1.4657911019855896], [1.3887915938972215, 0.9717572248539625, 1.8242847383490048, 0.8370914892300176, 0.7188814519855897], [0.14163227610277862, 0.3824079848539626, 0.10230242834900455, 0.7940963092300175, 1.4203928280144102], [1.6006841661027786, 0.8679576251460375, 1.3952377116509953, 1.0594358707699825, 1.1522734480144103], [1.3035188838972214, 0.6862079151460374, 0.8440557883490045, 0.7949088507699824, 1.0860329319855897], [1.1151059338972213, 1.5113741248539625, 1.1417524883490047, 1.1018773092300176, 1.8210951019855897], [0.9830720461027785, 0.8539154748539626, 0.28109014165099544, 0.8744357692300175, 0.21844388801441036], [0.4002954638972215, 0.8043383051460373, 0.8689960216509955, 0.7993723807699824, 1.2693867580144105], [1.3649306238972214, 0.5300436151460374, 1.2076450083490047, 0.28356678076998243, 0.08369178801441035], [0.7456624161027786, 1.9070171248539625, 0.9206814883490047, 0.8715904192300175, 2.0410025119855892], [0.05623465610277861, 0.7667192748539626, 0.13388724165099544, 1.0795210592300175, 0.5844770719855896]], 'feat_anom_flags': 0, 'mahalanobis_dist_time': [2.3608070081503936, 2.958678839475689, 2.13561074863536, 2.921438181757887, 1.77887327464589, 1.6108030879178812, 2.0165830134119127, 1.6786687873575696, 2.206035822184424, 2.2994951268630848, 3.383583928679968, 0.6198213856791773, 2.5491179019074903, 2.1758570035761062, 2.2303025227588105, 2.251728214402842, 2.699677542171421, 2.8307553928823457, 1.9923622595005384, 2.1616818522250076, 2.4264002660474246, 2.3628116441664853, 1.6893803401383172, 0.7248686234259698, 1.6421476586469892, 2.0759904104416345, 1.1312458015927636, 2.498209721109119, 3.0574787145809736, 2.6574772493101935]}, {'time_anom_flags': 1, 'X_time_abs_recon_err': [[0.0940580861027786, 0.3451636651460374, 0.15590137165099544, 0.5015215992300176, 0.5545364519855895], [1.2908476238972215, 1.0769800848539626, 1.3266827483490047, 1.7620923192300175, 1.5970770819855897], [1.0964155661027786, 0.17415332485396257, 0.08137122834900457, 0.3673879992300175, 0.8331614419855897], [0.8073508361027786, 0.9929414851460374, 1.1749255716509954, 0.5507377407699825, 1.6590071780144102], [2.0866743438972213, 0.08304234485396261, 0.9758375383490046, 0.4452592292300176, 0.8123442080144103], [0.3373692061027786, 1.9279791148539625, 0.9145150983490047, 1.1665400292300176, 0.8721900819855897], [1.1635873961027787, 0.6041928251460373, 0.017344191650995433, 0.05595917923001753, 1.5295666219855897], [1.6994817938972213, 1.3151900551460374, 1.1992808316509955, 1.1940799107699824, 0.028238278014410367], [0.7201272938972214, 0.4034214348539626, 1.1378441483490047, 0.9160043992300175, 1.7132850380144102], [0.9343906761027786, 1.4401032248539625, 0.7318036383490045, 1.6471589092300176, 0.06190476801441036], [1.4350087738972215, 0.2543744951460374, 0.6714771016509955, 0.20562593076998245, 2.2532144519855897], [1.3475218538972213, 1.1559159251460374, 0.13133684165099543, 0.6064303007699825, 1.2329185319855898], [1.0065024361027786, 1.2392462348539626, 1.6146296783490046, 0.5786008492300175, 1.6667957880144104], [0.17773725389722142, 1.1413726548539624, 0.8910724783490047, 1.4456937892300175, 0.7525637280144104], [1.6500233938972215, 1.1130128551460374, 0.8324134316509955, 0.08055094076998245, 1.0472929519855896], [1.3795374561027787, 1.0461516351460374, 0.21972246834900455, 0.5979554707699825, 1.3053980519855897], [0.1278863561027786, 1.1915554048539625, 1.7583618283490046, 0.6964868192300175, 0.04671689801441037], [1.9061777138972216, 0.9338697748539626, 0.3111846183490045, 1.4277683192300175, 1.1742928080144104], [0.19142065610277859, 0.9908870851460374, 0.8984554016509954, 0.6097916207699825, 0.2760034319855896], [0.6825072561027786, 0.4988333651460374, 0.14589244834900456, 0.8231130207699825, 2.1581567419855894], [1.8693408938972216, 1.5113970748539625, 1.8748115783490047, 0.9727372392300175, 0.44565321198558966], [9.14376949610278, 11.386045484853963, 7.278816588349004, 24.959578299230017, 24.13282198198559], [10.781424446102779, 15.837939465146038, 7.627562581650996, 7.806674249230017, 4.279469701985589], [25.439496356102776, 2.3296031851460373, 5.382606001650996, 3.0211449507699824, 30.52444930198559], [14.15613227610278, 15.768337814853963, 21.759638568349004, 21.778926159230018, 20.42363712801441], [19.602829443897225, 5.623248924853963, 5.328505008349004, 23.40768676923002, 0.6345146680144104], [8.998577056102778, 7.128205114853963, 15.774908161650995, 9.593038339230018, 21.40425683198559], [17.092579806102776, 1.6251512848539627, 14.368728651650995, 8.583372040769982, 4.74538292801441], [14.861832833897221, 18.659089155146038, 21.761990031650996, 20.70462700923002, 27.46706413198559], [9.796007153897222, 12.401208535146036, 7.639165768349004, 9.269680640769982, 17.41608159198559]], 'mahalanobis_dist_feat': [149.46182360579283, 109.31326275801212, 131.32045736217637, 162.55681939659837, 182.8573999846083], 'X_feat_abs_recon_err': [[0.0940580861027786, 0.3451636651460374, 0.15590137165099544, 0.5015215992300176, 0.5545364519855895], [1.2908476238972215, 1.0769800848539626, 1.3266827483490047, 1.7620923192300175, 1.5970770819855897], [1.0964155661027786, 0.17415332485396257, 0.08137122834900457, 0.3673879992300175, 0.8331614419855897], [0.8073508361027786, 0.9929414851460374, 1.1749255716509954, 0.5507377407699825, 1.6590071780144102], [2.0866743438972213, 0.08304234485396261, 0.9758375383490046, 0.4452592292300176, 0.8123442080144103], [0.3373692061027786, 1.9279791148539625, 0.9145150983490047, 1.1665400292300176, 0.8721900819855897], [1.1635873961027787, 0.6041928251460373, 0.017344191650995433, 0.05595917923001753, 1.5295666219855897], [1.6994817938972213, 1.3151900551460374, 1.1992808316509955, 1.1940799107699824, 0.028238278014410367], [0.7201272938972214, 0.4034214348539626, 1.1378441483490047, 0.9160043992300175, 1.7132850380144102], [0.9343906761027786, 1.4401032248539625, 0.7318036383490045, 1.6471589092300176, 0.06190476801441036], [1.4350087738972215, 0.2543744951460374, 0.6714771016509955, 0.20562593076998245, 2.2532144519855897], [1.3475218538972213, 1.1559159251460374, 0.13133684165099543, 0.6064303007699825, 1.2329185319855898], [1.0065024361027786, 1.2392462348539626, 1.6146296783490046, 0.5786008492300175, 1.6667957880144104], [0.17773725389722142, 1.1413726548539624, 0.8910724783490047, 1.4456937892300175, 0.7525637280144104], [1.6500233938972215, 1.1130128551460374, 0.8324134316509955, 0.08055094076998245, 1.0472929519855896], [1.3795374561027787, 1.0461516351460374, 0.21972246834900455, 0.5979554707699825, 1.3053980519855897], [0.1278863561027786, 1.1915554048539625, 1.7583618283490046, 0.6964868192300175, 0.04671689801441037], [1.9061777138972216, 0.9338697748539626, 0.3111846183490045, 1.4277683192300175, 1.1742928080144104], [0.19142065610277859, 0.9908870851460374, 0.8984554016509954, 0.6097916207699825, 0.2760034319855896], [0.6825072561027786, 0.4988333651460374, 0.14589244834900456, 0.8231130207699825, 2.1581567419855894], [1.8693408938972216, 1.5113970748539625, 1.8748115783490047, 0.9727372392300175, 0.44565321198558966], [9.14376949610278, 11.386045484853963, 7.278816588349004, 24.959578299230017, 24.13282198198559], [10.781424446102779, 15.837939465146038, 7.627562581650996, 7.806674249230017, 4.279469701985589], [25.439496356102776, 2.3296031851460373, 5.382606001650996, 3.0211449507699824, 30.52444930198559], [14.15613227610278, 15.768337814853963, 21.759638568349004, 21.778926159230018, 20.42363712801441], [19.602829443897225, 5.623248924853963, 5.328505008349004, 23.40768676923002, 0.6345146680144104], [8.998577056102778, 7.128205114853963, 15.774908161650995, 9.593038339230018, 21.40425683198559], [17.092579806102776, 1.6251512848539627, 14.368728651650995, 8.583372040769982, 4.74538292801441], [14.861832833897221, 18.659089155146038, 21.761990031650996, 20.70462700923002, 27.46706413198559], [9.796007153897222, 12.401208535146036, 7.639165768349004, 9.269680640769982, 17.41608159198559]], 'feat_anom_flags': 1, 'mahalanobis_dist_time': [2.25067312150549, 2.499811744343535, 1.8168550767572478, 1.6674255239657438, 2.818017096767465, 2.889925865977877, 2.336105556564381, 2.5148054207280626, 2.2063109738265188, 2.9844605982933667, 2.6725573263650317, 2.2601630895548492, 2.451505107950239, 2.1866508353074803, 2.763026528167184, 1.9079005762762555, 3.2930167849140886, 2.8155666954386214, 2.1488578099456177, 2.407082854459213, 3.0029468787176516, 64.92981880711933, 35.703490669420425, 62.62005095085461, 62.322422696596995, 65.60663254039311, 46.472272548437026, 43.468220736669856, 66.74176710934972, 36.075537582193164]}, {'time_anom_flags': 1, 'X_time_abs_recon_err': [[0.18047348389722143, 0.5150746548539626, 0.44968429834900453, 0.6364070792300176, 0.3147984503144104], [1.5793673138972215, 1.6411020148539626, 0.9944041683490046, 1.8548069792300175, 1.8662704019855896], [0.7490298361027786, 0.3855407948539626, 0.15989729165099542, 0.24701569076998245, 0.9387205319855896], [0.8902445461027786, 1.6466044351460374, 1.5067421516509953, 0.7596562007699825, 1.8717905180144103], [2.107100763897221, 0.8699095348539625, 0.8720772383490045, 0.8605479092300174, 1.5211848680144102], [0.5936140061027786, 1.3319587148539624, 1.2425898483490045, 1.7189194792300175, 1.7295150419855896], [1.1787152561027787, 0.052058654853962605, 0.8107562016509955, 0.22421106076998243, 2.0203434719855893], [1.2408811938972215, 0.9872125651460375, 0.6953733916509954, 1.2628679707699826, 0.4815671000144104], [0.5521753638972214, 0.5931658348539626, 0.9146274783490047, 0.17148773923001753, 1.9036332480144103], [0.8424544661027785, 1.4244457948539626, 1.5499629283490046, 1.3088009492300177, 0.3127260721144104], [0.7164653438972214, 0.1715336451460374, 0.7764410216509954, 0.10093130923001753, 1.5897531619855896], [1.4192375538972215, 1.3025364051460373, 0.19109393165099542, 0.7163722607699825, 1.2485510619855897], [1.0554176261027786, 1.1588401948539626, 0.8965187783490047, 0.8566028692300176, 1.6107667080144104], [0.48218839389722146, 1.0675776848539626, 0.8121222283490046, 1.1192131792300175, 0.5554536340144104], [1.5940784538972215, 0.9516139751460373, 1.0299966516509955, 0.5720489607699825, 1.7041371119855897], [0.5651286561027786, 1.0155398551460373, 0.3231203016509954, 0.5152439607699825, 1.6938476619855896], [0.6076131961027786, 0.6861116948539625, 1.3997399983490046, 0.9177645592300177, 0.38001956361441036], [1.8371433638972212, 0.7991825748539625, 0.6577090983490046, 0.7468711692300176, 2.0707300480144104], [0.44783916610277863, 1.1936202351460374, 1.2151849716509955, 0.9598649607699824, 0.4829381899855896], [0.4833840061027786, 0.5870205551460375, 0.1075260383490046, 0.15667529076998243, 2.2915776519855893], [1.7684119638972213, 0.9430374248539626, 1.0720257083490046, 1.4443605792300176, 1.0861303919855896], [2.0537640938972213, 22.04214190514604, 11.898874418349005, 17.145925050769982, 6.30260278801441], [16.83486630610278, 7.050748844853963, 11.503413351650996, 6.552972189230017, 13.06745471801441], [20.736852753897224, 3.9802041851460372, 7.435762161650995, 3.4562118907699824, 22.779991718014408], [7.887955756102778, 29.223932634853963, 37.72958918834901, 29.858210439230017, 20.91424741801441], [15.496665516102778, 11.472204784853963, 4.244313468349004, 17.045561389230016, 9.892074048014411], [9.695645516102779, 15.162804895146037, 4.4696596883490045, 2.6775923207699823, 21.250114918014408], [13.779200746102779, 2.9441381048539625, 11.521846848349004, 3.2850865292300178, 0.3268705999855896], [13.688604993897222, 22.68976526514604, 14.927519821650996, 35.33889141076998, 30.421104018014407], [12.206937196102778, 19.83767118485396, 8.091637211650996, 8.036820220769982, 27.68184408198559]], 'mahalanobis_dist_feat': [130.15844995605676, 165.05066325797472, 153.50707222136458, 174.38037375404673, 185.1713234429191], 'X_feat_abs_recon_err': [[0.18047348389722143, 0.5150746548539626, 0.44968429834900453, 0.6364070792300176, 0.3147984503144104], [1.5793673138972215, 1.6411020148539626, 0.9944041683490046, 1.8548069792300175, 1.8662704019855896], [0.7490298361027786, 0.3855407948539626, 0.15989729165099542, 0.24701569076998245, 0.9387205319855896], [0.8902445461027786, 1.6466044351460374, 1.5067421516509953, 0.7596562007699825, 1.8717905180144103], [2.107100763897221, 0.8699095348539625, 0.8720772383490045, 0.8605479092300174, 1.5211848680144102], [0.5936140061027786, 1.3319587148539624, 1.2425898483490045, 1.7189194792300175, 1.7295150419855896], [1.1787152561027787, 0.052058654853962605, 0.8107562016509955, 0.22421106076998243, 2.0203434719855893], [1.2408811938972215, 0.9872125651460375, 0.6953733916509954, 1.2628679707699826, 0.4815671000144104], [0.5521753638972214, 0.5931658348539626, 0.9146274783490047, 0.17148773923001753, 1.9036332480144103], [0.8424544661027785, 1.4244457948539626, 1.5499629283490046, 1.3088009492300177, 0.3127260721144104], [0.7164653438972214, 0.1715336451460374, 0.7764410216509954, 0.10093130923001753, 1.5897531619855896], [1.4192375538972215, 1.3025364051460373, 0.19109393165099542, 0.7163722607699825, 1.2485510619855897], [1.0554176261027786, 1.1588401948539626, 0.8965187783490047, 0.8566028692300176, 1.6107667080144104], [0.48218839389722146, 1.0675776848539626, 0.8121222283490046, 1.1192131792300175, 0.5554536340144104], [1.5940784538972215, 0.9516139751460373, 1.0299966516509955, 0.5720489607699825, 1.7041371119855897], [0.5651286561027786, 1.0155398551460373, 0.3231203016509954, 0.5152439607699825, 1.6938476619855896], [0.6076131961027786, 0.6861116948539625, 1.3997399983490046, 0.9177645592300177, 0.38001956361441036], [1.8371433638972212, 0.7991825748539625, 0.6577090983490046, 0.7468711692300176, 2.0707300480144104], [0.44783916610277863, 1.1936202351460374, 1.2151849716509955, 0.9598649607699824, 0.4829381899855896], [0.4833840061027786, 0.5870205551460375, 0.1075260383490046, 0.15667529076998243, 2.2915776519855893], [1.7684119638972213, 0.9430374248539626, 1.0720257083490046, 1.4443605792300176, 1.0861303919855896], [2.0537640938972213, 22.04214190514604, 11.898874418349005, 17.145925050769982, 6.30260278801441], [16.83486630610278, 7.050748844853963, 11.503413351650996, 6.552972189230017, 13.06745471801441], [20.736852753897224, 3.9802041851460372, 7.435762161650995, 3.4562118907699824, 22.779991718014408], [7.887955756102778, 29.223932634853963, 37.72958918834901, 29.858210439230017, 20.91424741801441], [15.496665516102778, 11.472204784853963, 4.244313468349004, 17.045561389230016, 9.892074048014411], [9.695645516102779, 15.162804895146037, 4.4696596883490045, 2.6775923207699823, 21.250114918014408], [13.779200746102779, 2.9441381048539625, 11.521846848349004, 3.2850865292300178, 0.3268705999855896], [13.688604993897222, 22.68976526514604, 14.927519821650996, 35.33889141076998, 30.421104018014407], [12.206937196102778, 19.83767118485396, 8.091637211650996, 8.036820220769982, 27.68184408198559]], 'feat_anom_flags': 1, 'mahalanobis_dist_time': [2.0513594721897133, 2.719146676386093, 1.626734161007828, 2.659782191302525, 1.9632426447433389, 2.276419132865058, 2.7001681140068814, 1.799206373841418, 2.3930926746040195, 2.188786950012706, 2.2660257819907663, 2.398869280269625, 0.9790113454227258, 1.5561497606296537, 1.6664943939331318, 1.9675424157694572, 2.100764768701091, 2.0751719351448696, 1.7497466431536497, 2.8544810912237435, 2.105311303279753, 45.94854667545251, 38.14488852052545, 48.92097727310473, 87.7470527316674, 45.33147982298009, 47.469852598349654, 30.96962325870153, 87.15582904665148, 58.264857493120935]}, {'time_anom_flags': 1, 'X_time_abs_recon_err': [[0.029037933897221396, 0.046312670146037405, 0.23952762855099544, 0.4294671292300175, 0.2477360919855896], [1.7068964638972215, 1.4638224948539627, 1.7498244983490048, 1.7516950492300176, 2.2200577719855894], [0.5604764761027786, 0.3386999749460374, 0.23358513025099542, 0.5521462692300175, 1.0834336819855896], [0.17424464610277862, 1.4281658951460374, 0.5730005026509954, 0.9760126307699825, 0.9900140880144104], [1.9255217138972214, 0.11664203914603738, 0.3432322303490046, 0.054804150769982435, 1.4010755180144103], [0.4355911861027786, 1.7144897848539626, 1.6959409283490046, 1.5093624492300175, 1.2939199419855896], [1.4006089361027785, 0.17091795185396258, 0.48014286765099545, 0.09564306923001753, 1.7716623819855897], [1.2195340338972214, 1.6336027051460376, 0.7982469116509954, 1.3643455307699826, 0.1662484880144104], [0.6434258238972215, 0.6472427248539625, 0.6279553583490045, 0.6297198892300175, 1.9488542780144102], [0.9578461161027786, 1.0404634848539625, 1.5795957983490045, 1.6734815892300177, 0.3198964180144104], [1.4811346038972215, 0.9742621761460375, 0.7819214066509954, 0.5082634707699825, 1.80556403198559], [1.4740933438972215, 1.3186694441460374, 0.13855365465099542, 1.3597689707699825, 1.0306298719855898], [1.6040489461027785, 0.8356762048539625, 1.3649272583490046, 0.4659872592300176, 1.2428014580144104], [0.8030500238972214, 1.6296677148539627, 0.5195031583490046, 0.8424260392300176, 1.2231382280144103], [1.5665304838972214, 0.4900113511460374, 1.2869841416509953, 0.3904295607699825, 1.4004376719855898], [0.5946544661027786, 0.7843997111460375, 0.43907023065099543, 0.6922561207699824, 1.8853171419855899], [0.004768933897221411, 1.2842785048539624, 1.2699517183490046, 1.0670725692300176, 0.4822166380144104], [2.3000913038972213, 1.5245812548539626, 0.4435081863490045, 0.9207150192300175, 2.1091284980144103], [0.3907746861027786, 0.6545671961460373, 0.5566046686509954, 0.7726966407699825, 0.042621538014410376], [1.1092122161027786, 0.3676211782660374, 0.5966333433490045, 0.2533989607699825, 1.5144607519855897], [2.114719823897221, 0.8175879048539625, 1.9730876683490048, 1.5567822692300175, 0.6451448219855898], [9.402857193897221, 19.93815101514604, 8.300660871650996, 12.640593769230017, 22.37290668198559], [16.530616793897224, 8.617305874853963, 14.108069301650996, 14.546972679230018, 9.94565948198559], [36.32350306610278, 0.2517709941460374, 9.853970041650996, 4.962914980769982, 33.32173123198559], [12.48701061610278, 16.22355211514604, 19.590540601650996, 20.944237859230018, 24.16803383801441], [15.231321186102779, 14.713478815146036, 1.2021677316509953, 12.460011319230018, 5.178473598014411], [10.273123536102778, 11.759779184853963, 3.897339388349004, 3.5468357007699822, 20.81307744198559], [24.837167086102777, 2.6414656248539625, 8.078658628349004, 0.6411830692300176, 7.17671153198559], [8.697772353897221, 24.78234828485396, 37.72528849834901, 19.733594649230017, 32.19808872801441], [11.53921223610278, 21.025946584853962, 7.778276568349005, 15.116323170769983, 7.379339601985589]], 'mahalanobis_dist_feat': [179.08257007672975, 149.49212080302127, 155.00013090647155, 129.53370837880757, 194.73826246858275], 'X_feat_abs_recon_err': [[0.029037933897221396, 0.046312670146037405, 0.23952762855099544, 0.4294671292300175, 0.2477360919855896], [1.7068964638972215, 1.4638224948539627, 1.7498244983490048, 1.7516950492300176, 2.2200577719855894], [0.5604764761027786, 0.3386999749460374, 0.23358513025099542, 0.5521462692300175, 1.0834336819855896], [0.17424464610277862, 1.4281658951460374, 0.5730005026509954, 0.9760126307699825, 0.9900140880144104], [1.9255217138972214, 0.11664203914603738, 0.3432322303490046, 0.054804150769982435, 1.4010755180144103], [0.4355911861027786, 1.7144897848539626, 1.6959409283490046, 1.5093624492300175, 1.2939199419855896], [1.4006089361027785, 0.17091795185396258, 0.48014286765099545, 0.09564306923001753, 1.7716623819855897], [1.2195340338972214, 1.6336027051460376, 0.7982469116509954, 1.3643455307699826, 0.1662484880144104], [0.6434258238972215, 0.6472427248539625, 0.6279553583490045, 0.6297198892300175, 1.9488542780144102], [0.9578461161027786, 1.0404634848539625, 1.5795957983490045, 1.6734815892300177, 0.3198964180144104], [1.4811346038972215, 0.9742621761460375, 0.7819214066509954, 0.5082634707699825, 1.80556403198559], [1.4740933438972215, 1.3186694441460374, 0.13855365465099542, 1.3597689707699825, 1.0306298719855898], [1.6040489461027785, 0.8356762048539625, 1.3649272583490046, 0.4659872592300176, 1.2428014580144104], [0.8030500238972214, 1.6296677148539627, 0.5195031583490046, 0.8424260392300176, 1.2231382280144103], [1.5665304838972214, 0.4900113511460374, 1.2869841416509953, 0.3904295607699825, 1.4004376719855898], [0.5946544661027786, 0.7843997111460375, 0.43907023065099543, 0.6922561207699824, 1.8853171419855899], [0.004768933897221411, 1.2842785048539624, 1.2699517183490046, 1.0670725692300176, 0.4822166380144104], [2.3000913038972213, 1.5245812548539626, 0.4435081863490045, 0.9207150192300175, 2.1091284980144103], [0.3907746861027786, 0.6545671961460373, 0.5566046686509954, 0.7726966407699825, 0.042621538014410376], [1.1092122161027786, 0.3676211782660374, 0.5966333433490045, 0.2533989607699825, 1.5144607519855897], [2.114719823897221, 0.8175879048539625, 1.9730876683490048, 1.5567822692300175, 0.6451448219855898], [9.402857193897221, 19.93815101514604, 8.300660871650996, 12.640593769230017, 22.37290668198559], [16.530616793897224, 8.617305874853963, 14.108069301650996, 14.546972679230018, 9.94565948198559], [36.32350306610278, 0.2517709941460374, 9.853970041650996, 4.962914980769982, 33.32173123198559], [12.48701061610278, 16.22355211514604, 19.590540601650996, 20.944237859230018, 24.16803383801441], [15.231321186102779, 14.713478815146036, 1.2021677316509953, 12.460011319230018, 5.178473598014411], [10.273123536102778, 11.759779184853963, 3.897339388349004, 3.5468357007699822, 20.81307744198559], [24.837167086102777, 2.6414656248539625, 8.078658628349004, 0.6411830692300176, 7.17671153198559], [8.697772353897221, 24.78234828485396, 37.72528849834901, 19.733594649230017, 32.19808872801441], [11.53921223610278, 21.025946584853962, 7.778276568349005, 15.116323170769983, 7.379339601985589]], 'feat_anom_flags': 1, 'mahalanobis_dist_time': [2.7092446906276666, 3.0091971601662073, 1.5716054624078122, 2.274346330476212, 2.5441284566361584, 2.3706033160171684, 2.261296674528312, 2.7336481156262185, 1.6283285632242304, 2.812627283121429, 1.694379781381864, 2.8162866180905333, 2.0287724487655026, 2.459057112476801, 2.225074274888211, 1.6255207666357068, 2.3521861348658337, 3.3656847719928793, 2.1110116241954153, 1.5653974192905564, 3.7535251982336546, 50.72960866888865, 44.54458538282463, 81.89032177351432, 61.22385466178557, 42.971330957121864, 40.81034735982659, 44.28098824071802, 90.34493024213553, 47.12709289342993]}, {'time_anom_flags': 1, 'X_time_abs_recon_err': [[0.42544713389722144, 0.36096841485396264, 0.17514779165099542, 0.016786429230017552, 0.10163147801441036], [1.6737919138972215, 1.5829957448539627, 1.2493304983490046, 1.5679272792300176, 1.4425774219855896], [0.9984433561027786, 0.1190265148539626, 0.3074410983490045, 0.23573081076998245, 1.2398533019855897], [0.07262278610277861, 0.9568073651460374, 1.4061555916509954, 0.6612527507699825, 1.5584738280144104], [1.7026621138972213, 0.15321907485396263, 0.3058116483490046, 0.5767499792300176, 1.4537360580144103], [0.42722479610277864, 1.5486483848539625, 1.7367685283490044, 1.6893531692300177, 0.9569485319855897], [0.9770928061027786, 0.6699597051460373, 0.06224530165099543, 0.3203318792300176, 1.4701722819855896], [1.2009853838972215, 1.5373562051460374, 0.8313997116509955, 1.3488126707699823, 0.003206968014410394], [0.6291598538972214, 0.7602226848539626, 0.9465410483490047, 1.0648694792300175, 1.8135495780144104], [1.6946513061027786, 1.4818213948539625, 1.1692136683490046, 1.2198511492300175, 0.11555419801441039], [1.4039293838972213, 0.8825008751460375, 0.9729952116509955, 0.03776693076998244, 1.74878457198559], [1.4594356838972213, 0.6927267651460374, 0.7508918916509955, 0.7907936907699824, 1.1781840519855897], [1.6362018761027786, 0.6398708548539624, 1.0687093483490047, 1.1046136092300176, 1.1867135780144105], [0.4893375638972214, 1.7121583648539627, 0.5471639883490045, 0.7986575092300177, 1.5423736480144103], [1.9121590338972216, 0.4114032751460374, 0.7867806216509954, 0.01791544076998247, 1.1782821819855898], [0.9032172361027786, 1.2230171351460375, 0.5091975716509954, 0.9179167207699824, 2.1990108319855897], [0.2779341761027786, 0.6588602248539626, 1.5206233983490047, 0.6546893092300176, 0.07597571801441039], [1.9837123038972215, 0.5772417148539626, 0.8597479083490047, 1.2047988292300176, 2.0562591780144106], [0.5805823161027786, 0.8375883451460374, 1.0610144416509955, 0.6715960907699825, 0.26437765198558966], [1.0380776361027786, 1.1619671651460375, 0.20043473165099543, 1.0050648607699824, 1.7343340819855897], [1.7053089238972214, 0.9873180348539625, 1.7530352583490048, 1.1135024192300176, 1.2401335119855896], [6.556167956102779, 11.896212864853963, 0.05033385834900456, 19.09264474076998, 12.59770164801441], [9.578776923897221, 5.266359355146037, 7.940614878349004, 5.885781749230018, 5.838153831985589], [34.337623556102784, 4.260492944853963, 12.051878031650995, 9.705489900769981, 16.88723152198559], [25.361709783897222, 20.74142873485396, 18.455736798349005, 19.14606867923002, 27.870223771985593], [11.684714976102779, 15.403931954853963, 0.6670020816509954, 22.494101980769983, 2.2188638680144104], [15.81200980389722, 14.392721945146038, 3.9590171016509954, 11.322926049230018, 19.089865538014408], [25.721023443897224, 0.4910024548539626, 10.453906268349005, 0.48036886923001754, 3.0868949380144106], [11.815552743897221, 35.600713344853965, 15.483424831650996, 15.979949960769982, 25.06918654198559], [0.4666616061027786, 19.27423041514604, 9.644906551650996, 11.976715129230017, 12.349695881985589]], 'mahalanobis_dist_feat': [183.862580115439, 166.05116282817673, 100.71731275969852, 139.17151863067943, 148.36657566165312], 'X_feat_abs_recon_err': [[0.42544713389722144, 0.36096841485396264, 0.17514779165099542, 0.016786429230017552, 0.10163147801441036], [1.6737919138972215, 1.5829957448539627, 1.2493304983490046, 1.5679272792300176, 1.4425774219855896], [0.9984433561027786, 0.1190265148539626, 0.3074410983490045, 0.23573081076998245, 1.2398533019855897], [0.07262278610277861, 0.9568073651460374, 1.4061555916509954, 0.6612527507699825, 1.5584738280144104], [1.7026621138972213, 0.15321907485396263, 0.3058116483490046, 0.5767499792300176, 1.4537360580144103], [0.42722479610277864, 1.5486483848539625, 1.7367685283490044, 1.6893531692300177, 0.9569485319855897], [0.9770928061027786, 0.6699597051460373, 0.06224530165099543, 0.3203318792300176, 1.4701722819855896], [1.2009853838972215, 1.5373562051460374, 0.8313997116509955, 1.3488126707699823, 0.003206968014410394], [0.6291598538972214, 0.7602226848539626, 0.9465410483490047, 1.0648694792300175, 1.8135495780144104], [1.6946513061027786, 1.4818213948539625, 1.1692136683490046, 1.2198511492300175, 0.11555419801441039], [1.4039293838972213, 0.8825008751460375, 0.9729952116509955, 0.03776693076998244, 1.74878457198559], [1.4594356838972213, 0.6927267651460374, 0.7508918916509955, 0.7907936907699824, 1.1781840519855897], [1.6362018761027786, 0.6398708548539624, 1.0687093483490047, 1.1046136092300176, 1.1867135780144105], [0.4893375638972214, 1.7121583648539627, 0.5471639883490045, 0.7986575092300177, 1.5423736480144103], [1.9121590338972216, 0.4114032751460374, 0.7867806216509954, 0.01791544076998247, 1.1782821819855898], [0.9032172361027786, 1.2230171351460375, 0.5091975716509954, 0.9179167207699824, 2.1990108319855897], [0.2779341761027786, 0.6588602248539626, 1.5206233983490047, 0.6546893092300176, 0.07597571801441039], [1.9837123038972215, 0.5772417148539626, 0.8597479083490047, 1.2047988292300176, 2.0562591780144106], [0.5805823161027786, 0.8375883451460374, 1.0610144416509955, 0.6715960907699825, 0.26437765198558966], [1.0380776361027786, 1.1619671651460375, 0.20043473165099543, 1.0050648607699824, 1.7343340819855897], [1.7053089238972214, 0.9873180348539625, 1.7530352583490048, 1.1135024192300176, 1.2401335119855896], [6.556167956102779, 11.896212864853963, 0.05033385834900456, 19.09264474076998, 12.59770164801441], [9.578776923897221, 5.266359355146037, 7.940614878349004, 5.885781749230018, 5.838153831985589], [34.337623556102784, 4.260492944853963, 12.051878031650995, 9.705489900769981, 16.88723152198559], [25.361709783897222, 20.74142873485396, 18.455736798349005, 19.14606867923002, 27.870223771985593], [11.684714976102779, 15.403931954853963, 0.6670020816509954, 22.494101980769983, 2.2188638680144104], [15.81200980389722, 14.392721945146038, 3.9590171016509954, 11.322926049230018, 19.089865538014408], [25.721023443897224, 0.4910024548539626, 10.453906268349005, 0.48036886923001754, 3.0868949380144106], [11.815552743897221, 35.600713344853965, 15.483424831650996, 15.979949960769982, 25.06918654198559], [0.4666616061027786, 19.27423041514604, 9.644906551650996, 11.976715129230017, 12.349695881985589]], 'feat_anom_flags': 1, 'mahalanobis_dist_time': [2.591295863532382, 2.05729205879719, 1.7232266631948507, 2.4554824347354467, 2.214495281896194, 2.53449622789144, 1.878230813020813, 2.742776271436858, 1.621388457189981, 2.56612760100196, 2.6648781009147284, 0.9082306090753258, 1.7818732969207676, 2.845468178608947, 2.486340972510497, 2.0678772687477958, 2.8285779661899397, 2.805156643098083, 1.7234210592716053, 2.074241008488954, 2.3293456393298766, 48.198052816426895, 21.680651614129115, 66.75842496810053, 71.78318667986146, 57.3951260389209, 45.88366110535358, 47.68194243526698, 81.49161303182586, 40.88614828785414]}, {'time_anom_flags': 1, 'X_time_abs_recon_err': [[0.2395990538972214, 0.27531667485396266, 0.6222232883490046, 0.13789293223001753, 0.35846537198558964], [1.4752610638972214, 1.1340756648539625, 1.1660834783490046, 1.6732150892300175, 1.9007099719855896], [0.6980493361027786, 0.10518884485396263, 0.4569590183490046, 0.018258705230017547, 0.4187284819855896], [0.7334241061027786, 1.6072712151460375, 1.2153420816509954, 0.8984541957699824, 1.0558554080144105], [1.9864182938972215, 0.5686701148539626, 0.2647675383490045, 0.5230311402300175, 1.0338171680144104], [0.6464094261027786, 1.5207928948539626, 1.6715414383490046, 1.7383817792300174, 0.9089110719855897], [1.3347777461027786, 0.5411480551460374, 0.4162856116509954, 0.32022070123001756, 1.5331675619855898], [2.116815603897221, 1.3973533051460374, 0.9279940316509954, 0.6856473327699825, 0.47525710801441035], [0.4335703538972214, 0.22701366485396263, 0.7932138483490045, 0.6860846692300175, 1.8256845780144104], [1.0852661861027786, 1.7808203148539627, 0.8205172983490046, 1.5347860692300175, 0.5100937719855896], [1.3073772138972215, 0.05930139514603738, 0.7289681816509954, 0.06072940123001758, 1.6165733719855897], [0.9697871438972214, 0.6457721251460373, 0.8622048116509955, 0.46800882876998245, 0.3726877519855896], [0.8637207161027786, 1.2958380848539626, 1.5448206383490046, 0.8315848192300175, 1.4924001780144103], [0.21719457389722138, 1.7221274848539627, 0.49710449834900455, 0.8701620692300176, 0.5536352680144103], [1.3629612038972214, 0.5214204051460374, 1.3144631916509955, 0.28335817546998243, 1.5230320519855898], [0.6157173861027786, 0.9928029951460373, 0.5913326116509954, 1.2070078907699826, 2.1890341819855896], [0.1600441161027786, 1.3809204448539625, 1.4180359283490047, 0.8849138492300175, 0.8055374680144104], [1.5916270338972214, 1.2015658548539625, 0.22123564834900455, 0.8943492892300176, 1.8315407180144103], [0.34051732610277863, 0.6323968451460373, 0.9626111616509954, 0.9859137897699825, 0.5228473719855897], [0.3651727461027786, 1.1282783451460374, 0.48131305834900456, 0.8645275607699825, 1.8829327119855896], [1.4791153838972215, 1.4243862348539627, 1.5494853783490046, 1.1461921992300175, 0.47951071198558964], [1.9484723461027786, 21.389308305146038, 1.9876507816509954, 18.79337418923002, 15.648090641985588], [17.26366979610278, 9.331269595146036, 8.730467788349005, 15.630824510769981, 20.708023568014408], [16.494658716102776, 0.06602911514603738, 13.546814238349004, 4.561849730769982, 36.35647935801441], [8.550978556102779, 19.062515495146037, 33.87727233834901, 28.391413810769983, 21.30794698198559], [15.464161603897221, 15.026752174853963, 0.6805878316509955, 12.861758889230018, 3.6421004980144107], [6.713086443897221, 7.098191275146037, 10.820766851650996, 15.048233810769982, 26.468259448014408], [18.402534886102778, 3.9183824951460373, 21.796087128349004, 1.8362360607699824, 4.48899520801441], [8.696766736102779, 36.90975700514604, 19.048205938349003, 19.12290181076998, 32.72119237198559], [2.307432246102779, 8.590337004853962, 2.834244218349004, 8.758880339230018, 6.356527921985589]], 'mahalanobis_dist_feat': [117.06472232024947, 165.49220153106782, 160.3903145224053, 150.030010605174, 203.16856102834308], 'X_feat_abs_recon_err': [[0.2395990538972214, 0.27531667485396266, 0.6222232883490046, 0.13789293223001753, 0.35846537198558964], [1.4752610638972214, 1.1340756648539625, 1.1660834783490046, 1.6732150892300175, 1.9007099719855896], [0.6980493361027786, 0.10518884485396263, 0.4569590183490046, 0.018258705230017547, 0.4187284819855896], [0.7334241061027786, 1.6072712151460375, 1.2153420816509954, 0.8984541957699824, 1.0558554080144105], [1.9864182938972215, 0.5686701148539626, 0.2647675383490045, 0.5230311402300175, 1.0338171680144104], [0.6464094261027786, 1.5207928948539626, 1.6715414383490046, 1.7383817792300174, 0.9089110719855897], [1.3347777461027786, 0.5411480551460374, 0.4162856116509954, 0.32022070123001756, 1.5331675619855898], [2.116815603897221, 1.3973533051460374, 0.9279940316509954, 0.6856473327699825, 0.47525710801441035], [0.4335703538972214, 0.22701366485396263, 0.7932138483490045, 0.6860846692300175, 1.8256845780144104], [1.0852661861027786, 1.7808203148539627, 0.8205172983490046, 1.5347860692300175, 0.5100937719855896], [1.3073772138972215, 0.05930139514603738, 0.7289681816509954, 0.06072940123001758, 1.6165733719855897], [0.9697871438972214, 0.6457721251460373, 0.8622048116509955, 0.46800882876998245, 0.3726877519855896], [0.8637207161027786, 1.2958380848539626, 1.5448206383490046, 0.8315848192300175, 1.4924001780144103], [0.21719457389722138, 1.7221274848539627, 0.49710449834900455, 0.8701620692300176, 0.5536352680144103], [1.3629612038972214, 0.5214204051460374, 1.3144631916509955, 0.28335817546998243, 1.5230320519855898], [0.6157173861027786, 0.9928029951460373, 0.5913326116509954, 1.2070078907699826, 2.1890341819855896], [0.1600441161027786, 1.3809204448539625, 1.4180359283490047, 0.8849138492300175, 0.8055374680144104], [1.5916270338972214, 1.2015658548539625, 0.22123564834900455, 0.8943492892300176, 1.8315407180144103], [0.34051732610277863, 0.6323968451460373, 0.9626111616509954, 0.9859137897699825, 0.5228473719855897], [0.3651727461027786, 1.1282783451460374, 0.48131305834900456, 0.8645275607699825, 1.8829327119855896], [1.4791153838972215, 1.4243862348539627, 1.5494853783490046, 1.1461921992300175, 0.47951071198558964], [1.9484723461027786, 21.389308305146038, 1.9876507816509954, 18.79337418923002, 15.648090641985588], [17.26366979610278, 9.331269595146036, 8.730467788349005, 15.630824510769981, 20.708023568014408], [16.494658716102776, 0.06602911514603738, 13.546814238349004, 4.561849730769982, 36.35647935801441], [8.550978556102779, 19.062515495146037, 33.87727233834901, 28.391413810769983, 21.30794698198559], [15.464161603897221, 15.026752174853963, 0.6805878316509955, 12.861758889230018, 3.6421004980144107], [6.713086443897221, 7.098191275146037, 10.820766851650996, 15.048233810769982, 26.468259448014408], [18.402534886102778, 3.9183824951460373, 21.796087128349004, 1.8362360607699824, 4.48899520801441], [8.696766736102779, 36.90975700514604, 19.048205938349003, 19.12290181076998, 32.72119237198559], [2.307432246102779, 8.590337004853962, 2.834244218349004, 8.758880339230018, 6.356527921985589]], 'feat_anom_flags': 1, 'mahalanobis_dist_time': [2.3048101739446283, 2.4091364562155473, 2.160731560570147, 1.9700875914721467, 2.1293387061020455, 2.4110169314583336, 1.5156788786496118, 2.829841527683704, 2.3529390241903334, 2.700849241777967, 2.4189074254451333, 1.4562115603488552, 1.8775532850665584, 3.246412057988083, 2.353635591367449, 2.138886940249092, 2.297155475807693, 2.362342781221407, 1.8297186872917237, 1.9784548138640898, 2.110221246308118, 54.42645703234964, 50.591171288373026, 70.40573060817412, 82.8426755561869, 44.668382414872575, 52.05844385143648, 54.91032079719693, 87.03848855688828, 20.538321748324066]}, {'time_anom_flags': 1, 'X_time_abs_recon_err': [[0.3368013638972214, 0.5904809808539626, 0.3086495843490045, 0.3012200972300175, 0.3389222839855896], [1.5721079138972214, 1.7251043548539626, 1.4886596983490046, 1.0827446692300176, 2.2540024619855896], [0.9784079561027785, 0.2969915514460374, 0.4477399163490046, 0.42474938323001754, 0.6895186719855897], [0.4475887261027786, 1.6998004451460373, 0.7893113116509953, 1.3764796507699824, 1.7300651580144104], [2.268327573897221, 0.2435924458539626, 0.8245178583490047, 0.2328064132300176, 1.4208717080144104], [0.4076164761027786, 1.4640768148539625, 1.0057336383490045, 1.2588632492300176, 1.6722916919855895], [1.3736500161027785, 0.22890078185396262, 0.17776295365099543, 0.5602359677699824, 1.4357507519855897], [1.6782473238972215, 1.4677988051460376, 1.0914003126509955, 1.0032245797699826, 0.3763636740144104], [0.22396058389722137, 0.6380214548539624, 0.5773131543490047, 0.2175289112300176, 1.9804756280144102], [1.1728077761027786, 1.7332839348539624, 1.1326571283490046, 1.2534935992300176, 0.23852981098558962], [1.5926095838972214, 0.4930400701460374, 0.29204608325099546, 0.2539146795699824, 2.3871486119855896], [0.6268351338972215, 0.7924653431460373, 0.9038371676509955, 0.5524121997699825, 1.0454544119855897], [1.1162086261027786, 0.6587026648539624, 1.0630067083490047, 0.8062368792300176, 1.0580730660144104], [0.4085650538972214, 1.5779946648539624, 1.1578182683490046, 1.2071654692300176, 1.3567765380144103], [1.3003481538972215, 0.6817016061460375, 1.2188801736509953, 0.24249062536998245, 1.5786313519855897], [0.5591005061027786, 0.6060530181460374, 0.5114573196509955, 0.30862820925998247, 1.4463215619855896], [0.10753741610277859, 1.2565165848539626, 1.4410505583490045, 0.7748599192300176, 0.16111585301441037], [1.9883250938972215, 0.9363958148539626, 0.5595010693490046, 1.1690603692300177, 1.9505760180144103], [0.5788683361027785, 0.5249354791460374, 0.9985677146509955, 0.26482555376998246, 0.14980677098558964], [0.7422045061027785, 0.3494750045460374, 0.037669683650995434, 0.32289879986998243, 1.9367404719855899], [1.5580502838972214, 1.1525777048539625, 1.4560761083490046, 0.7050029692300175, 0.38140325798558966], [3.5929150738972213, 9.448061515146037, 16.501612101650995, 10.916201089230018, 15.65866571801441], [17.978609703897224, 16.14944351514604, 7.297984698349004, 11.911725289230018, 8.34872440801441], [20.872722143897224, 4.665072864853963, 7.270163761650996, 3.2319735892300177, 12.724640681985589], [9.02203811610278, 23.364288315146037, 17.139156201650994, 31.21583191076998, 31.681608481985588], [17.353729063897223, 14.215907984853963, 1.7950901116509954, 11.742090410769983, 2.4244371080144105], [14.039734773897221, 17.82409471514604, 8.461556918349004, 1.9790721992300178, 18.47812871801441], [29.829744623897223, 1.9475542251460374, 22.369127901650995, 1.8283102392300177, 11.01023111801441], [8.061700123897221, 19.50861848485396, 26.066811101650995, 18.146894389230017, 23.64399398198559], [0.4221339938972214, 3.7442699151460372, 3.6421429316509957, 12.054696510769983, 13.657388081985589]], 'mahalanobis_dist_feat': [157.89955527366985, 134.9035274104375, 151.98358760552873, 139.21510881574022, 162.23068223996805], 'X_feat_abs_recon_err': [[0.3368013638972214, 0.5904809808539626, 0.3086495843490045, 0.3012200972300175, 0.3389222839855896], [1.5721079138972214, 1.7251043548539626, 1.4886596983490046, 1.0827446692300176, 2.2540024619855896], [0.9784079561027785, 0.2969915514460374, 0.4477399163490046, 0.42474938323001754, 0.6895186719855897], [0.4475887261027786, 1.6998004451460373, 0.7893113116509953, 1.3764796507699824, 1.7300651580144104], [2.268327573897221, 0.2435924458539626, 0.8245178583490047, 0.2328064132300176, 1.4208717080144104], [0.4076164761027786, 1.4640768148539625, 1.0057336383490045, 1.2588632492300176, 1.6722916919855895], [1.3736500161027785, 0.22890078185396262, 0.17776295365099543, 0.5602359677699824, 1.4357507519855897], [1.6782473238972215, 1.4677988051460376, 1.0914003126509955, 1.0032245797699826, 0.3763636740144104], [0.22396058389722137, 0.6380214548539624, 0.5773131543490047, 0.2175289112300176, 1.9804756280144102], [1.1728077761027786, 1.7332839348539624, 1.1326571283490046, 1.2534935992300176, 0.23852981098558962], [1.5926095838972214, 0.4930400701460374, 0.29204608325099546, 0.2539146795699824, 2.3871486119855896], [0.6268351338972215, 0.7924653431460373, 0.9038371676509955, 0.5524121997699825, 1.0454544119855897], [1.1162086261027786, 0.6587026648539624, 1.0630067083490047, 0.8062368792300176, 1.0580730660144104], [0.4085650538972214, 1.5779946648539624, 1.1578182683490046, 1.2071654692300176, 1.3567765380144103], [1.3003481538972215, 0.6817016061460375, 1.2188801736509953, 0.24249062536998245, 1.5786313519855897], [0.5591005061027786, 0.6060530181460374, 0.5114573196509955, 0.30862820925998247, 1.4463215619855896], [0.10753741610277859, 1.2565165848539626, 1.4410505583490045, 0.7748599192300176, 0.16111585301441037], [1.9883250938972215, 0.9363958148539626, 0.5595010693490046, 1.1690603692300177, 1.9505760180144103], [0.5788683361027785, 0.5249354791460374, 0.9985677146509955, 0.26482555376998246, 0.14980677098558964], [0.7422045061027785, 0.3494750045460374, 0.037669683650995434, 0.32289879986998243, 1.9367404719855899], [1.5580502838972214, 1.1525777048539625, 1.4560761083490046, 0.7050029692300175, 0.38140325798558966], [3.5929150738972213, 9.448061515146037, 16.501612101650995, 10.916201089230018, 15.65866571801441], [17.978609703897224, 16.14944351514604, 7.297984698349004, 11.911725289230018, 8.34872440801441], [20.872722143897224, 4.665072864853963, 7.270163761650996, 3.2319735892300177, 12.724640681985589], [9.02203811610278, 23.364288315146037, 17.139156201650994, 31.21583191076998, 31.681608481985588], [17.353729063897223, 14.215907984853963, 1.7950901116509954, 11.742090410769983, 2.4244371080144105], [14.039734773897221, 17.82409471514604, 8.461556918349004, 1.9790721992300178, 18.47812871801441], [29.829744623897223, 1.9475542251460374, 22.369127901650995, 1.8283102392300177, 11.01023111801441], [8.061700123897221, 19.50861848485396, 26.066811101650995, 18.146894389230017, 23.64399398198559], [0.4221339938972214, 3.7442699151460372, 3.6421429316509957, 12.054696510769983, 13.657388081985589]], 'feat_anom_flags': 1, 'mahalanobis_dist_time': [2.116546557948079, 2.7108652769097206, 1.3775087423850665, 2.3737150457609695, 2.8291829038119514, 1.8231823333345298, 1.8996188098436562, 2.2706366783282967, 2.4878161112855093, 2.5564284013235237, 2.7364862100407987, 1.0333127929623769, 0.9530954543440322, 1.8559452450841771, 2.208933149907521, 1.5376477459660873, 2.786379381056019, 2.4098497297158543, 2.246518101003105, 2.2413700031798736, 2.237391237411867, 40.104333984384425, 43.745544133470744, 39.70746875364806, 79.4530710235275, 43.640006995997716, 53.702715001073074, 70.48929272378162, 64.47094207721548, 33.08040106331805]}, {'time_anom_flags': 1, 'X_time_abs_recon_err': [[0.3779620208972214, 0.09834047485396263, 0.6388717333490046, 0.4600727612300175, 0.09612052198558962], [1.6127771038972214, 1.8992909448539628, 1.9808888183490045, 1.6235087992300175, 1.7848654619855895], [0.8523905581027785, 0.3549727348539626, 0.19098918434900458, 0.47314518323001753, 0.33530035198558966], [0.4086996131027786, 1.3991541551460374, 1.1803042046509955, 1.0641668407699825, 1.5608882580144103], [2.0659004938972214, 0.4844183248539626, 0.9104952683490046, 0.14560073123001754, 1.4444706280144104], [0.2427106528527786, 1.5341661248539626, 1.7975172483490047, 1.1819293792300176, 1.2739481619855897], [1.2973894461027786, 0.4899906551460374, 0.006741726349004551, 0.33989761436998245, 1.2682709719855896], [2.0834583938972213, 1.2938934951460375, 1.3493711716509953, 0.5139284897699825, 0.2603607180144104], [0.7351101638972214, 0.49578728485396256, 0.8707890083490046, 0.6918044722300175, 1.7175292380144103], [1.0043149141027787, 1.5442738048539626, 1.1800949383490047, 1.3755039592300176, 0.3094363119855896], [1.4623415938972215, 0.44519407514603737, 0.28443439903099543, 0.16520091776998244, 2.0906579719855896], [0.7666434738972214, 1.0926966251460375, 0.16014968365099544, 0.8732094267699825, 0.49598880198558964], [1.2003013271027787, 0.5379942048539625, 1.6231996383490046, 0.9294602992300176, 1.6334779580144103], [0.2832453098972214, 1.0547262448539625, 0.6901683153490046, 1.2185591892300176, 0.9922207380144104], [1.6216120038972215, 0.7473411651460373, 1.1417543096509954, 0.06840865076998245, 0.8090585419855896], [0.6156748621027786, 0.7670553751460374, 0.3920726576509954, 0.2975369110799824, 1.3764883219855897], [0.4447523221027786, 1.3659530048539625, 1.4060897483490047, 1.3166420092300175, 0.22085769801441038], [1.7733756338972213, 0.7207141748539625, 0.5265883203490045, 1.2266208092300175, 1.5635187480144104], [0.7531545751027786, 0.6144769751460374, 1.2892756316509955, 0.6678637397699825, 0.006687098014410364], [1.1577111311027786, 0.3269332951460374, 0.20631363534900454, 0.8797811007699824, 2.2645673019855894], [2.221255043897221, 1.3072556348539626, 1.9199514083490048, 1.1617827792300175, 1.2001841819855896], [10.240730616102779, 21.586882864853962, 4.754065688349004, 27.965184110769982, 14.60135588198559], [13.865974983897221, 13.022320985146036, 21.418116601650997, 11.339806010769982, 12.442866568014411], [26.45330841610278, 2.6489674948539625, 15.565902101650996, 4.337310249230018, 12.67689717801441], [19.471712983897223, 41.089800284853965, 20.928728501650994, 11.560479889230018, 35.933205058014416], [15.314295283897222, 6.976872604853963, 4.146142071650996, 21.772359110769983, 4.353162961985589], [11.925562416102778, 23.057462415146038, 18.876289401650997, 1.8489317707699824, 16.25605703801441], [19.347901316102778, 6.886526394853963, 6.953025648349004, 2.5960758592300177, 4.81379509198559], [5.846717313897221, 20.69496180514604, 18.646151798349006, 16.012992410769982, 47.04729562198559], [4.757684883897221, 14.325919775146037, 7.278958098349005, 5.585193409230017, 11.49853742198559]], 'mahalanobis_dist_feat': [152.22019864029, 190.91821509033718, 139.68386440815698, 140.96136122799786, 209.32924574218939], 'X_feat_abs_recon_err': [[0.3779620208972214, 0.09834047485396263, 0.6388717333490046, 0.4600727612300175, 0.09612052198558962], [1.6127771038972214, 1.8992909448539628, 1.9808888183490045, 1.6235087992300175, 1.7848654619855895], [0.8523905581027785, 0.3549727348539626, 0.19098918434900458, 0.47314518323001753, 0.33530035198558966], [0.4086996131027786, 1.3991541551460374, 1.1803042046509955, 1.0641668407699825, 1.5608882580144103], [2.0659004938972214, 0.4844183248539626, 0.9104952683490046, 0.14560073123001754, 1.4444706280144104], [0.2427106528527786, 1.5341661248539626, 1.7975172483490047, 1.1819293792300176, 1.2739481619855897], [1.2973894461027786, 0.4899906551460374, 0.006741726349004551, 0.33989761436998245, 1.2682709719855896], [2.0834583938972213, 1.2938934951460375, 1.3493711716509953, 0.5139284897699825, 0.2603607180144104], [0.7351101638972214, 0.49578728485396256, 0.8707890083490046, 0.6918044722300175, 1.7175292380144103], [1.0043149141027787, 1.5442738048539626, 1.1800949383490047, 1.3755039592300176, 0.3094363119855896], [1.4623415938972215, 0.44519407514603737, 0.28443439903099543, 0.16520091776998244, 2.0906579719855896], [0.7666434738972214, 1.0926966251460375, 0.16014968365099544, 0.8732094267699825, 0.49598880198558964], [1.2003013271027787, 0.5379942048539625, 1.6231996383490046, 0.9294602992300176, 1.6334779580144103], [0.2832453098972214, 1.0547262448539625, 0.6901683153490046, 1.2185591892300176, 0.9922207380144104], [1.6216120038972215, 0.7473411651460373, 1.1417543096509954, 0.06840865076998245, 0.8090585419855896], [0.6156748621027786, 0.7670553751460374, 0.3920726576509954, 0.2975369110799824, 1.3764883219855897], [0.4447523221027786, 1.3659530048539625, 1.4060897483490047, 1.3166420092300175, 0.22085769801441038], [1.7733756338972213, 0.7207141748539625, 0.5265883203490045, 1.2266208092300175, 1.5635187480144104], [0.7531545751027786, 0.6144769751460374, 1.2892756316509955, 0.6678637397699825, 0.006687098014410364], [1.1577111311027786, 0.3269332951460374, 0.20631363534900454, 0.8797811007699824, 2.2645673019855894], [2.221255043897221, 1.3072556348539626, 1.9199514083490048, 1.1617827792300175, 1.2001841819855896], [10.240730616102779, 21.586882864853962, 4.754065688349004, 27.965184110769982, 14.60135588198559], [13.865974983897221, 13.022320985146036, 21.418116601650997, 11.339806010769982, 12.442866568014411], [26.45330841610278, 2.6489674948539625, 15.565902101650996, 4.337310249230018, 12.67689717801441], [19.471712983897223, 41.089800284853965, 20.928728501650994, 11.560479889230018, 35.933205058014416], [15.314295283897222, 6.976872604853963, 4.146142071650996, 21.772359110769983, 4.353162961985589], [11.925562416102778, 23.057462415146038, 18.876289401650997, 1.8489317707699824, 16.25605703801441], [19.347901316102778, 6.886526394853963, 6.953025648349004, 2.5960758592300177, 4.81379509198559], [5.846717313897221, 20.69496180514604, 18.646151798349006, 16.012992410769982, 47.04729562198559], [4.757684883897221, 14.325919775146037, 7.278958098349005, 5.585193409230017, 11.49853742198559]], 'feat_anom_flags': 1, 'mahalanobis_dist_time': [2.454914295945614, 2.880720383046701, 1.8683726307513973, 1.7003078998239625, 2.588953776104935, 2.5652328309545385, 1.8620427172427378, 3.1225946425503817, 1.5547693581257884, 2.1643762278372844, 2.417269080113517, 2.262181130097954, 2.6130825689461417, 1.7059006163299495, 2.5434421962731357, 1.6719639488178777, 2.3436175837980597, 2.21840685471762, 2.2979551899195805, 2.6929577802250764, 2.9664479867733977, 67.55817452276169, 49.40605166020638, 56.18272131366201, 106.81902608375769, 56.885898855200786, 67.51142221220091, 34.835034612447735, 83.13379306723152, 32.89765068245757]}, {'time_anom_flags': 1, 'X_time_abs_recon_err': [[0.32900218089722144, 0.3666501048539626, 0.36635876834900455, 0.5048294552300175, 0.13074807998558963], [2.189621633897221, 1.6205222148539626, 1.4589328283490046, 1.6573511592300176, 1.4165915819855897], [1.2152825901027786, 0.15706101485396257, 0.13890107834900456, 0.48943170223001753, 0.7135484419855898], [0.3322234327027786, 1.4670199351460373, 0.7490532216509954, 1.0396742557699823, 1.1108101500144103], [2.048185563897221, 0.03526117514603738, 0.5783679683490046, 0.2125351652300176, 1.4687681780144104], [0.030777201102778595, 1.7929891248539627, 1.1489520683490047, 1.5678597892300175, 1.6771137519855899], [0.9650461621027786, 0.5691300851460374, 0.08094884834900457, 0.012575909230017557, 2.2080460719855894], [1.5639807438972215, 1.1980628251460375, 1.2069420616509954, 1.3901163607699825, 0.3874249679144104], [0.5580582108972214, 0.5184502748539626, 0.5239316383490045, 0.6441129142300176, 1.3956508080144103], [0.8350907261027786, 1.7781877148539627, 0.7296820783490046, 1.6317259792300176, 0.29427221441441037], [1.2929881538972214, 0.4627270451460374, 0.7246820716509954, 0.5484520217699824, 1.9379923919855895], [0.7639809938972215, 0.6759561451460374, 0.6773298116509954, 0.6907830157699825, 0.5532967379855895], [1.4341005461027785, 1.2120874248539626, 1.6493024183490046, 1.1247558092300176, 1.8324026080144102], [0.6821208898972214, 0.9936278448539626, 1.3337549183490047, 1.1213083792300176, 0.8664713090144103], [1.4939841438972215, 0.5341033651460374, 0.6086089116509954, 0.5171105577699824, 0.8830734419855897], [1.4509782661027786, 0.9637210251460373, 0.15825667165099544, 0.45770868676998244, 1.6355594919855896], [0.2275823865027786, 1.0996055448539626, 1.8218077383490046, 0.8339915792300177, 0.3675677480144104], [2.2745019838972214, 1.4854781548539626, 0.9937050683490045, 1.1622289592300175, 1.4756046680144104], [0.9129310671027786, 1.3611347151460373, 1.0394445416509954, 0.29974552735998244, 0.13740395301441038], [1.1370623851027786, 0.8264817651460374, 0.4148785783490046, 0.5567234177699825, 1.6322849419855896], [1.4163019238972214, 1.6799346248539626, 1.8310565283490046, 0.9113971192300176, 0.8533529819855896], [0.6447780858972214, 10.458295434853962, 3.5236027816509954, 10.649492210769981, 18.786049118014407], [11.412422083897221, 21.96333277514604, 12.360166121650996, 1.9987194907699823, 4.909640448014411], [19.761521016102776, 8.388265845146037, 9.339310008349004, 5.645467959230018, 25.41656808198559], [16.230861883897223, 14.430544595146037, 15.710390401650995, 15.203689189230017, 18.208899718014408], [13.43345588389722, 7.701752314853962, 1.8128148783490048, 15.629906010769982, 5.311242451985589], [20.385299383897223, 5.155869085146037, 18.454434408349005, 5.230667130769982, 19.87278198198559], [25.027596783897224, 1.4829656048539626, 27.502453938349003, 1.1804148317699825, 15.499414018014411], [18.404901516102775, 39.53942034514604, 35.66978705834901, 39.40692838923002, 26.46919368198559], [10.47667408389722, 11.309417205146037, 8.163866911650995, 18.887825210769982, 15.41742541801441]], 'mahalanobis_dist_feat': [163.56374332649955, 165.45739988086166, 183.57477051741975, 164.88442652856344, 174.8675114349201], 'X_feat_abs_recon_err': [[0.32900218089722144, 0.3666501048539626, 0.36635876834900455, 0.5048294552300175, 0.13074807998558963], [2.189621633897221, 1.6205222148539626, 1.4589328283490046, 1.6573511592300176, 1.4165915819855897], [1.2152825901027786, 0.15706101485396257, 0.13890107834900456, 0.48943170223001753, 0.7135484419855898], [0.3322234327027786, 1.4670199351460373, 0.7490532216509954, 1.0396742557699823, 1.1108101500144103], [2.048185563897221, 0.03526117514603738, 0.5783679683490046, 0.2125351652300176, 1.4687681780144104], [0.030777201102778595, 1.7929891248539627, 1.1489520683490047, 1.5678597892300175, 1.6771137519855899], [0.9650461621027786, 0.5691300851460374, 0.08094884834900457, 0.012575909230017557, 2.2080460719855894], [1.5639807438972215, 1.1980628251460375, 1.2069420616509954, 1.3901163607699825, 0.3874249679144104], [0.5580582108972214, 0.5184502748539626, 0.5239316383490045, 0.6441129142300176, 1.3956508080144103], [0.8350907261027786, 1.7781877148539627, 0.7296820783490046, 1.6317259792300176, 0.29427221441441037], [1.2929881538972214, 0.4627270451460374, 0.7246820716509954, 0.5484520217699824, 1.9379923919855895], [0.7639809938972215, 0.6759561451460374, 0.6773298116509954, 0.6907830157699825, 0.5532967379855895], [1.4341005461027785, 1.2120874248539626, 1.6493024183490046, 1.1247558092300176, 1.8324026080144102], [0.6821208898972214, 0.9936278448539626, 1.3337549183490047, 1.1213083792300176, 0.8664713090144103], [1.4939841438972215, 0.5341033651460374, 0.6086089116509954, 0.5171105577699824, 0.8830734419855897], [1.4509782661027786, 0.9637210251460373, 0.15825667165099544, 0.45770868676998244, 1.6355594919855896], [0.2275823865027786, 1.0996055448539626, 1.8218077383490046, 0.8339915792300177, 0.3675677480144104], [2.2745019838972214, 1.4854781548539626, 0.9937050683490045, 1.1622289592300175, 1.4756046680144104], [0.9129310671027786, 1.3611347151460373, 1.0394445416509954, 0.29974552735998244, 0.13740395301441038], [1.1370623851027786, 0.8264817651460374, 0.4148785783490046, 0.5567234177699825, 1.6322849419855896], [1.4163019238972214, 1.6799346248539626, 1.8310565283490046, 0.9113971192300176, 0.8533529819855896], [0.6447780858972214, 10.458295434853962, 3.5236027816509954, 10.649492210769981, 18.786049118014407], [11.412422083897221, 21.96333277514604, 12.360166121650996, 1.9987194907699823, 4.909640448014411], [19.761521016102776, 8.388265845146037, 9.339310008349004, 5.645467959230018, 25.41656808198559], [16.230861883897223, 14.430544595146037, 15.710390401650995, 15.203689189230017, 18.208899718014408], [13.43345588389722, 7.701752314853962, 1.8128148783490048, 15.629906010769982, 5.311242451985589], [20.385299383897223, 5.155869085146037, 18.454434408349005, 5.230667130769982, 19.87278198198559], [25.027596783897224, 1.4829656048539626, 27.502453938349003, 1.1804148317699825, 15.499414018014411], [18.404901516102775, 39.53942034514604, 35.66978705834901, 39.40692838923002, 26.46919368198559], [10.47667408389722, 11.309417205146037, 8.163866911650995, 18.887825210769982, 15.41742541801441]], 'feat_anom_flags': 1, 'mahalanobis_dist_time': [2.1928333852699398, 2.761852410077478, 1.9109679281033871, 1.9489879208309275, 2.7219224352965443, 2.765620600656895, 2.8335219101816493, 2.1053017595400227, 1.2373381869648636, 3.0894254809100814, 1.7645842680405865, 1.0736496744598496, 2.0874772755498263, 1.3905000295637349, 1.2201356674463542, 2.1737742710085146, 2.92913939963439, 2.5298977372169706, 3.046140706098121, 1.3239848977024653, 2.7358299345212234, 34.759928823909696, 57.761901705780815, 51.630574692567265, 49.94366856001436, 41.59273700123233, 57.042726394999725, 77.69759038577588, 104.10173722144998, 46.4624197491941]}]}\n"
     ]
    }
   ],
   "source": [
    "# Send instance dictionary to receive response from ML-Engine for online prediction\n",
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import json\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "api = discovery.build(\"ml\", \"v1\", credentials = credentials)\n",
    "\n",
    "request_data = {\"instances\": instances}\n",
    "\n",
    "parent = \"projects/%s/models/%s/versions/%s\" % (PROJECT, \"anomaly_detection\", \"v1\")\n",
    "response = api.projects().predict(body = request_data, name = parent).execute()\n",
    "print(\"response = {}\".format(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
