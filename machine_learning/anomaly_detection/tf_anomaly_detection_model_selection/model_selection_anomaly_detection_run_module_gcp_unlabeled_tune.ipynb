{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model module on GCP with unlabeled threshold tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = \"PROJECT\" # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = \"BUCKET\" # REPLACE WITH A BUCKET NAME\n",
    "REGION = \"us-central1\" # REPLACE WITH YOUR REGION e.g. us-central1\n",
    "\n",
    "# Import os environment variables\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] =  BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"TFVERSION\"] = \"1.13\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy data over to bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil -m cp -r data/* gs://$BUCKET/anomaly_detection/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os environment variables for global sequence shape hyperparameters\n",
    "os.environ[\"SEQ_LEN\"] = str(30)\n",
    "os.environ[\"NUM_FEAT\"] = str(5)\n",
    "\n",
    "# Import os environment variables for global training hyperparameters\n",
    "os.environ[\"START_DELAY_SECS\"] = str(60)\n",
    "os.environ[\"THROTTLE_SECS\"] = str(120)\n",
    "\n",
    "# Import os environment variables for global threshold hyperparameters\n",
    "os.environ[\"LABELED_TUNE_THRESH\"] = \"False\"\n",
    "\n",
    "# Import global dense hyperparameters\n",
    "os.environ[\"ENC_DNN_HIDDEN_UNITS\"] = \"64,32,16\"\n",
    "os.environ[\"LATENT_VECTOR_SIZE\"] = str(8)\n",
    "os.environ[\"DEC_DNN_HIDDEN_UNITS\"] = \"16,32,64\"\n",
    "os.environ[\"TIME_LOSS_WEIGHT\"] = str(1.0)\n",
    "os.environ[\"FEAT_LOSS_WEIGHT\"] = str(1.0)\n",
    "\n",
    "# Import global lstm hyperparameters\n",
    "os.environ[\"REVERSE_LABELS_SEQUENCE\"] = \"True\"\n",
    "os.environ[\"ENC_LSTM_HIDDEN_UNITS\"] = \"64,32,16\"\n",
    "os.environ[\"DEC_LSTM_HIDDEN_UNITS\"] = \"16,32,64\"\n",
    "os.environ[\"LSTM_DROPOUT_OUTPUT_KEEP_PROBS\"] = \"0.9,0.95,1.0\"\n",
    "os.environ[\"DNN_HIDDEN_UNITS\"] = \"1024,256,64\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train reconstruction variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os environment variables for reconstruction training hyperparameters\n",
    "os.environ[\"TRAIN_FILE_PATTERN\"] = \"gs://{}/anomaly_detection/data/train_norm_seq.csv\".format(BUCKET)\n",
    "os.environ[\"EVAL_FILE_PATTERN\"] = \"gs://{}/anomaly_detection/data/val_norm_1_seq.csv\".format(BUCKET)\n",
    "os.environ[\"PREVIOUS_TRAIN_STEPS\"] = str(0)\n",
    "os.environ[\"RECONSTRUCTION_EPOCHS\"] = str(1.0)\n",
    "os.environ[\"TRAIN_EXAMPLES\"] = str(64000)\n",
    "os.environ[\"LEARNING_RATE\"] = str(0.1)\n",
    "os.environ[\"TRAINING_MODE\"] = \"reconstruction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/anomaly_detection/trained_model/dense_unlabeled\n",
    "JOBNAME=job_anomaly_detection_reconstruction_dense_unlabeled_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$PWD/anomaly_detection_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=1.13 \\\n",
    "  -- \\\n",
    "  --train_file_pattern=$TRAIN_FILE_PATTERN \\\n",
    "  --eval_file_pattern=$EVAL_FILE_PATTERN \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --job-dir=./tmp \\\n",
    "  --seq_len=$SEQ_LEN \\\n",
    "  --num_feat=$NUM_FEAT \\\n",
    "  --train_batch_size=32 \\\n",
    "  --eval_batch_size=32 \\\n",
    "  --previous_train_steps=$PREVIOUS_TRAIN_STEPS \\\n",
    "  --reconstruction_epochs=$RECONSTRUCTION_EPOCHS \\\n",
    "  --train_examples=$TRAIN_EXAMPLES \\\n",
    "  --learning_rate=$LEARNING_RATE \\\n",
    "  --start_delay_secs=$START_DELAY_SECS \\\n",
    "  --throttle_secs=$THROTTLE_SECS \\\n",
    "  --model_type=\"dense_autoencoder\" \\\n",
    "  --enc_dnn_hidden_units=$ENC_DNN_HIDDEN_UNITS \\\n",
    "  --latent_vector_size=$LATENT_VECTOR_SIZE \\\n",
    "  --dec_dnn_hidden_units=$DEC_DNN_HIDDEN_UNITS \\\n",
    "  --time_loss_weight=$TIME_LOSS_WEIGHT \\\n",
    "  --feat_loss_weight=$FEAT_LOSS_WEIGHT \\\n",
    "  --training_mode=$TRAINING_MODE \\\n",
    "  --labeled_tune_thresh=$LABELED_TUNE_THRESH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/anomaly_detection/trained_model/lstm_unlabeled\n",
    "JOBNAME=job_anomaly_detection_reconstruction_lstm_unlabeled_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$PWD/anomaly_detection_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=1.13 \\\n",
    "  -- \\\n",
    "  --train_file_pattern=$TRAIN_FILE_PATTERN \\\n",
    "  --eval_file_pattern=$EVAL_FILE_PATTERN \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --job-dir=./tmp \\\n",
    "  --seq_len=$SEQ_LEN \\\n",
    "  --num_feat=$NUM_FEAT \\\n",
    "  --train_batch_size=32 \\\n",
    "  --eval_batch_size=32 \\\n",
    "  --previous_train_steps=$PREVIOUS_TRAIN_STEPS \\\n",
    "  --reconstruction_epochs=$RECONSTRUCTION_EPOCHS \\\n",
    "  --train_examples=$TRAIN_EXAMPLES \\\n",
    "  --learning_rate=$LEARNING_RATE \\\n",
    "  --start_delay_secs=$START_DELAY_SECS \\\n",
    "  --throttle_secs=$THROTTLE_SECS \\\n",
    "  --model_type=\"lstm_enc_dec_autoencoder\" \\\n",
    "  --reverse_labels_sequence=$REVERSE_LABELS_SEQUENCE \\\n",
    "  --enc_lstm_hidden_units=$ENC_LSTM_HIDDEN_UNITS \\\n",
    "  --dec_lstm_hidden_units=$DEC_LSTM_HIDDEN_UNITS \\\n",
    "  --lstm_dropout_output_keep_probs=$LSTM_DROPOUT_OUTPUT_KEEP_PROBS \\\n",
    "  --dnn_hidden_units=$DNN_HIDDEN_UNITS \\\n",
    "  --training_mode=$TRAINING_MODE \\\n",
    "  --labeled_tune_thresh=$LABELED_TUNE_THRESH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/anomaly_detection/trained_model/pca_unlabeled\n",
    "JOBNAME=job_anomaly_detection_reconstruction_pca_unlabeled_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$PWD/anomaly_detection_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=1.13 \\\n",
    "  -- \\\n",
    "  --train_file_pattern=$TRAIN_FILE_PATTERN \\\n",
    "  --eval_file_pattern=$EVAL_FILE_PATTERN \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --job-dir=./tmp \\\n",
    "  --seq_len=$SEQ_LEN \\\n",
    "  --num_feat=$NUM_FEAT \\\n",
    "  --train_batch_size=32 \\\n",
    "  --eval_batch_size=32 \\\n",
    "  --previous_train_steps=$PREVIOUS_TRAIN_STEPS \\\n",
    "  --reconstruction_epochs=1.0 \\\n",
    "  --train_examples=$TRAIN_EXAMPLES \\\n",
    "  --eval_examples=6400 \\\n",
    "  --start_delay_secs=$START_DELAY_SECS \\\n",
    "  --throttle_secs=$THROTTLE_SECS \\\n",
    "  --model_type=\"pca\" \\\n",
    "  --training_mode=$TRAINING_MODE \\\n",
    "  --labeled_tune_thresh=$LABELED_TUNE_THRESH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning of reconstruction hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile hyperparam_reconstruction_dense.yaml\n",
    "trainingInput:\n",
    "  scaleTier: STANDARD_1\n",
    "  hyperparameters:\n",
    "    hyperparameterMetricTag: rmse\n",
    "    goal: MINIMIZE\n",
    "    maxTrials: 30\n",
    "    maxParallelTrials: 1\n",
    "    params:\n",
    "    - parameterName: enc_dnn_hidden_units\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: [\"64 32 16\", \"256 128 16\", \"64 64 64\"]\n",
    "    - parameterName: latent_vector_size\n",
    "      type: INTEGER\n",
    "      minValue: 8\n",
    "      maxValue: 16\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: dec_dnn_hidden_units\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: [\"16 32 64\", \"16 128 256\", \"64 64 64\"]\n",
    "    - parameterName: train_batch_size\n",
    "      type: INTEGER\n",
    "      minValue: 8\n",
    "      maxValue: 512\n",
    "      scaleType: UNIT_LOG_SCALE\n",
    "    - parameterName: learning_rate\n",
    "      type: DOUBLE\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.1\n",
    "      scaleType: UNIT_LINEAR_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/anomaly_detection/hyperparam_reconstruction_dense_unlabeled\n",
    "JOBNAME=job_anomaly_detection_hyperparam_reconstruction_dense_unlabeled_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$PWD/anomaly_detection_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --config=hyperparam_reconstruction_dense.yaml \\\n",
    "  --runtime-version=1.13 \\\n",
    "  -- \\\n",
    "  --train_file_pattern=gs://$BUCKET/anomaly_detection/data/train_norm_seq.csv \\\n",
    "  --eval_file_pattern=gs://$BUCKET/anomaly_detection/data/val_norm_1_seq.csv \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --seq_len=30 \\\n",
    "  --num_feat=5 \\\n",
    "  --train_batch_size=32 \\\n",
    "  --eval_batch_size=32 \\\n",
    "  --previous_train_steps=0 \\\n",
    "  --reconstruction_epochs=1.0 \\\n",
    "  --train_examples=64000 \\\n",
    "  --start_delay_secs=60 \\\n",
    "  --throttle_secs=120 \\\n",
    "  --training_mode=\"reconstruction\" \\\n",
    "  --labeled_tune_thresh=True \\\n",
    "  --num_time_anom_thresh=300 \\\n",
    "  --num_feat_anom_thresh=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile hyperparam_reconstruction_lstm.yaml\n",
    "trainingInput:\n",
    "  scaleTier: STANDARD_1\n",
    "  hyperparameters:\n",
    "    hyperparameterMetricTag: rmse\n",
    "    goal: MINIMIZE\n",
    "    maxTrials: 30\n",
    "    maxParallelTrials: 1\n",
    "    params:\n",
    "    - parameterName: enc_lstm_hidden_units\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: [\"64 32 16\", \"256 128 16\", \"64 64 64\"]\n",
    "    - parameterName: dec_lstm_hidden_units\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: [\"16 32 64\", \"16 128 256\", \"64 64 64\"]\n",
    "    - parameterName: lstm_dropout_output_keep_probs\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: [\"0.9 1.0 1.0\", \"0.95 0.95 1.0\", \"0.95 0.95 0.95\"]\n",
    "    - parameterName: dnn_hidden_units\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: [\"256 128 64\", \"256 128 16\", \"64 64 64\"]\n",
    "    - parameterName: train_batch_size\n",
    "      type: INTEGER\n",
    "      minValue: 8\n",
    "      maxValue: 512\n",
    "      scaleType: UNIT_LOG_SCALE\n",
    "    - parameterName: learning_rate\n",
    "      type: DOUBLE\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.1\n",
    "      scaleType: UNIT_LINEAR_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/anomaly_detection/hyperparam_reconstruction_lstm_unlabeled\n",
    "JOBNAME=job_anomaly_detection_hyperparam_reconstruction_lstm_unlabeled_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$PWD/anomaly_detection_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --config=hyperparam_reconstruction_lstm.yaml \\\n",
    "  --runtime-version=1.13 \\\n",
    "  -- \\\n",
    "  --train_file_pattern=gs://$BUCKET/anomaly_detection/data/train_norm_seq.csv \\\n",
    "  --eval_file_pattern=gs://$BUCKET/anomaly_detection/data/val_norm_1_seq.csv \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --seq_len=30 \\\n",
    "  --num_feat=5 \\\n",
    "  --train_batch_size=32 \\\n",
    "  --eval_batch_size=32 \\\n",
    "  --previous_train_steps=0 \\\n",
    "  --reconstruction_epochs=1.0 \\\n",
    "  --train_examples=64000 \\\n",
    "  --start_delay_secs=60 \\\n",
    "  --throttle_secs=120 \\\n",
    "  --training_mode=\"reconstruction\" \\\n",
    "  --labeled_tune_thresh=True \\\n",
    "  --num_time_anom_thresh=300 \\\n",
    "  --num_feat_anom_thresh=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile hyperparam_reconstruction_pca.yaml\n",
    "trainingInput:\n",
    "  scaleTier: STANDARD_1\n",
    "  hyperparameters:\n",
    "    hyperparameterMetricTag: rmse\n",
    "    goal: MINIMIZE\n",
    "    maxTrials: 30\n",
    "    maxParallelTrials: 1\n",
    "    params:\n",
    "    - parameterName: k_principal_components_time\n",
    "      type: INTEGER\n",
    "      minValue: 2\n",
    "      maxValue: 10\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: k_principal_components_feat\n",
    "      type: INTEGER\n",
    "      minValue: 2\n",
    "      maxValue: 10\n",
    "      scaleType: UNIT_LINEAR_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/anomaly_detection/hyperparam_reconstruction_pca_unlabeled\n",
    "JOBNAME=job_anomaly_detection_hyperparam_reconstruction_pca_unlabeled_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$PWD/anomaly_detection_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --config=hyperparam_reconstruction_pca.yaml \\\n",
    "  --runtime-version=1.13 \\\n",
    "  -- \\\n",
    "  --train_file_pattern=gs://$BUCKET/anomaly_detection/data/train_norm_seq.csv \\\n",
    "  --eval_file_pattern=gs://$BUCKET/anomaly_detection/data/val_norm_1_seq.csv \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --seq_len=30 \\\n",
    "  --num_feat=5 \\\n",
    "  --train_batch_size=32 \\\n",
    "  --eval_batch_size=32 \\\n",
    "  --previous_train_steps=0 \\\n",
    "  --reconstruction_epochs=1.0 \\\n",
    "  --train_examples=64000 \\\n",
    "  --eval_examples=6400 \\\n",
    "  --start_delay_secs=60 \\\n",
    "  --throttle_secs=120 \\\n",
    "  --training_mode=\"reconstruction\" \\\n",
    "  --labeled_tune_thresh=True \\\n",
    "  --num_time_anom_thresh=300 \\\n",
    "  --num_feat_anom_thresh=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train error distribution variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os environment variables for error dist training hyperparameters\n",
    "os.environ[\"TRAIN_FILE_PATTERN\"] = \"gs://{}/anomaly_detection/data/val_norm_1_seq.csv\".format(BUCKET)\n",
    "os.environ[\"EVAL_FILE_PATTERN\"] = \"gs://{}/anomaly_detection/data/val_norm_1_seq.csv\".format(BUCKET)\n",
    "os.environ[\"PREVIOUS_TRAIN_STEPS\"] = str(2000)\n",
    "os.environ[\"TRAIN_EXAMPLES\"] = str(6400)\n",
    "os.environ[\"TRAINING_MODE\"] = \"calculate_error_distribution_statistics\"\n",
    "os.environ[\"EPS\"] = \"1e-12\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/anomaly_detection/trained_model/dense_unlabeled\n",
    "JOBNAME=job_anomaly_detection_calculate_error_distribution_statistics_dense_unlabeled_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$PWD/anomaly_detection_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=1.13 \\\n",
    "  -- \\\n",
    "  --train_file_pattern=$TRAIN_FILE_PATTERN \\\n",
    "  --eval_file_pattern=$EVAL_FILE_PATTERN \\\n",
    "  --output_dir=$PWD/trained_model/dense_unlabeled \\\n",
    "  --job-dir=./tmp \\\n",
    "  --seq_len=$SEQ_LEN \\\n",
    "  --num_feat=$NUM_FEAT \\\n",
    "  --train_batch_size=32 \\\n",
    "  --eval_batch_size=32 \\\n",
    "  --previous_train_steps=$PREVIOUS_TRAIN_STEPS \\\n",
    "  --train_examples=$TRAIN_EXAMPLES \\\n",
    "  --start_delay_secs=$START_DELAY_SECS \\\n",
    "  --throttle_secs=$THROTTLE_SECS \\\n",
    "  --model_type=\"dense_autoencoder\" \\\n",
    "  --enc_dnn_hidden_units=$ENC_DNN_HIDDEN_UNITS \\\n",
    "  --latent_vector_size=$LATENT_VECTOR_SIZE \\\n",
    "  --dec_dnn_hidden_units=$DEC_DNN_HIDDEN_UNITS \\\n",
    "  --time_loss_weight=$TIME_LOSS_WEIGHT \\\n",
    "  --feat_loss_weight=$FEAT_LOSS_WEIGHT \\\n",
    "  --training_mode=$TRAINING_MODE \\\n",
    "  --labeled_tune_thresh=$LABELED_TUNE_THRESH \\\n",
    "  --eps=$EPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/anomaly_detection/trained_model/lstm_unlabeled\n",
    "JOBNAME=job_anomaly_detection_calculate_error_distribution_statistics_lstm_unlabeled_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$PWD/anomaly_detection_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=1.13 \\\n",
    "  -- \\\n",
    "  --train_file_pattern=$TRAIN_FILE_PATTERN \\\n",
    "  --eval_file_pattern=$EVAL_FILE_PATTERN \\\n",
    "  --output_dir=$PWD/trained_model/lstm_unlabeled \\\n",
    "  --job-dir=./tmp \\\n",
    "  --seq_len=$SEQ_LEN \\\n",
    "  --num_feat=$NUM_FEAT \\\n",
    "  --train_batch_size=32 \\\n",
    "  --eval_batch_size=32 \\\n",
    "  --previous_train_steps=$PREVIOUS_TRAIN_STEPS \\\n",
    "  --train_examples=$TRAIN_EXAMPLES \\\n",
    "  --start_delay_secs=$START_DELAY_SECS \\\n",
    "  --throttle_secs=$THROTTLE_SECS \\\n",
    "  --model_type=\"lstm_enc_dec_autoencoder\" \\\n",
    "  --reverse_labels_sequence=$REVERSE_LABELS_SEQUENCE \\\n",
    "  --enc_lstm_hidden_units=$ENC_LSTM_HIDDEN_UNITS \\\n",
    "  --dec_lstm_hidden_units=$DEC_LSTM_HIDDEN_UNITS \\\n",
    "  --lstm_dropout_output_keep_probs=$LSTM_DROPOUT_OUTPUT_KEEP_PROBS \\\n",
    "  --dnn_hidden_units=$DNN_HIDDEN_UNITS \\\n",
    "  --training_mode=$TRAINING_MODE \\\n",
    "  --labeled_tune_thresh=$LABELED_TUNE_THRESH \\\n",
    "  --eps=$EPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/anomaly_detection/trained_model/pca_unlabeled\n",
    "JOBNAME=job_anomaly_detection_calculate_error_distribution_statistics_pca_unlabeled_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$PWD/anomaly_detection_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=1.13 \\\n",
    "  -- \\\n",
    "  --train_file_pattern=$TRAIN_FILE_PATTERN \\\n",
    "  --eval_file_pattern=$EVAL_FILE_PATTERN \\\n",
    "  --output_dir=$PWD/trained_model/pca_unlabeled \\\n",
    "  --job-dir=./tmp \\\n",
    "  --seq_len=$SEQ_LEN \\\n",
    "  --num_feat=$NUM_FEAT \\\n",
    "  --train_batch_size=32 \\\n",
    "  --eval_batch_size=32 \\\n",
    "  --previous_train_steps=2200 \\\n",
    "  --train_examples=$TRAIN_EXAMPLES \\\n",
    "  --start_delay_secs=$START_DELAY_SECS \\\n",
    "  --throttle_secs=$THROTTLE_SECS \\\n",
    "  --model_type=\"pca\" \\\n",
    "  --training_mode=$TRAINING_MODE \\\n",
    "  --labeled_tune_thresh=$LABELED_TUNE_THRESH \\\n",
    "  --eps=$EPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune anomaly thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os environment variables for tune threshold training hyperparameters\n",
    "os.environ[\"PREVIOUS_TRAIN_STEPS\"] = str(2200)\n",
    "os.environ[\"TRAIN_EXAMPLES\"] = str(12800)\n",
    "os.environ[\"TRAINING_MODE\"] = \"tune_anomaly_thresholds\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os environment variables for unlabeled tune threshold training hyperparameters\n",
    "os.environ[\"TRAIN_FILE_PATTERN\"] = \"gs://{}/anomaly_detection/data/unlabeled_val_mixed_seq.csv\".format(BUCKET)\n",
    "os.environ[\"EVAL_FILE_PATTERN\"] = \"gs://{}/anomaly_detection/data/unlabeled_val_mixed_seq.csv\".format(BUCKET)\n",
    "os.environ[\"TIME_THRESH_SCL\"] = str(2.0)\n",
    "os.environ[\"FEAT_THRESH_SCL\"] = str(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/anomaly_detection/trained_model/dense_unlabeled\n",
    "JOBNAME=job_anomaly_detection_tune_anomaly_thresholds_dense_unlabeled_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$PWD/anomaly_detection_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=1.13 \\\n",
    "  -- \\\n",
    "  --train_file_pattern=$TRAIN_FILE_PATTERN \\\n",
    "  --eval_file_pattern=$EVAL_FILE_PATTERN \\\n",
    "  --output_dir=$PWD/trained_model/dense_unlabeled \\\n",
    "  --job-dir=./tmp \\\n",
    "  --seq_len=$SEQ_LEN \\\n",
    "  --num_feat=$NUM_FEAT \\\n",
    "  --train_batch_size=32 \\\n",
    "  --eval_batch_size=32 \\\n",
    "  --previous_train_steps=$PREVIOUS_TRAIN_STEPS \\\n",
    "  --train_examples=$TRAIN_EXAMPLES \\\n",
    "  --start_delay_secs=$START_DELAY_SECS \\\n",
    "  --throttle_secs=$THROTTLE_SECS \\\n",
    "  --model_type=\"dense_autoencoder\" \\\n",
    "  --enc_dnn_hidden_units=$ENC_DNN_HIDDEN_UNITS \\\n",
    "  --latent_vector_size=$LATENT_VECTOR_SIZE \\\n",
    "  --dec_dnn_hidden_units=$DEC_DNN_HIDDEN_UNITS \\\n",
    "  --time_loss_weight=$TIME_LOSS_WEIGHT \\\n",
    "  --feat_loss_weight=$FEAT_LOSS_WEIGHT \\\n",
    "  --training_mode=$TRAINING_MODE \\\n",
    "  --labeled_tune_thresh=$LABELED_TUNE_THRESH \\\n",
    "  --time_thresh_scl=$TIME_THRESH_SCL \\\n",
    "  --feat_thresh_scl=$FEAT_THRESH_SCL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/anomaly_detection/trained_model/lstm_unlabeled\n",
    "JOBNAME=job_anomaly_detection_tune_anomaly_thresholds_lstm_unlabeled_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$PWD/anomaly_detection_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=1.13 \\\n",
    "  -- \\\n",
    "  --train_file_pattern=$TRAIN_FILE_PATTERN \\\n",
    "  --eval_file_pattern=$EVAL_FILE_PATTERN \\\n",
    "  --output_dir=$PWD/trained_model/lstm_unlabeled \\\n",
    "  --job-dir=./tmp \\\n",
    "  --seq_len=$SEQ_LEN \\\n",
    "  --num_feat=$NUM_FEAT \\\n",
    "  --train_batch_size=32 \\\n",
    "  --eval_batch_size=32 \\\n",
    "  --previous_train_steps=$PREVIOUS_TRAIN_STEPS \\\n",
    "  --train_examples=$TRAIN_EXAMPLES \\\n",
    "  --start_delay_secs=$START_DELAY_SECS \\\n",
    "  --throttle_secs=$THROTTLE_SECS \\\n",
    "  --model_type=\"lstm_enc_dec_autoencoder\" \\\n",
    "  --reverse_labels_sequence=$REVERSE_LABELS_SEQUENCE \\\n",
    "  --enc_lstm_hidden_units=$ENC_LSTM_HIDDEN_UNITS \\\n",
    "  --dec_lstm_hidden_units=$DEC_LSTM_HIDDEN_UNITS \\\n",
    "  --lstm_dropout_output_keep_probs=$LSTM_DROPOUT_OUTPUT_KEEP_PROBS \\\n",
    "  --dnn_hidden_units=$DNN_HIDDEN_UNITS \\\n",
    "  --training_mode=$TRAINING_MODE \\\n",
    "  --labeled_tune_thresh=$LABELED_TUNE_THRESH \\\n",
    "  --time_thresh_scl=$TIME_THRESH_SCL \\\n",
    "  --feat_thresh_scl=$FEAT_THRESH_SCL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/anomaly_detection/trained_model/pca_unlabeled\n",
    "JOBNAME=job_anomaly_detection_tune_anomaly_thresholds_pca_unlabeled_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$PWD/anomaly_detection_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=1.13 \\\n",
    "  -- \\\n",
    "  --train_file_pattern=$TRAIN_FILE_PATTERN \\\n",
    "  --eval_file_pattern=$EVAL_FILE_PATTERN \\\n",
    "  --output_dir=$PWD/trained_model/pca_unlabeled \\\n",
    "  --job-dir=./tmp \\\n",
    "  --seq_len=$SEQ_LEN \\\n",
    "  --num_feat=$NUM_FEAT \\\n",
    "  --train_batch_size=32 \\\n",
    "  --eval_batch_size=32 \\\n",
    "  --previous_train_steps=2400 \\\n",
    "  --train_examples=$TRAIN_EXAMPLES \\\n",
    "  --start_delay_secs=$START_DELAY_SECS \\\n",
    "  --throttle_secs=$THROTTLE_SECS \\\n",
    "  --model_type=\"pca\" \\\n",
    "  --training_mode=$TRAINING_MODE \\\n",
    "  --labeled_tune_thresh=$LABELED_TUNE_THRESH \\\n",
    "  --time_thresh_scl=$TIME_THRESH_SCL \\\n",
    "  --feat_thresh_scl=$FEAT_THRESH_SCL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"anomaly_detection_dense_unlabeled\"\n",
    "MODEL_VERSION=\"v1\"\n",
    "MODEL_LOCATION=$(gsutil ls gs://$BUCKET/anomaly_detection/trained_model/dense_unlabeled/export/exporter/ | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models create $MODEL_NAME --regions $REGION\n",
    "gcloud ml-engine versions create $MODEL_VERSION --model $MODEL_NAME --origin $MODEL_LOCATION --runtime-version 1.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"anomaly_detection_lstm_unlabeled\"\n",
    "MODEL_VERSION=\"v1\"\n",
    "MODEL_LOCATION=$(gsutil ls gs://$BUCKET/anomaly_detection/trained_model/lstm_unlabeled/export/exporter/ | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models create $MODEL_NAME --regions $REGION\n",
    "gcloud ml-engine versions create $MODEL_VERSION --model $MODEL_NAME --origin $MODEL_LOCATION --runtime-version 1.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"anomaly_detection_pca_unlabeled\"\n",
    "MODEL_VERSION=\"v1\"\n",
    "MODEL_LOCATION=$(gsutil ls gs://$BUCKET/anomaly_detection/trained_model/pca_unlabeled/export/exporter/ | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models create $MODEL_NAME --regions $REGION\n",
    "gcloud ml-engine versions create $MODEL_VERSION --model $MODEL_NAME --origin $MODEL_LOCATION --runtime-version 1.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNLABELED_CSV_COLUMNS = [\"tag_{0}\".format(tag) for tag in range(0, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "unlabeled_test_mixed_sequences_array = np.loadtxt(\n",
    "    fname=\"data/unlabeled_test_mixed_seq.csv\", dtype=str, delimiter=\",\")\n",
    "print(\"unlabeled_test_mixed_sequences_array.shape = {}\".format(\n",
    "    unlabeled_test_mixed_sequences_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_prediction_instances = 10\n",
    "print(\"labels = {}\".format(\n",
    "  labeled_test_mixed_sequences_array[0:number_of_prediction_instances, -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCloud ML-Engine prediction from deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_normal_string_list = unlabeled_test_mixed_sequences_array.tolist()[0:number_of_prediction_instances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format dataframe to instances list to get sent to ML-Engine\n",
    "instances = [{UNLABELED_CSV_COLUMNS[i]: example[i]\n",
    "              for i in range(len(UNLABELED_CSV_COLUMNS))} \n",
    "             for example in unlabeled_test_mixed_sequences_array.tolist()[0:number_of_prediction_instances]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send instance dictionary to receive response from ML-Engine for online prediction\n",
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import json\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "api = discovery.build(\"ml\", \"v1\", credentials = credentials)\n",
    "\n",
    "request_data = {\"instances\": instances}\n",
    "\n",
    "parent = \"projects/%s/models/%s/versions/%s\" % (PROJECT, \"anomaly_detection_dense_unlabeled\", \"v1\")\n",
    "response = api.projects().predict(body = request_data, name = parent).execute()\n",
    "print(\"response = {}\".format(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send instance dictionary to receive response from ML-Engine for online prediction\n",
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import json\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "api = discovery.build(\"ml\", \"v1\", credentials = credentials)\n",
    "\n",
    "request_data = {\"instances\": instances}\n",
    "\n",
    "parent = \"projects/%s/models/%s/versions/%s\" % (PROJECT, \"anomaly_detection_lstm_unlabeled\", \"v1\")\n",
    "response = api.projects().predict(body = request_data, name = parent).execute()\n",
    "print(\"response = {}\".format(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send instance dictionary to receive response from ML-Engine for online prediction\n",
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import json\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "api = discovery.build(\"ml\", \"v1\", credentials = credentials)\n",
    "\n",
    "request_data = {\"instances\": instances}\n",
    "\n",
    "parent = \"projects/%s/models/%s/versions/%s\" % (PROJECT, \"anomaly_detection_pca_unlabeled\", \"v1\")\n",
    "response = api.projects().predict(body = request_data, name = parent).execute()\n",
    "print(\"response = {}\".format(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
